<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Econometrics and Free Software</title>
    <link>https://www.brodrigues.co/</link>
    <description>Recent content on Econometrics and Free Software</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Apr 2024 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://www.brodrigues.co/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Reproducible data science with Nix, part 11 -- build and cache binaries with Github Actions and Cachix</title>
      <link>https://www.brodrigues.co/blog/2024-04-04-nix_for_r_part_11/</link>
      <pubDate>Thu, 04 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2024-04-04-nix_for_r_part_11/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/own_cache.jpg&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;I have this package on CRAN called &lt;code&gt;{chronicler}&lt;/code&gt; and last month I got an email
from CRAN telling me that building the package was failing, and I had two weeks
to fix it.&lt;/p&gt;
&lt;p&gt;I immediately thought that some dependency that my package depends on got
updated, and somehow broke something. But when I checked the results of the
build, I was surprised, to say the least:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/chronicler_check_results.png&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;How come my package was only failing on Fedora? Now that was really weird. There
was no way this was right. Also, I couldn’t reproduce this bug on my local
machine… but I could reproduce it on Github Actions, on Ubuntu (but it was ok
on CRAN’s Debian which is really close to Ubuntu!), but couldn’t reproduce it
either on Windows! What was going on? So I started digging, and my first idea
was to look at the list of packages that got released on CRAN on that day (March
12th 2024) or just before, and saw something that caught my eye: a new version
of &lt;code&gt;{tidyselect}&lt;/code&gt; had just been released and even though my package doesn’t
directly depend on it, I knew that this package was likely a dependency of some
direct dependency of &lt;code&gt;{chronicler}&lt;/code&gt;. So I looked into the release notes, and
there it was:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;* `eval_select()` out-of-bounds errors now use the verb &amp;quot;select&amp;quot; rather than
  &amp;quot;subset&amp;quot; in the error message for consistency with `dplyr::select()` (#271).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I knew this was what I was looking for, because the unit test that was failing
to pass was a test that should error because &lt;code&gt;dplyr::select()&lt;/code&gt; was being used on
a column that didn’t exist. So the success of that test was defined as &lt;em&gt;finding
the following error message in the log&lt;/em&gt;, which contained the word &lt;em&gt;subset&lt;/em&gt; but
now it should be &lt;em&gt;select&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;But why was this failing only on Fedora on CRAN and on Ubuntu on Github Actions
(but ok on Debian on CRAN)? And why couldn’t I reproduce the bug on my OpenSuse
Linux computer, even though I was building a bleeding edge development
environment using Nix?&lt;/p&gt;
&lt;p&gt;And then it hit me like my older brother used to.&lt;/p&gt;
&lt;p&gt;When building packages, CRAN doesn’t seem to use pre-compiled binaries on
Fedora, so packages get built from source. This means that it takes longer to
test on Fedora, as packages have to be built from source, but it also means that
only the very latest releases of packages get used. On other platforms,
pre-compiled binaries get used if available, and because &lt;code&gt;{tidyselect}&lt;/code&gt; had just
come out that very day, older binaries of &lt;code&gt;{tidyselect}&lt;/code&gt; were being used on
these platforms, but not on Fedora. And because these older binaries didn’t
include this change, the unit test was still passing successfully on there.&lt;/p&gt;
&lt;p&gt;On Github Actions, code coverage was computed using &lt;code&gt;covr::codecov()&lt;/code&gt; which
installs the package in a temporary directory and seems to pull its dependencies
directly from CRAN. Because CRAN doesn’t offer Linux binaries packages got
compiled from source, hence why the test was failing there, as the very latest
version of &lt;code&gt;{tidyselect}&lt;/code&gt; was being used (btw, use Dirk Eddelbuettel’s
&lt;a href=&#34;https://github.com/eddelbuettel/r2u&#34;&gt;r2u&lt;/a&gt; if you binaries for Ubuntu).&lt;/p&gt;
&lt;p&gt;And on my local machine, even though I was using the latest commit of &lt;code&gt;nixpkgs&lt;/code&gt;
to have the most bleeding edge packages for my environment, I had forgotten that
the R packages on &lt;code&gt;nixpkgs&lt;/code&gt; always lag behind the CRAN releases.&lt;/p&gt;
&lt;p&gt;This is because R packages on &lt;code&gt;nixpkgs&lt;/code&gt; tend to get updated alongside a new
release of R, and the reason is to ensure a certain level of quality. You see,
the vast majority of CRAN (and Bioconductor) packages are made available through
&lt;code&gt;nixpkgs&lt;/code&gt; in a fully automated way. But some packages do require some manual
intervention to work on Nix. And we only know this if we try to build these
packages, but building packages requires quite a lot of resources. I go into
more detail
&lt;a href=&#34;https://www.brodrigues.co/blog/2024-02-29-nix_for_r_part_10/&#34;&gt;here&lt;/a&gt;, but in
summary we can’t build CRAN packages every single day to see if everything works
well, so we only rebuild the whole tree whenever there’s a new release of R.
Packages get built on a CI infrastructure called &lt;em&gt;Hydra&lt;/em&gt;, and then get cached on
&lt;code&gt;cache.nixos.org&lt;/code&gt; so whenever someone wants to install a package, a pre-built
binary gets pulled from the cache instead of getting installed from source. For
packages that don’t need compiling this is not that big of a time save, but for
packages that do need to get compiled it is huge. Depending on which packages
you want to install, if you had to build everything from source, it could
potentially take hours, but if you can install pre-built binaries it’s just a
matter of how quick your internet connection is.&lt;/p&gt;
&lt;p&gt;Anyways, I went back to my fork of &lt;code&gt;nixpkgs&lt;/code&gt; and updated the expression defining
the CRAN packages myself and installed the latest versions of packages from my
fork.&lt;/p&gt;
&lt;p&gt;Before the update, this was the error message I was testing against:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/cant_subset.png&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and this was on version 1.2.0 of &lt;code&gt;{tidyselect}&lt;/code&gt;:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/tidyselect_120.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;but after the update, this was the error message:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/cant_select.png&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;on version 1.2.1 of &lt;code&gt;{tidyselect}&lt;/code&gt;:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/tidyselect_121.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;so I found the issue, and updated my unit testing accordingly, and pushed the
update to CRAN. All is well that ends well, but… this made me think. I needed
to have an easy way to have bleeding edge packages on hand from Nix at all
moments, and so I started working on it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;github-actions-to-the-rescue&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Github Actions to the rescue&lt;/h2&gt;
&lt;p&gt;As described in my &lt;a href=&#34;https://www.brodrigues.co/blog/2024-02-29-nix_for_r_part_10/&#34;&gt;previous blog
post&lt;/a&gt; updating the
Nix expressions defining the R packages on &lt;code&gt;nixpkgs&lt;/code&gt; involves running an R
script that generates a Nix expression which then builds the R packages when
needed. So what I did was create a Github actions that would run this R script
every 6 hours, and push the changes to a branch of my &lt;code&gt;nixpkgs&lt;/code&gt; fork. This way,
I would always have the possibility to use this branch if I needed bleeding edge
packages. Because this can be of interest to others, &lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp
Baumann&lt;/a&gt; started a Github organisation
hosting this fork of &lt;code&gt;nixpkgs&lt;/code&gt; that gets updated daily which you can find
&lt;a href=&#34;https://github.com/rstats-on-nix&#34;&gt;here&lt;/a&gt;. Because this action needs to run
several times a day, it should be on a schedule, but actions on a schedule can
only run from master/main. But that’s not what we wanted, so instead, we are
using another action, on another repository, that pushes a random file to the
target repository to get the action going. You can find this repository
&lt;a href=&#34;https://github.com/b-rodrigues/trigger-r-updates&#34;&gt;here&lt;/a&gt; with complete
instructions. So to summarise:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An action on schedule runs from b-rodrigues/trigger-r-updates and pushes a file to rstats-on-nix/nixpkgs on the &lt;code&gt;r-daily-source&lt;/code&gt; branch&lt;/li&gt;
&lt;li&gt;This triggers an action that updates all of &lt;code&gt;nixpkgs&lt;/code&gt;, including R packages, and pushes all the updates to the &lt;code&gt;r-daily&lt;/code&gt; branch (you can find it &lt;a href=&#34;https://github.com/rstats-on-nix/nixpkgs/blob/r-daily-source/.github/workflows/r-daily.yml&#34;&gt;here&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;We can now use the &lt;code&gt;r-daily&lt;/code&gt; branch to get bleeding edge R packages on Nix!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This happens without any form of testing though, so packages could be in a
broken state (hey, that’s the definition of bleeding edge, after all!), and
also, if anyone would like to use this fork to build a development environment,
they’d have to rebuild a lot of packages from source. Again, this is because
these packages are defined in a fork of &lt;code&gt;nixpkgs&lt;/code&gt; and they don’t get built on
Hydra to populate the public cache that Nix uses by default. So while this fork
is interesting because it provides bleeding edges packages, using it on a
day-to-day basis can be quite tedious.&lt;/p&gt;
&lt;p&gt;And this is where &lt;a href=&#34;https://www.cachix.org/&#34;&gt;Cachix&lt;/a&gt; comes into play.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-your-own-binary-cache-on-cachix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setting up your own binary cache on Cachix&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cachix.org/&#34;&gt;Cachix&lt;/a&gt; is an amazing tool that makes it incredibly
easy to set up your own cache. Simply build the packages once, and push the
binaries to the cache. As long as these packages don’t get updated, they’ll get
pulled from the cache instead of getting rebuilt.&lt;/p&gt;
&lt;p&gt;So now, here is what I do with my packages: I define a &lt;code&gt;default.nix&lt;/code&gt; file that
defines a development environment that uses my fork of &lt;code&gt;nixpkgs&lt;/code&gt; as the source
for packages. For example,
&lt;a href=&#34;https://github.com/b-rodrigues/rix/blob/master/default.nix&#34;&gt;here&lt;/a&gt; is this file
that defines the environment for my &lt;code&gt;{rix}&lt;/code&gt; package. I can use this environment
to work on my package, and make sure that anyone else that wants to contribute,
contributes using the same environment. As you can see on line 2, the
&lt;code&gt;rstats-on-nix&lt;/code&gt; bleeding edge fork gets used:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; pkgs = import (fetchTarball &amp;quot;https://github.com/rstats-on-nix/nixpkgs/archive/refs/heads/r-daily.tar.gz&amp;quot;) {};&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, still on &lt;code&gt;{rix}&lt;/code&gt;’s repository, I define a new action that builds this
environment periodically, but using the binary cache I set up with Cachix. You
can find this action
&lt;a href=&#34;https://github.com/b-rodrigues/rix/blob/master/.github/workflows/cachix-dev-env.yml&#34;&gt;here&lt;/a&gt;.
So the &lt;code&gt;r-daily&lt;/code&gt; branch of our &lt;code&gt;nixpkgs&lt;/code&gt; fork gets updated every 6 hour and this
environment gets updated every 12 hours, 30 minutes past the hour.&lt;/p&gt;
&lt;p&gt;Now, every time I want to work on my package, I simply use &lt;code&gt;nix-build&lt;/code&gt; on my
computer to update the development environment. This is what I see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;copying path &amp;#39;/nix/store/0l0iw4hz7xvykvhsjg8nqkvyl31js96l-r-stringr-1.5.1&amp;#39; from &amp;#39;https://b-rodrigues.cachix.org&amp;#39;...
copying path &amp;#39;/nix/store/cw3lc7b0zydsricl5155jbmldm1vcyvr-r-tibble-3.2.1&amp;#39; from &amp;#39;https://b-rodrigues.cachix.org&amp;#39;...
copying path &amp;#39;/nix/store/y32kpp09l34cdgksnr89cyvz6p5s94z8-r-tidyselect-1.2.1&amp;#39; from &amp;#39;https://b-rodrigues.cachix.org&amp;#39;...
copying path &amp;#39;/nix/store/sw24yx1jwy9xzq8ai5m2gzaamvyi5r0h-r-rematch2-2.1.2&amp;#39; from &amp;#39;https://b-rodrigues.cachix.org&amp;#39;...
copying path &amp;#39;/nix/store/z6b4vii7hvl9mc53ykxrwks1lkfzgmr4-r-dplyr-1.1.4&amp;#39; from &amp;#39;https://b-rodrigues.cachix.org&amp;#39;...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as you can see, packages get pulled from my cache. Packages that are already
available from the usual, public, &lt;code&gt;cache.nixos.org&lt;/code&gt; don’t get rebuilt nor cached
in mine; they simply continue getting pulled directly from there. This makes
using the development environment very easy, and guarantees I’m always mirroring
the state of packages released on CRAN. The other interesting thing is that I
can use that cache with other actions. For example,
&lt;a href=&#34;https://github.com/b-rodrigues/rix/blob/master/.github/workflows/tests-r-via-nix.yaml&#34;&gt;here&lt;/a&gt;
is the action that runs the unit tests included in the package in an environment
that has Nix installed on it (some unit tests need Nix to be available to run).
On line 25 you can see that we install Nix and set our fork as the repository to
use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix_path: nixpkgs=https://github.com/rstats-on-nix/nixpkgs/archive/refs/heads/r-daily.tar.gz&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and just below, we set up the cache:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- uses: cachix/cachix-action@v14
  with:
    name: b-rodrigues # this is the name of my cache&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By using my cache, I make sure that the test runs with the freshest possible
packages, and don’t run the risk of having a test succeed on an outdated
environment. And you might have noticed that I am not authenticating to Cachix:
to simply pull binaries, to authentication is needed!&lt;/p&gt;
&lt;p&gt;Cachix has a free plan of up to 5Gb which is more than enough to set up several
development environments like this, and is really, really, easy to set up, and
it works on your computer and on Github Actions, as shown. If you want to use
this development environment to contribute to &lt;code&gt;{rix}&lt;/code&gt;, check out the
instructions on
&lt;a href=&#34;https://github.com/b-rodrigues/rix/blob/master/CONTRIBUTING.md#development-environment&#34;&gt;Contributing.md&lt;/a&gt;
file.&lt;/p&gt;
&lt;p&gt;You can use the same approach to always have development environments ready for
your different projects, and I will likely add the possibility to use this fork
of &lt;code&gt;nixpkgs&lt;/code&gt; with my &lt;code&gt;{rix}&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to &lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp Baumann&lt;/a&gt; for nudging me
into the direction of using Cachix and showing the way!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 10 -- contributing to nixpkgs</title>
      <link>https://www.brodrigues.co/blog/2024-02-29-nix_for_r_part_10/</link>
      <pubDate>Thu, 29 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2024-02-29-nix_for_r_part_10/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/nix_parents.jpg&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve very recently started contributing to the &lt;code&gt;nixpkgs&lt;/code&gt; repository of packages,
which contains all the packages you can install from the Nix package manager. My
contributions are fairly modest: I help fix R packages that need some tweaking
to make them successfully build for Nix. Most of these fixes are very simple
one-liners.&lt;/p&gt;
&lt;p&gt;Most users of any free and open source tool rarely contribute to the development
of this tool: I don’t think it is due to lack of skills and/or time or interest,
but mostly because starting to contribute to a tool requires some knowledge that
is rarely written down (even more so for an entire ecosystem). These tools and
ecosystems grow organically, and if you’re not in the right spot at the right
time or are not lucky enough to have kind people taking time to explain things
to you, contributing might feel completely overwhelming.&lt;/p&gt;
&lt;p&gt;Thankfully, I was very lucky to have found the small but very active
community of R contributors to &lt;code&gt;nixpkgs&lt;/code&gt; on
&lt;a href=&#34;https://matrix.to/#/#r:nixos.org&#34;&gt;Matrix&lt;/a&gt; which very kindly took the time
to bring me up to speed!&lt;/p&gt;
&lt;p&gt;I wanted to share my experiences in this blog post: but this blog post is not
just going to be about me contributing to &lt;code&gt;nixpkgs&lt;/code&gt; from the perspective of an R
user (and giving you some pointers on how to start yourself), but also about how
I built a report (let’s call it like that) to keep track of which R packages got
fixed. This report is built using R, Nix, Github Actions and lists all the failed
R package builds from Hydra (more on this later). The report gets updated
every day automatically at midnight, and is accessible
&lt;a href=&#34;https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html&#34;&gt;here&lt;/a&gt;.
I also used a very minimalistic approach to build this: no &lt;code&gt;{tidyverse}&lt;/code&gt;
packages, and no Quarto. Why? Mostly just to keep dependencies at a minimum to
accelerate CI/CD, but also for fun. And honestly, I must admit that base R is
more than capable on its own and had forgotten that.&lt;/p&gt;
&lt;div id=&#34;contributing-to-nixpkgs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Contributing to nixpkgs&lt;/h2&gt;
&lt;p&gt;As explained in
&lt;a href=&#34;https://www.brodrigues.co/blog/2023-12-19-nix_for_r_part_8/&#34;&gt;part 8&lt;/a&gt;, &lt;code&gt;nixpkgs&lt;/code&gt; is
“nothing but” a huge GitHub repository containing thousands of Nix expressions.
These expressions are then used to actually build the software that then gets
installed by Nix. For example, &lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/nixpkgs-unstable/pkgs/development/libraries/quarto/default.nix&#34;&gt;this is the expression for
Quarto&lt;/a&gt;.
As you can see, it starts by downloading the pre-compiled binary, and then
applying “patches”. Essentially making sure that Quarto installed by Nix is able
to find the other pieces installed by Nix that Quarto needs (Deno, Pandoc, Typst
and so on). It then continues by installing Quarto itself (because we’re
downloading a pre-compiled binary, &lt;em&gt;installation&lt;/em&gt; consists in moving files in
the right spot), finally some tests are executed (&lt;code&gt;quarto check&lt;/code&gt;) and then some
metadata is defined. Not every package is defined like this, with a single Nix
expression, though. For example, individual R packages are not defined like
this. Instead, every package from CRAN and Bioconductor gets built using only a
handful of files that can be found
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/tree/nixpkgs-unstable/pkgs/development/r-modules&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;(By the way, you can look for packages and find their associated Nix expressions
on the &lt;a href=&#34;https://search.nixos.org/packages?channel=unstable&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=quarto&#34;&gt;NixOS package search&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The way this works, is that periodically the
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/generic-builder.nix&#34;&gt;&lt;code&gt;generate-r-packages.R&lt;/code&gt;&lt;/a&gt;
script is run and generates the
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/cran-packages.nix&#34;&gt;&lt;code&gt;cran-packages.nix&lt;/code&gt;&lt;/a&gt;
file (and the equivalent Bioconductor files). For each package on CRAN, a line gets written in the script
with the package’s name, its current version on CRAN, and very importantly its
dependencies. For example, here is the line for &lt;code&gt;{dplyr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dplyr = derive2 { name=&amp;quot;dplyr&amp;quot;; version=&amp;quot;1.1.4&amp;quot;;
   sha256=&amp;quot;1jsq8pj12bngy66xms486j8a65wxvyqs944q9rxkiaylsla08wyg&amp;quot;;
   depends=[cli generics glue lifecycle magrittr pillar R6 rlang tibble tidyselect vctrs]; };&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These dependencies are actually the packages that can be found in the
&lt;a href=&#34;https://github.com/tidyverse/dplyr/blob/main/DESCRIPTION&#34;&gt;&lt;code&gt;DESCRIPTION&lt;/code&gt;&lt;/a&gt; file
under &lt;code&gt;Imports&lt;/code&gt;.
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/cran-packages.nix&#34;&gt;&lt;code&gt;cran-packages.nix&lt;/code&gt;&lt;/a&gt;
(and the same goes for the Bioconductor equivalents, &lt;code&gt;bioc-packages.nix&lt;/code&gt;,
&lt;code&gt;bioc-annotation-packages.nix&lt;/code&gt; and &lt;code&gt;bioc-experiment-packages.nix&lt;/code&gt;) get imported
in the
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/default.nix&#34;&gt;&lt;code&gt;default.nix&lt;/code&gt;&lt;/a&gt;
file. In it, another file, &lt;code&gt;generic-builder.nix&lt;/code&gt; gets also imported, which
contains a function that will attempt building the package. Most of the time
this succeeds, but some packages require further tweaks. Packages that have a
field &lt;code&gt;NeedsCompilation&lt;/code&gt; in their DESCRIPTION files are usually candidates for
further tweaking: these packages require system-level dependencies, which are
often listed under &lt;code&gt;SystemRequirements&lt;/code&gt; (but not always, which complicates
matters). For example, the &lt;code&gt;{terra}&lt;/code&gt; package has these system requirements
listed in itself DESCRIPTION file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SystemRequirements:	C++17, GDAL (&amp;gt;= 2.2.3), GEOS (&amp;gt;= 3.4.0), PROJ (&amp;gt;= 4.9.3), sqlite3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so these also need to be added if we want to build them on Nix. But if we look at the
line for &lt;code&gt;{terra}&lt;/code&gt; in &lt;code&gt;cran-packages.nix&lt;/code&gt;, this is what we see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;terra = derive2 { name=&amp;quot;terra&amp;quot;; version=&amp;quot;1.7-65&amp;quot;; 
  sha256=&amp;quot;0m9s5am8l6il1q0skab614cx0qjsb1i9xcv6nm0sdzj7p9lrzkfl&amp;quot;; 
  depends=[Rcpp]; };&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Only &lt;code&gt;{Rcpp}&lt;/code&gt; is listed, which is a dependency, yes, but an R package
dependency, not a system-level requirement. System-level requirements need to
be added in the &lt;code&gt;default.nix&lt;/code&gt; file manually. In the &lt;code&gt;default.nix&lt;/code&gt;, you’ll find a
long list of packages called &lt;code&gt;packagesWithNativeBuildInputs&lt;/code&gt; and
&lt;code&gt;packagesWithBuildInputs&lt;/code&gt;. &lt;em&gt;NativeBuildInputs&lt;/em&gt; and &lt;em&gt;BuildInputs&lt;/em&gt; are Nix jargon
for dependencies the package needs, at compile-time and then at run-time
specifically. For example, &lt;code&gt;{Rcpp}&lt;/code&gt; is a &lt;em&gt;BuildInput&lt;/em&gt; of &lt;code&gt;{terra}&lt;/code&gt;, while the
system-level requirements are &lt;em&gt;NativeBuildInputs&lt;/em&gt; (in the context of R packages
though, this rarely matters. If you want more details, refer to &lt;a href=&#34;https://gist.github.com/b-rodrigues/c677b59126d05d43347ed9623ddd5b0c&#34;&gt;this
Gist&lt;/a&gt; I’ve
forked).&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;{terra}&lt;/code&gt;, this means that we need to add this line to the list
&lt;code&gt;{packagesWithNativeBuildInputs}&lt;/code&gt; (I simplified the syntax here a bit):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;terra = [ gdal proj geos ];&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;gdal&lt;/code&gt;, &lt;code&gt;proj&lt;/code&gt; and &lt;code&gt;geos&lt;/code&gt; are the system requirements that need to be added for
&lt;code&gt;{terra}&lt;/code&gt; to build successfully on Hydra.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hydra&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hydra&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Hydra is a tool for continuous integration testing and software release that
uses a purely functional language to describe build jobs and their dependencies&lt;/em&gt;
(source: &lt;a href=&#34;https://hydra.nixos.org/build/248007843/download/1/hydra/#introduction&#34;&gt;the Hydra
Manual&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;If you’re coming from R, think of Hydra as &lt;a href=&#34;https://builder.r-hub.io/&#34;&gt;R-hub&lt;/a&gt;,
which will check and build your R package before submitting to CRAN. Hydra
periodically tries to rebuild packages. If that package fails, then the log
gets hosted. When it comes to R packages, we can check which packages
built successfully or not on &lt;a href=&#34;https://hydra.nixos.org/jobset/nixpkgs/r-updates&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As of writing, the latest evaluation was in mid-January. A new release of R is
going to get released on the 29th of February (or maybe was already released,
I’m not sure when this blog post is going to get posted), and this is when new
evaluations will likely be executed. Evaluations are the processes by which Nix
expressions get… evaluated and used to actually build packages. So if we look
into the results of the evaluation of the 17th of January, we see that 757 jobs
failed:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/hydra_failing_jobs.jpg&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;One job doesn’t strictly correspond to one package though: packages get built for different
architectures, and each architecture gets its build process. If we log into the details
of the first package whose build failed &lt;code&gt;{AIUQ}&lt;/code&gt;, we see this:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/hydra_failed.jpg&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From the log we see that actually what failed one of its dependencies, &lt;code&gt;{SuperGauss}&lt;/code&gt;,
so fixing &lt;code&gt;{SuperGauss}&lt;/code&gt; will likely fix &lt;code&gt;{AIUQ}&lt;/code&gt; (I say likely because maybe another
needed dependency also fails). So we could try to fix &lt;code&gt;{SuperGauss}&lt;/code&gt; first. Let’s see
why &lt;code&gt;{SuperGauss}&lt;/code&gt;, by clicking on &lt;code&gt;raw&lt;/code&gt;:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/hydra_failed_raw.jpg&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Here is what we see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Running phase: unpackPhase
unpacking source archive /nix/store/615bdvjchxrd7wp5m7dhg4g04yv7ncza-SuperGauss_2.0.3.tar.gz
source root is SuperGauss
setting SOURCE_DATE_EPOCH to timestamp 1645735202 of file SuperGauss/MD5
Running phase: patchPhase
Running phase: updateAutotoolsGnuConfigScriptsPhase
Running phase: configurePhase
Running phase: buildPhase
Running phase: checkPhase
Running phase: installPhase
* installing *source* package &amp;#39;SuperGauss&amp;#39; ...
** package &amp;#39;SuperGauss&amp;#39; successfully unpacked and MD5 sums checked
** using staged installation
checking for gcc... /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc accepts -g... yes
checking for /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc option to accept ISO C89... none needed
checking for pkg-config... no
checking for FFTW... configure: error: in `/build/SuperGauss&amp;#39;:
configure: error: The pkg-config script could not be found or is too old.  Make sure it
is in your PATH or set the PKG_CONFIG environment variable to the full
path to pkg-config.

Alternatively, you may set the environment variables FFTW_CFLAGS
and FFTW_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

To get pkg-config, see &amp;lt;http://pkg-config.freedesktop.org/&amp;gt;.
See `config.log&amp;#39; for more details
ERROR: configuration failed for package &amp;#39;SuperGauss&amp;#39;
* removing &amp;#39;/nix/store/jxv5p85x24xmfcnifw2ibvx9jhk9f2w4-r-SuperGauss-2.0.3/library/SuperGauss&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is essentially what we would see if we tried to install &lt;code&gt;{SuperGauss}&lt;/code&gt; on
Linux. The error message is quite clear here: a system-level dependency,
&lt;code&gt;pkg-config&lt;/code&gt; is missing. Looks like we found our first package to fix!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixing-a-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixing a package&lt;/h2&gt;
&lt;p&gt;The first step is to fork and clone the &lt;code&gt;nixpkgs&lt;/code&gt; GitHub repository to your
computer (be patient, the repository is huge so the download will take some
time):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone git@github.com:b-rodrigues/nixpkgs.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s also a good idea to add the original &lt;code&gt;nixpkgs&lt;/code&gt; as an &lt;code&gt;upstream&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git remote add upstream https://github.com/NixOS/nixpkgs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This way, you can pull changes from the original &lt;code&gt;nixpkgs&lt;/code&gt; repository into your
fork easily with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git fetch upstream master
git merge upstream/master&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two commands synchronize your local copy of the repository with upstream.
So now we can create a new branch to try to fix &lt;code&gt;{SuperGauss}&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git branch -b fix_supergauss&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then we should try to build &lt;code&gt;{SuperGauss}&lt;/code&gt; locally. This is because
it might have been fixed in the meantime by someone else, so let’s try to
build it with (run the following command in a terminal at the root of
your local copy of the &lt;code&gt;nixpkgs&lt;/code&gt; repository):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-build -A rPackages.SuperGauss&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but I often prefer to use this instead, because this will build the package
and drop me into a shell where I can start R, load the package, and try it
by running some of its examples:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell -I nixpkgs=/path/to/my/nixpkgs -p rPackages.SuperGauss R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If any of the commands above fail with the same error message as on Hydra,
we know that it hasn’t been fixed yet. So the fix consists in opening the
&lt;code&gt;pkgs/development/r-modules/default.nix&lt;/code&gt; and add the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SuperGauss = [ pkg-config ];&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in either the lists &lt;code&gt;packagesWithBuildInputs&lt;/code&gt; or &lt;code&gt;packagesWithNativeBuildInputs&lt;/code&gt;
(as explained above, it doesn’t really matter). Trying to rebuild &lt;code&gt;SuperGauss&lt;/code&gt;
again will result in a new error message. Another dependecy needs to be added:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SuperGauss = [ pkg-config fftw.dev ];&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, building succeeds! We can now commit, push, and open a pull request.
Commit messages need to be formatted in a certain way, as per &lt;code&gt;nixpkgs&lt;/code&gt;
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/master/CONTRIBUTING.md&#34;&gt;contributing
guide&lt;/a&gt;, so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git add .
git commit -m &amp;quot;rPackages.SuperGauss: add dependencies&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;also, there should only be one commit per fix. So if in the process of fixing a
package you commited several times, you will need to use &lt;code&gt;git rebase&lt;/code&gt; to squash
all the commits into one. Once you open the pull request, a maintainer will get
pinged, and merge the PR if everything is alright (which is usually the case for
these one-liners). You can see the PR for &lt;code&gt;{SuperGauss}&lt;/code&gt;
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/pull/287209&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The process is relatively simple once you did it once or twice, but there are
some issues: there is no easy way to find out on which packages we should focus
on. For example, is &lt;code&gt;{SuperGauss}&lt;/code&gt; really that important? The fix was very
simple, so it’s ok, but if it took more effort, should we spend the limited time
we have on it, or should we focus on another package? Also, if someone has
already opened a PR to fix a package, but that PR hasn’t been merged yet, if I
try to also fix the same package and try to build the package, it would still
fail. So I might think that no one is taking care of it, and waste time
duplicating efforts instead of either focusing on another package, or reviewing
the open PR to accelerate the process of merging.&lt;/p&gt;
&lt;p&gt;Discussing this with other contributors, &lt;a href=&#34;https://fosstodon.org/deck/@kupac@functional.cafe&#34;&gt;László
Kupcsik&lt;/a&gt; suggested we could
use &lt;code&gt;{packageRank}&lt;/code&gt; to find out which packages are getting a lot of downloads
from CRAN, and so we could focus on fixing these packages first. This is a great
idea and it gave me the idea to build some kind of report that would do this
automatically for us, and also list opened and merged PRs so we wouldn’t risk
duplicating efforts.&lt;/p&gt;
&lt;p&gt;This report can be found
&lt;a href=&#34;https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html&#34;&gt;here&lt;/a&gt;
and now I’ll explain how I built it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;which-packages-to-fix-and-keeping-track-of-prs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Which packages to fix and keeping track of PRs&lt;/h2&gt;
&lt;p&gt;So the main idea was to know on which packages to focus on. So essentially, we
wanted this table:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/hydra_failing_jobs.jpg&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;but with &lt;code&gt;{packageRank}&lt;/code&gt; added to it. So the first step was to scrape this
table, using &lt;code&gt;{rvest}&lt;/code&gt;. This is what you can find on lines 11 to 63 of this
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R&#34;&gt;{targets}
workflow&lt;/a&gt;
(alongside some basic cleaning). I won’t go too much into detail, but if
something’s not clear, ping me on &lt;a href=&#34;https://twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; or
&lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or even open an issue on the
report’s
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/issues&#34;&gt;repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next I also get the reason the package failed building. So in the example from
before, &lt;code&gt;{AIUQ}&lt;/code&gt; failed because &lt;code&gt;{SuperGauss}&lt;/code&gt; failed. On Hydra, you should be
clicking to see this, but here I scrape it as well automatically, and add this
information in a column called &lt;code&gt;fails_because_of&lt;/code&gt;. This is what you can read on
lines
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R#L65&#34;&gt;65 to 77&lt;/a&gt;.
I use a function called &lt;code&gt;safe_get_failed_deps()&lt;/code&gt;, which you can find in the
&lt;code&gt;functions.R&lt;/code&gt; script &lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L41C1-L68C2&#34;&gt;on
here&lt;/a&gt;.
&lt;code&gt;safe_get_failed_deps()&lt;/code&gt; wraps the main function, &lt;code&gt;get_failed_deps()&lt;/code&gt;, with
&lt;code&gt;tryCatch()&lt;/code&gt;. This is because if anything goes wrong, I want my function
to return &lt;code&gt;NULL&lt;/code&gt; instead of an error, which would crash the whole pipeline.&lt;/p&gt;
&lt;p&gt;Next, I add the packages’ rank using a function that wraps
&lt;code&gt;packageRank::packageRank()&lt;/code&gt; called &lt;code&gt;safe_packageRank()&lt;/code&gt; on &lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R#L97&#34;&gt;line 97&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;safe_packageRank()&lt;/code&gt; uses &lt;code&gt;tryCatch()&lt;/code&gt; to return &lt;code&gt;NULL&lt;/code&gt; in case there’s an error.
This is needed because &lt;code&gt;packageRank()&lt;/code&gt; will only work on CRAN packages, but Hydra
also tries to build Bioconductor packages: when these packages’ names get passed
to &lt;code&gt;packageRank()&lt;/code&gt;, an error gets returned because these are not CRAN packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;packageRank(&amp;quot;haha&amp;quot;)
Error: haha: misspelled or not on CRAN/Archive.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but instead of an error that would stop the pipeline, I prefer it simply returns
&lt;code&gt;NULL&lt;/code&gt;, hence &lt;code&gt;tryCatch()&lt;/code&gt;. Also, I compute the rank of the package listed under
the &lt;code&gt;fails_because_of&lt;/code&gt; column and not the &lt;code&gt;package&lt;/code&gt; column. If we go back to our
example from before, &lt;code&gt;{AIUQ}&lt;/code&gt; failed because &lt;code&gt;{SuperGauss}&lt;/code&gt; failed, I’m actually
interested in the rank of &lt;code&gt;{SuperGauss}&lt;/code&gt;, and not &lt;code&gt;{AIUQ}&lt;/code&gt; (which I way I went
to all the trouble to scrape the failing dependency).&lt;/p&gt;
&lt;p&gt;So, for now, when comparing to the table on Hydra, we have two further columns
with the dependency that actually fails (or not, if the package fails on its own
and not because of a dependency), and the rank of either the dependency that
fails or the package itself.&lt;/p&gt;
&lt;p&gt;Next, I’d like to see if PRs have already been opened and merged. For this, I
use the &lt;code&gt;gh&lt;/code&gt; tool, which is a command line tool to interact with GitHub
repositories. I wrote the &lt;code&gt;get_prs()&lt;/code&gt; wrapper around &lt;code&gt;gh&lt;/code&gt; to list the opened or
the merged PRs of the &lt;code&gt;nixpkgs&lt;/code&gt; repository. This is what it looks like (and is
defined
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L8C1-L21C2&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;get_prs &amp;lt;- function(state){

  output_path &amp;lt;- paste0(state, &amp;quot;_prs.json&amp;quot;)

  # Run the command
  system(paste0(
    &amp;quot;gh pr list --state=&amp;quot;, state,
    &amp;quot; --search=rPackages -R NixOS/nixpkgs --json title,updatedAt,url &amp;gt; &amp;quot;,
    output_path
  ))

  # Return path for targets
  output_path
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because the PRs follow the contributing guidelines, I can easily process the PRs
titles to get the name of the package (I essentially need to go from the string
“rPackages.SuperGauss: fixing build” to “SuperGauss”) using regular expressions.
This is what happens in the &lt;code&gt;clean_prs()&lt;/code&gt; function
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L23&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most of what follows is merging the right data frames and ensuring that I have
something clean to show. Finally, an &lt;code&gt;.Rmd&lt;/code&gt; document gets compiled, which you
can find
&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/r-updates-fails.Rmd&#34;&gt;here&lt;/a&gt;.
This will get compiled to an &lt;code&gt;.html&lt;/code&gt; file which is what you see when you click
&lt;a href=&#34;https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This runs every day at midnight using GitHub actions (&lt;a href=&#34;https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/.github/workflows/compile_table.yaml&#34;&gt;the workflow is
here&lt;/a&gt;)
and then I use the &lt;code&gt;raw.githack.com&lt;/code&gt; &lt;a href=&#34;https://raw.githack.com/&#34;&gt;here&lt;/a&gt; to serve
the rendered HTML file. So every time I push, or at midnight, the action runs,
computes the package rank, checks if new PRs are available or have been merged,
and the rendered file is immediately available. How’s that for serverless CI/CD?&lt;/p&gt;
&lt;p&gt;If you are interested in using Nix to make your analyses reproducible, check out
&lt;a href=&#34;https://www.brodrigues.co/tags/nix/&#34;&gt;the other blog posts in this series&lt;/a&gt; and
join our small but motivated community of R contributors to &lt;code&gt;nixpkgs&lt;/code&gt; on
&lt;a href=&#34;https://matrix.to/#/#r:nixos.org&#34;&gt;Matrix&lt;/a&gt;. If you are interested in the history
of Nix, checkout this super interesting &lt;a href=&#34;https://economicsfromthetopdown.com/2024/02/17/nixing-technological-lock-in/&#34;&gt;blog
post&lt;/a&gt;
by &lt;a href=&#34;https://mastodon.online/@blair_fix&#34;&gt;Blair Fix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’re interested into using project-specific, and reproducible development
environments, give &lt;code&gt;{rix}&lt;/code&gt; and Nix a try! Learn more about &lt;code&gt;{rix}&lt;/code&gt; on its Github
repository &lt;a href=&#34;https://github.com/b-rodrigues/rix&#34;&gt;here&lt;/a&gt; or
&lt;a href=&#34;https://b-rodrigues.github.io/rix/&#34;&gt;website&lt;/a&gt;. We wrote many vignettes that are
conveniently numbered, so don’t hesitate to &lt;a href=&#34;https://b-rodrigues.github.io/rix/articles/a-getting-started.html&#34;&gt;get
started&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to the colleagues of the Matrix nixpkgs R channel for the fruitful discussions that
helped shape this blog post and for proof-reading.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 9 -- rix is looking for testers!</title>
      <link>https://www.brodrigues.co/blog/2024-02-02-nix_for_r_part_9/</link>
      <pubDate>Fri, 02 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2024-02-02-nix_for_r_part_9/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/kick_rix.png&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After 5 months of work, &lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp Baumann&lt;/a&gt;
and myself are happy to announce that our package, &lt;code&gt;{rix}&lt;/code&gt; is getting quite
close to being in a state we consider “done” (well, at least, for a first
release). We plan on submit it first to
&lt;a href=&#34;https://ropensci.org/software-review/&#34;&gt;rOpenSci&lt;/a&gt; for review, and later to CRAN.
But in the meantime, if you could test the package, we’d be grateful! We are
especially interested to see if you find the documentation clear, and if you are
able to run the features that require an installation of Nix, the &lt;code&gt;nix_build()&lt;/code&gt;
and &lt;code&gt;with_nix()&lt;/code&gt; functions. And I would truly recommend you read this blog post
to the end, because I guarantee you’ll have your mind blown! If that’s not the
case, send an insult my way on social media.&lt;/p&gt;
&lt;div id=&#34;what-is-rix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is rix?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;{rix}&lt;/code&gt; is an R package that leverages Nix, a powerful package manager focusing
on reproducible builds. With Nix, it is possible to create project-specific
environments that contain a project-specific version of R and R packages (as
well as other tools or languages, if needed). You can use &lt;code&gt;{rix}&lt;/code&gt; and Nix to
replace renv and Docker with one single tool. Nix is an incredibly useful piece
of software for ensuring reproducibility of projects, in research or otherwise,
or for running web applications like Shiny apps or plumber APIs in a controlled
environment. The advantage of using Nix over Docker is that the environments
that you define using Nix are not isolated from the rest of your machine: you
can still access files and other tools installed on your computer.&lt;/p&gt;
&lt;p&gt;For example, here is how you could use &lt;code&gt;{rix}&lt;/code&gt; to generate a file called
&lt;code&gt;default.nix&lt;/code&gt;, which can then be used by Nix to actually build that environment
for you:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rix)

path_default_nix &amp;lt;- tempdir()

rix(r_ver = &amp;quot;latest&amp;quot;,
    r_pkgs = c(&amp;quot;dplyr&amp;quot;, &amp;quot;ggplot2&amp;quot;),
    system_pkgs = NULL,
    git_pkgs = NULL,
    ide = &amp;quot;code&amp;quot;,
    shell_hook = NULL,
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # This file was generated by the {rix} R package v0.5.1.9000 on 2024-02-02
## # with following call:
## # &amp;gt;rix(r_ver = &amp;quot;5ad9903c16126a7d949101687af0aa589b1d7d3d&amp;quot;,
## #  &amp;gt; r_pkgs = c(&amp;quot;dplyr&amp;quot;,
## #  &amp;gt; &amp;quot;ggplot2&amp;quot;),
## #  &amp;gt; system_pkgs = NULL,
## #  &amp;gt; git_pkgs = NULL,
## #  &amp;gt; ide = &amp;quot;code&amp;quot;,
## #  &amp;gt; project_path = path_default_nix,
## #  &amp;gt; overwrite = TRUE,
## #  &amp;gt; print = TRUE,
## #  &amp;gt; shell_hook = NULL)
## # It uses nixpkgs&amp;#39; revision 5ad9903c16126a7d949101687af0aa589b1d7d3d for reproducibility purposes
## # which will install R version latest
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/5ad9903c16126a7d949101687af0aa589b1d7d3d.tar.gz&amp;quot;) {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) dplyr ggplot2 languageserver;
## };
##    system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocales nix ;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == &amp;quot;x86_64-linux&amp;quot; then  &amp;quot;${pkgs.glibcLocales}/lib/locale/locale-archive&amp;quot; else &amp;quot;&amp;quot;;
##     LANG = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_ALL = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_TIME = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MONETARY = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_PAPER = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MEASUREMENT = &amp;quot;en_US.UTF-8&amp;quot;;
## 
##     buildInputs = [  rpkgs  system_packages  ];
##       
##   }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You don’t need to have Nix installed to use &lt;code&gt;{rix}&lt;/code&gt; and generate this
expression! This is especially useful if you want to generate an expression that
should then be used in a CI/CD environment for example.&lt;/p&gt;
&lt;p&gt;But if you do have Nix installed, then you can use two great functions that
Philipp implemented, which we are really excited to tell you about!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nix_build-and-with_nix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;nix_build() and with_nix()&lt;/h2&gt;
&lt;p&gt;When you have a &lt;code&gt;default.nix&lt;/code&gt; file that was generated by &lt;code&gt;rix::rix()&lt;/code&gt;, and if
you have Nix installed on your system, you can build the corresponding
environment using the command line tool &lt;code&gt;nix-build&lt;/code&gt;. But you can also build that
environment straight from an R session, by using
&lt;a href=&#34;https://b-rodrigues.github.io/rix/reference/nix_build.html&#34;&gt;&lt;code&gt;rix::nix_build()&lt;/code&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;But the reason
&lt;a href=&#34;https://b-rodrigues.github.io/rix/reference/nix_build.html&#34;&gt;&lt;code&gt;nix_build()&lt;/code&gt;&lt;/a&gt; is
really useful, is because it gets called by
&lt;a href=&#34;https://b-rodrigues.github.io/rix/reference/with_nix.html&#34;&gt;&lt;code&gt;with_nix()&lt;/code&gt;&lt;/a&gt;.
&lt;a href=&#34;https://b-rodrigues.github.io/rix/reference/with_nix.html&#34;&gt;&lt;code&gt;with_nix()&lt;/code&gt;&lt;/a&gt; is a
very interesting function, because it allows you to evaluate a single function
within a so-called subshell. That subshell can have a whole other version of R
and R packages than your main session, and you can use it to execute an
arbitrary function (or a whole, complex expression), and then get the result
back into your main session. You could use older versions of packages to get a
result that might not be possible to get in a current version. Consider the
following example: on a recent version of &lt;code&gt;{stringr}&lt;/code&gt;,
&lt;code&gt;stringr::str_subset(c(&#34;&#34;, &#34;a&#34;), &#34;&#34;)&lt;/code&gt; results in an error, but older versions
would return &lt;code&gt;&#34;a&#34;&lt;/code&gt;. Returning an error is actually what this should do, but hey,
if you have code that relies on that old behaviour you can now execute that old
code within a subshell that contains that older version of &lt;code&gt;{stringr}&lt;/code&gt;. Start by
creating a folder to contain everything needed for your subshell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_env_stringr &amp;lt;- file.path(&amp;quot;.&amp;quot;, &amp;quot;_env_stringr_1.4.1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, it is advised to use
&lt;a href=&#34;https://b-rodrigues.github.io/rix/reference/rix_init.html&#34;&gt;&lt;code&gt;rix::rix_init()&lt;/code&gt;&lt;/a&gt;
to generate an &lt;code&gt;.Rprofile&lt;/code&gt; for that subshell, which sets a number of environment
variables. This way, when the R session in that subshell starts, we don’t have
any interference between that subshell and the main R session, as the R packages
that must be available to the subshell are only taken from the Nix store. The
Nix store is where software installed by Nix is… stored, and we don’t want R
to be confused and go look for R packages in the user’s library, which could
happen without this specific &lt;code&gt;.Rprofile&lt;/code&gt; file:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix_init(
  project_path = path_env_stringr,
  rprofile_action = &amp;quot;overwrite&amp;quot;,
  message_type = &amp;quot;simple&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ### Bootstrapping isolated, project-specific, and runtime-pure R setup via Nix ###
## 
## ==&amp;gt; Created isolated nix-R project folder:
##  /home/cbrunos/six_to/dev_env/b-rodrigues.github.com/content/blog/_env_stringr_1.4.1 
## ==&amp;gt; R session running via Nix (nixpkgs)
## * R session not running from RStudio
## ==&amp;gt; Added `.Rprofile` file and code lines for new R sessions launched from:
## /home/cbrunos/six_to/dev_env/b-rodrigues.github.com/content/blog/_env_stringr_1.4.1
## 
## * Added the location of the Nix store to `PATH` environmental variable for new R sessions on host/docker RStudio:
## /nix/var/nix/profiles/default/bin&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now generate the &lt;code&gt;default.nix&lt;/code&gt; file for that subshell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix(
  r_ver = &amp;quot;latest&amp;quot;,
  r_pkgs = &amp;quot;stringr@1.4.1&amp;quot;,
  overwrite = TRUE,
  project_path = path_env_stringr
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how we use the latest version of R (we could have used any other), but
&lt;code&gt;{stringr}&lt;/code&gt; on version 1.4.1. Finally, we use &lt;code&gt;with_nix()&lt;/code&gt; to evaluate
&lt;code&gt;stringr::str_subset(c(&#34;&#34;, &#34;a&#34;), &#34;&#34;)&lt;/code&gt; inside that subshell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;out_nix_stringr &amp;lt;- with_nix(
  expr = function() stringr::str_subset(c(&amp;quot;&amp;quot;, &amp;quot;a&amp;quot;), &amp;quot;&amp;quot;),
  program = &amp;quot;R&amp;quot;,
  exec_mode = &amp;quot;non-blocking&amp;quot;,
  project_path = path_env_stringr,
  message_type = &amp;quot;simple&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## * R session not running from RStudio
## ### Prepare to exchange arguments and globals for `expr` between the host and Nix R sessions ###
## * checking code in `expr` for potential problems:
##  `codetools::checkUsage(fun = expr)`
## 
## * checking code in `expr` for potential problems:
## 
## * checking code in `globals_exprs` for potential problems:
## 
## ==&amp;gt; Running deparsed expression via `nix-shell` in non-blocking mode:
## 
## 
## ==&amp;gt; Process ID (PID) is 19688.
## ==&amp;gt; Receiving stdout and stderr streams...
## 
## ==&amp;gt; `expr` succeeded!
## ### Finished code evaluation in `nix-shell` ###
## 
## * Evaluating `expr` in `nix-shell` returns:
## [1] &amp;quot;a&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can check if the result is really &lt;code&gt;&#34;a&#34;&lt;/code&gt; or not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(&amp;quot;a&amp;quot;, out_nix_stringr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;with_nix()&lt;/code&gt; should work whether you installed your main R session using Nix, or
not, but we’re not sure this is true for Windows (or rather, WSL2): we don’t have
a Windows license to test this on Windows, so if you’re on Windows and use WSL2
and want to test this, we would be very happy to hear from you!&lt;/p&gt;
&lt;p&gt;If you’re interested into using project-specific, and reproducible development
environments, give &lt;code&gt;{rix}&lt;/code&gt; and Nix a try! Learn more about &lt;code&gt;{rix}&lt;/code&gt; on its Github
repository &lt;a href=&#34;https://github.com/b-rodrigues/rix&#34;&gt;here&lt;/a&gt; or
&lt;a href=&#34;https://b-rodrigues.github.io/rix/&#34;&gt;website&lt;/a&gt;. We wrote many vignettes that are
conveniently numbered, so don’t hesitate to &lt;a href=&#34;https://b-rodrigues.github.io/rix/articles/a-getting-started.html&#34;&gt;get
started&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 8 -- nixpkgs, a tale of the magic of free and open source software and a call for charity</title>
      <link>https://www.brodrigues.co/blog/2023-12-19-nix_for_r_part_8/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-12-19-nix_for_r_part_8/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/santa_tux.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This is part 8 of a series of blog posts about Nix. Check out
the other parts &lt;a href=&#34;https://www.brodrigues.co/tags/nix/&#34;&gt;here&lt;/a&gt;.
TLDR: free and open source software is one of the most important
common goods with enormous positive externalities: if you want to
help funding it, keep reading!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I wanted to quickly discuss about &lt;code&gt;nixpkgs&lt;/code&gt;, which is the collection of packages
that can be installed using Nix. Why is a project like Nix and &lt;code&gt;nixpkgs&lt;/code&gt;
important, even if you don’t use Nix? In actuality, you may not realise it, but
you very much benefit from projects like Nix even if you don’t use it. Let me
explain.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nixpkgs&lt;/code&gt; is “just” a Github repository containing thousands upon thousands of
Nix expressions. When installing a package, these expressions get evaluated, and
the package in question gets installed. What &lt;em&gt;installed&lt;/em&gt; means can vary:
sometimes the package gets built from source, sometimes a pre-compiled binary
package for your operating system gets downloaded and installed.&lt;/p&gt;
&lt;p&gt;For example,
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/blob/dce218f4f35440622d2056f93ddc335351763bb4/pkgs/development/libraries/quarto/default.nix&#34;&gt;here&lt;/a&gt;
is the Nix expression that downloads and installs Quarto. This is an example of
an expression that downloads the pre-compiled Quarto package from Quarto’s own
Github repository, and then &lt;em&gt;installs&lt;/em&gt; it. The installation process in this case
is essentially making sure that Quarto is able to find its dependencies, which
also get installed from Nix, and some R and Python packages to make
Quarto work well with both languages also get installed.&lt;/p&gt;
&lt;p&gt;Because Nix packages are “nothing but” Nix expressions hosted on Github,
contributing to Nix is as simple as opening a PR. For example,
&lt;a href=&#34;https://github.com/NixOS/nixpkgs/pull/263108&#34;&gt;here&lt;/a&gt; is a draft PR I opened to
prepare for the imminent release of Quarto &lt;code&gt;1.4&lt;/code&gt;. My goal when I opened this
draft PR was to get used to contributing to &lt;code&gt;nixpkgs&lt;/code&gt; (this was my second or
third PR to &lt;code&gt;nixpkgs&lt;/code&gt;, and I did some rookie mistakes when opening my first
ones) and also to make the latest version of Quarto available on Nix as quickly
as possible. But this PR had an unexpected consequence: through it, we found a
bug in Quarto, which was then fixed before the actual release of the next
version!&lt;/p&gt;
&lt;p&gt;You see, how these things work is that when software gets released, operating
system specific packages get built downstream. In the case of Quarto, this is
not entirely true though: the developers of Quarto release many pre-compiled
packages for Windows, macOS and several Linux distribution themselves. But they
don’t do so for many other operating systems (which is entirely normal: there’s
just too many! So releasing pre-built binaries for the main operating systems is
more than enough), so the maintainers of these other operating systems (or
package managers) have to package the software themselves. In the case of
scientific software like Quarto, this usually means that it must get packaged
for the Conda package manager (popular among Python users) and Nix (and there’s
certainly other package managers out there that provide Quarto for other
&lt;em&gt;exotic&lt;/em&gt; systems) (Note: in the case of Quarto, I think the Quarto devs
themselves also package it for Conda, though).&lt;/p&gt;
&lt;p&gt;Turns out that when trying to package the pre-releases of Quarto for Nix, we
discovered a regression in the upstream code that would not only affect
packaging for Nix, but also for other package managers. We opened an issue on
&lt;a href=&#34;https://github.com/quarto-dev/quarto-cli/issues/7344&#34;&gt;Quarto’s issue tracker&lt;/a&gt;
and after some discussion, the bug was identified and adressed in a matter of
hours. And now everyone gets to enjoy a better version of Quarto!&lt;/p&gt;
&lt;p&gt;This type of thing happens quite a lot in the background of open source
development. My mind always gets blown when I think about the enormous amount of
hours that get put by hobbyists and paid developers into open source and how
well everything works. Truly a Christmas miracle (but one that happens all
around the year)!&lt;/p&gt;
&lt;p&gt;But it’s not all good and perfect. Some software is more complex to package, and
requires much more work. For example the RStudio IDE is one of these. It’s a
complex piece of software with many dependencies, and while it is available on
Nix, it can only be installed on Windows and Linux. If you’re a Nix user on
macOS, you won’t be able to install RStudio, unfortunately. And, unfortunately
also, if you install RStudio using the usual macOS installer, it won’t be able
to find any version of R and R packages installed with Nix. This is because
RStudio needs to be patched to make it work nicely with Nix (just like we have
to patch and prepare Quarto to play well with Nix). And packaging Rstudio for
Nix on macOS requires some expertise and hardware that we R users/contributers
to Nix don’t have all have access to.&lt;/p&gt;
&lt;p&gt;This is where I appeal to your generosity: I have contacted a company called
Numtide which offers a packaging service. You tell them which software you want
on Nix, they write the expression and open a PR to &lt;code&gt;nixpkgs&lt;/code&gt;. But this costs
money: so I started a Gofundme which you can find
&lt;a href=&#34;https://www.gofundme.com/f/package-rstudio-for-nix-on-macos-platforms&#34;&gt;here&lt;/a&gt;
to fund this. The goal is 4500€, which would cover the work, plus Gofundme
fees and interest rate risk. I stated in the Gofundme that if the goal was not
reached until the end of the year, I would donate all the money to the R
foundation, but I might extend it to end of January 2024 instead.&lt;/p&gt;
&lt;p&gt;So here is my ask: if you want to help make free and open source software
better, consider donating to this Gofundme! As explained above, even if you
don’t use Nix, everyone can benefit from work that is done by everyone, be it
upstream or downstream. And if the goal is not met, your donation will go to the
R foundation anyways!&lt;/p&gt;
&lt;p&gt;The link to the Gofundme is
&lt;a href=&#34;https://www.gofundme.com/f/package-rstudio-for-nix-on-macos-platforms&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope you can help out with this and make free and open source available and
better for everyone.&lt;/p&gt;
&lt;p&gt;Many thanks, merry Christmas and happy new year!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to
follow me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or
&lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates
and &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;
or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my
&lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;. You can also watch
my videos on
&lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;. So much
content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;/&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy
me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 7 -- Building a Quarto book using Nix on Github Actions</title>
      <link>https://www.brodrigues.co/blog/2023-10-20-nix_for_r_part7/</link>
      <pubDate>Fri, 20 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-10-20-nix_for_r_part7/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/nix_users_press_both_buttons.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Back in June I self-published a book on Amazon’s Kindle Direct Publishing
service and wrote a blog post detailling how you could achieve that using
Quarto, which you can read
&lt;a href=&#34;https://www.brodrigues.co/blog/2023-06-29-book_quarto/&#34;&gt;here&lt;/a&gt;. The book is
about &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;building reproducible analytical pipelines with
R&lt;/a&gt;. For the purposes of this post I made
a &lt;a href=&#34;https://github.com/b-rodrigues/kdp_quarto&#34;&gt;template on Github&lt;/a&gt; that you could
fork and use as a starting point to write your own book. The book also gets
built using Github Actions each time you push new changes: a website gets built,
an E-book for e-ink devices and a Amazon KDP-ready PDF for print get also built.
That template used dedicated actions to install the required version of R,
Quarto, and R packages (using &lt;code&gt;{renv}&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Let’s take a look at the workflow file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;on:
  push:
    branches: main

name: Render and Publish

jobs:
  build-deploy:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup pandoc
        uses: r-lib/actions/setup-pandoc@v2

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: &amp;#39;4.3.1&amp;#39;

      - name: Setup renv
        uses: r-lib/actions/setup-renv@v2

      - name: Set up Quarto
        uses: quarto-dev/quarto-actions/setup@v2
        with:
          # To install LaTeX to build PDF book 
          tinytex: true 
          # uncomment below and fill to pin a version
          #version: 1.3.353

      - name: Publish to GitHub Pages (and render)
        uses: quarto-dev/quarto-actions/publish@v2
        with:
          target: gh-pages
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there are a lot of different moving pieces to get this to work.
Since then I discovered Nix (if you’ve not been following my adventures, there’s
6 other parts to this series as of today), and now I wrote another template that
uses Nix to handle the book’s dependencies instead of dedicated actions and
&lt;code&gt;{renv}&lt;/code&gt;. You can find the repository
&lt;a href=&#34;https://github.com/b-rodrigues/quarto_book_nix&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is what the workflow file looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: Build book using Nix

on:
  push:
    branches:
      - main
      - master

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Code
      uses: actions/checkout@v3

    - name: Install Nix
      uses: DeterminateSystems/nix-installer-action@main
      with:
        logger: pretty
        log-directives: nix_installer=trace
        backtrace: full

    - name: Nix cache
      uses: DeterminateSystems/magic-nix-cache-action@main

    - name: Build development environment
      run: |
        nix-build

    - name: Publish to GitHub Pages (and render)
      uses: b-rodrigues/quarto-nix-actions/publish@main
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first thing you should notice is that this file is much shorter.&lt;/p&gt;
&lt;p&gt;The first step, &lt;code&gt;Checkout Code&lt;/code&gt; makes the code available to the rest of the
steps. I then install Nix on this runner using the Determinate Systems
&lt;code&gt;nix-installer-action&lt;/code&gt; and then I use another action from Determinate Systems,
the &lt;code&gt;magic-nix-cache-action&lt;/code&gt;. This action caches all the packages so that they
don’t need to get re-built each time a change gets pushed, speeding up the
process by a lot. The development environment gets then built using &lt;code&gt;nix-build&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, an action I defined runs, &lt;code&gt;quarto-nix-actions/publish&lt;/code&gt;. This is a fork
of the &lt;code&gt;quarto-actions/publish&lt;/code&gt; action which you can find
&lt;a href=&#34;https://github.com/quarto-dev/quarto-actions/blob/main/publish/action.yml&#34;&gt;here&lt;/a&gt;.
My fork simply makes sure that the &lt;code&gt;quarto render&lt;/code&gt; and &lt;code&gt;quarto publish&lt;/code&gt; commands
run in the &lt;a href=&#34;https://github.com/b-rodrigues/quarto-nix-actions/blob/f48f5a7813eb4978a2f557ff45bcc854526fb80b/publish/action.yml#L58&#34;&gt;Nix environment defined for the
project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can see the book website
&lt;a href=&#34;https://b-rodrigues.github.io/quarto_book_nix/&#34;&gt;here&lt;/a&gt;; read it, it’s explains
everything in much more details than this blog post! But if you’re busy, read
continue reading this blog post instead.&lt;/p&gt;
&lt;p&gt;The obvious next question is why bother with this second, Nix-centric, approach?&lt;/p&gt;
&lt;p&gt;There are at least three reasons. The first is that it is possible to define
so-called &lt;code&gt;default.nix&lt;/code&gt; files that the Nix package manager then uses to build a
fully reproducible development environment. This environment will contain all
the packages that you require, and will not interfere with any other packages
installed on your system. This essentially means that you can have
project-specific &lt;code&gt;default.nix&lt;/code&gt; files, each specifying the requirements for
specific projects. This file can then be used as-is on any other platform to
re-create your environment. The second reason is that when installing a package
that requires system-level dependencies, &lt;code&gt;{rJava}&lt;/code&gt; for example, all the
lower-level dependencies get automatically installed as well. Forget about
reading error messages of &lt;code&gt;install.packages()&lt;/code&gt; to find which system development
library you need to install first. The third reason is that you can pin a
specific revision of &lt;code&gt;nixpkgs&lt;/code&gt; to ensure reproducibility.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;nixpkgs&lt;/code&gt; mono-repository is “just” a Github repository which you can find
here: &lt;a href=&#34;https://github.com/NixOS/nixpkgs&#34;&gt;https://github.com/NixOS/nixpkgs&lt;/a&gt;. This
repository contains Nix expressions to build and install more than 80’000
packages and you can search for installable Nix packages
&lt;a href=&#34;https://search.nixos.org/packages&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Because &lt;code&gt;nixpkgs&lt;/code&gt; is a “just” Github repository, it is possible to use a
specific commit hash to install the packages as they were at a specific point in
time. For example, if you use this commit, &lt;code&gt;7c9cc5a6e&lt;/code&gt;, you’ll get the very
latest packages as of the 19th of October 2023, but if you used this one
instead: &lt;code&gt;976fa3369&lt;/code&gt;, you’ll get packages from the 19th of August 2023.&lt;/p&gt;
&lt;p&gt;This ability to deal with both underlying system-level dependencies and pin
package versions at a specific commit is extremely useful on Git(Dev)Ops
platforms like Github Actions. Debugging installation failures of packages can
be quite frustrating, especially on Github Actions, and especially if you’re not
already familiar with how Linux distributions work. Having a tool that handles
all of that for you is amazing. The difficult part is writing these
&lt;code&gt;default.nix&lt;/code&gt; files that the Nix package manager requires to actually build
these development environments. But don’t worry, with my co-author &lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp
Baumann&lt;/a&gt;, we developed an R package called
&lt;code&gt;{rix}&lt;/code&gt; which generates these &lt;code&gt;default.nix&lt;/code&gt; files for you.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{rix}&lt;/code&gt; is an R package that makes it very easy to generate very complex
&lt;code&gt;default.nix&lt;/code&gt; files. These files can in turn be used by the Nix package manager
to build project-specific environments. The book’s Github repository contains a
file called &lt;code&gt;define_env.R&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rix)

rix(r_ver = &amp;quot;4.3.1&amp;quot;,
    r_pkgs = c(&amp;quot;quarto&amp;quot;),
    system_pkgs = &amp;quot;quarto&amp;quot;,
    tex_pkgs = c(
      &amp;quot;amsmath&amp;quot;,
      &amp;quot;framed&amp;quot;,
      &amp;quot;fvextra&amp;quot;,
      &amp;quot;environ&amp;quot;,
      &amp;quot;fontawesome5&amp;quot;,
      &amp;quot;orcidlink&amp;quot;,
      &amp;quot;pdfcol&amp;quot;,
      &amp;quot;tcolorbox&amp;quot;,
      &amp;quot;tikzfill&amp;quot;
    ),
    ide = &amp;quot;other&amp;quot;,
    shell_hook = &amp;quot;&amp;quot;,
    project_path = &amp;quot;.&amp;quot;,
    overwrite = TRUE,
    print = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{rix}&lt;/code&gt; ships the &lt;code&gt;rix()&lt;/code&gt; function which takes several arguments. These
arguments allow you to specify an R version, a list of R packages, a list of
system packages, TeXLive packages and other options that allow you to specify
your requirements. Running this code generates this &lt;code&gt;default.nix&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# This file was generated by the {rix} R package v0.4.1 on 2023-10-19
# with following call:
# &amp;gt;rix(r_ver = &amp;quot;976fa3369d722e76f37c77493d99829540d43845&amp;quot;,
#  &amp;gt; r_pkgs = c(&amp;quot;quarto&amp;quot;),
#  &amp;gt; system_pkgs = &amp;quot;quarto&amp;quot;,
#  &amp;gt; tex_pkgs = c(&amp;quot;amsmath&amp;quot;,
#  &amp;gt; &amp;quot;framed&amp;quot;,
#  &amp;gt; &amp;quot;fvextra&amp;quot;,
#  &amp;gt; &amp;quot;environ&amp;quot;,
#  &amp;gt; &amp;quot;fontawesome5&amp;quot;,
#  &amp;gt; &amp;quot;orcidlink&amp;quot;,
#  &amp;gt; &amp;quot;pdfcol&amp;quot;,
#  &amp;gt; &amp;quot;tcolorbox&amp;quot;,
#  &amp;gt; &amp;quot;tikzfill&amp;quot;),
#  &amp;gt; ide = &amp;quot;other&amp;quot;,
#  &amp;gt; project_path = &amp;quot;.&amp;quot;,
#  &amp;gt; overwrite = TRUE,
#  &amp;gt; print = TRUE,
#  &amp;gt; shell_hook = &amp;quot;&amp;quot;)
# It uses nixpkgs&amp;#39; revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
# which will install R version 4.3.1
# Report any issues to https://github.com/b-rodrigues/rix
let
 pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) quarto;
};
  tex = (pkgs.texlive.combine {
  inherit (pkgs.texlive) scheme-small amsmath framed fvextra environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
});
 system_packages = builtins.attrValues {
  inherit (pkgs) R glibcLocalesUtf8 quarto;
};
  in
  pkgs.mkShell {
    LOCALE_ARCHIVE = if pkgs.system == &amp;quot;x86_64-linux&amp;quot; then  &amp;quot;${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive&amp;quot; else &amp;quot;&amp;quot;;
    LANG = &amp;quot;en_US.UTF-8&amp;quot;;
    LC_ALL = &amp;quot;en_US.UTF-8&amp;quot;;
    LC_TIME = &amp;quot;en_US.UTF-8&amp;quot;;
    LC_MONETARY = &amp;quot;en_US.UTF-8&amp;quot;;
    LC_PAPER = &amp;quot;en_US.UTF-8&amp;quot;;
    LC_MEASUREMENT = &amp;quot;en_US.UTF-8&amp;quot;;

    buildInputs = [  rpkgs tex system_packages  ];
  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This file defines the environment that is needed to build your book: be it
locally on your machine, or on a GitOps platform like Github Actions. All that
matters is that you have the Nix package manager installed (thankfully, it’s
available for Windows –through WSL2–, Linux and macOS).&lt;/p&gt;
&lt;p&gt;Being able to work locally on a specific environment, defined through code, and
use that environment on the cloud as well, is great. It doesn’t matter that the
code runs on Ubuntu on the Github Actions runner, and if that operating system
is not the one you use as well. Thanks to Nix, your code will run on exactly the
same environment. Because of that, you can use &lt;code&gt;ubuntu-latest&lt;/code&gt; as your runner,
because exactly the same packages will always get installed. This is not the
case with my first template that uses dedicated actions and &lt;code&gt;{renv}&lt;/code&gt;: there, the
runner uses &lt;code&gt;ubuntu-22.04&lt;/code&gt;, a fixed version of the Ubuntu operating system. The
risk here, is that once these runners get decommissioned (Ubuntu 22.04 is a
&lt;em&gt;long-term support&lt;/em&gt; release of Ubuntu, so it’ll stop getting updated sometime in
2027), my code won’t be able to run anymore. This is because there’s no
guarantee that the required version of R, Quarto, and all the other packages I
need will be installable on that new release of Ubuntu. So for example, suppose
I have the package &lt;code&gt;{foo}&lt;/code&gt; at version 1.0 that requires the system-level
development library &lt;code&gt;bar-dev&lt;/code&gt; at version 0.4 to be installed on Ubuntu. This is
not an issue now, as Ubuntu 22.04 ships version 0.4 of &lt;code&gt;bar-dev&lt;/code&gt;. But it is very
unlikely that the future version of Ubuntu from 2027 will ship that version, and
there’s no guarantee my package will successfully build and work as expected
with a more recent version of &lt;code&gt;bar-dev&lt;/code&gt;. With Nix, this is not an issue; because
I pin a specific commit of &lt;code&gt;nixpkgs&lt;/code&gt;, not only will &lt;code&gt;{foo}&lt;/code&gt; at version 1.0 get
installed, its dependency &lt;code&gt;bar-dev&lt;/code&gt; at version 0.4 will get installed by Nix as
well, and get used to build &lt;code&gt;{foo}&lt;/code&gt;. It doesn’t matter that my underlying
operating system ships a more recent version of &lt;code&gt;bar-dev&lt;/code&gt;. I really insist on
this point, because this is not something that you can easily deal with, even
with Docker. This is because when you use Docker, you need to be able to rebuild
the image as many times as you need (the alternative is to store, forever, the
built image), and just like for Github Actions runners, the underlying Ubuntu
image will be decommissioned and stop working one day.&lt;/p&gt;
&lt;p&gt;In other words, if you need long-term reproducibility, you should really
consider using Nix, and even if you don’t need long-term reproducibility, you
should really consider using Nix. This is because Nix makes things much easier.
But there is one point where Nix is at a huge disadvantage when compared to the
alternatives: the entry cost is quite high, as I’ve discussed in my &lt;a href=&#34;https://www.brodrigues.co/blog/2023-10-05-repro_overview/&#34;&gt;previous
blog post&lt;/a&gt;. But I’m
hoping that through my blog posts, this entry cost is getting lowered for R
users!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An overview of what&#39;s out there for reproducibility with R</title>
      <link>https://www.brodrigues.co/blog/2023-10-05-repro_overview/</link>
      <pubDate>Thu, 05 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-10-05-repro_overview/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/like_this.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this short blog post I’ll be summarizing what I learnt these past years about
reproducibility with R. I’ll give some high-level explanations about different
tools and then link to different blog posts of mine.&lt;/p&gt;
&lt;p&gt;I see currently two main approaches with some commonalities, so let’s start with
the commonalities.&lt;/p&gt;
&lt;div id=&#34;commonalities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Commonalities&lt;/h2&gt;
&lt;p&gt;These are aspects that I think will help you build reproducible projects, but
that are not strictly necessary. These are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Git for code versioning;&lt;/li&gt;
&lt;li&gt;unit tests (be it on your code or data);&lt;/li&gt;
&lt;li&gt;literate programming;&lt;/li&gt;
&lt;li&gt;packaging code;&lt;/li&gt;
&lt;li&gt;build automation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think that these aspects are really very important nice-to-haves, but
depending on the project you might not have to use all these tools or techniques
(but I would really recommend that you think very hard about these requirements
and make sure that you actually, really, don’t need them).&lt;/p&gt;
&lt;p&gt;What’s also important is how you organize the work if you’re in a team. Making
sure that everyone is on the same page and uses the same tools and approaches is
very important.&lt;/p&gt;
&lt;p&gt;Now that we have the commonalities out of the way, let’s discuss the “two
approaches”. Let’s start by the most popular one.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-and-something-else&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Docker and “something else”&lt;/h2&gt;
&lt;p&gt;Docker is a very popular containerisation solution. The idea is to build an
&lt;em&gt;image&lt;/em&gt; that contains everything needed to run and rebuild your project in a
single command. You can add a specific version of R with the required packages
in it, your project files and so on. You could even add the data directly into
the image or provide the required data at run-time, it’s up to you.&lt;/p&gt;
&lt;p&gt;The “something else” can be several things, but they all deal with the problem
of providing the right packages for your analysis. You see, if you run an
analysis today, you’ll be using certain versions of packages. The same versions
of packages need to be made available inside that Docker image. To do so, a
popular choice for R users is to use
&lt;a href=&#34;https://rstudio.github.io/renv/index.html&#34;&gt;{renv}&lt;/a&gt;, but there’s also
&lt;a href=&#34;https://groundhogr.com/&#34;&gt;{groundhog}&lt;/a&gt; and
&lt;a href=&#34;https://github.com/gesistsa/rang&#34;&gt;{rang}&lt;/a&gt;. You could also use CRAN snapshots
from the &lt;a href=&#34;https://packagemanager.posit.co/client/#/repos/cran/setup?snapshot=2023-09-25&amp;amp;r_environment=other&#34;&gt;Posit Public Package
Manager&lt;/a&gt;.
Whatever you choose, Docker by itself is not enough: Docker provides a base
where you can then add these other things on top.&lt;/p&gt;
&lt;p&gt;To know more, read this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;https://www.brodrigues.co/blog/2022-11-19-raps/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-30-pipelines-as/&#34;&gt;https://www.brodrigues.co/blog/2022-11-30-pipelines-as/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/&#34;&gt;https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-01-12-repro_r/&#34;&gt;https://www.brodrigues.co/blog/2023-01-12-repro_r/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By combining Docker plus any of the other packages listed above (or by using the
PPPM) you can quite easily build reproducible projects, because what you end up
doing, is essentially building something like a capsule that contains everything
needed to run the project (this capsule is what is called an &lt;em&gt;image&lt;/em&gt;). Then, you
don’t run R and the scripts to build the project, you run the image, and within
that image, R is executed on the provided scripts. This running instance of an
image is called a &lt;em&gt;container&lt;/em&gt;. This approach is by far the most popular and can
even be used on Github Actions if your project is hosted on Github. On a scale
from 1 to 10, I would say that the entry cost is about 3 if you already have
some familiarity with Linux, but can go up to 7 if you’ve never touched Linux.
What does Linux have to do with all this? Well, the Docker images that you are
going to build will be based on Linux (most of the time the Ubuntu distribution)
so familiarity with Linux or Ubuntu is a huge plus. You could use &lt;code&gt;{renv}&lt;/code&gt;,
&lt;code&gt;{rang}&lt;/code&gt; or &lt;code&gt;{groundhog}&lt;/code&gt; without Docker, directly on your PC, but the issue
here is that your operating system and the version of R changes through time.
And both of these can have an impact on the reproducibility of your project.
Hence, why we use Docker to, in a sense, “freeze” both the underlying operating
system and version of R inside that image, and then, every container executed
from that image will have the required versions of software.&lt;/p&gt;
&lt;p&gt;One issue with Docker is that if you build an image today, the underlying Linux
distribution will get out of date at some point, and you won’t be able to
rebuild the image. So you either need to build the image and store it forever,
or you need to maintain your image and port your code to newer base Ubuntu
images.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nix&lt;/h2&gt;
&lt;p&gt;Nix is a package manager for Linux (and Windows through WSL) and macOS, but also
a programming language that focuses on reproducibility of software builds,
meaning that using Nix it’s possible to build software in a completely
reproducible way. Nix is incredibly flexible, so it’s also possible to use it to
build reproducible development environments, or run reproducible analytical
pipelines. What Nix doesn’t easily allow, unlike &lt;code&gt;{renv}&lt;/code&gt; for example, is to
install a specific version of one specific package. But I also wrote a package
called &lt;a href=&#34;https://b-rodrigues.github.io/rix/&#34;&gt;{rix}&lt;/a&gt; (co-authored by Philipp
Baumann) that makes it easier for R users to get started with Nix and also
allows to install arbitrary versions of packages easily using the Nix package
manager. So you can define an environment with any version of R, plus
corresponding packages, and install specific versions of specific packages if
needed as well. Packages that are hosted on Github can also get easily installed
if needed. Let me make this clear: using Nix, you install both R and R packages
so there’s no need to use &lt;code&gt;install.packages()&lt;/code&gt; anymore. Everything is managed by
Nix.&lt;/p&gt;
&lt;p&gt;Using Nix, we can define our environment and build instructions as code, and
have the build process always produce exactly the same result. This definition
of the environment and build instructions are written using the Nix programming
language inside a simple text file, which then gets used to actually realize the
build. This means that regardless of “when” or “where” you rebuild your project,
&lt;em&gt;exactly&lt;/em&gt; the same packages (all the way down to the system libraries and
compilers and all that stuff we typically never think about) will get installed
to rebuild the project.&lt;/p&gt;
&lt;p&gt;Essentially, using the Nix package manager, you can replace Docker + any of the
other tools listed above to build reproducible projects. The issue with Nix
however is that the entry cost is quite high: even if you’re already familiar
with Linux and package managers, Nix is really an incredible deep tool. So I
would say that the entry cost is around 9 out of 10…, but to bring this entry
cost down, I have written 6 blog posts to get you started:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&#34;&gt;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/&#34;&gt;https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-30-nix_for_r_part3/&#34;&gt;https://www.brodrigues.co/blog/2023-07-30-nix_for_r_part3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4/&#34;&gt;https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-09-15-nix_for_r_part5/&#34;&gt;https://www.brodrigues.co/blog/2023-09-15-nix_for_r_part5/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/&#34;&gt;https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, by the way, it is entirely possible to build a Docker image based on
Ubuntu, install the Nix package manager on it, and then use Nix inside Docker
to install the right software to build a reproducible project. This approach
is extremely flexible, as it uses the best of both worlds in my opinion: we can
take advantage of the popularity of Docker so that we can run containers
anywhere, but use Nix to truly have reproducible builds. This also solves the
issue I discussed before: if you’re using Nix inside Docker, it doesn’t matter
if the base image gets outdated: simply use a newer base image, and Nix will
take care of always installing the right versions of the needed pieces of
software for your project.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So which should you learn, Docker or Nix? While Docker is certainly more popular
these days, I think that Nix is very interesting and not that hard to use
&lt;strong&gt;once&lt;/strong&gt; you learnt the basics (which does take some time). But the entry costs
for any of these tools is in the end quite high and, very annoyingly, building
reproducible projects does not get enough recognition, even in science where
reproducibility is supposedly one of its corner stones. However, I think that
you should definitely invest time in learning the tools and best practices
required for building reproducible projects, because by making sure that a
project is reproducible you end up increasing its quality as well. Furthermore,
you avoid stressful situations where you get asked “hey, where did that
graph/result/etc come from?” and you have no idea why the script that supposedly
built that output does not reproduce the same output again.&lt;/p&gt;
&lt;p&gt;If you read all the blog posts above but still want to learn and know more about
reproducibility you can get my &lt;a href=&#34;https://leanpub.com/raps-with-r/c/blog_reader&#34;&gt;ebook at a
discount&lt;/a&gt; or get a physical copy
on
&lt;a href=&#34;https://www.amazon.com/Building-reproducible-analytical-pipelines-R/dp/B0C87H6MGF/ref=sr_1_1?keywords=building+reproducible+analytical+pipelines&amp;amp;sr=8-1&#34;&gt;Amazon&lt;/a&gt;
or you can &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;read it for free&lt;/a&gt;. That book does not
discuss Nix, but I will very certainly be writing another book focusing this
time on Nix during 2024.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ZSA Voyager review</title>
      <link>https://www.brodrigues.co/blog/2023-09-29-voyager/</link>
      <pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-09-29-voyager/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=NlgmH5q9uNk&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/travelling_with_my_keyboard.png&#34; title = &#34;Click for banger&#34; width=&#34;70%&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now for something completely different than our usual programming: today I’m
sharing my thoughts on the latest ZSA mechanical keyboard, the
&lt;a href=&#34;https://www.zsa.io/voyager/buy/&#34;&gt;Voyager&lt;/a&gt;. First things first: this is in no
way shape or form sponsored by ZSA. But Erez, if you’d like to send me money
you’re more than welcome.&lt;/p&gt;
&lt;p&gt;Here’s what the keyboard looks like:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;854&#34; height=&#34;480&#34; controls autoplay muted loop&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/voyager.mp4&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Yes, it comes with RGB LEDs. Why do mechanical keyboards come with RGB LEDs? No
idea, I usually don’t care for them, but unlike other keyboards from ZSA, you
cannot order the Voyager without them. So now my keyboard looks like a Christmas
tree. And by the way, yes, you can get the good old regular QWERTY layout
instead of the dots. I chose to get blank keys because I don’t look at my
keyboard when typing.&lt;/p&gt;
&lt;p&gt;It’s quite small and there aren’t many keys on it. But it’s very comfortable
to use. I’ll try to explain why.&lt;/p&gt;
&lt;p&gt;If you don’t know anything about mechanical keyboards, I think you might find
this blog post useful. I’ll explain the basics and also why you might want to
consider one if you’re a programmer.&lt;/p&gt;
&lt;p&gt;First of all, let me just get this out of the way: typing on a mechanical
keyboard will not make you type any faster. I think that people that buy
mechanical keyboards also tend to be people that spend some time learning how to
touch-type, so yeah, they’ll type faster than most people that never bother to
learn to touch-type, but two touch-typists, one that use a mechanical keyboard
and another that uses a normal keyboard, will roughly type at the same speed.&lt;/p&gt;
&lt;p&gt;So if not for speed, why bother with mechanical keyboards?&lt;/p&gt;
&lt;p&gt;In my opinion, the main advantage of mechanical keyboards is customization. You
can customize absolutely everything: not just how the keyboard looks, but also
how it works. Many mechanical keyboards come with a firmware called QMK which
enables you to program each key. So for instance I have a key that types “&amp;lt;-”
and another that types “%&amp;gt;%”, very useful for an R programmer like myself. You
can configure such things at the level of you favourite text editor, but it’s
nice to also have the option at the level of the hardware, because it means that
you can now easily type these programming symbols anywhere: on social media, an
email, a forum… Configuring this firmware on keyboards made by ZSA, like the
Voyager, is incredibly easy: there’s a web-application called Oryx that you can
use for all they keyboards. Simply select the keys, change what you must and
flash the new firmware to your keyboard! For example here, I’m configuring a
key to output “,” when pressed, but to output “_” when double-tapped:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/oryx.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And for the flashing process you don’t even have to install anything on your
computer: if you’re using a Chromium based browser like Google Chrome, you can
flash it from the Web Browser. You can even browse other people’s
configurations, for example here’s
&lt;a href=&#34;https://configure.zsa.io/voyager/layouts/l9eWG/ErJeQ/0&#34;&gt;mine&lt;/a&gt; (and you can even
customize the RGB).&lt;/p&gt;
&lt;p&gt;I use the French ergonomic BÉPO layout, the English equivalent would be Dvorak.
You can add different layers, for example by holding one key, all the other keys
now output something different when pressed (like holding down the SHIFT key
produces capital letters), but you can make any key switch layers and then any
other key output anything. For example I have a layer in which I configured keys
to move my mouse and click. I don’t use that very often, but in case I forget my
mouse if I’m traveling, I could also use my keyboard as a mouse now.&lt;/p&gt;
&lt;p&gt;Hardware can also be customized: the color of the keyboard, but also the keycaps
(I have the blank ones, as you’ve seen above) and also the switches. If
you’re not into mechanical keyboard I guess this doesn’t mean anything. Keycaps
are these:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/caps.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and switches are these:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/switches.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And you can change either the caps, the switches or both. The keyboard is
&lt;em&gt;hot-swapable&lt;/em&gt; meaning that you can actually replace the switches. Here is a
switch with a keycap on it that I removed from my keyboard:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;854&#34; height=&#34;480&#34; controls loop&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/pressing_switch.mp4&#34; type=&#34;video/mp4&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Again, if you’re not into mechanical keyboard it’s difficult to see why this is
really a nice thing: but being able to change caps and switches allows you to
truly make the keyboard feel and sound just right for you.&lt;/p&gt;
&lt;p&gt;Let me explain: there’s switches that make no sound and that are very easy to
press: they’re called linear switches. Then there’s switches that make a nice
clicky sound and that require more force to press, and there’s switches that
make even more noise and that require a lot of force to press. The harder ones
are so-called “clicky” switches and the intermediate ones “tactile”. There’s a
lot more subtlety than that, but even I don’t know everything about switches.
What matters is that you can swap these, and find the ones that are just right
for you. My first mechanical keyboard, also one from ZSA, the Ergodox EZ
(pictured below) came with red switches. At the time, I had no idea what
switches I should get, so I bought the reds because they were silent, and I
figured that I would prefer silent ones. Turns out that I absolutely hated them.
It didn’t fill right because they were extremely light, and simply by resting my
hands on the keyboard I would press keys by mistake. Then I bought clicky
switches, and since then haven’t looked back. Clicky switches make a nice
“click” sound when you press them, because there’s actually a little mechanism
that produces this noise when you press them. It’s like pushing an actual
button. Much more satisfying, and much better, in my opinion, for typing. So for
this board I got the white ones, which are the clickiest. It’s also the one’s I
had for my other mechanical keyboard, the Planck EZ, also by ZSA:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/planck.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I also experimented with heavier ones on my other board (an Idobao ID75, a
somewhat overgrown Planck, not by ZSA but also very customizable through
&lt;a href=&#34;https://get.vial.today/&#34;&gt;VIAL&lt;/a&gt;):&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/idobao.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The switches there are heavier, and I enjoy them a lot as well.&lt;/p&gt;
&lt;p&gt;Now, this keyboard isn’t cheap, but it does come with a lot of nice stuff in the
box. You get 3 usb cables, 4 more switches, several keycaps more, and a carrying
bag.&lt;/p&gt;
&lt;p&gt;And as you can see, it’s a so-called low profile keyboard:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/low_voyager_1.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can even remove these little feet from the keyboard (they’re magnetic):&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/magnetic_feet.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;to get it even lower:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/low_voyager_2.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve never had such a keyboard in the past and I must say that it’s really
comfortable to use. I don’t need to use any wrist rests anymore, which is kinda
nice. Because it’s low-profile the switches and keycaps are different from the
usual ones you get for other mechanical keyboards:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/mx_vs_choc.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Anyways, I really enjoy this form factor, not just that it’s low profile, but
also that it doesn’t have a lot of keys. I like this, because my hands don’t
need to move at all. If I need numbers for example, I switch layers, and now the
keys that would usually be directly under my fingers will output numbers when
pressed. So instead of my fingers going to the keys, they keys go to my fingers.
It gets some time to get used to this, but once you know how to do that, it’s
just great.&lt;/p&gt;
&lt;p&gt;So, should you buy a Voyager? I might not advise it to you for a first
mechanical keyboard. There’s much cheaper ones that you can get and see if
mechanical keyboards are for you. If you can, try some out in a store, I think
it’s especially important to find the right switches for your style. As I’ve
written above, I started with linear reds which I hated, thankfully I tried
clicky whites before abandoning my mechanical keyboard adventure. If you’re
already a hardened mechanical keyboard user, and are looking for a light
keyboard that you can take with you on your travels, I think that it’s hard to
overlook the Voyager. There are other nice, very transportable keyboards out
there, but the build quality of ZSA and the firmware customization tool they
provide, Oryx, is hard to beat.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 6 -- CI/CD has never been easier</title>
      <link>https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/</link>
      <pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gymnastics.png&#34; width=&#34;50%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Warning: I highly recommend you read this &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/&#34;&gt;blog
post&lt;/a&gt; first, which
will explain how to run a pipeline inside Nix in detail. This blog post will
assume that you’ve read that one, and it would also help if you’re familiar with
Github Actions, if not, read this &lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;other blog post of mine as
well&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is getting ridiculous. The meme that I’m using as a header for this blog
post perfectly summaries how I feel.&lt;/p&gt;
&lt;p&gt;This will be a short blog post, because Nix makes things so easy that there’s
not much to say. I wanted to try how I could use Nix on Github Actions to run a
reproducible pipeline. This pipeline downloads some data, prepares it, and fits
a machine learning model. It is code that I had laying around from an old video
on the now deprecated &lt;code&gt;{drake}&lt;/code&gt; package, &lt;code&gt;{targets}&lt;/code&gt; predecessor.&lt;/p&gt;
&lt;p&gt;You can find the pipeline
&lt;a href=&#34;https://github.com/b-rodrigues/nix_ml_cicd_demo/tree/main&#34;&gt;here&lt;/a&gt;
and you can also take a look at the same pipeline but which uses Docker
&lt;a href=&#34;https://github.com/b-rodrigues/mlops_demo&#34;&gt;here&lt;/a&gt;
for comparison purposes.&lt;/p&gt;
&lt;p&gt;What I wanted to achieve was the following: I wanted to set up a reproducible
environment with Nix on my computer, work on my pipeline locally, and then have
it run on Github Actions as well. But I wanted my pipeline to run exactly on the
same environment as the one I was using to develop it. In a world without Nix,
this means using a mix of &lt;code&gt;{renv}&lt;/code&gt; (or &lt;code&gt;{groundhog}&lt;/code&gt; or &lt;code&gt;{rang}&lt;/code&gt;) and a Docker
image that ships the right version of R. I would then need to write a Github
Actions workflow file that builds that Docker image, then runs it and saves the
outputs as artifacts. Also, in practice that image would not be exactly the same
as my local environment: I would have the same version of R and R packages, but
every other system-level dependency would be a different version unless I use
that Dockerized environment to develop locally, something I suggested you should
do merely &lt;a href=&#34;https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/&#34;&gt;4 months
ago&lt;/a&gt; (oooh, how blind
was I!).&lt;/p&gt;
&lt;p&gt;With Nix, not only can I take care of the version of R and R packages with one
single tool but also every underlying system-level dependency gets handled by
Nix. So if I use a package that requires, say, Java, or GDAL, or any other of
these usual suspects that make installing their R bindings so tricky, Nix will
handle this for me without any intervention on my part. I can also use this
environment to develop locally, and then, once I’m done working locally,
&lt;em&gt;exactly&lt;/em&gt; this environment, &lt;em&gt;exactly&lt;/em&gt; every bit of that environment, will get
rebuilt and used to run my code on Github Actions.&lt;/p&gt;
&lt;p&gt;So &lt;a href=&#34;https://github.com/b-rodrigues/nix_ml_cicd_demo&#34;&gt;this is the repository&lt;/a&gt;
where you can find the code. There’s a &lt;code&gt;{targets}&lt;/code&gt; script that defines the
pipeline and a &lt;code&gt;functions/&lt;/code&gt; folder with some code that I wrote for said
pipeline. What’s unfamiliar to you (unless you’ve been reading my Nix adventures
since the beginning) is the &lt;code&gt;default.nix&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let
 pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) tidymodels vetiver targets xgboost;
};
 system_packages = builtins.attrValues {
  inherit (pkgs) R;
};
in
 pkgs.mkShell {
  buildInputs = [  rpkgs system_packages  ];
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This few lines of code define an environment that pulls packages from revision
&lt;code&gt;976fa3369d722e76f37c77493d99829540d43845&lt;/code&gt; of &lt;code&gt;nixpkgs&lt;/code&gt;. It installs the
packages &lt;code&gt;{tidymodels}&lt;/code&gt;, &lt;code&gt;{vetiver}&lt;/code&gt;, &lt;code&gt;{targets}&lt;/code&gt; and &lt;code&gt;{xgboost}&lt;/code&gt; (actually, I’m
not using &lt;code&gt;{vetiver}&lt;/code&gt; for this &lt;em&gt;yet&lt;/em&gt;, so it could even be removed). Then it also
installs R. Because we’re using that specific revision of Nix, exactly the same
packages (and their dependencies) will get installed, regardless of when we
build this environment. I want to insist that this file is 12 lines long and it
defines a complete environment. The equivalent &lt;code&gt;Dockerfile&lt;/code&gt; is much longer, and
not even completely reproducible, and I would have needed external tools like
&lt;code&gt;{renv}&lt;/code&gt; (or use the Posit CRAN mirror dated snapshots) as you can check out
&lt;a href=&#34;https://github.com/b-rodrigues/mlops_demo&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s now turn our attention to the workflow file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: train_model

on:
  push:
    branches: [main]

jobs:
  targets:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
    steps:

      - uses: actions/checkout@v3

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@main
        with:
          logger: pretty
          log-directives: nix_installer=trace
          backtrace: full

      - name: Nix cache
        uses: DeterminateSystems/magic-nix-cache-action@main

      - name: Build development environment
        run: |
          nix-build

      - name: Check if previous runs exists
        id: runs-exist
        run: git ls-remote --exit-code --heads origin targets-runs
        continue-on-error: true

      - name: Checkout previous run
        if: steps.runs-exist.outcome == &amp;#39;success&amp;#39;
        uses: actions/checkout@v2
        with:
          ref: targets-runs
          fetch-depth: 1
          path: .targets-runs

      - name: Restore output files from the previous run
        if: steps.runs-exist.outcome == &amp;#39;success&amp;#39;
        run: |
          nix-shell default.nix --run &amp;quot;Rscript -e &amp;#39;for (dest in scan(\&amp;quot;.targets-runs/.targets-files\&amp;quot;, what = character())) {
            source &amp;lt;- file.path(\&amp;quot;.targets-runs\&amp;quot;, dest)
            if (!file.exists(dirname(dest))) dir.create(dirname(dest), recursive = TRUE)
            if (file.exists(source)) file.rename(source, dest)
          }&amp;#39;&amp;quot;

      - name: Run model
        run: |
          nix-shell default.nix --run &amp;quot;Rscript -e &amp;#39;targets::tar_make()&amp;#39;&amp;quot;

      - name: Identify files that the targets pipeline produced
        run: git ls-files -mo --exclude=renv &amp;gt; .targets-files

      - name: Create the runs branch if it does not already exist
        if: steps.runs-exist.outcome != &amp;#39;success&amp;#39;
        run: git checkout --orphan targets-runs

      - name: Put the worktree in the runs branch if the latter already exists
        if: steps.runs-exist.outcome == &amp;#39;success&amp;#39;
        run: |
          rm -r .git
          mv .targets-runs/.git .
          rm -r .targets-runs

      - name: Upload latest run
        run: |
          git config --local user.name &amp;quot;GitHub Actions&amp;quot;
          git config --local user.email &amp;quot;actions@github.com&amp;quot;
          rm -r .gitignore .github/workflows
          git add --all -- &amp;#39;:!renv&amp;#39;
          for file in $(git ls-files -mo --exclude=renv)
          do
            git add --force $file
          done
          git commit -am &amp;quot;Run pipeline&amp;quot;
          git push origin targets-runs

      - name: Prepare failure artifact
        if: failure()
        run: rm -rf .git .github .targets-files .targets-runs

      - name: Post failure artifact
        if: failure()
        uses: actions/upload-artifact@main
        with:
          name: ${{ runner.os }}-r${{ matrix.config.r }}-results
          path: .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The workflow file above is heavily inspired from the one you get when you run
&lt;code&gt;targets::tar_github_actions()&lt;/code&gt;. Running this puts the following
&lt;a href=&#34;https://github.com/ropensci/targets/blob/22103e19584ea15ae44328c07bc9d2699b004a47/inst/templates/github_actions.yaml&#34;&gt;file&lt;/a&gt;
on the root of your &lt;code&gt;{targets}&lt;/code&gt; project. This file is a Github Actions workflow
file, which means that each time you push your code on Github, the pipeline will
run in the cloud. However it needs you to use &lt;code&gt;{renv}&lt;/code&gt; with the project so that
the right packages get installed. You’ll also see a step called &lt;code&gt;Install Linux dependencies&lt;/code&gt; which you will have to adapt to your project.&lt;/p&gt;
&lt;p&gt;All of this can be skipped when using Nix. All that must be done is installing
Nix itself, using the &lt;code&gt;nix-installer-action&lt;/code&gt; from Determinate Systems, then
using the &lt;code&gt;magic-nix-cache-action&lt;/code&gt; which caches the downloaded packages so we
don’t need to wait for the environment to build each time we push (unless we
changed the environment of course) and that’s about it. We then build the
environment on Github Actions using &lt;code&gt;nix-build&lt;/code&gt; and then run the pipeline using
&lt;code&gt;nix-shell default.nix --run &#34;Rscript -e &#39;targets::tar_make()&#39;&#34;&lt;/code&gt;. All the other
steps are copied almost verbatim from the linked file above and make sure that
the computed targets only get recomputed if I edit anything that impacts them,
and also that they get pushed into a branch called &lt;code&gt;targets-runs&lt;/code&gt;. I say &lt;em&gt;copied
almost verbatim&lt;/em&gt; because some steps must run inside R, so we need to specify
that we want to use the R that is available through the Nix environment we just
built.&lt;/p&gt;
&lt;p&gt;Now, each time we push, the following happens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if we didn’t change anything to &lt;code&gt;default.nix&lt;/code&gt;, the environment gets retrieved from the cache. If we did change something, then environment gets rebuilt (or rather, only the parts that need to be rebuilt, the rest will still get retrieved from the cache)&lt;/li&gt;
&lt;li&gt;if we didn’t change anything to the &lt;code&gt;_targets.R&lt;/code&gt; pipeline itself, then every target will get skipped. If not, only the targets that need to get recomputed will get recomputed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One last thing that I didn’t mention: on line 9 you’ll see this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;runs-on: ubuntu-latest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this means that the Github Actions will run on the latest available version of
Ubuntu, which is obviously not fixed. When the next LTS gets released in April
2024, this pipeline will be running on Ubuntu 24.04 instead of the current LTS,
version 22.04. This is not good practice because we don’t want the underlying
operating system to be changing, because this could have an impact on the
reproducibility of our pipeline. But with Nix, this &lt;strong&gt;does not matter&lt;/strong&gt;.
Remember that we are using a specific revision of &lt;code&gt;nixpkgs&lt;/code&gt; for our pipeline, so
the &lt;em&gt;exact&lt;/em&gt; same version of not only R and R packages gets installed, but every
underlying piece of software that needs to be available will be installed as
well. We could be running this in 50 years on Ubuntu LTS 74.04 and it would
still install the same stuff and run the same code and produce exactly the same
results.&lt;/p&gt;
&lt;p&gt;This is really bonkers.&lt;/p&gt;
&lt;p&gt;Nix is an incredibly powerful tool. I’ve been exploring and using it for 3
months now, but if something impresses me more than how useful it is, is how
terribly unknown it still is. I hope that this series of blog posts will
motivate other people to learn it.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 5 -- Reproducible literate programming with Nix and Quarto</title>
      <link>https://www.brodrigues.co/blog/2023-09-15-nix_for_r_part5/</link>
      <pubDate>Fri, 15 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-09-15-nix_for_r_part5/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/ayylmao.png&#34; max-width=&#34;100%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This blog post is a copy-paste from &lt;a href=&#34;https://b-rodrigues.github.io/rix/articles/building-an-environment-for-literate-programming.html&#34;&gt;this vignette&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This vignette will walk you through setting up a development environment with
&lt;code&gt;{rix}&lt;/code&gt; that can be used to compile Quarto documents into PDFs. We are going to
use the &lt;a href=&#34;https://github.com/quarto-journals/jss&#34;&gt;Quarto template for the JSS&lt;/a&gt; to
illustrate the process. The first section will show a simple way of achieving
this, which will also be ideal for interactive development (writing the doc).
The second section will discuss a way to build the document in a completely
reproducible manner once it’s done.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;starting-with-the-basics-simple-but-not-entirely-reproducible&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Starting with the basics (simple but not entirely reproducible)&lt;/h2&gt;
&lt;p&gt;This approach will not be the most optimal, but it will be the simplest. We will
start by building a development environment with all our dependencies, and we
can then use it to compile our document interactively. But this approach is not
quite reproducible and requires manual actions. In the next section we will show
you to build a 100% reproducible document in a single command.&lt;/p&gt;
&lt;p&gt;Since we need both the &lt;code&gt;{quarto}&lt;/code&gt; R package as well as the &lt;code&gt;quarto&lt;/code&gt; engine, we
add both of them to the &lt;code&gt;r_pkgs&lt;/code&gt; and &lt;code&gt;system_pkgs&lt;/code&gt; of arguments of &lt;code&gt;{rix}&lt;/code&gt;.
Because we want to compile a PDF, we also need to have &lt;code&gt;texlive&lt;/code&gt; installed, as
well as some LaTeX packages. For this, we use the &lt;code&gt;tex_pkgs&lt;/code&gt; argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rix)

path_default_nix &amp;lt;- tempdir()

rix(r_ver = &amp;quot;4.3.1&amp;quot;,
    r_pkgs = c(&amp;quot;quarto&amp;quot;),
    system_pkgs = &amp;quot;quarto&amp;quot;,
    tex_pkgs = c(&amp;quot;amsmath&amp;quot;),
    ide = &amp;quot;other&amp;quot;,
    shell_hook = &amp;quot;&amp;quot;,
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &amp;gt;rix(r_ver = &amp;quot;976fa3369d722e76f37c77493d99829540d43845&amp;quot;,
## #  &amp;gt; r_pkgs = c(&amp;quot;quarto&amp;quot;),
## #  &amp;gt; system_pkgs = &amp;quot;quarto&amp;quot;,
## #  &amp;gt; tex_pkgs = c(&amp;quot;amsmath&amp;quot;),
## #  &amp;gt; ide = &amp;quot;other&amp;quot;,
## #  &amp;gt; project_path = path_default_nix,
## #  &amp;gt; overwrite = TRUE,
## #  &amp;gt; print = TRUE,
## #  &amp;gt; shell_hook = &amp;quot;&amp;quot;)
## # It uses nixpkgs&amp;#39; revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == &amp;quot;x86_64-linux&amp;quot; then  &amp;quot;${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive&amp;quot; else &amp;quot;&amp;quot;;
##     LANG = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_ALL = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_TIME = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MONETARY = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_PAPER = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MEASUREMENT = &amp;quot;en_US.UTF-8&amp;quot;;
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Save these lines into a script called &lt;code&gt;build_env.R&lt;/code&gt; for instance, and run the
script into a new folder made for this project.)&lt;/p&gt;
&lt;p&gt;By default, &lt;code&gt;{rix}&lt;/code&gt; will install the “small” version of the &lt;code&gt;texlive&lt;/code&gt;
distribution available on Nix. To see which &lt;code&gt;texlive&lt;/code&gt; packages get installed
with this small version, you can click
&lt;a href=&#34;https://search.nixos.org/packages?channel=unstable&amp;amp;show=texlive.combined.scheme-small&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=scheme-small&#34;&gt;here&lt;/a&gt;.
We start by adding the &lt;code&gt;amsmath&lt;/code&gt; package then build the environment using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nix_build()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, drop into the Nix shell with &lt;code&gt;nix-shell&lt;/code&gt;, and run &lt;code&gt;quarto add quarto-journals/jss&lt;/code&gt;. This will install the template linked above. Then, in the
folder that contains &lt;code&gt;build_env.R&lt;/code&gt;, the generated &lt;code&gt;default.nix&lt;/code&gt; and &lt;code&gt;result&lt;/code&gt;
download the following files from
&lt;a href=&#34;https://github.com/quarto-journals/jss/&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;article-visualization.pdf&lt;/li&gt;
&lt;li&gt;bibliography.bib&lt;/li&gt;
&lt;li&gt;template.qmd&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and try to compile &lt;code&gt;template.qmd&lt;/code&gt; by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;quarto render template.qmd --to jss-pdf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should get the following error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Quitting from lines 99-101 [unnamed-chunk-1] (template.qmd)
Error in `find.package()`:
! there is no package called &amp;#39;MASS&amp;#39;
Backtrace:
 1. utils::data(&amp;quot;quine&amp;quot;, package = &amp;quot;MASS&amp;quot;)
 2. base::find.package(package, lib.loc, verbose = verbose)
Execution halted
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So there’s an R chunk in &lt;code&gt;template.qmd&lt;/code&gt; that uses the &lt;code&gt;{MASS}&lt;/code&gt; package. Change
&lt;code&gt;build_env.R&lt;/code&gt; to generate a new &lt;code&gt;default.nix&lt;/code&gt; file that will now add &lt;code&gt;{MASS}&lt;/code&gt; to
the environment when built:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix(r_ver = &amp;quot;4.3.1&amp;quot;,
    r_pkgs = c(&amp;quot;quarto&amp;quot;, &amp;quot;MASS&amp;quot;),
    system_pkgs = &amp;quot;quarto&amp;quot;,
    tex_pkgs = c(&amp;quot;amsmath&amp;quot;),
    ide = &amp;quot;other&amp;quot;,
    shell_hook = &amp;quot;&amp;quot;,
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &amp;gt;rix(r_ver = &amp;quot;976fa3369d722e76f37c77493d99829540d43845&amp;quot;,
## #  &amp;gt; r_pkgs = c(&amp;quot;quarto&amp;quot;,
## #  &amp;gt; &amp;quot;MASS&amp;quot;),
## #  &amp;gt; system_pkgs = &amp;quot;quarto&amp;quot;,
## #  &amp;gt; tex_pkgs = c(&amp;quot;amsmath&amp;quot;),
## #  &amp;gt; ide = &amp;quot;other&amp;quot;,
## #  &amp;gt; project_path = path_default_nix,
## #  &amp;gt; overwrite = TRUE,
## #  &amp;gt; print = TRUE,
## #  &amp;gt; shell_hook = &amp;quot;&amp;quot;)
## # It uses nixpkgs&amp;#39; revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto MASS;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == &amp;quot;x86_64-linux&amp;quot; then  &amp;quot;${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive&amp;quot; else &amp;quot;&amp;quot;;
##     LANG = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_ALL = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_TIME = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MONETARY = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_PAPER = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MEASUREMENT = &amp;quot;en_US.UTF-8&amp;quot;;
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trying to compile the document results now in another error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;compilation failed- no matching packages
LaTeX Error: File `orcidlink.sty&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that the LaTeX &lt;code&gt;orcidlink&lt;/code&gt; package is missing, and we can solve the
problem by adding &lt;code&gt;&#34;orcidlink&#34;&lt;/code&gt; to the list of &lt;code&gt;tex_pkgs&lt;/code&gt;. Rebuild the
environment and try again to compile the template. Trying again yields a new
error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;compilation failed- no matching packages
LaTeX Error: File `tcolorbox.sty&amp;#39; not found.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just as before, add the &lt;code&gt;tcolorbox&lt;/code&gt; package to the list of &lt;code&gt;tex_pkgs&lt;/code&gt;. You will
need to do this several times for some other packages. There is unfortunately no
easier way to list the dependencies and requirements of a LaTeX document.&lt;/p&gt;
&lt;p&gt;This is what the final script to build the environment looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix(r_ver = &amp;quot;4.3.1&amp;quot;,
    r_pkgs = c(&amp;quot;quarto&amp;quot;, &amp;quot;MASS&amp;quot;),
    system_pkgs = &amp;quot;quarto&amp;quot;,
    tex_pkgs = c(
      &amp;quot;amsmath&amp;quot;,
      &amp;quot;environ&amp;quot;,
      &amp;quot;fontawesome5&amp;quot;,
      &amp;quot;orcidlink&amp;quot;,
      &amp;quot;pdfcol&amp;quot;,
      &amp;quot;tcolorbox&amp;quot;,
      &amp;quot;tikzfill&amp;quot;
    ),
    ide = &amp;quot;other&amp;quot;,
    shell_hook = &amp;quot;&amp;quot;,
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &amp;gt;rix(r_ver = &amp;quot;976fa3369d722e76f37c77493d99829540d43845&amp;quot;,
## #  &amp;gt; r_pkgs = c(&amp;quot;quarto&amp;quot;,
## #  &amp;gt; &amp;quot;MASS&amp;quot;),
## #  &amp;gt; system_pkgs = &amp;quot;quarto&amp;quot;,
## #  &amp;gt; tex_pkgs = c(&amp;quot;amsmath&amp;quot;,
## #  &amp;gt; &amp;quot;environ&amp;quot;,
## #  &amp;gt; &amp;quot;fontawesome5&amp;quot;,
## #  &amp;gt; &amp;quot;orcidlink&amp;quot;,
## #  &amp;gt; &amp;quot;pdfcol&amp;quot;,
## #  &amp;gt; &amp;quot;tcolorbox&amp;quot;,
## #  &amp;gt; &amp;quot;tikzfill&amp;quot;),
## #  &amp;gt; ide = &amp;quot;other&amp;quot;,
## #  &amp;gt; project_path = path_default_nix,
## #  &amp;gt; overwrite = TRUE,
## #  &amp;gt; print = TRUE,
## #  &amp;gt; shell_hook = &amp;quot;&amp;quot;)
## # It uses nixpkgs&amp;#39; revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto MASS;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == &amp;quot;x86_64-linux&amp;quot; then  &amp;quot;${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive&amp;quot; else &amp;quot;&amp;quot;;
##     LANG = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_ALL = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_TIME = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MONETARY = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_PAPER = &amp;quot;en_US.UTF-8&amp;quot;;
##     LC_MEASUREMENT = &amp;quot;en_US.UTF-8&amp;quot;;
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The template will now compile with this environment. To look for a LaTeX
package, you can use the &lt;a href=&#34;https://ctan.org/pkg/orcidlink?lang=en&#34;&gt;search engine on
CTAN&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As stated in the beginning of this section, this approach is not the most
optimal, but it has its merits, especially if you’re still working on the
document. Once the environment is set up, you can simply work on the doc and
compile it as needed using &lt;code&gt;quarto render&lt;/code&gt;. In the next section, we will explain
how to build a 100% reproducible document.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reproducible-literate-programming&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;100% reproducible literate programming&lt;/h2&gt;
&lt;p&gt;Let’s not forget that Nix is not just a package manager, but also a programming
language. The &lt;code&gt;default.nix&lt;/code&gt; files that &lt;code&gt;{rix}&lt;/code&gt; generates are written in this
language, which was made entirely for the purpose of building software. If you
are not a developer, you may not realise it but the process of compiling a
Quarto or LaTeX document is very similar to the process of building any piece of
software. So we can use Nix to compile a document in a completely reproducible
environment.&lt;/p&gt;
&lt;p&gt;First, let’s fork the repo that contains the Quarto template we need. We will
fork &lt;a href=&#34;https://github.com/quarto-journals/jss&#34;&gt;this repo&lt;/a&gt;. This repo contains the
&lt;code&gt;template.qmd&lt;/code&gt; file that we can change (which is why we fork it, in practice we
would replace this &lt;code&gt;template.qmd&lt;/code&gt; by our own, finished, source &lt;code&gt;.qmd&lt;/code&gt; file). Now
we need to change our &lt;code&gt;default.nix&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let
 pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
 rpkgs = builtins.attrValues {
   inherit (pkgs.rPackages) quarto MASS;
 };
 tex = (pkgs.texlive.combine {
   inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
 });
 system_packages = builtins.attrValues {
   inherit (pkgs) R quarto;
 };
 in
 pkgs.mkShell {
   buildInputs = [  rpkgs tex system_packages  ];
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let
 pkgs = import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz&amp;quot;) {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) quarto MASS;
 };
 tex = (pkgs.texlive.combine {
  inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
 });
 system_packages = builtins.attrValues {
  inherit (pkgs) R quarto;
 };
 in
 pkgs.stdenv.mkDerivation {
   name = &amp;quot;my-paper&amp;quot;;
   src = pkgs.fetchgit {
       url = &amp;quot;https://github.com/b-rodrigues/my_paper/&amp;quot;;
       branchName = &amp;quot;main&amp;quot;;
       rev = &amp;quot;715e9f007d104c23763cebaf03782b8e80cb5445&amp;quot;;
       sha256 = &amp;quot;sha256-e8Xg7nJookKoIfiJVTGoJkvCuFNTT83YZ6SK3GT2T8g=&amp;quot;;
     };
   buildInputs = [  rpkgs tex system_packages  ];
   buildPhase =
     &amp;#39;&amp;#39;
     # Deno needs to add stuff to $HOME/.cache
     # so we give it a home to do this
     mkdir home
     export HOME=$PWD/home
     quarto add --no-prompt $src
     quarto render $PWD/template.qmd --to jss-pdf
     &amp;#39;&amp;#39;;
   installPhase =
     &amp;#39;&amp;#39;
     mkdir -p $out
     cp template.pdf $out/
     &amp;#39;&amp;#39;;
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we changed the second part of the file, we’re not building a shell anymore
using &lt;code&gt;mkShell&lt;/code&gt;, but a &lt;em&gt;derivation&lt;/em&gt;. &lt;em&gt;Derivation&lt;/em&gt; is Nix jargon for package, or
software. So what is our derivation? First, we clone the repo we forked just
before (I forked the repository and called it &lt;code&gt;my_paper&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pkgs.stdenv.mkDerivation {
  name = &amp;quot;my-paper&amp;quot;;
  src = pkgs.fetchgit {
      url = &amp;quot;https://github.com/b-rodrigues/my_paper/&amp;quot;;
      branchName = &amp;quot;main&amp;quot;;
      rev = &amp;quot;715e9f007d104c23763cebaf03782b8e80cb5445&amp;quot;;
      sha256 = &amp;quot;sha256-e8Xg7nJookKoIfiJVTGoJkvCuFNTT83YZ6SK3GT2T8g=&amp;quot;;
    };&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This repo contains our quarto template, and because we’re using a specific
commit, we will always use exactly this release of the template for our
document. This is in contrast to before where we used &lt;code&gt;quarto add quarto-journals/jss&lt;/code&gt; to install the template. Doing this interactively makes our
project not reproducible because if we compile our Quarto doc today, we would be
using the template as it is today, but if we compile the document in 6 months,
then we would be using the template as it would be in 6 months (I should say
that it is possible to install specific releases of Quarto templates using
following notation: &lt;code&gt;quarto add quarto-journals/jss@v0.9.2&lt;/code&gt; so this problem can
be mitigated).&lt;/p&gt;
&lt;p&gt;The next part of the file contains following lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;buildInputs = [  rpkgs tex system_packages  ];
buildPhase =
  &amp;#39;&amp;#39;
  # Deno needs to add stuff to $HOME/.cache
  # so we give it a home to do this
  mkdir home
  export HOME=$PWD/home
  quarto add --no-prompt $src
  quarto render $PWD/template.qmd --to jss-pdf
  &amp;#39;&amp;#39;;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;buildInputs&lt;/code&gt; are the same as before. What’s new is the &lt;code&gt;buildPhase&lt;/code&gt;.
This is actually the part in which the document gets compiled. The first
step is to create a &lt;code&gt;home&lt;/code&gt; directory. This is because Quarto needs to save
the template we want to use in &lt;code&gt;/home/.cache/deno&lt;/code&gt;. If you’re using
&lt;code&gt;quarto&lt;/code&gt; interactively, that’s not an issue, since your home directory
will be used. But with Nix, things are different, so we need to create
an empty directory and specify this as the home. This is what these
two lines do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir home
export HOME=$PWD/home&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(&lt;code&gt;$PWD&lt;/code&gt; —Print Working Directory— is a shell variable referring to the current
working directory.)&lt;/p&gt;
&lt;p&gt;Now, we need to install the template that we cloned from Github. For this we can
use &lt;code&gt;quarto add&lt;/code&gt; just as before, but instead of installing it directly from
Github, we install it from the repository that we cloned. We also add the
&lt;code&gt;--no-prompt&lt;/code&gt; flag so that the template gets installed without asking us for
confirmation. This is similar to how when building a Docker image, we don’t want
any interactive prompt to show up, or else the process will get stuck. &lt;code&gt;$src&lt;/code&gt;
refers to the path of our downloaded Github repository. Finally we can compile
the document:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;quarto render $PWD/template.qmd --to jss-pdf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will compile the &lt;code&gt;template.qmd&lt;/code&gt; (our finished paper). Finally, there’s the
&lt;code&gt;installPhase&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;installPhase =
  &amp;#39;&amp;#39;
  mkdir -p $out
  cp template.pdf $out/
  &amp;#39;&amp;#39;;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;$out&lt;/code&gt; is a shell variable defined inside the build environment and refers to
the path, so we can use it to create a directory that will contain our output
(the compiled PDF file). So we use &lt;code&gt;mkdir -p&lt;/code&gt; to recursively create all the
directory structure, and then copy the compiled document to &lt;code&gt;$out/&lt;/code&gt;. We can now
build our document by running &lt;code&gt;nix_build()&lt;/code&gt;. Now, you may be confused by the
fact that you won’t see the PDF in your working directory. But remember that
software built by Nix will always be stored in the Nix store, so our PDF is also
in the store, since this is what we built. To find it, run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;readlink result&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which will show the path to the PDF. You could use this to open the
PDF in your PDF viewer application (on Linux at least):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xdg-open $(readlink result)/template.pdf&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This vignette showed two approaches, both have their merits: the first approach
that is more interactive is useful while writing the document. You get access to
a shell and can work on the document and compile it quickly. The second approach
is more useful once the document is ready and you want to have a way of quickly
rebuilding it for reproducibility purposes. This approach should also be quite
useful in a CI/CD environment.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 4 -- So long, {renv} and Docker, and thanks for all the fish</title>
      <link>https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4/</link>
      <pubDate>Sat, 12 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/friendship ended with docker.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For this blog post, I also made a youtube video that goes over roughly the same
ideas, but the blog post is more detailed as I explain the contents of
&lt;code&gt;default.nix&lt;/code&gt; files, which I don’t do in the video. Watch the video
&lt;a href=&#34;https://www.youtube.com/watch?v=c1LhgeTTxaI&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is the fourth post in a series of posts about Nix. &lt;em&gt;Disclaimer:&lt;/em&gt; I’m a
super beginner with Nix. So this series of blog posts is more akin to notes that
I’m taking while learning than a super detailed Nix tutorial. So if you’re a Nix
expert and read something stupid in here, that’s normal. This post is going to
focus on R (obviously) but the ideas are applicable to any programming language.&lt;/p&gt;
&lt;p&gt;If you’ve never heard of Nix, take a look at &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&#34;&gt;part
1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this blog post I will go over many, nitty-gritty details and explain, line by
line, what a Nix expression you can use to build an environment for your
projects contains. In practice, building such an environment allows you to
essentially replace &lt;code&gt;{renv}&lt;/code&gt;+Docker, but writing the right expressions to
achieve it is not easy. So this blog post will also go over the features of
&lt;code&gt;{rix}&lt;/code&gt;, an &lt;a href=&#34;https://b-rodrigues.github.io/rix/index.html&#34;&gt;R package&lt;/a&gt; by
&lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp Baumann&lt;/a&gt; and myself.&lt;/p&gt;
&lt;p&gt;Let me also address the click-bait title directly. Yes, the title is click-bait
and I got you. I don’t believe that &lt;code&gt;{renv}&lt;/code&gt; and Docker are going away any time
soon and you should not hesitate to invest the required time to get to know and
use these tools (I wrote &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;something by the way&lt;/a&gt;). But
I am more and more convinced that Nix is an amazing alternative that offers many
possibilities, albeit with a high entry cost. By writing &lt;code&gt;{rix}&lt;/code&gt;, we aimed at
decreasing this entry cost as much as possible. However, more documentation,
examples, etc., need to be written and more testing is required. This series of
blog posts is a first step to get the word out and get people interested in the
package and more broadly in Nix. So if you’re interested or intrigued, don’t
hesitate to get in touch!&lt;/p&gt;
&lt;p&gt;This will be a long and boring post. Unless you really want to know how all of
this works go watch the Youtube video, which is more practical instead. I needed
to write this down, as it will likely serve as documentation. I’m essentially
beta testing it with you, so if you do take the time to read, and even better,
to try out the code, please let us know how it went! Was it clear, was it
simple, was it useful? Many thanks in advance.&lt;/p&gt;
&lt;div id=&#34;part-1-starting-a-new-project-with-nix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1: starting a new project with Nix&lt;/h2&gt;
&lt;p&gt;Let’s suppose that you don’t even have R installed on your computer yet. Maybe
you bought a new computer, or changed operating system, whatever. Maybe you even
have R already, which you installed from the installer that you can download
from the R project website. It doesn’t matter, as we are going to install a
(somewhat) isolated version of R using Nix for the purposes of this blog post.
If you don’t know where to start, it’s simple: first, use the &lt;a href=&#34;https://zero-to-nix.com/start/install&#34;&gt;installer from
Determinate Systems&lt;/a&gt;. This installer will
make it easy to install Nix on Linux, macOS or Windows (with WSL2). Once you
have Nix installed, you can use it to install R and &lt;code&gt;{rix}&lt;/code&gt; to start building
reproducible development environments. To help you get started, you can run this
line here (as documented in &lt;code&gt;{rix}&lt;/code&gt;’s Readme), which will &lt;em&gt;drop you into a Nix
shell&lt;/em&gt; with R and &lt;code&gt;{rix}&lt;/code&gt; available. Run the line inside a terminal (if you’re
running Windows, run this in a Linux distribution that you installed for WSL2):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell --expr &amp;quot;$(curl -sl https://raw.githubusercontent.com/b-rodrigues/rix/master/inst/extdata/default.nix)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will take a bit to run, and then you will be inside an R session. This
environment is not suited for development, but is only provided as an easy way
for you to start using &lt;code&gt;{rix}&lt;/code&gt;. Using &lt;code&gt;{rix}&lt;/code&gt;, you can now use it to create a
more complex environment suited for a project that you would like to start.
Let’s start by loading &lt;code&gt;{rix}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rix)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can run the following command to create an environment with the latest
version of R and some packages (change the R version and list of packages to
suit your needs):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_default_nix &amp;lt;- &amp;quot;path/to/my/project&amp;quot;

rix(r_ver = &amp;quot;current&amp;quot;,
    r_pkgs = c(&amp;quot;dplyr&amp;quot;, &amp;quot;ggplot2&amp;quot;),
    other_pkgs = NULL,
    git_pkgs = list(package_name = &amp;quot;housing&amp;quot;,
                    repo_url = &amp;quot;https://github.com/rap4all/housing&amp;quot;,
                    branch_name = &amp;quot;fusen&amp;quot;,
                    commit = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;),
    ide = &amp;quot;rstudio&amp;quot;,
    project_path = path_default_nix,
    overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running the code above will create the following &lt;code&gt;default.nix&lt;/code&gt; file in
&lt;code&gt;path/to/my/project&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# This file was generated by the {rix} R package on Sat Aug 12 22:18:55 2023
# with following call:
# &amp;gt;rix(r_ver = &amp;quot;cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd&amp;quot;,
#  &amp;gt; r_pkgs = c(&amp;quot;dplyr&amp;quot;,
#  &amp;gt; &amp;quot;ggplot2&amp;quot;),
#  &amp;gt; other_pkgs = NULL,
#  &amp;gt; git_pkgs = list(package_name = &amp;quot;housing&amp;quot;,
#  &amp;gt; repo_url = &amp;quot;https://github.com/rap4all/housing&amp;quot;,
#  &amp;gt; branch_name = &amp;quot;fusen&amp;quot;,
#  &amp;gt; commit = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;),
#  &amp;gt; ide = &amp;quot;rstudio&amp;quot;,
#  &amp;gt; project_path = path_default_nix,
#  &amp;gt; overwrite = TRUE)
# It uses nixpkgs&amp;#39; revision cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd for reproducibility purposes
# which will install R as it was as of nixpkgs revision: cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd
# Report any issues to https://github.com/b-rodrigues/rix
{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd.tar.gz&amp;quot;) {} }:

with pkgs;

let
  my-r = rWrapper.override {
    packages = with rPackages; [
        dplyr
        ggplot2
        (buildRPackage {
          name = &amp;quot;housing&amp;quot;;
          src = fetchgit {
          url = &amp;quot;https://github.com/rap4all/housing&amp;quot;;
          branchName = &amp;quot;fusen&amp;quot;;
          rev = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;;
          sha256 = &amp;quot;sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&amp;quot;;
          };
          propagatedBuildInputs = [
            dplyr
            ggplot2
            janitor
            purrr
            readxl
            rlang
            rvest
            stringr
            tidyr
            ];
          })
        ];
    };
  my-rstudio = rstudioWrapper.override {
    packages = with rPackages; [
        dplyr
        ggplot2
        (buildRPackage {
          name = &amp;quot;housing&amp;quot;;
          src = fetchgit {
          url = &amp;quot;https://github.com/rap4all/housing&amp;quot;;
          branchName = &amp;quot;fusen&amp;quot;;
          rev = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;;
          sha256 = &amp;quot;sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&amp;quot;;
          };
          propagatedBuildInputs = [
            dplyr
            ggplot2
            janitor
            purrr
            readxl
            rlang
            rvest
            stringr
            tidyr
            ];
          })
        ];
    };
in
 mkShell {
   LOCALE_ARCHIVE = &amp;quot;${glibcLocales}/lib/locale/locale-archive&amp;quot;;
     buildInputs = [
        my-r
        my-rstudio
      ];
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s go through it. The first thing you will notice is that this file is
written in a language that you might not know: this language is called Nix as
well! So &lt;em&gt;Nix&lt;/em&gt; can both refer to the package manager, but also to the
programming language. The Nix programming language was designed for creating and
composing &lt;em&gt;derivations&lt;/em&gt;. A derivation is Nix jargon for a package (not
necessarily an R package; any piece of software that you can install through Nix
is a package). To know more about the language itself, you can
&lt;a href=&#34;https://nixos.org/manual/nix/stable/language/index.html&#34;&gt;RTFM&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s go back to our &lt;code&gt;default.nix&lt;/code&gt; file. The first lines state the revision of
&lt;code&gt;nixpkgs&lt;/code&gt; used that is being used in this expression, as well as which version
of R gets installed through it. &lt;code&gt;nixpkgs&lt;/code&gt; is Nix’s repository which contains all
the software that we will be installing. This is important to understand: since
all the expressions that build all the software available through &lt;code&gt;nixpkgs&lt;/code&gt; are
versioned on &lt;a href=&#34;https://github.com/NixOS/nixpkgs/tree/master/pkgs&#34;&gt;Github&lt;/a&gt;, it is
possible to choose a particular commit, or revision, and use that particular
release of &lt;code&gt;nixpkgs&lt;/code&gt;. So by judiciously choosing the right commit, it’s possible
to install any version of R (well any version until 3.0.2). &lt;code&gt;{rix}&lt;/code&gt; takes care
of this for you: state the version of R that is needed, and the right revision
will be returned (the list of R versions and revisions can be found
&lt;a href=&#34;https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;amp;package=r&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The call that was used to generate the &lt;code&gt;default.nix&lt;/code&gt; file is also saved, but if
you look at the argument &lt;code&gt;r_ver&lt;/code&gt;, the &lt;code&gt;nixpkgs&lt;/code&gt; revision is specified instead of
&lt;code&gt;&#34;current&#34;&lt;/code&gt;. This is because if you re-run this call but keep
&lt;code&gt;r_ver = &#34;current&#34;&lt;/code&gt;, another, more recent &lt;code&gt;nixpkgs&lt;/code&gt; revision will get used
instead, which will break reproducibility. To avoid this, the expression gets
changed, so if you re-run it, you’re sure to find the exact same environment.&lt;/p&gt;
&lt;p&gt;Then comes this line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd.tar.gz&amp;quot;) {} }:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This actually defines a function with argument &lt;code&gt;pkgs&lt;/code&gt; that is optional (hence
the &lt;code&gt;?&lt;/code&gt;). All that follows, &lt;code&gt;import (fetchTarball ... ) {}&lt;/code&gt; is the default value
for &lt;code&gt;pkgs&lt;/code&gt; if no argument is provided when you run this (which will always be
the case). So here, if I call this function without providing any &lt;code&gt;pkgs&lt;/code&gt;
argument, the release of &lt;code&gt;nixpkgs&lt;/code&gt; at that commit will be used. Then comes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [
      dplyr
      ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;with pkgs&lt;/code&gt; statement makes all the imported packages available in the scope
of the function. So I can write &lt;code&gt;quarto&lt;/code&gt; if I want to install Quarto (the
program that compiles &lt;code&gt;.qmd&lt;/code&gt; files, not the &lt;code&gt;{quarto}&lt;/code&gt; R package that provides
bindings to it) instead of &lt;code&gt;nixpkgs.quarto&lt;/code&gt;. Actually, R also has &lt;code&gt;with()&lt;/code&gt;, so
you can write this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with(mtcars, plot(mpg ~ hp))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;instead of this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(mtcars$mpg ~ mtcars$hp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then follows a &lt;code&gt;let ... in&lt;/code&gt;. This is how a variable gets defined locally, for
example, this is a valid Nix statement:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let x = 1; y = 2; in x + y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which will obviously return &lt;code&gt;3&lt;/code&gt;. So here we are defining a series of packages
that will ultimately be available in our environment. These packages are named
&lt;code&gt;my-pkgs&lt;/code&gt; and are a list of R packages. You can see that I use a wrapper called
&lt;code&gt;rWrapper&lt;/code&gt; which changes certain options to make R installed through Nix work
well. This wrapper has a &lt;code&gt;packages&lt;/code&gt; attribute which I override using its
&lt;code&gt;.override&lt;/code&gt; method, and then I redefine &lt;code&gt;packages&lt;/code&gt; as a list of R packages. Just
like before, I use &lt;code&gt;with rPackages&lt;/code&gt; before listing them, which allows me to
write &lt;code&gt;dplyr&lt;/code&gt; instead of &lt;code&gt;rPackages.dplyr&lt;/code&gt; to refer to the &lt;code&gt;{dplyr}&lt;/code&gt; packages. R
packages that have a &lt;code&gt;.&lt;/code&gt; character in their name must be written using &lt;code&gt;_&lt;/code&gt;, so
if you need &lt;code&gt;{data.table}&lt;/code&gt; you’ll need to write &lt;code&gt;data_table&lt;/code&gt; (but &lt;code&gt;{rix}&lt;/code&gt; does
this for you as well, so don’t worry). Then follows the list of R packages
available through &lt;code&gt;nixpkgs&lt;/code&gt; (which is the entirety of CRAN:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;packages = with rPackages; [
          dplyr
          ggplot2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each time you need to add a package, add it here, and rebuild your environment,
do not run &lt;code&gt;install.packages(blabla)&lt;/code&gt; to install the &lt;code&gt;{blabla}&lt;/code&gt; package, because
it’s likely not going to work anyways, and it’s not reproducible. Your projects
need to be entirely defined as code. This also means that packages that have
helper functions that install something, for example
&lt;code&gt;tinytex::install_tinytex()&lt;/code&gt;, cannot be used anymore. Instead, you will need to
install &lt;code&gt;texlive&lt;/code&gt; (by putting it in &lt;code&gt;other_pkgs&lt;/code&gt;) and rebuild the expression. We
plan to write vignettes documenting all these use-cases. For example, my blog is
still built using Hugo (and will likely stay like this forever). I’m using a
very old version of Hugo to generate it (I don’t want to upgrade and have to
deal with potential issues), so I install the right version I need using Nix,
instead of using &lt;code&gt;blogdown::install_hugo()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then comes the expression that installs a package from Github:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(buildRPackage {
  name = &amp;quot;housing&amp;quot;;
  src = fetchgit {
  url = &amp;quot;https://github.com/rap4all/housing&amp;quot;;
  branchName = &amp;quot;fusen&amp;quot;;
  rev = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;;
  sha256 = &amp;quot;sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&amp;quot;;
  };
  propagatedBuildInputs = [
    dplyr
    ggplot2
    janitor
    purrr
    readxl
    rlang
    rvest
    stringr
    tidyr
    ];
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see it’s quite a mouthful, but it was generated from this R code
only:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;git_pkgs = list(package_name = &amp;quot;housing&amp;quot;,
                repo_url = &amp;quot;https://github.com/rap4all/housing&amp;quot;,
                branch_name = &amp;quot;fusen&amp;quot;,
                commit = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;),&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to install more than one package, you can also provide a list of
lists, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;git_pkgs = list(
  list(package_name = &amp;quot;housing&amp;quot;,
       repo_url = &amp;quot;https://github.com/rap4all/housing/&amp;quot;,
       branch_name = &amp;quot;fusen&amp;quot;,
       commit = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;),
  list(package_name = &amp;quot;fusen&amp;quot;,
       repo_url = &amp;quot;https://github.com/ThinkR-open/fusen&amp;quot;,
       branch_name = &amp;quot;main&amp;quot;,
       commit = &amp;quot;d617172447d2947efb20ad6a4463742b8a5d79dc&amp;quot;)
),
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the right expressions will be generated. There’s actually a lot going on
here, so let me explain. The first thing is the &lt;code&gt;sha256&lt;/code&gt; field. This field
contains a hash that gets generated by Nix, and that must be provided by the
user. But users rarely, if ever, know this value, so instead what they do is
they try to build the expression without providing it. An error message like
this one gets returned:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error: hash mismatch in fixed-output derivation &amp;#39;/nix/store/449zx4p6x0yijym14q3jslg55kihzw66-housing-1c86095.drv&amp;#39;:
         specified: sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=
            got:    sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;sha256&lt;/code&gt; can now get copy-and-pasted into the expression. This approach is
called “Trust On First Use”, or TOFU for short. Because this is quite annoying,
&lt;code&gt;{rix}&lt;/code&gt; provides a “private” function, called &lt;code&gt;get_sri_hash_deps()&lt;/code&gt; that
generates this hash for you. The issue is that this hash cannot be computed
easily if you don’t have Nix installed, and since I don’t want to force users to
install Nix to use &lt;code&gt;{rix}&lt;/code&gt;, what I did is that I set up a server with Nix
installed and a &lt;code&gt;{plumber}&lt;/code&gt; api. &lt;code&gt;get_sri_hash_deps()&lt;/code&gt; makes a call to that api
and gets back the &lt;code&gt;sha256&lt;/code&gt;, and also a list of packages (more on this later).&lt;/p&gt;
&lt;p&gt;You can try making a call to the api if you have &lt;code&gt;curl&lt;/code&gt; installed on your
system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://git2nixsha.dev:1506/hash?repo_url=https://github.com/rap4all/housing/&amp;amp;branchName=fusen&amp;amp;commit=1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot; -H &amp;quot;accept: */*&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is what you will get back:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;sri_hash&amp;quot; : [&amp;quot;sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&amp;quot;],
  &amp;quot;deps&amp;quot;     : [&amp;quot;dplyr ggplot2 janitor purrr readxl rlang rvest stringr tidyr&amp;quot;]
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason computing &lt;code&gt;sri_hash&lt;/code&gt; is not easy is because it gets computed on the
folder containing the source code (after having deleted the &lt;code&gt;.git&lt;/code&gt; folder in the
case of a Github repo) after it was &lt;em&gt;serialised&lt;/em&gt;. You are certainly familiar
with serialisations such as the ZIP or TAR serialisation (in other words,
zipping a folder is “serialising” it). But these serialisation algorithms come
with certain shortcomings that I won’t discuss here, but if you’re interested
check out section &lt;em&gt;5.2. The Nix store&lt;/em&gt; from Eelco Dolstra’s Phd thesis which you
can find &lt;a href=&#34;https://archive.is/S9meY&#34;&gt;here&lt;/a&gt;. Instead, a Nix-specific serialisation
algorithm was developed, called NAR. So to compute this hash, I either had to
implement this serialisation algorithm in R, or write an api that does that for
me by using the implementation that ships with Nix. Since I’m not talented
enough to implement such an algorithm in R, I went for the api. But who knows,
maybe in the future this could be done. There are implementation of this
algorithm in other programming languages like Rust, so maybe packaging the Rust
binary could be an option.&lt;/p&gt;
&lt;p&gt;This gets then further processed by &lt;code&gt;rix()&lt;/code&gt;. The second thing that gets returned
is a list of packages. These get scraped from the &lt;code&gt;Imports&lt;/code&gt; and &lt;code&gt;LinkingTo&lt;/code&gt;
sections of the &lt;code&gt;DESCRIPTION&lt;/code&gt; file from the package and are then provided as the
&lt;code&gt;propagatedBuildInputs&lt;/code&gt; in the Nix expression. These packages are dependencies
that must be available to your package at build and run-time.&lt;/p&gt;
&lt;p&gt;You should know that as of today (&lt;code&gt;{rix}&lt;/code&gt; commit &lt;code&gt;15cadf7f&lt;/code&gt;) GitHub packages
that use the &lt;code&gt;Remotes&lt;/code&gt; field (so that have dependencies that are also on Github)
are not handled by &lt;code&gt;{rix}&lt;/code&gt;, but supporting this is planned. What &lt;code&gt;{rix}&lt;/code&gt;
supports though is installing packages from the CRAN archives, so you can
specify a version of a package and have that installed. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix(r_ver = &amp;quot;current&amp;quot;,
    r_pkgs = c(&amp;quot;dplyr@0.8.0&amp;quot;, &amp;quot;ggplot2@3.1.1&amp;quot;),
    other_pkgs = NULL,
    git_pkgs = NULL,
    ide = &amp;quot;other&amp;quot;,
    path = path_default_nix,
    overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The difference with the &lt;code&gt;default.nix&lt;/code&gt; file from before is that these packages
get downloaded off the CRAN archives, so &lt;code&gt;fetchzip()&lt;/code&gt; is used to download them
instead of &lt;code&gt;fetchgit()&lt;/code&gt; (both Nix functions). Here is what the generated Nix
code looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(buildRPackage {
  name = &amp;quot;dplyr&amp;quot;;
  src = fetchzip {
  url = &amp;quot;https://cran.r-project.org/src/contrib/Archive/dplyr/dplyr_0.8.0.tar.gz&amp;quot;;
  sha256 = &amp;quot;sha256-f30raalLd9KoZKZSxeTN71PG6BczXRIiP6g7EZeH09U=&amp;quot;;
  };
  propagatedBuildInputs = [
    assertthat
    glue
    magrittr
    pkgconfig
    R6
    Rcpp
    rlang
    tibble
    tidyselect
    BH
    plogr
    Rcpp
    ];
})
(buildRPackage {
  name = &amp;quot;ggplot2&amp;quot;;
  src = fetchzip {
  url = &amp;quot;https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.1.1.tar.gz&amp;quot;;
  sha256 = &amp;quot;sha256-0Qv/5V/XMsFBcGEFy+3IAaBJIscRMTwGong6fiP5Op0=&amp;quot;;
  };
  propagatedBuildInputs = [
    digest
    gtable
    lazyeval
    MASS
    mgcv
    plyr
    reshape2
    rlang
    scales
    tibble
    viridisLite
    withr
    ];
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what this looks like:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/new_r_old_pkgs.png&#34; width=&#34;100%&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This feature should ideally be used sparingly. If you want to reconstruct an
environment as it was around a specific date (for example to run an old
project), use the version of R that was current at that time. This will ensure
that every package that gets installed is at a version compatible with that
version of R, which might not be the case if you need to install a very old
version of one particular package. But this feature is quite useful if you want
to install a package that is not available on CRAN anymore, but that is
archived, like
&lt;a href=&#34;https://cran.r-project.org/web/packages/ZeligChoice/index.html&#34;&gt;{ZeligChoice}&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then a second list of packages gets defined, this time using the
&lt;code&gt;rstudioWrapper&lt;/code&gt; wrapper. This is because I specified that I wanted to use
RStudio, but RStudio is a bit peculiar. It redefines many paths and so if you
have RStudio installed in your system, it won’t be able to “see” the R installed
through Nix. So you have to install RStudio through Nix as well (this is not
necessary for VS Code nor Emacs, and likely not for other editors as well).
However, it is still necessary to provide each package, again, to the
&lt;code&gt;rstudioWrapper&lt;/code&gt;. This is because the RStudio installed through Nix is also not
able to “see” the R installed through Nix as well. But don’t worry, this does
not take twice the space, since the packages simply get symlinked.&lt;/p&gt;
&lt;p&gt;The last part of the expression uses &lt;code&gt;mkShell&lt;/code&gt; which builds a shell with the
provided &lt;code&gt;buildInputs&lt;/code&gt; (our list of packages). There is also a line to define
the location of the locale archive, which should properly configure the locale
of the shell (so language, time zone and units):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;in
 mkShell {
   LOCALE_ARCHIVE = &amp;quot;${glibcLocales}/lib/locale/locale-archive&amp;quot;;
     buildInputs = [
        my-r
        my-rstudio
      ];
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this file in hand, we can now build the environment and use it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-using-your-environment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2: using your environment&lt;/h2&gt;
&lt;p&gt;So let’s suppose that you have a &lt;code&gt;default.nix&lt;/code&gt; file and you wish to build the
environment. To do so, you need to have Nix installed, and, thanks to the
contributions of &lt;a href=&#34;https://github.com/philipp-baumann&#34;&gt;Philipp Baumann&lt;/a&gt;, you can
use &lt;code&gt;rix::nix_build()&lt;/code&gt; to build the environment as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nix_build(project_path = path_default_nix, exec_mode = &amp;quot;blocking&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you prefer, you can use Nix directly as well; navigate to the project folder
containing the &lt;code&gt;default.nix&lt;/code&gt; file and run the command line tool &lt;code&gt;nix-build&lt;/code&gt; that
gets installed with Nix:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-build&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will take some time to run, depending on whether cached binary packages can
be pulled from &lt;a href=&#34;https://cache.nixos.org/&#34; class=&#34;uri&#34;&gt;https://cache.nixos.org/&lt;/a&gt; or not. Once the build process is
done, you should see a file called &lt;code&gt;result&lt;/code&gt; next to the &lt;code&gt;default.nix&lt;/code&gt; file. You
can now &lt;em&gt;drop&lt;/em&gt; into the Nix shell by typing this into your operating system’s
terminal (after you navigated to the folder containing the &lt;code&gt;default.nix&lt;/code&gt; and
&lt;code&gt;result&lt;/code&gt; files):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(this time, you really have to leave your current R session! But Philipp and
myself are thinking about how we could also streamline this part as well…).&lt;/p&gt;
&lt;p&gt;The environment that you just built is not an entirely isolated environment: you
can still interact with your computer, unlike with Docker. For example, you can
still use programs that are installed on your computer. This means that you can
run your usual editor as well, but starting it from the Nix shell will make your
editor be able to “see” the R installed in that environment. You need to be
careful with this, because sometimes this can lead to surprising behavior. For
example, if you already have R installed with some packages, these packages
could interfere with your Nix environment. There are two ways of dealing with
this: you either only use Nix-based environments to work (which would be my
primary recommendation, as there can be no interference between different Nix
environments), or you call &lt;code&gt;nix-shell --pure&lt;/code&gt; instead of just &lt;code&gt;nix-shell&lt;/code&gt;. This
will ensure that only whatever is available in the environment gets used, but be
warned that Nix environments are very, very lean, so you might need to add some
tools to have something completely functional.&lt;/p&gt;
&lt;p&gt;We can take advantage of the fact that environments are not completely isolated
to use our IDEs. For example, if you use VS Code or Emacs, you can use the one
that is installed directly on your system, as explained before. As already
explained, but to drive the point home, if you’re an RStudio user, you need to
specify the &lt;code&gt;ide = &#34;rstudio&#34;&lt;/code&gt; argument to &lt;code&gt;rix()&lt;/code&gt;, because in the case of
RStudio, it needs to be installed by Nix as well (the current available RStudio
version installed by Nix is now out of date, but efforts are ongoing to update
it). This is because RStudio looks for R runtimes in very specific paths, and
these need to be patched to see Nix-provided R versions. Hence the version that
gets installed by Nix gets patched so that RStudio is able to find the correct
runtimes.&lt;/p&gt;
&lt;p&gt;Once you dropped into the shell, simply type &lt;code&gt;rstudio&lt;/code&gt; to launch RStudio in that
environment (or &lt;code&gt;code&lt;/code&gt; if you use VS Code or &lt;code&gt;other&lt;/code&gt; if you use Emacs, or any
other editor). On Linux, RStudio may fail to launch with this error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Could not initialize GLX
Aborted (core dumped)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;change your &lt;code&gt;default.nix&lt;/code&gt; file from this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkShell {
  LOCALE_ARCHIVE = &amp;quot;${glibcLocales}/lib/locale/locale-archive&amp;quot;;
    buildInputs = [
       my-r
       my-rstudio
     ];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkShell {
  LOCALE_ARCHIVE = &amp;quot;${glibcLocales}/lib/locale/locale-archive&amp;quot;;
    buildInputs = [
       my-r
       my-rstudio
     ];
  shellHook = &amp;#39;&amp;#39;
    export QT_XCB_GL_INTEGRATION=none
  &amp;#39;&amp;#39;;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which should solve the issue, which is related to hardware acceleration as far
as I can tell.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;shellHook&lt;/code&gt;s are a nice feature which I haven’t discussed a lot yet (I did so in
part 2 of this series, to run a &lt;code&gt;{targets}&lt;/code&gt; pipeline each time I dropped into
the shell). Whatever goes into the &lt;code&gt;shellHook&lt;/code&gt; gets executed as soon as one
drops into the Nix shell. I personally have to add the
&lt;code&gt;export QT_XCB_GL_INTEGRATION=none&lt;/code&gt; line in on virtual machines and on my
desktop computer as well, but I’ve had problems in the past with my graphics
drivers, and I think it’s related. I’m planning also to add an option to &lt;code&gt;rix()&lt;/code&gt;
to add this automatically.&lt;/p&gt;
&lt;p&gt;If you need to add packages, best is to call &lt;code&gt;rix::rix()&lt;/code&gt; again, but this time,
provide the &lt;code&gt;nixpkgs&lt;/code&gt; revision as the argument to &lt;code&gt;r_ver&lt;/code&gt;. Copy and paste the
call from the generated &lt;code&gt;default.nix&lt;/code&gt; to an R console and rerun it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix(r_ver = &amp;quot;cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd&amp;quot;,
    r_pkgs = c(&amp;quot;dplyr&amp;quot;, &amp;quot;ggplot2&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;quarto&amp;quot;),
    other_pkgs = &amp;quot;quarto&amp;quot;,
    git_pkgs = list(package_name = &amp;quot;housing&amp;quot;,
                    repo_url = &amp;quot;https://github.com/rap4all/housing&amp;quot;,
                    branch_name = &amp;quot;fusen&amp;quot;,
                    commit = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;),
    ide = &amp;quot;rstudio&amp;quot;,
    path = path_default_nix,
    overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the call above I’ve added the &lt;code&gt;{tidyr}&lt;/code&gt; and &lt;code&gt;{quarto}&lt;/code&gt; packages, as well as
the &lt;code&gt;quarto&lt;/code&gt; command line utility to generate &lt;code&gt;.qmd&lt;/code&gt; files. For &lt;code&gt;r_ver&lt;/code&gt; I’m this
time using the &lt;code&gt;nixpkgs&lt;/code&gt; revision from my original &lt;code&gt;default.nix&lt;/code&gt; file. This will
ensure that my environment stays the same.&lt;/p&gt;
&lt;p&gt;So if you have read up until this point, let me first thank you, and secondly
humbly ask you to test &lt;code&gt;{rix}&lt;/code&gt;! I’m looking for testers, especially on Windows
and macOS, and would be really grateful if you could provide some feedback on
the package. To report anything, simply open issue
&lt;a href=&#34;https://github.com/b-rodrigues/rix/issues&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Philipp for proof-reading this post.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 3 -- frictionless {plumber} api deployments with Nix</title>
      <link>https://www.brodrigues.co/blog/2023-07-30-nix_for_r_part3/</link>
      <pubDate>Sun, 30 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-07-30-nix_for_r_part3/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/i_use_nix_for_all_my_package_management_needs.png&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is the third post in a series of posts about Nix. Disclaimer: I’m a super
beginner with Nix. So this series of blog posts is more akin to notes that I’m
taking while learning than a super detailed tutorial. So if you’re a Nix expert
and read something stupid in here, that’s normal. This post is going to focus on
R (obviously) but the ideas are applicable to any programming language.&lt;/p&gt;
&lt;p&gt;This blog post is part tutorial on creating an api using the &lt;code&gt;{plumber}&lt;/code&gt; R
package, part an illustration of how Nix makes developing and deploying a
breeze.&lt;/p&gt;
&lt;div id=&#34;part-1-getting-it-to-work-locally&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1: getting it to work locally&lt;/h2&gt;
&lt;p&gt;So in &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&#34;&gt;part 1&lt;/a&gt; I
explained what Nix was and how you could use it to build reproducible
development environments. In &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/&#34;&gt;part
2&lt;/a&gt; I talked about
running a &lt;code&gt;{targets}&lt;/code&gt; pipeline in a reproducible environment set up with Nix,
and in this blog post I’ll talk about how I made an api using {plumber} and how
Nix made going from my development environment to the production environment (on
Digital Ocean) the simplest ever. Originally I wanted to focus on interactive
work using Nix, but that’ll be very likely for part 4, maybe even part 5 (yes, I
really have a lot to write about).&lt;/p&gt;
&lt;p&gt;Let me just first explain what &lt;code&gt;{plumber}&lt;/code&gt; is before continuing. I already
talked about &lt;code&gt;{plumber}&lt;/code&gt;
&lt;a href=&#34;https://www.brodrigues.co/blog/2021-06-04-own_knit_server/&#34;&gt;here&lt;/a&gt;, but in
summary, &lt;code&gt;{plumber}&lt;/code&gt; allows you to build an api. What is an api? Essentially a
service that you can call in different ways and which returns something to you.
For example, you could send a Word document to this api and get back the same
document converted in PDF. Or you could send some English text and get back a
translation. Or you could send some data and get a prediction from a machine
learning model. It doesn’t matter: what’s important is that apis completely
abstract the programming language that is being used to compute whatever should
be computed. With &lt;code&gt;{plumber}&lt;/code&gt;, you can create such services using R. This is
pretty awesome, because it means that whatever it is you can make with R, you
could build a service around it and make it available to anyone. Of course you
need a server that actually has R installed and that gets and processes the
requests it receives, and this is where the problems start. And by problems I
mean THE single biggest problem that you have to deal with whenever you develop
something on your computer, and then have to make it work somewhere else:
deployment. If you’ve had to deal with deployments you might not understand why
it’s so hard. I certainly didn’t really get it until I’ve wanted to deploy my
first Shiny app, many moons ago. And this is especially true whenever you don’t
want to use any “off the shelf” services like &lt;em&gt;shinyapps.io&lt;/em&gt;. In the &lt;a href=&#34;https://www.brodrigues.co/blog/2021-06-04-own_knit_server/&#34;&gt;blog post
I mentioned above&lt;/a&gt;,
I used Docker to deploy the api. But Docker, while an amazing tool, is also
quite heavy to deal with. Nix offers an alternative to Docker which I think you
should know and think about. Let me try to convince you.&lt;/p&gt;
&lt;p&gt;So let’s make a little &lt;code&gt;{plumber}&lt;/code&gt; api and deploy that in the cloud. For this, I’m
using Digital Ocean, but any other service that allows you to spin a virtual
machine (VM) with Ubuntu on it will do. If you don’t have a Digital Ocean
account, you can use my &lt;a href=&#34;https://m.do.co/c/b68adc727710&#34;&gt;referral link&lt;/a&gt; to get
200$ in credit for 60 days, more than enough to experiment. A VM serving a
&lt;code&gt;{plumber}&lt;/code&gt; api needs at least 1 gig of RAM, and the cheapest one with 1 gig of
ram is 6$ a month (if you spend 25$ of that credit, I’ll get 25$ too, so don’t
hesitate to experiment, you’ll be doing me a solid as well).&lt;/p&gt;
&lt;p&gt;I won’t explain what my api does, this doesn’t really matter for this blog post.
But I’ll have to explain it in a future blog post, because it’s related to a
package I’m working on, called &lt;a href=&#34;https://github.com/b-rodrigues/rix&#34;&gt;{rix}&lt;/a&gt; which
I’m writing to ease the process of building reproducible environments for R
using Nix. So for this blog post, let’s make something very simple: let’s take
the classic machine learning task of predicting survival of the passengers of
the Titanic (which was not that long ago in the news again…) and make a
service out of it.&lt;/p&gt;
&lt;p&gt;What’s going to happen is this: users will make a request to the api giving some
basic info about themselves: a simple ML model (I’ll go with logistic regression
and call it “machine learning” just to make the statisticians reading this
seethe lmao), the machine learning model is going to use this to compute a
prediction and the result will be returned to the user. Now to answer a question
that comes up often when I explain this stuff: &lt;em&gt;why not use Shiny? Users can
enter their data and get a prediction and there’s a nice UI and everything?!&lt;/em&gt;.
Well yes, but it depends on what it is you actually want to do. An api is useful
mostly in situations where you need that request to be made by another machine
and then that machine will do something else with that prediction it got back.
It could be as simple as showing it in a nice interface, or maybe the machine
that made the request will then use that prediction and insert it somewhere for
archiving for example. So think of it this way: use an api when machines need to
interact with other machines, a Shiny app for when humans need to interact with
a machine.&lt;/p&gt;
&lt;p&gt;Ok so first, because I’m using Nix, I’ll create an environment that will contain
everything I need to build this api. I’m doing that in the most simple way
possible, simply by specifying an R version and the packages I need inside a
file called &lt;code&gt;default.nix&lt;/code&gt;. Writing this file if you’re not familiar with Nix can
be daunting, so I’ve developed a package, called &lt;code&gt;{rix}&lt;/code&gt; to write these files
for you. Calling this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix::rix(r_ver = &amp;quot;4.2.2&amp;quot;,
         r_pkgs = c(&amp;quot;plumber&amp;quot;, &amp;quot;tidymodels&amp;quot;),
         other_pkgs = NULL,
         git_pkgs = NULL,
         ide = &amp;quot;other&amp;quot;,
         path = &amp;quot;titanic_api/&amp;quot;, # you might need to create this folder
         overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;generates this file for me:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# This file was generated by the {rix} R package on Sat Jul 29 15:50:41 2023
# It uses nixpkgs&amp;#39; revision 8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8 for reproducibility purposes
# which will install R version 4.2.2
# Report any issues to https://github.com/b-rodrigues/rix
{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz&amp;quot;) {} }:

  with pkgs;

  let
  my-r = rWrapper.override {
    packages = with rPackages; [
      plumber tidymodels
    ];
  };
  in
  mkShell {
    buildInputs = [
      my-r
      ];
  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(for posterity’s sake: this is using &lt;a href=&#34;https://github.com/b-rodrigues/rix/tree/935fb194b38adfb085a5bda9ebe5dc5bb504f2cb&#34;&gt;this version of
{rix}&lt;/a&gt;.
Also, if you want to learn more about &lt;code&gt;{rix}&lt;/code&gt; take a look at its
&lt;a href=&#34;https://b-rodrigues.github.io/rix/&#34;&gt;website&lt;/a&gt;. It’s still in very early
development, comments and PR more than welcome!)&lt;/p&gt;
&lt;p&gt;To build my api I’ll have to have &lt;code&gt;{plumber}&lt;/code&gt; installed. I also install the
&lt;code&gt;{tidymodels}&lt;/code&gt; package. I actually don’t need &lt;code&gt;{tidymodels}&lt;/code&gt; for what I’m doing
(base R can fit logistic regressions just fine), but the reason I’m installing
it is to mimic a “real-word example” as closely as possible (a project with some
dependencies).&lt;/p&gt;
&lt;p&gt;When I called &lt;code&gt;rix::rix()&lt;/code&gt; to generate the &lt;code&gt;default.nix&lt;/code&gt; file, I specified that
I wanted R version 4.2.2 (because let’s say that this is the version I need.
It’s also possible to get the current version of R by passing “current” to
&lt;code&gt;r_ver&lt;/code&gt;). You don’t see any reference to this version of R in the &lt;code&gt;default.nix&lt;/code&gt;
file, but this is the version that will get installed because it’s the version
that comes with that particular revision of the &lt;code&gt;nixpkgs&lt;/code&gt; repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This url downloads that particular revision on &lt;code&gt;nixpkgs&lt;/code&gt; containing R version
4.2.2. &lt;code&gt;{rix}&lt;/code&gt; finds the right revision for you (using &lt;a href=&#34;https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;amp;package=r&#34;&gt;this handy
service&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;While &lt;code&gt;{rix}&lt;/code&gt; doesn’t require your system to have Nix installed, if you want to
continue you’ll have to install Nix. To install Nix, I recommend you don’t use
the official installer, even if it’s quite simple to use. Instead, the
&lt;a href=&#34;https://zero-to-nix.com/start/install&#34;&gt;Determinate Systems&lt;/a&gt; installer seems
better to me. On Windows, you will need to enable WSL2. An alternative is to run
all of this inside a Docker container (but more on this later if you’re thinking
something along the lines of &lt;em&gt;isn’t the purpose of Nix to not have to use
Docker?&lt;/em&gt; then see you in the conclusion). Once you have Nix up and running, go
inside the &lt;code&gt;titanic_api/&lt;/code&gt; folder (which contains the &lt;code&gt;default.nix&lt;/code&gt; file above)
and run the following command inside a terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-build&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will build the environment according to the instructions in the
&lt;code&gt;default.nix&lt;/code&gt; file. Depending on what you want/need, this can take some time.
Once the environment is done building, you can “enter” into it by typing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this is where you would use this environment to work on your api. As I
stated above, I’ll discuss interactive work using a Nix environment in a future
blog post. Leave the terminal with this Nix shell open and create an empty text
wile next to &lt;code&gt;default.nix&lt;/code&gt; and call it &lt;code&gt;titanic_api.R&lt;/code&gt; and put this in there
using any text editor of your choice:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#* Would you have survived the Titanic sinking?
#* @param sex Character. &amp;quot;male&amp;quot; or &amp;quot;female&amp;quot;
#* @param age Integer. Your age.
#* @get /prediction
function(sex, age) {

  trained_logreg &amp;lt;- readRDS(&amp;quot;trained_logreg.rds&amp;quot;)

  dataset &amp;lt;- data.frame(sex = sex, age = as.numeric(age))

  parsnip::predict.model_fit(trained_logreg,
                             new_data = dataset)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This script is a &lt;code&gt;{plumber}&lt;/code&gt; api. It’s a simple function that uses an already
&lt;em&gt;trained&lt;/em&gt; logistic regression (lol) by loading it into its scope using the
&lt;code&gt;readRDS()&lt;/code&gt; function. It then returns a prediction. The script that I wrote to
train the model is this one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(parsnip)

titanic_raw &amp;lt;- read.csv(&amp;quot;https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv&amp;quot;)

titanic &amp;lt;- titanic_raw |&amp;gt;
  subset(select = c(Survived,
                    Sex,
                    Age))

names(titanic) &amp;lt;- c(&amp;quot;survived&amp;quot;, &amp;quot;sex&amp;quot;, &amp;quot;age&amp;quot;)

titanic$survived = as.factor(titanic$survived)

logreg_spec &amp;lt;- logistic_reg() |&amp;gt;
  set_engine(&amp;quot;glm&amp;quot;)

trained_logreg &amp;lt;- logreg_spec |&amp;gt;
  fit(survived ~ ., data = titanic)

saveRDS(trained_logreg, &amp;quot;trained_logreg.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re familiar with this Titanic prediction task, you will have noticed that
the script above is completely stupid. I only kept two variables to fit the
logistic regression. But the reason I did this is because this blog post is not
about fitting models, but about apis. So bear with me. Anyways, once you’re run
the script above to generate the file &lt;code&gt;trained_logreg.rds&lt;/code&gt; containing the
trained model, you can locally test the api using &lt;code&gt;{plumber}&lt;/code&gt;. Go back to the
terminal that is running your Nix shell, and now type &lt;code&gt;R&lt;/code&gt; to start R in that
session. You can then run your api inside that session using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plumber::pr(&amp;quot;titanic_api.R&amp;quot;) |&amp;gt;
  plumber::pr_run(port = &amp;quot;8000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Open your web browser and visit
&lt;a href=&#34;http://localhost:8000/__docs__/&#34;&gt;http://localhost:8000/&lt;strong&gt;docs&lt;/strong&gt;/&lt;/a&gt;
to see the Swagger interface to your api (Swagger is a nice little tool
that makes testing your apis way easier).&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/swagger_plumber.png&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Using Swagger you can try out your api, click on (1) then on (2). You can enter
some mock data in (3) and (4) and then run the computation by clicking on
“Execute” (5). You’ll see the result in (7). (6) gives you a &lt;code&gt;curl&lt;/code&gt; command to
run exactly this example from a terminal. Congrats, your &lt;code&gt;{plumber}&lt;/code&gt; api is
running on your computer! Now we need to deploy it online and make it available to
the world.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deploying-your-api&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deploying your api&lt;/h2&gt;
&lt;p&gt;So if you have a Digital Ocean account log in (and if you don’t, use my
&lt;a href=&#34;https://m.do.co/c/b68adc727710&#34;&gt;referral link&lt;/a&gt; to get 200$ to test things out)
and click on the top-right corner on the “Create” button, and then select “Droplet”
(a fancy name for a VM):&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/digital_ocean_1.png&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the next screen, select the region closest to you and then select Ubuntu as
the operating system, “Regular” for the CPU options, and then the 4$ (or the 6&lt;span class=&#34;math inline&#34;&gt;\(, it doesn&amp;#39;t matter at this stage) a month Droplet. We will need to upgrade it immediately after having created it in order to actually build the environment. This is because building the environment requires some more RAM than what the 6\)&lt;/span&gt; option offers, but starting from the cheapest option ensures that we
will then be able to downsize back to it, after the build process is done.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/digital_ocean_2.png&#34; width=&#34;60%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next comes how you want to authenticate to your VM. There are two options, one
using an SSH key, another using a password. If you’re already using Git, you can
use the same SSH key. Click on “New SSH Key” and paste the public key in the box
(you should find the key under &lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt; if you’re using Linux). If
you’re not using Git and have no idea what SSH keys are, my first piece of
advice is to start using Git and then to generate an SSH key and login using it.
This is much more secure than a password. Finally, click on “Create Droplet”.
This will start building your VM. Once the Droplet is done building, you can
check out its IP address:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/digital_ocean_3.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s immediately resize the Droplet to a larger size. As I said before,
this is only required to build our production environment using Nix. Once
the build is done, we can downsize again to the cheapest Droplet:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/digital_ocean_4.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Choose a Droplet with 2 gigs of RAM to be on the safe side, and also enable the
reserved IP option (this is a static IP that will never change):&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/digital_ocean_5.png&#34; width=&#34;80%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Finally, turn on your Droplet, it’s time to log in to it using SSH.&lt;/p&gt;
&lt;p&gt;Open a terminal on your computer and connect to your Droplet using SSH (starting
now, &lt;code&gt;user@local_computer&lt;/code&gt; refers to a terminal opened on your computer and
&lt;code&gt;root@droplet&lt;/code&gt; to an active ssh session inside your Droplet):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@local_computer &amp;gt; ssh root@IP_ADDRESS_OF_YOUR_DROPLET&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and add a folder that will contain the project’s files:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; mkdir titanic_api&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, let’s now copy our files to the Droplet using &lt;code&gt;scp&lt;/code&gt;. Open a terminal on
your computer, and navigate to where the &lt;code&gt;default.nix&lt;/code&gt; file is. If you prefer
doing this graphically, you can use Filezilla. Run the following command to
copy the &lt;code&gt;default.nix&lt;/code&gt; file to the Droplet:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@local_computer &amp;gt; scp default.nix root@IP_ADDRESS_OF_YOUR_DROPLET:/root/titanic_api/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now go back to the terminal that is logged into your Droplet. We now need to
install Nix. For this, follow the instructions from the &lt;a href=&#34;https://zero-to-nix.com/start/install&#34;&gt;Determinate
Systems&lt;/a&gt; installer, and run this line in
the Droplet:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; curl --proto &amp;#39;=https&amp;#39; --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pay attention to the final message once the installation is done:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Nix was installed successfully!
To get started using Nix, open a new shell or run `. /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So run &lt;code&gt;. /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh&lt;/code&gt; to start
the Nix daemon. Ok so now comes the magic of Nix. You can now build the exact
same environment that you used to build the pipeline on your computer in this
Droplet. Simply run &lt;code&gt;nix-build&lt;/code&gt; for the build process to start. I don’t really
know how to describe how easy and awesome this is. You may be thinking &lt;em&gt;well
installing R and a couple of packages is not that hard&lt;/em&gt;, but let me remind you
that we are using a Droplet that is running Ubuntu, which is likely NOT the
operating system that you are running. Maybe you are on Windows, maybe you are
on macOS, or maybe you’re running another Linux distribution. Whatever it is
you’re using, it will be different from that Droplet. Even if you’re running
Ubuntu on your computer, chances are that you’ve changed the CRAN repositories
from the default Ubuntu ones to the Posit ones, or maybe you’re using
&lt;a href=&#34;https://github.com/eddelbuettel/r2u&#34;&gt;r2u&lt;/a&gt;. Basically, the chances that you will
have the exact same environment in that Droplet than the one running on your
computer is basically 0. And if you’re already familiar with Docker, I think
that you will admit that this is much, much easier than dockerizing your
&lt;code&gt;{plumber}&lt;/code&gt; api. If you don’t agree, please shoot me an
&lt;a href=&#34;mailto:bruno@brodrigues.co&#34;&gt;email&lt;/a&gt; and tell me why, I’m honestly curious. Also,
let me stress again that if you needed to install a package like &lt;code&gt;{xlsx}&lt;/code&gt; that
requires Java to be installed, Nix would install the right version of Java for
you.&lt;/p&gt;
&lt;p&gt;Once the environment is done building, you can downsize your Droplet. Go back to
your Digital Ocean account, select that Droplet and choose “Resize Droplet”, and
go back to the 6$ a month plan.&lt;/p&gt;
&lt;p&gt;SSH back into the Droplet and copy the trained model &lt;code&gt;trained_logreg.rds&lt;/code&gt; and
the api file, &lt;code&gt;titanic_api.R&lt;/code&gt; to the Droplet using &lt;code&gt;scp&lt;/code&gt; or Filezilla. It’s time
to run the api. To do so, the obvious way would be simply to start an R session
and to execute the code to run the api. However, if something happens and the R
session dies, the api won’t restart. Instead, I’m using a CRON job and an
utility called &lt;code&gt;run-one&lt;/code&gt;. This utility, pre-installed in Ubuntu, runs one (1)
script at a time, and ensures that only one instance of said script is running.
So by putting this in a CRON job (CRON is a scheduler, so it executes a script
as often as you specify), &lt;code&gt;run-one&lt;/code&gt; will try to run the script. If it’s still
running, nothing happens, if the script is not running, it runs it.&lt;/p&gt;
&lt;p&gt;So go back to your local computer, and create a new text file, call it
&lt;code&gt;run_api.sh&lt;/code&gt; and write the following text in it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
while true
do
nix-shell /root/titanic_api/default.nix --run &amp;quot;Rscript -e &amp;#39;plumber::pr_run(plumber::pr(\&amp;quot;/root/titanic_api/titanic_api.R\&amp;quot;), host = \&amp;quot;0.0.0.0\&amp;quot;, port=80)&amp;#39;&amp;quot;
 sleep 10
done&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then copy this to your VM using &lt;code&gt;scp&lt;/code&gt; or Filezilla, to
&lt;code&gt;/root/titanic_api/run_api.sh&lt;/code&gt;. Then SSH back into your Droplet, go to where
the script is using &lt;code&gt;cd&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; cd /root/titanic_api/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and make the script executable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; chmod +x run_api.sh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re almost done. Now, let’s edit the &lt;code&gt;crontab&lt;/code&gt;, to specify that we want
this script to be executed every hour using &lt;code&gt;run-one&lt;/code&gt; (so if it’s running,
nothing happens, if it died, it gets restarted). To edit the &lt;code&gt;crontab&lt;/code&gt;,
type &lt;code&gt;crontab -e&lt;/code&gt; and select the editor you’re most comfortable with. If
you have no idea, select the first option, &lt;code&gt;nano&lt;/code&gt;. Using your keyboard
keys, navigate all the way down and type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;*/60 * * * * run-one /root/titanic_api/run_api.sh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;save the file by typing &lt;code&gt;CTRL-X&lt;/code&gt;, and then type &lt;code&gt;Y&lt;/code&gt; when asked &lt;code&gt;Save modified buffer?&lt;/code&gt;, and then type the &lt;code&gt;ENTER&lt;/code&gt; key when prompted for &lt;code&gt;File name to write&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We are now ready to start the api. Make sure CRON restarts by running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; service cron reload&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then run the script using &lt;code&gt;nohup&lt;/code&gt; followed by &lt;code&gt;run-one&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@droplet &amp;gt; nohup run-one /root/titanic_api/run_api.sh &amp;amp;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;run-one&lt;/code&gt; will now run the script and will ensure that only one instance of the
script is running (the &lt;code&gt;&amp;amp;&lt;/code&gt; character at the end means “run this in the
background” an &lt;code&gt;nohup&lt;/code&gt;, which stands for “no hang-up”, ensures the command will
continue running even when you close the terminal). If for any reason the
process dies, CRON will restart an instance of the script. We can now call our
api using this &lt;code&gt;curl&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user@local_computer &amp;gt; curl -X GET &amp;quot;http://IP_ADDRESS_OF_YOUR_DROPLET/prediction?sex=female&amp;amp;age=45&amp;quot; -H &amp;quot;accept: */*&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don’t have &lt;code&gt;curl&lt;/code&gt; installed, you can use &lt;a href=&#34;https://reqbin.com/curl&#34;&gt;this
webservice&lt;/a&gt;. You should see this answer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[{
    &amp;quot;.pred_class&amp;quot;: &amp;quot;1&amp;quot;
}]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll leave my Droplet running for a few days after I post this, so if you
want you can try it out run this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://142.93.164.182/prediction?sex=female&amp;amp;age=45&amp;quot; -H &amp;quot;accept: */*&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The answer is in the JSON format, and can now be ingested by some other script
which can now process it further.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This was a long blog post. While it is part of my Nix series of blog posts, I
almost didn’t talk about it, and this is actually the neat part. Nix made
something that is usually difficult to solve trivially simple. Without Nix, the
alternative would be to bundle the api with all its dependencies and an R
interpreter using Docker or install everything by hand on the server. But the
issue with Docker is that it’s not necessarily much easier than Nix, and you
still have to make sure building the image is reproducible. So you have to make
sure to use an image that ships with the right version of R and use &lt;code&gt;{renv}&lt;/code&gt; to
restore your packages. If you have system-level dependencies that are required,
you also have to deal with those. Nix takes care of all of this for you, so that
you can focus on all the other aspects of deployment, which take the bulk of the
effort and time.&lt;/p&gt;
&lt;p&gt;In the post I mentioned that you could also run Nix inside a Docker container.
If you are already invested in Docker, Nix is still useful because you can use
base NixOS images (NixOS is a Linux distribution that uses Nix as its package
manager) or you could install Nix inside an Ubuntu image and then benefit from
the reproducibility offered by Nix. Simply add &lt;code&gt;RUN nix-build&lt;/code&gt; to your
Dockerfile, and everything you need gets installed. You can even use Nix to
build Docker images instead of writing a Dockerfile. The possibilities are
endless!&lt;/p&gt;
&lt;p&gt;Now, before you start building apis using R, you may want to read this blog post
&lt;a href=&#34;https://matthewrkaye.com/posts/2023-06-29-lessons-learned-from-running-r-in-production/lessons-learned-from-running-r-in-production.html&#34;&gt;here&lt;/a&gt;
as well. I found it quite interesting: it discusses the shortcomings of using
R to build apis like I showed you here, which I think you need to know. If you
have needs like the author of this blog post, then maybe R and &lt;code&gt;{plumber}&lt;/code&gt; is not
the right solution for you.&lt;/p&gt;
&lt;p&gt;Next time, in part 4, I’ll either finally discuss how to do interactive work
using a Nix environment, or I’ll discuss my package, &lt;code&gt;{rix}&lt;/code&gt; in more detail.
We’ll see!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 2 -- running {targets} pipelines with Nix</title>
      <link>https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/pipeline_nix.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is the second post in a series of posts about Nix. Disclaimer: I’m a super
beginner with Nix. So this series of blog posts is more akin to notes that I’m
taking while learning than a super detailed tutorial. So if you’re a Nix expert
and read something stupid in here, that’s normal. This post is going to focus on
R (obviously) but the ideas are applicable to any programming language.&lt;/p&gt;
&lt;p&gt;So in &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&#34;&gt;part 1&lt;/a&gt; I
explained what Nix was and how you could use it to build reproducible
development environments. Now, let’s go into more details and actually set up
some environments and run a &lt;code&gt;{targets}&lt;/code&gt; pipeline using it.&lt;/p&gt;
&lt;p&gt;Obviously the first thing you should do is install Nix. A lot of what I’m
showing here comes from the &lt;a href=&#34;https://nix.dev/tutorials/&#34;&gt;Nix.dev&lt;/a&gt; so if you want
to install Nix, then look at the instructions
&lt;a href=&#34;https://nix.dev/tutorials/install-nix&#34;&gt;here&lt;/a&gt;. If you’re using Windows, you’ll
have to have WSL2 installed. If you don’t want to install Nix just yet, you can
also play around with a NixOS Docker image. NixOS is a Linux distribution that
uses the concepts of Nix for managing the whole operating system, and obviously
comes with the Nix package manager installed. But if you’re using Nix inside
Docker you won’t be able to work interactively with graphical applications like
RStudio, due to how Docker works (but more on working interactively with IDEs in
part 3 of this series, which I’m already drafting).&lt;/p&gt;
&lt;p&gt;Assuming you have Nix installed, you should be able to run the following command
in a terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell -p sl&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will launch a Nix shell with the &lt;code&gt;sl&lt;/code&gt; package installed. Because &lt;code&gt;sl&lt;/code&gt; is
not available, it’ll get installed on the fly, and you will get “dropped” into a
Nix shell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[nix-shell:~]$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now run &lt;code&gt;sl&lt;/code&gt; and marvel at what it does (I won’t spoil you). You can quit
the Nix shell by typing &lt;code&gt;exit&lt;/code&gt; and you’ll go back to your usual terminal. If you
try now to run &lt;code&gt;sl&lt;/code&gt; it won’t work (unless you installed on your daily machine).
So if you need to go back to that Nix shell and rerun &lt;code&gt;sl&lt;/code&gt;, simply rerun:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell -p sl&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time you’ll be dropped into the Nix shell immediately and can run &lt;code&gt;sl&lt;/code&gt;.
So if you need to use R, simply run the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell -p R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you’ll be dropped in a Nix shell with R. This version of R will be different
than the one potentially already installed on your system, and it won’t have
access to any R packages that you might have installed. This is because Nix
environment are isolated from the rest of your system (well, not quite, but
again, more on this in part 3). So you’d need to add packages as well (exit the
Nix shell and run this command to add packages):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell -p R rPackages.dplyr rPackages.janitor&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now start R in that Nix shell and load the &lt;code&gt;{dplyr}&lt;/code&gt; and &lt;code&gt;{janitor}&lt;/code&gt;
packages. You might be wondering how I knew that I needed to type
&lt;code&gt;rPackages.dplyr&lt;/code&gt; to install &lt;code&gt;{dplyr}&lt;/code&gt;. You can look for this information
&lt;a href=&#34;https://search.nixos.org/packages&#34;&gt;online&lt;/a&gt;. By the way, if a package uses the
&lt;code&gt;.&lt;/code&gt; character in its name, you should replace that &lt;code&gt;.&lt;/code&gt; character by &lt;code&gt;_&lt;/code&gt; so to
install &lt;code&gt;{data.table}&lt;/code&gt; write &lt;code&gt;rPackages.data_table&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So that’s nice and dandy, but not quite what we want. Instead, what we want is
to be able to declare what we need in terms of packages, dependencies, etc,
inside a file, and have Nix build an environment according to these
specifications which we can then use for our daily needs. To do so, we need to
write a so-called &lt;code&gt;default.nix&lt;/code&gt; file. This is what such a file looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/e11142026e2cef35ea52c9205703823df225c947.tar.gz&amp;quot;) {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [dplyr ggplot2 R];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wont discuss the intricate details of writing such a file just yet, because
it’ll take too much time and I’ll be repeating what you can find on the
&lt;a href=&#34;https://nix.dev/&#34;&gt;Nix.dev&lt;/a&gt; website. I’ll give some pointers though. But for
now, let’s assume that we already have such a &lt;code&gt;default.nix&lt;/code&gt; file that we defined
for our project, and see how we can use it to run a &lt;code&gt;{targets}&lt;/code&gt; pipeline. I’ll
explain how I write such files.&lt;/p&gt;
&lt;div id=&#34;running-a-targets-pipeline-using-nix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running a {targets} pipeline using Nix&lt;/h2&gt;
&lt;p&gt;Let’s say I have this, more complex, &lt;code&gt;default.nix&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz&amp;quot;) {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [
      targets
      tarchetypes
      rmarkdown
    (buildRPackage {
      name = &amp;quot;housing&amp;quot;;
      src = fetchgit {
        url = &amp;quot;https://github.com/rap4all/housing/&amp;quot;;
        branchName = &amp;quot;fusen&amp;quot;;
        rev = &amp;quot;1c860959310b80e67c41f7bbdc3e84cef00df18e&amp;quot;;
        sha256 = &amp;quot;sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&amp;quot;;
      };
    propagatedBuildInputs = [
        dplyr
        ggplot2
        janitor
        purrr
        readxl
        rlang
        rvest
        stringr
        tidyr
        ];
      })
    ];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the file above defines an environment that contains all the required packages
to run a pipeline that you can find on &lt;a href=&#34;https://github.com/b-rodrigues/nix_targets_pipeline&#34;&gt;this Github
repository&lt;/a&gt;. What’s
interesting is that I need to install a package that’s only been released on
Github, the &lt;code&gt;{housing}&lt;/code&gt; package that I wrote for the &lt;a href=&#34;https://raps-with-r.dev/packages.html&#34;&gt;purposes of my
book&lt;/a&gt;, and I can do so in that file as
well, using the &lt;code&gt;fetchgit()&lt;/code&gt; function. Nix has many such functions, called
&lt;em&gt;fetchers&lt;/em&gt; that simplify the process of downloading files from the internet, see
&lt;a href=&#34;https://ryantm.github.io/nixpkgs/builders/fetchers/&#34;&gt;here&lt;/a&gt;. This function takes
some self-explanatory inputs as arguments, and two other arguments that might
not be that self-explanatory: &lt;code&gt;rev&lt;/code&gt; and &lt;code&gt;sha256&lt;/code&gt;. &lt;code&gt;rev&lt;/code&gt; is actually the commit
on the Github repository. This commit is the one that I want to use for this
particular project. So if I keep working on this package, then building an
environment with this &lt;code&gt;default.nix&lt;/code&gt; will always pull the source code as it was
at that particular commit. &lt;code&gt;sha256&lt;/code&gt; is the hash of the downloaded repository. It
makes sure that the files weren’t tampered with. How did I obtain that? Well,
the simplest way is to set it to the empty string &lt;code&gt;&#34;&#34;&lt;/code&gt; and then try to build the
environment. This error message will pop-up:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;error: hash mismatch in fixed-output derivation &amp;#39;/nix/store/449zx4p6x0yijym14q3jslg55kihzw66-housing-1c86095.drv&amp;#39;:
         specified: sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=
            got:    sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So simply copy the hash from the last line, and rebuild! Then if in the future
something happens to the files, you’ll know. Another interesting input is
&lt;code&gt;propagatedBuildInputs&lt;/code&gt;. These are simply the dependencies of the &lt;code&gt;{housing}&lt;/code&gt;
package. To find them, see the &lt;code&gt;Imports:&lt;/code&gt; section of the
&lt;a href=&#34;https://github.com/rap4all/housing/blob/fusen/DESCRIPTION&#34;&gt;DESCRIPTION&lt;/a&gt; file.
There’s also the &lt;code&gt;fetchFromGithub&lt;/code&gt; fetcher that I could have used, but unlike
&lt;code&gt;fetchgit&lt;/code&gt;, it is not possible to specify the branch name we want to use. Since
here I wanted to get the code from the branch called &lt;code&gt;fusen&lt;/code&gt;, I had to use
&lt;code&gt;fetchgit&lt;/code&gt;. The last thing I want to explain is the very first line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz&amp;quot;) {} }:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In particular the url. This url points to a specific release of &lt;code&gt;nixpkgs&lt;/code&gt;, that
ships the required version of R for this project, R version 4.2.2. How did I
find this release of &lt;code&gt;nixpkgs&lt;/code&gt;? There’s a handy service for that
&lt;a href=&#34;https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;amp;package=r&#34;&gt;here&lt;/a&gt;.
So using this service, I get the right commit hash for the release that install
R version 4.2.2.&lt;/p&gt;
&lt;p&gt;Ok, but before building the environment defined by this file, let me just say
that I know what you’re thinking. Probably something along the lines of: &lt;em&gt;damn
it Bruno, this looks complicated and why should I care? Let me just use
{renv}!!&lt;/em&gt; and I’m not going to lie, writing the above file from scratch didn’t
take me long in typing, but it took me long in reading. I had to read quite a
lot (look at &lt;a href=&#34;https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/&#34;&gt;part
1&lt;/a&gt; for some nice
references) before being comfortable enough to write it. But I’ll just say this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;continue reading, because I hope to convince you that Nix is really worth the effort&lt;/li&gt;
&lt;li&gt;I’m working on a package that will help R users generate &lt;code&gt;default.nix&lt;/code&gt; files like the one from above with minimal effort (more on this at the end of the blog post)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re following along, instead of typing this file, you can clone
this &lt;a href=&#34;https://github.com/b-rodrigues/nix_targets_pipeline&#34;&gt;repository&lt;/a&gt;.
This repository contains the &lt;code&gt;default.nix&lt;/code&gt; file from above, and a &lt;code&gt;{targets}&lt;/code&gt;
pipeline that I will run in that environment.&lt;/p&gt;
&lt;p&gt;Ok, so now let’s build the environment by running &lt;code&gt;nix-build&lt;/code&gt; inside a terminal
in the folder that contains this file. It should take a bit of time, because
many of the packages will need to be built from source. But they &lt;strong&gt;will&lt;/strong&gt; get
built. Then, you can drop into a Nix shell using &lt;code&gt;nix-shell&lt;/code&gt; and then type R,
which will start the R session in that environment. You can then simply run
&lt;code&gt;targets::tar_make()&lt;/code&gt;, and you’ll see the file &lt;code&gt;analyse.html&lt;/code&gt; appear, which is
the output of the &lt;code&gt;{targets}&lt;/code&gt; pipeline.&lt;/p&gt;
&lt;p&gt;Before continuing, let me just make you realize three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we just ran a targets pipeline with all the needed dependencies which include not only package dependencies, but the right version of R (version 4.2.2) as well, and all required system dependencies;&lt;/li&gt;
&lt;li&gt;we did so WITHOUT using any containerization tool like Docker;&lt;/li&gt;
&lt;li&gt;the whole thing is &lt;strong&gt;completely&lt;/strong&gt; reproducible; the exact same packages will forever be installed, regardless of &lt;em&gt;when&lt;/em&gt; we build this environment, because I’m using a particular release of &lt;code&gt;nixpkgs&lt;/code&gt; (8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8) so each piece of software this release of Nix installs is going to stay constant.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And I need to stress &lt;em&gt;completely reproducible&lt;/em&gt;. Because using {renv}+Docker,
while providing a very nice solution, still has some issues. First of all, with
Docker, the underlying operating system (often Ubuntu) evolves and changes
through time. So lower level dependencies might change. And at some point in the
future, that version of Ubuntu will not be supported anymore. So it won’t be
possible to rebuild the image, because it won’t be possible to download any
software into it. So either we build our Docker image and really need to make
sure to keep it forever, or we need to port our pipeline to newer versions of
Ubuntu, without any guarantee that it’s going to work exactly the same. Also, by
defining &lt;code&gt;Dockerfile&lt;/code&gt;s that build upon &lt;code&gt;Dockerfile&lt;/code&gt;s that build upon
&lt;code&gt;Dockerfile&lt;/code&gt;s, it’s difficult to know what is actually installed in a particular
image. This situation can of course be avoided by writing &lt;code&gt;Dockerfile&lt;/code&gt;s in such
a way that it doesn’t rely on any other &lt;code&gt;Dockerfile&lt;/code&gt;, but that’s also a lot of
effort. Now don’t get me wrong: I’m not saying Docker should be canceled. I
still think that it has its place and that its perfectly fine to use it (I’ll
take a project that uses &lt;code&gt;{renv}&lt;/code&gt;+Docker any day over one that doesn’t!). But
you should be aware of alternative ways of running pipelines in a reproducible
way, and Nix is such a way.&lt;/p&gt;
&lt;p&gt;Going back to our pipeline, we could also run the pipeline with this command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell /path/to/default.nix --run &amp;quot;Rscript -e &amp;#39;setwd(\&amp;quot;/path/to\&amp;quot;);targets::tar_make()&amp;#39;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but it’s a bit of a mouthful. What you could do instead is running the pipeline
each time you drop into the nix shell by adding a so-called &lt;code&gt;shellHook&lt;/code&gt;. For
this, we need to change the &lt;code&gt;default.nix&lt;/code&gt; file again. Add these lines in the
&lt;code&gt;mkShell&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...
mkShell {
  buildInputs = [my-pkgs];
  shellHook = &amp;#39;&amp;#39;
     Rscript -e &amp;quot;targets::tar_make()&amp;quot;
  &amp;#39;&amp;#39;;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, each time you drop into the Nix shell in the folder containing that
&lt;code&gt;default.nix&lt;/code&gt; file, &lt;code&gt;targets::tar_make()&lt;/code&gt; get automatically executed. You can
then inspect the results.&lt;/p&gt;
&lt;p&gt;In the next blog post, I’ll show how we can use that environment with IDEs like
RStudio, VS Code and Emacs to work interactively. But first, let me quickly talk
about a package I’ve been working on to ease the process of writing
&lt;code&gt;default.nix&lt;/code&gt; files.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rix-reproducible-environments-with-nix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rix: Reproducible Environments with Nix&lt;/h2&gt;
&lt;p&gt;I wrote a very early, experimental package called &lt;code&gt;{rix}&lt;/code&gt; which will help write
these &lt;code&gt;default.nix&lt;/code&gt; files for us. &lt;code&gt;{rix}&lt;/code&gt; is an R package that hopefully will
make R users want to try out Nix for their development purposes. It aims to
mimic the workflow of &lt;code&gt;{renv}&lt;/code&gt;, or to be more exact, the workflow of what Python
users do when starting a new project. Usually what they do is create a
completely fresh environment using &lt;code&gt;pyenv&lt;/code&gt; (or another similar tool). Using
&lt;code&gt;pyenv&lt;/code&gt;, Python developers can install a per project version of Python and
Python packages, but unlike Nix, won’t install system-level dependencies as
well.&lt;/p&gt;
&lt;p&gt;If you want to install &lt;code&gt;{rix}&lt;/code&gt;, run the following line in an R session:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/rix&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then using the &lt;code&gt;rix()&lt;/code&gt; function to create a &lt;code&gt;default.nix&lt;/code&gt; file like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix::rix(r_ver = &amp;quot;current&amp;quot;,
         pkgs = c(&amp;quot;dplyr&amp;quot;, &amp;quot;janitor&amp;quot;),
         ide = &amp;quot;rstudio&amp;quot;,
         path = &amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a &lt;code&gt;default.nix&lt;/code&gt; file that Nix can use to build an environment
that includes the current versions of R, &lt;code&gt;{dplyr}&lt;/code&gt; and &lt;code&gt;{janitor}&lt;/code&gt;, and RStudio
as well. Yes you read that right: you need to have a per-project RStudio
installation. The reason is that RStudio modifies environment variables and so
your “locally” installed RStudio would not find the R version installed with
Nix. This is not the case with other IDEs like VS Code or Emacs. If you
want to have an environment with another version of R, simply run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rix::rix(r_ver = &amp;quot;4.2.1&amp;quot;,
         pkgs = c(&amp;quot;dplyr&amp;quot;, &amp;quot;janitor&amp;quot;),
         ide = &amp;quot;rstudio&amp;quot;,
         path = &amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you’ll get an environment with R version 4.2.1. To see which versions are
available, you can run &lt;code&gt;rix::available_r()&lt;/code&gt;. Learn more about &lt;code&gt;{rix}&lt;/code&gt; on its
&lt;a href=&#34;https://b-rodrigues.github.io/rix/&#34;&gt;website&lt;/a&gt;. It’s in very early stages, and
doesn’t handle packages that have only been released on Github, yet. And the
interface might change. I’m thinking of making it possible to list the packages
in a yaml file and then have &lt;code&gt;rix()&lt;/code&gt; generate the &lt;code&gt;default.nix&lt;/code&gt; file from the
yaml file. This might be cleaner. There is already something like this called
&lt;a href=&#34;https://github.com/luispedro/nixml/tree/main&#34;&gt;Nixml&lt;/a&gt;, so maybe I don’t even
need to rewrite anything!&lt;/p&gt;
&lt;p&gt;But I’ll discuss this is more detail next time, where I’ll explain how you can
use development environments built with Nix using an IDE.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The great &lt;a href=&#34;https://nix.dev/tutorials/install-nix&#34;&gt;Nix.dev&lt;/a&gt; tutorials.&lt;/li&gt;
&lt;li&gt;This &lt;a href=&#34;https://rgoswami.me/posts/rethinking-r-nix/&#34;&gt;blog post: Statistical Rethinking and Nix&lt;/a&gt; I referenced in part 1 as well, it helped me install my &lt;code&gt;{housing}&lt;/code&gt; package from Github.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/luispedro/nixml/tree/main&#34;&gt;Nixml&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible data science with Nix, part 1 -- what is Nix</title>
      <link>https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/</link>
      <pubDate>Thu, 13 Jul 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/nix.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is the first of a (hopefully) series of posts about Nix. Disclaimer: I’m a
super beginner with Nix. So this series of blog posts is more akin to notes that
I’m taking while learning than a super detailed tutorial. So if you’re a Nix
expert and read something stupid in here, that’s normal. This post is going to
focus on R (obviously) but the ideas are applicable to any programming language.&lt;/p&gt;
&lt;p&gt;To ensure that a project is reproducible you need to deal with at least four
things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make sure that the required/correct version of R (or any other language) is installed;&lt;/li&gt;
&lt;li&gt;Make sure that the required versions of packages are installed;&lt;/li&gt;
&lt;li&gt;Make sure that system dependencies are installed (for example, you’d need a working Java installation to install the &lt;code&gt;{rJava}&lt;/code&gt; R package on Linux);&lt;/li&gt;
&lt;li&gt;Make sure that you can install all of this for the hardware you have on hand.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the three first bullet points, the consensus seems to be a mixture of Docker
to deal with system dependencies, &lt;code&gt;{renv}&lt;/code&gt; for the packages (or &lt;code&gt;{groundhog}&lt;/code&gt;,
or a fixed CRAN snapshot like those &lt;a href=&#34;https://packagemanager.posit.co/__docs__/user/get-repo-url/#ui-frozen-urls&#34;&gt;Posit
provides&lt;/a&gt;)
and the &lt;a href=&#34;https://github.com/r-lib/rig&#34;&gt;R installation manager&lt;/a&gt; to install the
correct version of R (unless you use a Docker image as base that already ships
the required version by default). As for the last point, the only way out is to
be able to compile the software for the target architecture. There’s a lot of
moving pieces, and knowledge that you need to know and I even wrote a whole 522
pages &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;book about all of this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But it turns out that this is not the only solution. Docker + &lt;code&gt;{renv}&lt;/code&gt; (or some
other way to deal with packages) is likely the most popular way to ensure
reproducibility of your projects, but there are other tools to achieve this. One
such tool is called Nix.&lt;/p&gt;
&lt;p&gt;Nix is a package manager for Linux distributions, macOS and apparently it even
works on Windows if you enable WSL2. What’s a package manager? If you’re not a
Linux user, you may not be aware. Let me explain it this way: in R, if you want
to install a package to provide some functionality not included with a vanilla
installation of R, you’d run this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;dplyr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out that Linux distributions, like Ubuntu for example, work in a
similar way, but for software that you’d usually install using an installer (at
least on Windows). For example you could install Firefox on Ubuntu using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install firefox&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(there’s also graphical interfaces that make this process “more user-friendly”).
In Linux jargon, &lt;code&gt;packages&lt;/code&gt; are simply what normies call software (or I guess
it’s all “apps” these days). These packages get downloaded from so-called
repositories (think of CRAN, the repository of R packages) but for any type of
software that you might need to make your computer work: web browsers, office
suites, multimedia software and so on.&lt;/p&gt;
&lt;p&gt;So Nix is just another package manager that you can use to install software.&lt;/p&gt;
&lt;p&gt;But what interests us is not using Nix to install Firefox, but instead to
install R and the R packages that we require for our analysis (or any other
programming language that we need). But why use Nix instead of the usual ways to
install software on our operating systems?&lt;/p&gt;
&lt;p&gt;The first thing that you should know is that Nix’s repository, &lt;code&gt;nixpkgs&lt;/code&gt;, is
huge. Humongously huge. As I’m writing these lines, &lt;a href=&#34;https://search.nixos.org/packages&#34;&gt;there’s more than 80’000
pieces of software available&lt;/a&gt;, and the
&lt;em&gt;entirety of CRAN&lt;/em&gt; is also available through &lt;code&gt;nixpkgs&lt;/code&gt;. So instead of installing
R as you usually do and then use &lt;code&gt;install.packages()&lt;/code&gt; to install packages, you
could use Nix to handle everything. But still, why use Nix at all?&lt;/p&gt;
&lt;p&gt;Nix has an interesting feature: using Nix, it is possible to install software in
(relatively) isolated environments. So using Nix, you can install as many
versions of R and R packages that you need. Suppose that you start working on a
new project. As you start the project, with Nix, you would install a
project-specific version of R and R packages that you would only use for that
particular project. If you switch projects, you’d switch versions of R and R
packages. If you are familiar with &lt;code&gt;{renv}&lt;/code&gt;, you should see that this is exactly
the same thing: the difference is that not only will you have a project-specific
library of R packages, you will also have a project-specific R version. So if
you start a project now, you’d have R version 4.2.3 installed (the latest
version available in &lt;code&gt;nixpkgs&lt;/code&gt; but not the latest version available, more on
this later), with the accompagnying versions of R packages, for as long as the
project lives (which can be a long time). If you start a project next year, then
that project will have its own R, maybe R version 4.4.2 or something like that,
and the set of required R packages that would be current at that time. This is
because Nix always installs the software that you need in separate, (isolated)
environments on your computer. So you can define an environment for one specific
project.&lt;/p&gt;
&lt;p&gt;But Nix even goes even further: not only can you install R and R packages using
Nix (in isolated) project-specific environments, Nix even installs the required
system dependencies. So for example if I need &lt;code&gt;{rJava}&lt;/code&gt;, Nix will make sure to
install the correct version of Java as well, always in that project-specific
environment (so if you already some Java version installed on your system, there
won’t be any interference).&lt;/p&gt;
&lt;p&gt;What’s also pretty awesome, is that you can use a specific version of &lt;code&gt;nixpkgs&lt;/code&gt;
to &lt;em&gt;always&lt;/em&gt; get &lt;em&gt;exactly&lt;/em&gt; the same versions of &lt;strong&gt;all&lt;/strong&gt; the software whenever you
build that environment to run your project’s code. The environment gets defined
in a simple plain-text file, and anyone using that file to build the environment
will get exactly, byte by byte, the same environment as you when you initially
started the project. And this also regardless of the operating system that is
used.&lt;/p&gt;
&lt;p&gt;So let me illustrate this. After &lt;a href=&#34;https://nix.dev/tutorials/install-nix&#34;&gt;installing
Nix&lt;/a&gt;, I can define an environment by
writing a file called &lt;code&gt;default.nix&lt;/code&gt; that looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{ pkgs ? import (fetchTarball &amp;quot;https://github.com/NixOS/nixpkgs/archive/e11142026e2cef35ea52c9205703823df225c947.tar.gz&amp;quot;) {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [ dplyr ggplot2 R];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this certainly looks complicated! And it is. The entry cost to Nix is quite
high, because, actually, Nix is more than a package manager. It is also a
programming language, and this programming language gets used to configure
environments. I won’t go too much into detail, but you’ll see in the first line
that I’m using a specific version of &lt;code&gt;nixpkgs&lt;/code&gt; that gets downloaded directly
from Github. This means that all the software that I will install with that
specific version of &lt;code&gt;nixpkgs&lt;/code&gt; will always install the same software. This is
what ensures that R and R packages are versioned. Basically, by using a specific
version of &lt;code&gt;nixpkgs&lt;/code&gt;, I pin all the versions of all the software that this
particular version of Nix will &lt;em&gt;ever&lt;/em&gt; install. I then define a variable called
&lt;code&gt;my-pkgs&lt;/code&gt; which lists the packages I want to install (&lt;code&gt;{dplyr}&lt;/code&gt;, &lt;code&gt;{ggplot2}&lt;/code&gt; and
&lt;code&gt;R&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;By the way, this may look like it would take a lot of time to install because,
after all, you need to install R, R packages and underlying system dependencies,
but thankfully there is an online cache of binaries that gets automatically used
by Nix (&lt;a href=&#34;https://cache.nixos.org/&#34;&gt;cache.nixos.org&lt;/a&gt;) for fast installations. If
binaries are not available, sources get compiled.&lt;/p&gt;
&lt;p&gt;I can now create an environment with these exact specifications using (in the
directory where &lt;code&gt;default.nix&lt;/code&gt; is):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-build&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or I could use the R version from this environment to run some arbitrary code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nix-shell /home/renv/default.nix --run &amp;quot;Rscript -e &amp;#39;sessionInfo()&amp;#39;&amp;quot; &amp;gt;&amp;gt; /home/renv/sessionInfo.txt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(assuming my &lt;code&gt;default.nix&lt;/code&gt; file is available in the &lt;code&gt;/home/renv/&lt;/code&gt; directory).
This would build the environment on the fly and run &lt;code&gt;sessionInfo()&lt;/code&gt; inside of
it. Here are the contents of this &lt;code&gt;sessionInfo.txt&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R version 4.2.3 (2023-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)

Matrix products: default
BLAS/LAPACK: /nix/store/pbfs53rcnrzgjiaajf7xvwrfqq385ykv-blas-3/lib/libblas.so.3

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_4.2.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks like any other output of the &lt;code&gt;sessionInfo()&lt;/code&gt; function, but there is
something quite unusual: the &lt;code&gt;BLAS/LAPACK&lt;/code&gt; line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BLAS/LAPACK: /nix/store/pbfs53rcnrzgjiaajf7xvwrfqq385ykv-blas-3/lib/libblas.so.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;BLAS is a library that R uses for linear algebra, matrix multiplication and
vector operations. R usually ships with its own version of BLAS and LAPACK, but
it’s also possible to use external ones. Here, we see that the path to the
shared object &lt;code&gt;libblas.so.3&lt;/code&gt; is somewhere in &lt;code&gt;/nix/store/....&lt;/code&gt;. &lt;code&gt;/nix/store/&lt;/code&gt; is
where all the software gets installed. The long chain of seemingly random
characters is a hash, essentially the unique identifier of that particular
version of BLAS. This means that unlike Docker, if you’re using Nix you are also
certain than these types of dependencies, that may have an impact on your
results, also get handled properly, and that the exact same version you used
will keep getting installed in the future. Docker images also evolve, and even
if you use an LTS release of Ubuntu as a base, the underlying system packages
will evolve through time as well. And there will be a point in time where this
release will be abandoned (LTS releases receive 5 years of support), so if you
need to rebuild a Docker images based on an LTS that doesn’t get supported
anymore, you’re out of luck.&lt;/p&gt;
&lt;p&gt;If you don’t want to install Nix just yet on your computer, you should know that
there’s also a complete operating system called NixOS, that uses Nix as its
package manager, and that there are Docker images that use NixOS as a base. So
this means that you could use such an image and then build the environment (that
is 100% completely reproducible) inside and run a container that will always
produce the same output. To see an example of this, check out this &lt;a href=&#34;https://github.com/b-rodrigues/nix_experiments/tree/master&#34;&gt;Github
repo&lt;/a&gt;. I’m writing a
Dockerfile as I usually do, but actually I could even use Nix to define the
Docker image for me, it’s that powerful!&lt;/p&gt;
&lt;p&gt;Nix seems like a very powerful tool to me. But there are some “issues”:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As I stated above, the entry cost is quite high, because Nix is not “just a tool”, it’s a complete programming language that can even run pipelines, so you could technically even replace something like &lt;code&gt;{targets}&lt;/code&gt; with it;&lt;/li&gt;
&lt;li&gt;If you need to install specific versions of R packages, that are not pinned to dates, then Nix is not for you. Nix will always create a coherent environment with R and R packages that go together for a particular release of &lt;code&gt;nixpkgs&lt;/code&gt;. If for some reason you need a very old version of &lt;code&gt;{ggplot2}&lt;/code&gt; but a much more recent version of &lt;code&gt;{dplyr}&lt;/code&gt;, using Nix won’t make this any easier than other methods;&lt;/li&gt;
&lt;li&gt;There is no easy way (afaik) to find the version of &lt;code&gt;nixpkgs&lt;/code&gt; that you need to download to find the version of R that you may need; &lt;strong&gt;UPDATE&lt;/strong&gt;: turns out that there is such a &lt;a href=&#34;https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;amp;package=r&#34;&gt;simple tool&lt;/a&gt;, thanks to &lt;span class=&#34;citation&#34;&gt;@shane&lt;/span&gt;&lt;span class=&#34;citation&#34;&gt;@hachyderm.io&lt;/span&gt; for the telling me!&lt;/li&gt;
&lt;li&gt;R packages (and I guess others for other programming languages as well) that are available on the stable channel of &lt;code&gt;nixpkgs&lt;/code&gt; lag a bit behind their counterparts on CRAN. These usually all get updated whenever there’s a new release of R. Currently however, R is at version 4.2.3, but R should be at version 4.3.1 on the stable branch of &lt;code&gt;nixpkgs&lt;/code&gt;. This can sometimes happen due to various reasons (there are actual human beings behind this that volunteer their time and they also have a life). There is however an “unstable” &lt;code&gt;nixpkgs&lt;/code&gt; channel that contains bleeding edge versions of R packages (and R itself) if you really need the latest versions of packages (don’t worry about the “unstable” label, from my understanding this simply means that package have not been thoroughly tested yet, but is still pretty much rock-solid);&lt;/li&gt;
&lt;li&gt;If you need something that is not on CRAN (or Bioconductor) then it’s still possible to use Nix to install these packages, but you’ll have to perform some manual configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will keep exploring Nix, and this is essentially my todo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using my environment that I installed with Nix to work interactively;&lt;/li&gt;
&lt;li&gt;write some tool that lets me specify an R version, a list of packages and it generates a &lt;code&gt;default.nix&lt;/code&gt; file automagically (ideally it should also deal with packages only available on Github);&lt;/li&gt;
&lt;li&gt;????&lt;/li&gt;
&lt;li&gt;Profit!&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Resources&lt;/h3&gt;
&lt;p&gt;Here are some of the resources I’ve been using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://nix.dev/tutorials/first-steps/towards-reproducibility-pinning-nixpkgs#pinning-nixpkgs&#34;&gt;nix.dev tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nix-tutorial.gitlabpages.inria.fr/nix-tutorial/installation.html&#34;&gt;INRIA’s Nix tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nixos.org/guides/nix-pills/&#34;&gt;Nix pills&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nix-community/nix-data-science&#34;&gt;Nix for Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://christitus.com/nixos-explained/&#34;&gt;NixOS explained&lt;/a&gt;: NixOS is an entire Linux distribution that uses Nix as its package manager.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rgoswami.me/posts/nix-r-devtools/&#34;&gt;Blog post: Nix with R and devtools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rgoswami.me/posts/rethinking-r-nix/&#34;&gt;Blog post: Statistical Rethinking and Nix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lazamar.github.io/download-specific-package-version-with-nix/&#34;&gt;Blog post: Searching and installing old versions of Nix packages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;thanks&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Thanks&lt;/h3&gt;
&lt;p&gt;Many thanks to &lt;a href=&#34;https://github.com/jbedo&#34;&gt;Justin Bedő&lt;/a&gt;, maintainer of the R
package for Nix, for answering all my questions on Nix!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to self-publish a technical book on Leanpub and Amazon using Quarto</title>
      <link>https://www.brodrigues.co/blog/2023-06-29-book_quarto/</link>
      <pubDate>Thu, 29 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-06-29-book_quarto/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gosling.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;UPDATE: I’ve update this blog post on the 30 of June 2023. I corrected a statement
where I said that the &lt;code&gt;_quarto.yml&lt;/code&gt; file is where you can choose the version of R
to compile the book. That’s wrong, choosing the version of R to compile the book
is done on the Github Actions workflow. I’ve also added some answers to questions
I got on social media.&lt;/p&gt;
&lt;p&gt;So I’ve recently self-published a book on both
&lt;a href=&#34;https://leanpub.com/raps-with-r/&#34;&gt;Leanpub&lt;/a&gt; as an Ebook and
&lt;a href=&#34;https://www.amazon.com/dp/B0C87H6MGF&#34;&gt;Amazon&lt;/a&gt; as a &lt;em&gt;physical&lt;/em&gt; book and thought
that it would be worth it to write down how to do it. I’ve wasted some time
getting everything to work flawlessly so if you’re looking for a guide on how to
create both an ebook and a print-ready PDF for Amazon’s Kindle Direct Publishing
service using Quarto, you’ve come to the right place.&lt;/p&gt;
&lt;p&gt;If you don’t want to waste time reading, &lt;a href=&#34;https://github.com/b-rodrigues/kdp_quarto&#34;&gt;just fork this
repo&lt;/a&gt; and use that as a starting
point. Each time you push a change to the repo, a website, Epub and PDF get
generated using Github Actions. If you want to understand the details, read on.&lt;/p&gt;
&lt;div id=&#34;your-books-dependencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Your book’s dependencies&lt;/h2&gt;
&lt;p&gt;You should start by creating an &lt;code&gt;renv.lock&lt;/code&gt; file. This file will list all the
dependencies of your book. For example, if you’re using &lt;code&gt;{ggplot2}&lt;/code&gt; to make
graphs or &lt;code&gt;{flextable}&lt;/code&gt; for tables, the &lt;code&gt;renv.lock&lt;/code&gt; file will list them and then
this file will be used to download the required packages by Github Actions (more
on Github Actions later) to create the book. The template comes with one such
&lt;code&gt;renv.lock&lt;/code&gt; file, but you should generate one specific to your project. Simply
install &lt;code&gt;{renv}&lt;/code&gt; and run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;renv::init()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Answer “Y” to the question and wait a little. The &lt;code&gt;renv.lock&lt;/code&gt; file should appear
alongside the source of your book now. If you need to install more packages to
keep writing your book, install them as usual (using
&lt;code&gt;install.packages(&#34;package&#34;)&lt;/code&gt;) but then don’t forget to create a new &lt;code&gt;renv.lock&lt;/code&gt;
file using &lt;code&gt;renv::snapshot()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quarto.yml&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;_quarto.yml&lt;/h2&gt;
&lt;p&gt;Whatever output format, everything gets defined in the &lt;code&gt;_quarto.yml&lt;/code&gt; file in the
root directory of your book. This file is where you can choose which themes to
use for your website for example, which output formats you want to compile your
book into, etc. I’ll discuss each option for each format below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generating-the-website&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generating the website&lt;/h2&gt;
&lt;p&gt;I’m using Github Actions to generate each format of the book. Github Actions is
essentially a computer hosted by Github that you can use to run arbitrary
commands. These commands must be written in a specific file which must be put in
a specific place in your repository.
&lt;a href=&#34;https://github.com/b-rodrigues/kdp_quarto/blob/main/.github/workflows/build_book.yml&#34;&gt;Here&lt;/a&gt;
is that file for the repo I linked above. I won’t go into details because I’ve
explained how Github Actions works
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;here&lt;/a&gt; already, but you’ll notice
that you can choose a version of R to compile your document and also a different
version of Quarto. This can be useful for reproducibility.&lt;/p&gt;
&lt;p&gt;Create a new branch called &lt;code&gt;gh-pages&lt;/code&gt; and then go to settings, then on the
side-bar on the left choose “Actions”, and scroll down. Then, in “Workflow
persmissions”, check “Read and Write permissions” and “Allow Github Actions to
create and approve pull requests”. Then go to “Pages” which you can find on the
side-bar on the left, and choose “Deploy from a branch” under “Build and
deployment” and choose “gh-pages” and “root”:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/github_pages.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Each time you push, the website to your book will get updated. Here are the options
I chose for my website, which you can find in the &lt;code&gt;_quarto.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;html:
   theme:
     light: flatly
     dark: solar
   css:
     epub.css&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So my website is available in two themes, a dark and light one. I highly
recommend you also provide two themes. You can also provide a &lt;code&gt;.css&lt;/code&gt; file to
customize the appearance of you website, and of your ebook (that’s because an
Epub is actually a bunch of html files). The &lt;code&gt;.css&lt;/code&gt; I’m using is quite simple,
the only thing it’s doing is making sure that images won’t be wider than the
web-page. You can view the website of this template book
&lt;a href=&#34;https://b-rodrigues.github.io/kdp_quarto/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generating-an-ebook&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generating an Ebook&lt;/h2&gt;
&lt;p&gt;Let’s continue with the &lt;code&gt;.epub&lt;/code&gt; format. This is an Ebook format that can be read
on E-readers such as the Kindle from Amazon. If you want to sell an Ebook on
Leanpub (or send it to your Kindle), it needs to pass a tool called &lt;code&gt;epubcheck&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I’ve already written about generating ebooks in the past
(&lt;a href=&#34;https://www.brodrigues.co/blog/2023-03-03-quarto_books/&#34;&gt;here&lt;/a&gt;). However, the
advice in that blog post was only valid because there were bugs in the version
of Quarto that was current at the time and so I showed some workarounds. With
the current version, no workarounds are needed anymore, Epubs generated by
Quarto now pass &lt;code&gt;epubcheck&lt;/code&gt;. Check the source, specifically &lt;code&gt;index.qmd&lt;/code&gt; to see
how I include graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;generating-a-print-ready-pdf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Generating a print-ready PDF&lt;/h2&gt;
&lt;p&gt;This was the hardest part: I’m using Amazon’s KDP service to sell physical
copies of the book and the PDF needs to be in a specific format. I’m using the 6
x 9 format without bleed, which seems to be the most common. If you look again
at the &lt;code&gt;_quarto.yml&lt;/code&gt; file, you should see this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  pdf:
    keep-tex: true
    documentclass: scrbook
    classoption: [paper=6in:9in,pagesize=pdftex,headinclude=on,footinclude=on,12pt]
    include-in-header:
      text: |
        \usepackage{fvextra}
        \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
        \areaset[0.50in]{4.5in}{8in}
    include-before-body:
      text: |
        \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
           showspaces = false,
           showtabs = false,
           breaksymbolleft={},
           breaklines
           % Note: setting commandchars=\\\{\} here will cause an error 
        }
    fig-pos: &amp;#39;H&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What’s important is ‘classoption’:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;classoption: [paper=6in:9in,pagesize=pdftex,headinclude=on,footinclude=on,12pt]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where I can choose the dimensions of the book (6 x 9) and the size of the font (12pt).
Then:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include-in-header:
  text: |
    \usepackage{fvextra}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
    \areaset[0.50in]{4.5in}{8in}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;fvextra&lt;/code&gt; and the call to &lt;code&gt;\DefineVerbatimEnvironment&lt;/code&gt; I make sure that long lines of code
get wrapped in the PDF. Without this, long lines of code would simply continue outside the margins
of the PDF, and Amazon’s KDP doesn’t accept a PDF like this.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\areaset[0.50in]{4.5in}{8in}&lt;/code&gt;: this is the area that well be used for writing. These are the correct
dimensions for a 6 by 9 book without bleed. Then, I keep customizing the &lt;code&gt;verbatim&lt;/code&gt; environment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
       showspaces = false,
       showtabs = false,
       breaksymbolleft={},
       breaklines
       % Note: setting commandchars=\\\{\} here will cause an error 
    }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the last option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fig-pos: &amp;#39;H&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This ensures that the figures are placed EXACTLY where you say they should be in
the final PDF. For those of you that use LaTeX, you know that LaTeX sometimes
takes some liberties with figure placement. I’ve been told the lie that LaTeX
knows where to place the figures perfectly well many times but I don’t buy
it. So use &lt;code&gt;fig-pos: &#39;H&#39;&lt;/code&gt; to avoid lots of frustration.&lt;/p&gt;
&lt;p&gt;That’s it! You should now be able to generate a book that is print-ready, and
an Epub that passes &lt;code&gt;epubcheck&lt;/code&gt; as well as website. You can now just focus
on writing. Also check the source of &lt;code&gt;index.qmd&lt;/code&gt; for to see how to include text
in the PDF only (or not show text in the PDF).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;my-personal-experience-and-some-faq&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My personal experience and some FAQ&lt;/h2&gt;
&lt;p&gt;Overall, I enjoyed using both Leanpub and Amazon to publish my book. Leanpub is
really nice, because they really offer a very nice deal: you get 80% of the
sales price as royalties, which is the highest share I’ve seen. Also the people
working there are really nice, I’ve had the chance to discuss with Len Epp,
Leanpub’s cofounder, in his &lt;a href=&#34;https://youtu.be/aXfjhf2cDo0&#34;&gt;Frontmatter podcast&lt;/a&gt;
and would definitely continue using their platform in the future. Regarding
Amazon I must say that the experience was quite good as well; the only friction
I had was getting the PDF in the right format for printing, but that’s hardly
something that Amazon can be blamed for. After all if the PDF’s formatting is
bad, the books will look like crap as well. One thing you should know though is
that you need to get a VAT number to sell books on Amazon. I live in Luxembourg
and getting one is trivial, but in other countries this may be more complex. You
should know as well that Leanpub can sell the physical copies of your book,
through Amazon, for you. They essentially act as a publisher then. This way, you
don’t need to get a VAT number, if that’s difficult for you. But you’ll need to
share the Amazon royalties with Leanpub.&lt;/p&gt;
&lt;p&gt;When publishing a book through Amazon’s KDP service, you also get access to a
basic book cover editor that you can use to create a cover for your book. You
can provide an image and then use the editor to create the cover, but you can
also provide a ready-made cover if you have the talent to make one using an
image editing software. Once you’re done, and click “Publish” on Amazon, the
book will get reviewed by a human. This process can take up to three days, but
in my case it took only 4 to 6 hours. However, my book was rejected, twice. One
time was because one of the images I used in the book had colour bars in the
bottom right corner, that I needed to remove, and the other time was because the
“g” in my name, “Rodrigues” was cut by the cover editor and it was hard to tell
if it was a “g” or a “q”. Once I corrected both issues, the book was available
for order on Amazon.com within the day. The other marketplaces, like France and
Germany took one day more, and the UK marketplace took 4 days.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;I’m sorry, I have no idea where I found all of this stuff. I looked for it for
some time, and if memory serves most of this came from stackoverflow.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why you should consider working on a dockerized development environment</title>
      <link>https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/</link>
      <pubDate>Mon, 08 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/ship_pc.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Last year I wrote a post about dockerizing &lt;code&gt;{targets}&lt;/code&gt;’s pipelines (&lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;link to
post&lt;/a&gt;) and between that blog
post and this one, I’ve written a whole book on building reproducible analytical
pipelines that you can read &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;here&lt;/a&gt; (for free!). In the
book I explain how you can build projects that will stay reproducible thanks to
Docker. With Docker, you don’t only ship the code to your project, but ship &lt;em&gt;a
whole computer&lt;/em&gt; with it, and your project will be executed inside that computer.
By &lt;em&gt;whole computer&lt;/em&gt; I mean the whole computational environment: so a version of
R, the required packages your project depends on, all of it running on a Linux
distribution (usually Ubuntu). The whole project can then be executed like any
program from your computer (whether you’re running Windows, macOS or Linux) or
even on the cloud with a single command.&lt;/p&gt;
&lt;p&gt;In this blog post, I’ll discuss something that I’ve been trying for some time
now: working directly from a dockerized environment. The idea is to have a
Docker image that comes with R, all the usual packages I use for development,
Quarto, a LaTeX distribution (that I installed with &lt;code&gt;{tinytex}&lt;/code&gt;) and finally, my
IDE of choice, Spacemacs (if you use RStudio, just read on, I’ll explain how you
can achieve the same thing but with RStudio instead). Why do this? Well because
this way I can deploy the exact same environment anywhere. If I get a new
computer, I’m only one command line away from a functioning environment. If I
want to dockerize a &lt;code&gt;{targets}&lt;/code&gt; pipeline, I can write a new Dockerfile that
builds upon this image which ensures that there are no discrepancies between the
development environment and the production environment. And because I’m building
the image on top of a Rocker image, everything just work. If I need to install a
package that might be tricky to install (for example, a package that depends on
&lt;code&gt;{rJava}&lt;/code&gt;, using Docker might be the simplest way to get it to work.&lt;/p&gt;
&lt;p&gt;So, here’s the Dockerfile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# This builds upon the Rocker project&amp;#39;s versioned image for R version 4.3
FROM rocker/r-ver:4.3

# install `gpg-agent` and `software-properties-common` which are needed to add an Ubuntu ppa to install Emacs
RUN apt-get update \
    &amp;amp;&amp;amp; apt-get install -y --no-install-recommends \
    gpg-agent software-properties-common

# add the ppa which includes the latest version of Emacs
RUN add-apt-repository ppa:kelleyk/emacs

# Install `git`, `wget` and the latest `Emacs`
RUN apt-get update \
    &amp;amp;&amp;amp; apt-get install -y --no-install-recommends \
    git \
    wget \
    emacs28-nox

# Install spacemacs by cloning its repository
RUN git clone -b develop https://github.com/syl20bnr/spacemacs ~/.emacs.d

# Download my .spacemacs config file
RUN wget https://raw.githubusercontent.com/b-rodrigues/dotfiles/master/dotfiles/.spacemacs -O ~/.spacemacs

# This launches emacs in daemon mode. This is needed to initialize spacemacs.
# Running it in daemon mode is required because a Dockerfile must be setup non-interactively
RUN emacs --daemon

# Install a bunch of Ubuntu dependencies. These are typical dependencies required to use some
# R packages on Linux.
RUN apt-get update \
   &amp;amp;&amp;amp; apt-get install -y --no-install-recommends \
   aspell \
   aspell-en \
   aspell-fr \
   aspell-pt-pt \
   libfontconfig1-dev \
   libglpk-dev \
   libxml2-dev \
   libcairo2-dev \
   libgit2-dev \
   default-libmysqlclient-dev \
   libpq-dev \
   libsasl2-dev \
   libsqlite3-dev \
   libssh2-1-dev \
   libxtst6 \
   libcurl4-openssl-dev \
   libharfbuzz-dev \
   libfribidi-dev \
   libfreetype6-dev \
   libpng-dev \
   libtiff5-dev \
   libjpeg-dev \
   libxt-dev \
   unixodbc-dev \
   pandoc

# Download the latest version of Quarto
RUN wget https://github.com/quarto-dev/quarto-cli/releases/download/v1.3.340/quarto-1.3.340-linux-amd64.deb -O ~/quarto.deb

# Install the latest version of Quarto
RUN apt-get install --yes ~/quarto.deb

# Remove the installer
RUN rm ~/quarto.deb

# Create a directory to host my projects
RUN mkdir /root/projects/

# Write a bunch of lines to the .Rprofile
# This makes sure that the httpgd server runs on localhost and on the port 8888
RUN echo &amp;#39;options(httpgd.host = &amp;quot;0.0.0.0&amp;quot;, httpgd.port = 8888, httpgd.token = &amp;quot;aaaaaaaa&amp;quot;)&amp;#39; &amp;gt;&amp;gt; /root/.Rprofile

# This option clones renv cache folders inside the root folder of the projects. This makes
# sure that they stay persistent across reboots.
RUN echo &amp;#39;options(renv.config.cache.symlinks = FALSE)&amp;#39; &amp;gt;&amp;gt; /root/.Rprofile

# Serve shiny apps through localhost and port 8888
RUN echo &amp;#39;options(shiny.host = &amp;quot;0.0.0.0&amp;quot;, shiny.port = 8888)&amp;#39; &amp;gt;&amp;gt; /root/.Rprofile

# Set the CRAN package repositories to the PPPM at the 28th of April
RUN echo &amp;#39;options(repos = c(REPO_NAME = &amp;quot;https://packagemanager.rstudio.com/cran/__linux__/jammy/2023-04-28&amp;quot;))&amp;#39; &amp;gt;&amp;gt; /root/.Rprofile

# Install the usual packages I use
RUN R -e &amp;quot;install.packages(c(&amp;#39;quarto&amp;#39;, &amp;#39;remotes&amp;#39;, &amp;#39;tinytex&amp;#39;, &amp;#39;tidyverse&amp;#39;, &amp;#39;arrow&amp;#39;, &amp;#39;chronicler&amp;#39;, &amp;#39;janitor&amp;#39;, &amp;#39;targets&amp;#39;, &amp;#39;tarchetypes&amp;#39;, &amp;#39;openxlsx&amp;#39;, &amp;#39;shiny&amp;#39;, &amp;#39;flexdashboard&amp;#39;, &amp;#39;data.table&amp;#39;, &amp;#39;httpgd&amp;#39;, &amp;#39;blogdown&amp;#39;, &amp;#39;bookdown&amp;#39;))&amp;quot; 

# Install the g2r package (not yet available on CRAN)
RUN R -e &amp;quot;remotes::install_github(&amp;#39;devOpifex/g2r&amp;#39;)&amp;quot;

# Install a LaTeX distro using tinytex
RUN R -e &amp;quot;tinytex::install_tinytex()&amp;quot;

# Install hugo for blogging
RUN R -e &amp;quot;blogdown::install_hugo()&amp;quot;

# Expose port 8888
EXPOSE 8888&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(and &lt;a href=&#34;https://github.com/b-rodrigues/ess_dev_env&#34;&gt;here’s&lt;/a&gt; the repository where you can find it).&lt;/p&gt;
&lt;p&gt;I’ve explained each line of the Dockerfile using comments in the Dockerfile
itself. But before explaining it in more detail, here’s a word from this blog
post’s sponsor: me, I’m this post’s sponsor.&lt;/p&gt;
&lt;p&gt;If you have read until here dear reader, let me express my gratitude by offering
you a &lt;a href=&#34;https://leanpub.com/raps-with-r/c/blog_reader&#34;&gt;discount code&lt;/a&gt; to purchase
a DRM-free Epub and PDF version of my book, Building reproducible analytical
pipelines with R (that you can also read for free
&lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;here&lt;/a&gt; by the way). Using the &lt;a href=&#34;https://leanpub.com/raps-with-r/c/blog_reader&#34;&gt;discount
code&lt;/a&gt; you can get a DRM-free epub
and PDF version of the book for 14.99 instead of 19.99! If you want a good old
physical book instead, you’ll need to wait some more, I still need to get the
formatting right before making it available through Amazon self-publishing
service.&lt;/p&gt;
&lt;p&gt;Now back to our Dockerfile. There are several decisions that I took that I need
explain: first, why use a versioned image, and why use the PPPM at a specific
date? I did this so that it doesn’t matter &lt;em&gt;when&lt;/em&gt; I build the image, I always
know which version of R and packages I get. Then, what’s with all the options
that I write to the &lt;code&gt;.Rprofile&lt;/code&gt;? Well, don’t forget that when I will be running
the Docker container defined by this image, I will be using Emacs inside a
terminal. So if I want to see plots for example, I need to use the &lt;code&gt;{httpgd}&lt;/code&gt;
package. This package provides a graphics device that runs on a web server, so
if I tell &lt;code&gt;{httpgd}&lt;/code&gt; to serve the images over port &lt;code&gt;8888&lt;/code&gt;, and then expose this
port in the Dockerfile, I can access &lt;code&gt;{httpgd}&lt;/code&gt; from my web browser by pointing
it to &lt;code&gt;http://localhost:8888&lt;/code&gt;. Here’s how this looks like:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dev_env_httpgd.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The terminal on top of the image is running my dockerized environment, and below
you see my web browser on to the &lt;code&gt;http://localhost:8888/live?token=aaaaaaaa&lt;/code&gt;
url to access the &lt;code&gt;{httpgd}&lt;/code&gt; web server &lt;em&gt;that is running inside the Docker
container&lt;/em&gt;. And it’s the same logic with Shiny: if I’m working on a Shiny app
from inside the container, I can access it by going to &lt;code&gt;http://localhost:8888/&lt;/code&gt;.
Now, I have to do all of this because I’m running Emacs, but if you’re
developing with RStudio, you could instead run RStudio server, access it on
&lt;code&gt;http://localhost:8888/&lt;/code&gt;, and then no need to think about configuring on which
ports &lt;code&gt;{httpgd}&lt;/code&gt; serves images, or on which port Shiny apps should run.
Everything will be directly visible from within RStudio. &lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/rstudio_4.3.0.Dockerfile&#34;&gt;Here is
the
Dockerfile&lt;/a&gt;
to run R version 4.3 with RStudio as the IDE. If you want to use this, you could
simply start from the above Dockerfile and then add the stuff you need, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/rstudio:4.3.0

# and add what you want below like installing R packages and whatnot&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is still one important thing that you should know before using a
dockerized development environment: a running Docker container can be changed
(for example, you could install new R packages), but once you shut it down and
restart it, any change will be lost. So how do you save your work? Well, you
need to run the Docker image with a volume. A volume is nothing more than a
folder on your computer that is linked to a folder inside the Docker container.
Anything that gets saved there from the Docker container will be available on
your computer, and vice-versa. Here is the command that I use to run my
container:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm -it --name ess_dev_env -p 8888:8888 -v /home/path_to_volume/folder:/root/projects:rw brodriguesco/ess_dev_env:main-cdcb1719d emacs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take note of the &lt;code&gt;-v&lt;/code&gt; flag, especially what comes after:
&lt;code&gt;/home/path_to_volume/folder:/root/projects:rw&lt;/code&gt;. &lt;code&gt;/home/path_to_volume/folder&lt;/code&gt;
is the folder on my computer, and it is linked to the &lt;code&gt;/root/projects&lt;/code&gt; folder
inside the Docker container. When I run the above command inside a terminal,
Spacemacs starts and I can get to work! If you build a development environment
based on RStudio, you would essentially use the same command, you would only
need to set a password to login first (read the instructions
&lt;a href=&#34;https://rocker-project.org/images/versioned/rstudio.html#how-to-use&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Also, if you forgot to add a package and want to install it and make this change
permanent, the best way is to add it to the Dockerfile and rebuild the image.
I’ve streamlined this process by using Github Actions to build images and push
them to Docker Hub. Take a look at the &lt;a href=&#34;https://github.com/b-rodrigues/ess_dev_env&#34;&gt;Github repository where my Dockerfile is
hosted&lt;/a&gt;, and if you are familiar
with Github Actions, take a look at my workflow file. You’ll see that I’ve set
up Github Actions to build the Docker image and push it to Docker Hub each time
I commit, and name the Docker image &lt;code&gt;ess_dev_env:main-xxxxx&lt;/code&gt; where &lt;code&gt;xxxxx&lt;/code&gt; is
the corresponding commit hash on Github (so I can easily know which image was
built with which commit).&lt;/p&gt;
&lt;p&gt;I’ll be using this dockerized image for some time, and see how it feels. For now, it
works quite well!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;ve been blogging for 10 years</title>
      <link>https://www.brodrigues.co/blog/2023-04-25-10_years/</link>
      <pubDate>Tue, 25 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-04-25-10_years/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/10_years.jpg&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve been blogging for 10 years, actually even a bit more than that, my very first
blog is not online anymore and if I remember correctly was in French. I think it
was around 2010 when I was a Master’s student.&lt;/p&gt;
&lt;p&gt;Anyways, here are my thoughts on why I think blogging is a very nice activity if
you’re interested in technology or science.&lt;/p&gt;
&lt;p&gt;The primary reason I started my blog was to have a repository of code snippets
that I could re-use. Anytime I had to do something for my thesis or for work, I
would write instructions around the code that I’ve used to explain how and why
things worked out. But I needed a spot to save these scripts, and it turns out
that a blog was the best solution for this: it doesn’t require any subscription
to a (very often proprietary) service to store my notes for me, and I need 0
discipline to maintain a blog. Simply write a post, push to Github, website gets
updated. If I would store the notes myself on my computer instead, this would
mean a lot of work, and I would need to think about how to make them available
across devices.&lt;/p&gt;
&lt;p&gt;The other reason is that I thought that this would be a good way for me to
contribute to the wider free software and open source ecosystem. I’m not a
programmer, so contributing code would be quite difficult for me. I’ve recently
published a &lt;a href=&#34;https://b-rodrigues.github.io/chronicler/&#34;&gt;package&lt;/a&gt;, so in the end
I ended up contributing code, but that was more due to “luck” finding an actual
problem that hadn’t been solved (well, that’s not really the case, logging in R
had been solved, but not using a monad and for some reason I had become obsessed
with monads in 2022) and also thanks to the help of much better programmers than
myself. So writing and posting these blog posts would be my way to contribute to
the community. I think that this was the right decision, as I’ve had many people
throughout the years thank me for some of my blog posts that helped them with
some of their tasks.&lt;/p&gt;
&lt;p&gt;Now, not all blog posts were about problems that I encountered throughout my
career. There were also some blog posts about topics that piqued my interest,
but purely out of curiosity. For example the ones about NLP, like this
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract/&#34;&gt;one&lt;/a&gt;,
among others. I’m lucky enough that I find enjoyment in programming and exploring
data for fun, so I do write a lot of code. But how did I manage to consistently
write blog posts for 10 years+?&lt;/p&gt;
&lt;p&gt;I think that part of the reason is that I have literally 0 commitment to this
blog. I don’t force myself to write on a schedule and sometimes don’t write for
months like in 2020 where I didn’t write for 5 months because I was busy
renovating my home and taking care of my baby daughter. I didn’t even miss
writing. I think that one of the reasons this works is also because I have
absolutely 0 trackers on this website. For all I know, this post will get read
by 3 people, me, you and my mom. The only clue I have that one particular post
was successful is if people reshare the announcement I make on social media, or
if they contact me with questions or praise, or if it gets picked up for the R
weekly highlights. By not having any trackers and not having really a clue of
what people like, I avoid falling into the “recommendation engine” or “SEO”
trap. If I did use trackers and knew exactly what my &lt;em&gt;audience&lt;/em&gt; wanted, I’d be
very incentivized to just continue writing what would generate the most traffic.
And the issue with that, is that it would feel like a job, and I very likely
would have abandoned this endeavour a long time ago. What generates a lot of
traffic are posts mostly aimed at beginners, tutorials that explain how to do a
t-test or make a bar graph with two y-axes, but sorry, I’m not interested. I
don’t &lt;em&gt;hate&lt;/em&gt; beginners, but I don’t only want to write tutorials to serve ads to
my readers and tell them to subscribe to newsletters, bla bla bla. I have no
qualms with people doing this, but that’s simply not my thing. Not interested (and
don’t get me wrong, I have nothing against tutorial blog post, quite the contrary,
especially when they present some lesser-known features of a package).&lt;/p&gt;
&lt;p&gt;Also, the first thing I install on my web-browser is an ad-blocker, and I would
be a huge hypocrite if I tracked my blog’s visits. To be fully transparent, I do
use Goatcounter for my latest book &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;here&lt;/a&gt;, but I don’t
adjust the book’s content to the audience. It’s just to know if people read it,
because writing a book takes some effort and I was curious. I might remove it in
the future though. Again, nothing against people trying to live off the
internet, I myself accept
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;donations&lt;/a&gt;, but if I started to look
into what drives people to click and donate, I’d turn this into a job, and that
would be the fastest way for me to hate blogging.&lt;/p&gt;
&lt;p&gt;So the reason this has been working is simply because I avoided considering this
as an obligation, a duty or a job, and in order to do this, I avoid collecting
data.&lt;/p&gt;
&lt;p&gt;So blogging is a nice way to store code snippets and quickly find them. These
code snippets can in turn help other people facing similar issues. But what are
some other benefits of blogging? First, by turning your code into a full-fledged
blog post, it also forces you to think more carefully about the solution you
found. Very often, while writing the blog post to a problem I’ve solved, I often
find a simpler, more elegant solution, and then use that solution instead to
solve my problem. It’s a similar idea to rubber duck debugging, or writing a
Minimal Reproducible Example when opening an issue because (you think) you found
a nasty bug somewhere in that package you use daily and never bothered reading
the documentation for carefully. Blogging is also a way to get some feedback by
other people, and sometimes people show me other ways of doing things, like
&lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows/&#34;&gt;here&lt;/a&gt;. Blogging
also helped me meet people in the real world, and discuss with them about
certain of the topics I’ve blogged about. I think that’s really neat.&lt;/p&gt;
Blogging also helps (at least it helped me) realize what I really enjoy about
statistics, programming, and data science, and once you have a nice collection
of blog posts, you could turn them easily into a book. That’s another way of
contributing to the community. I’ve written two books, the latest one seems
to really interest people:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
My book is done. I need to write a conclusion to the last chapter and will likely rewrite some paragraphs, but I won&#39;t make major changes anymore. So if you&#39;re interested in building reproducible analytical pipelines with &lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt;, take a look it&#39;s free: &lt;a href=&#34;https://t.co/Vx8LGpddwR&#34;&gt;https://t.co/Vx8LGpddwR&lt;/a&gt; &lt;a href=&#34;https://t.co/PKFb2P4pJK&#34;&gt;pic.twitter.com/PKFb2P4pJK&lt;/a&gt;
&lt;/p&gt;
— Bruno Rodrigues (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;&lt;span class=&#34;citation&#34;&gt;@fosstodon.org&lt;/span&gt;) (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1650229398988095489?ref_src=twsrc%5Etfw&#34;&gt;April 23, 2023&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;That’s my most “viral” tweet! Before it was this classic:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
&#34;doing science&#34; &lt;a href=&#34;https://t.co/T0TJQ6vY6q&#34;&gt;pic.twitter.com/T0TJQ6vY6q&lt;/a&gt;
&lt;/p&gt;
— Bruno Rodrigues (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;&lt;span class=&#34;citation&#34;&gt;@fosstodon.org&lt;/span&gt;) (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1443538925474222080?ref_src=twsrc%5Etfw&#34;&gt;September 30, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I’m sure that many people, maybe even you!, work in an industry that tackles
many interesting problems, and could share that with the world either through
blog posts or books, or videos (yes, I also do that
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;sometimes&lt;/a&gt;), and many
people would find that interesting. I’ve had people tell me that they have
nothing interesting to write about, so they don’t even want to start. Who cares,
just write.&lt;/p&gt;
&lt;p&gt;So it’d be cool if you blogged. I like it, so maybe you will as well?&lt;/p&gt;
&lt;p&gt;Anyways, thanks for reading, especially if you’ve been reading my blog for years.&lt;/p&gt;
&lt;p&gt;Here’s to 10 more years!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automating checks of *handcrafted* Word tables with {docxtractr}</title>
      <link>https://www.brodrigues.co/blog/2023-03-18-docxtractr/</link>
      <pubDate>Sat, 18 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-03-18-docxtractr/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/excel_nightmare.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately not everyone knows about literate programming so many tables in
Word documents are “generated” by hand (generated is really too strong a word)
and what very often happens is that these handcrafted tables have typos. Usually
it’s totals that are wrong. Checking the totals in these tables by hand with a
pocket calculator is a tedious, long and boring job.&lt;/p&gt;
&lt;p&gt;So as my job’s &lt;em&gt;statistician but also kinda automation dude that types all day
in a weird black box&lt;/em&gt;, I’ve been asked if it were possible to automate these
checks on tables in a Word document. And of course, the answer is yes, because
whatever you need to get done, there’s an R package for that!&lt;/p&gt;
&lt;p&gt;There are, to my knowledge, 2 packages that we can use to get tables from a Word
document into R (an activity that I will now refer to as &lt;em&gt;office-scraping&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;These packages are &lt;code&gt;{officer}&lt;/code&gt; and &lt;code&gt;{docxtractr}&lt;/code&gt;. For his particular task I’ve
used &lt;code&gt;{docxtractr}&lt;/code&gt;. The reason is that &lt;code&gt;{docxtractr}&lt;/code&gt; returns the table
“as-is”, while &lt;code&gt;{officer}&lt;/code&gt; returns a tibble where each cell of the table gets a
row in the tibble. &lt;code&gt;{officer}&lt;/code&gt;’s representation of the scraped tables might be
useful in some cases, but in this particular case, &lt;code&gt;{docxtractr}&lt;/code&gt;’s approach was
exactly what I needed.&lt;/p&gt;
&lt;p&gt;First of all, we need a Word document with some tables.&lt;a href=&#34;https://github.com/rbind/b-rodrigues.github.com/raw/master/content/blog/report.docx&#34;&gt;Here’s
one&lt;/a&gt;
I’ve prepared that contains two tables that look close to the ones I had to deal
with. In the actual document, there were hundreds of such tables. Here’s a
picture of the tables in case you can’t open the document:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/report_tables.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The first table is divided by departments of the company, and each section of
the table has its own sub-total. As stated in the beginning, the goal is to
check for typos by recomputing the sub-totals and totals and then comparing
the original tables with the ones where the totals were recomputed.&lt;/p&gt;
&lt;p&gt;The problem we will face with each table are the merged cells; if there were
no merged cells, scraping them with &lt;code&gt;{docxtractr}&lt;/code&gt; would be trivially simple,
but because of these merged cells, we will have to write quite a lot of code
to get them in a format that we can actually use.&lt;/p&gt;
&lt;div id=&#34;extracting-the-tables-using-docxtractr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extracting the tables using {docxtractr}&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;{docxtractr}&lt;/code&gt; has a very handy function that gets all the tables from a Word
document and puts them into a list (it’s also possible to extract other stuff
like comments). Let’s start by loading &lt;code&gt;{dplyr}&lt;/code&gt; (for the rest of the functions,
I’ll use the &lt;code&gt;package::function()&lt;/code&gt; notation to make it clear where the functions
come from):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now read the document using &lt;code&gt;{docxtractr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;doc_raw &amp;lt;- docxtractr::read_docx(&amp;quot;report.docx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let’s get all the tables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_tables &amp;lt;- docxtractr::docx_extract_all_tbls(doc_raw)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now take a look at the second element of the list, which corresponds to
the second table (I’m starting with the second table because it’s the smallest
of the two):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1 &amp;lt;- list_tables[[1]] %&amp;gt;%
  janitor::clean_names()

table_2 &amp;lt;- list_tables[[2]] %&amp;gt;%
  janitor::clean_names()

table_2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 × 11
##   company            x2020 x2021 x2022 na    na_2  na_3  na_4  na_5  na_6  na_7 
##   &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 &amp;quot;&amp;quot;                 M     F     Total M     F     Total M     F     Total &amp;lt;NA&amp;gt; 
## 2 &amp;quot;Luxembourg branc… Work… 92    124   210   87    129   216   99    129   228  
## 3 &amp;quot;&amp;quot;                 Mana… 22    81    103   28    81    109   26    85    112  
## 4 &amp;quot;&amp;quot;                 Assi… 1     0     10    1     0     1     1     0     1    
## 5 &amp;quot;&amp;quot;                 Dire… 3     1     4     0     0     0     0     1     0    
## 6 &amp;quot;External consult… 38    55    95    35    64    99    42    70    112   &amp;lt;NA&amp;gt; 
## 7 &amp;quot;Statisticians&amp;quot;    0     0     0     0     0     0     0     0     0     &amp;lt;NA&amp;gt; 
## 8 &amp;quot;Total&amp;quot;            156   263   419   151   274   425   168   285   453   &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, because of the merged cells, the rows are not all aligned with
the columns. So we need to split the table, and treat the two parts separately.
I’m starting with the part of the table where the rows are correctly aligned
with the columns. This is just a matter of renaming some columns, and converting
the numbers (that are represented as characters) into &lt;code&gt;numeric&lt;/code&gt;s:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_2_1 &amp;lt;- table_2 %&amp;gt;%
  select(-company) %&amp;gt;%
  filter(!is.na(na_7)) %&amp;gt;%
  purrr::set_names(
    c(&amp;quot;worker_type&amp;quot;,
      &amp;quot;m_2020&amp;quot;,
      &amp;quot;f_2020&amp;quot;,
      &amp;quot;t_2020&amp;quot;,
      &amp;quot;m_2021&amp;quot;,
      &amp;quot;f_2021&amp;quot;,
      &amp;quot;t_2021&amp;quot;,
      &amp;quot;m_2022&amp;quot;,
      &amp;quot;f_2022&amp;quot;,
      &amp;quot;t_2022&amp;quot;
      )
    ) %&amp;gt;%
  mutate(across(!starts_with(&amp;quot;worker&amp;quot;),
                as.numeric))

table_2_1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 × 10
##   worker_type m_2020 f_2020 t_2020 m_2021 f_2021 t_2021 m_2022 f_2022 t_2022
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Workers         92    124    210     87    129    216     99    129    228
## 2 Managers        22     81    103     28     81    109     26     85    112
## 3 Assistants       1      0     10      1      0      1      1      0      1
## 4 Directors        3      1      4      0      0      0      0      1      0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now deal with the second part of the table. This is the part of the table
where the rows were not aligned with the columns, due to the merged cells.
The operations are essentially the same as before, the difference is that we need
to remove a different column (here we remove &lt;code&gt;na_7&lt;/code&gt;, before it was &lt;code&gt;company&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_2_2 &amp;lt;- table_2 %&amp;gt;%
  filter(is.na(na_7)) %&amp;gt;%
  select(-na_7) %&amp;gt;%
  rename(worker_type = company) %&amp;gt;%
  filter(worker_type != &amp;quot;&amp;quot;) %&amp;gt;%
  purrr::set_names(
           c(&amp;quot;worker_type&amp;quot;,
             &amp;quot;m_2020&amp;quot;,
             &amp;quot;f_2020&amp;quot;,
             &amp;quot;t_2020&amp;quot;,
             &amp;quot;m_2021&amp;quot;,
             &amp;quot;f_2021&amp;quot;,
             &amp;quot;t_2021&amp;quot;,
             &amp;quot;m_2022&amp;quot;,
             &amp;quot;f_2022&amp;quot;,
             &amp;quot;t_2022&amp;quot;
             )
         ) %&amp;gt;%
  mutate(across(!starts_with(&amp;quot;worker&amp;quot;),
                as.numeric))

table_2_2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 10
##   worker_type     m_2020 f_2020 t_2020 m_2021 f_2021 t_2021 m_2022 f_2022 t_2022
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 External consu…     38     55     95     35     64     99     42     70    112
## 2 Statisticians        0      0      0      0      0      0      0      0      0
## 3 Total              156    263    419    151    274    425    168    285    453&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I didn’t comment the operations, but if you’re following along, take some time
to see what each line does.&lt;/p&gt;
&lt;p&gt;Now we can bind the rows and we end up with the table from the Word document as
a flat and easy to manipulate data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_2_clean &amp;lt;- bind_rows(
  table_2_1,
  table_2_2
)

table_2_clean&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 × 10
##   worker_type     m_2020 f_2020 t_2020 m_2021 f_2021 t_2021 m_2022 f_2022 t_2022
##   &amp;lt;chr&amp;gt;            &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Workers             92    124    210     87    129    216     99    129    228
## 2 Managers            22     81    103     28     81    109     26     85    112
## 3 Assistants           1      0     10      1      0      1      1      0      1
## 4 Directors            3      1      4      0      0      0      0      1      0
## 5 External consu…     38     55     95     35     64     99     42     70    112
## 6 Statisticians        0      0      0      0      0      0      0      0      0
## 7 Total              156    263    419    151    274    425    168    285    453&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of this because of these merged cells! This may seem like a lot of work, but
imagine that you need to check 50 such tables. You could put all the previous
operations into a function and then simply apply that function over all the
tables (which is exactly what I did at my job). So you end up with 50 cleaned
tables in a matter of seconds. Now let’s not forget our original objective, we
wanted to recompute the totals to check if everything was alright. In the
operations below I remove the columns that represent the totals and remove the
row with the grand totals as well. I then simply recompute the totals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_2_totals &amp;lt;- table_2_clean %&amp;gt;%
  select(-starts_with(&amp;quot;t_&amp;quot;)) %&amp;gt;%
  filter(worker_type != &amp;quot;Total&amp;quot;) %&amp;gt;%
  mutate(
    t_2020 = m_2020 + f_2020,
    t_2021 = m_2021 + f_2021,
    t_2022 = m_2022 + f_2022,
    ) %&amp;gt;%
  select(
    worker_type,
    m_2020,
    f_2020,
    t_2020,
    m_2021,
    f_2021,
    t_2021,
    m_2022,
    f_2022,
    t_2022,
    ) %&amp;gt;%
  janitor::adorn_totals()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now compare both data frames and see if there were mistakes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_2_clean == table_2_totals&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      worker_type m_2020 f_2020 t_2020 m_2021 f_2021 t_2021 m_2022 f_2022 t_2022
## [1,]        TRUE   TRUE   TRUE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE
## [2,]        TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE  FALSE
## [3,]        TRUE   TRUE   TRUE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE
## [4,]        TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE  FALSE
## [5,]        TRUE   TRUE   TRUE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE
## [6,]        TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE
## [7,]        TRUE   TRUE  FALSE  FALSE   TRUE   TRUE   TRUE   TRUE   TRUE   TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do see a bunch of &lt;code&gt;FALSE&lt;/code&gt; statements, so we need to check those! This is
where some typos where found.&lt;/p&gt;
&lt;p&gt;Let’s now deal with table 1. The way we will handle this one will be very
similar to the one before. It’s just that we have subtotals to deal with as
well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 × 8
##    by_department   fte        persons na    na_2  na_3  na_4  na_5 
##    &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
##  1 &amp;quot;&amp;quot;              M          F       Total M     F     Total &amp;lt;NA&amp;gt; 
##  2 &amp;quot;Dep A&amp;quot;         Workers    12,30   33,40 55,70 13    36    59   
##  3 &amp;quot;&amp;quot;              Managers   3,80    19,90 15,70 4     19    19   
##  4 &amp;quot;&amp;quot;              Assistants 0,00    0,00  0,00  0     0     0    
##  5 &amp;quot;&amp;quot;              Directors  0,20    0,00  0,20  1     0     1    
##  6 &amp;quot;Total – Dep A&amp;quot; 26,30      45,30   71,60 28,00 51,00 79,00 &amp;lt;NA&amp;gt; 
##  7 &amp;quot;Dep B&amp;quot;         Workers    31,80   39,60 71,40 32    41    73   
##  8 &amp;quot;&amp;quot;              Managers   3,00    13,50 16,50 3     15    18   
##  9 &amp;quot;&amp;quot;              Assistants 0,00    0,00  0,00  0     0     0    
## 10 &amp;quot;&amp;quot;              Directors  0,20    0,20  0,40  1     1     2    
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here as well, we have a problem with merged cells. But only the rows with the
totals are affected. So just like before, we can split that into two tables and
deal with the two parts separately:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1_1 &amp;lt;- table_1 %&amp;gt;%
  filter(!grepl(&amp;quot;(t|T)otal&amp;quot;, by_department),
         fte != &amp;quot;M&amp;quot;) %&amp;gt;%
  purrr::set_names(
           c(&amp;quot;department&amp;quot;,
             &amp;quot;worker_type&amp;quot;,
             &amp;quot;m_fte&amp;quot;,
             &amp;quot;f_fte&amp;quot;,
             &amp;quot;t_fte&amp;quot;,
             &amp;quot;m_hc&amp;quot;,
             &amp;quot;f_hc&amp;quot;,
             &amp;quot;t_hc&amp;quot;
             )
         ) %&amp;gt;%
  mutate(department = ifelse(department == &amp;quot;&amp;quot;,
                              NA,
                              department)) %&amp;gt;%
  tidyr::fill(department, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%
  mutate(across(contains(&amp;quot;fte&amp;quot;),
                \(x)(gsub(pattern = &amp;quot;,&amp;quot;, replacement = &amp;quot;.&amp;quot;, x = x))),
         across(-c(&amp;quot;department&amp;quot;, &amp;quot;worker_type&amp;quot;),
                as.numeric)) %&amp;gt;%
  as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here again, it’s really worth it to take your time going through all the
different commands.&lt;/p&gt;
&lt;p&gt;Let’s now clean the totals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1_2 &amp;lt;- table_1 %&amp;gt;%
  filter(grepl(&amp;quot;(t|T)otal&amp;quot;, by_department),
         fte != &amp;quot;M&amp;quot;) %&amp;gt;%
  select(by_department, na_5, everything()) %&amp;gt;%
  purrr::set_names(
           c(&amp;quot;department&amp;quot;,
             &amp;quot;worker_type&amp;quot;,
             &amp;quot;m_fte&amp;quot;,
             &amp;quot;f_fte&amp;quot;,
             &amp;quot;t_fte&amp;quot;,
             &amp;quot;m_hc&amp;quot;,
             &amp;quot;f_hc&amp;quot;,
             &amp;quot;t_hc&amp;quot;
             )
         ) %&amp;gt;%
  tidyr::fill(department, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%
  mutate(across(-c(&amp;quot;department&amp;quot;, &amp;quot;worker_type&amp;quot;),
                \(x)(gsub(pattern = &amp;quot;,&amp;quot;, replacement = &amp;quot;.&amp;quot;, x = x))),
         across(-c(&amp;quot;department&amp;quot;, &amp;quot;worker_type&amp;quot;),
                as.numeric)) %&amp;gt;%
  as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can bind the rows and we end up with a clean data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1 &amp;lt;- bind_rows(
  table_1_1,
  table_1_2
)

table_1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       department worker_type m_fte  f_fte  t_fte m_hc f_hc t_hc
## 1          Dep A     Workers  12.3  33.40  55.70   13   36   59
## 2          Dep A    Managers   3.8  19.90  15.70    4   19   19
## 3          Dep A  Assistants   0.0   0.00   0.00    0    0    0
## 4          Dep A   Directors   0.2   0.00   0.20    1    0    1
## 5          Dep B     Workers  31.8  39.60  71.40   32   41   73
## 6          Dep B    Managers   3.0  13.50  16.50    3   15   18
## 7          Dep B  Assistants   0.0   0.00   0.00    0    0    0
## 8          Dep B   Directors   0.2   0.20   0.40    1    1    2
## 9          Dep C     Workers  19.0  24.20  43.20   20   26   46
## 10         Dep C    Managers   1.0   8.95   9.95    1   11   12
## 11         Dep C  Assistants   0.0   0.00   0.00    0    0    0
## 12         Dep C   Directors   0.0   0.00   0.00    0    0    0
## 13         Dep D     Workers   7.5   5.00  12.50    8    5   13
## 14         Dep D    Managers   0.5   1.60   2.10    1    2    3
## 15         Dep D  Assistants   1.0   0.00   1.60    1    0    1
## 16         Dep D   Directors   0.4   0.00   0.40    1    0    1
## 17         Dep E     Workers  11.8  13.75  27.55   14   16   30
## 18         Dep E    Managers  16.0  38.20  54.20   17   42   59
## 19         Dep E  Assistants   0.0   0.00   0.00    0    0    0
## 20         Dep E   Directors   0.0   0.00   0.00    0    0    0
## 21         Dep F     Workers   0.2   0.00   0.20    1    0    1
## 22         Dep F    Managers   0.0   0.00   0.00    0    0    0
## 23         Dep F  Assistants   0.0   0.00   0.00    0    0    0
## 24         Dep F   Directors   0.2   0.00   0.20    1    0    1
## 25 Total – Dep A        &amp;lt;NA&amp;gt;  26.3  45.30  71.60   28   51   79
## 26 Total – Dep B        &amp;lt;NA&amp;gt;  35.0  53.30  98.30   36   57   93
## 27 Total – Dep C        &amp;lt;NA&amp;gt;  20.0  33.15  53.15   21   37   58
## 28 Total – Dep D        &amp;lt;NA&amp;gt;   9.4   6.60  16.00   11    7   18
## 29 Total – Dep E        &amp;lt;NA&amp;gt;  29.8  51.95  81.75   31   58   89
## 30 Total – Dep F        &amp;lt;NA&amp;gt;   1.0   1.00   0.20    1    1    1
## 31   Grand total        &amp;lt;NA&amp;gt; 101.5 195.40 316.90  129  216  345&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, let’s not forget our objective: recomputing the totals to see if
everything is alright. So because we need each sub-total, one per department,
we will simply group by departments and use &lt;code&gt;janitor::adorn_totals()&lt;/code&gt;. But
&lt;code&gt;janitor::adorn_totals()&lt;/code&gt; does not work on grouped data frames. So instead
I use &lt;code&gt;group_nest()&lt;/code&gt; to create a tibble with a list column, and then map
&lt;code&gt;janitor::adorn_totals&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1_subtotals &amp;lt;- table_1 %&amp;gt;%
  filter(!grepl(&amp;quot;(t|T)otal&amp;quot;, department)) %&amp;gt;%
  group_nest(department) %&amp;gt;%
  mutate(data = purrr::map(data, janitor::adorn_totals)) %&amp;gt;%
  tidyr::unnest(cols = data) %&amp;gt;%
  arrange(department) %&amp;gt;%
  as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok so in the table above I have the subtotals per department. Now, I need to
compute the grand total:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1_total &amp;lt;- table_1_subtotals %&amp;gt;%
  filter(grepl(&amp;quot;Total&amp;quot;, worker_type)) %&amp;gt;%
  janitor::adorn_totals()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I just need to bind the grand total to the table from before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1_clean &amp;lt;- bind_rows(
  table_1_subtotals,
  filter(
    table_1_total,
    department == &amp;quot;Total&amp;quot;)
)

table_1_clean&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    department worker_type m_fte  f_fte  t_fte m_hc f_hc t_hc
## 1       Dep A     Workers  12.3  33.40  55.70   13   36   59
## 2       Dep A    Managers   3.8  19.90  15.70    4   19   19
## 3       Dep A  Assistants   0.0   0.00   0.00    0    0    0
## 4       Dep A   Directors   0.2   0.00   0.20    1    0    1
## 5       Dep A       Total  16.3  53.30  71.60   18   55   79
## 6       Dep B     Workers  31.8  39.60  71.40   32   41   73
## 7       Dep B    Managers   3.0  13.50  16.50    3   15   18
## 8       Dep B  Assistants   0.0   0.00   0.00    0    0    0
## 9       Dep B   Directors   0.2   0.20   0.40    1    1    2
## 10      Dep B       Total  35.0  53.30  88.30   36   57   93
## 11      Dep C     Workers  19.0  24.20  43.20   20   26   46
## 12      Dep C    Managers   1.0   8.95   9.95    1   11   12
## 13      Dep C  Assistants   0.0   0.00   0.00    0    0    0
## 14      Dep C   Directors   0.0   0.00   0.00    0    0    0
## 15      Dep C       Total  20.0  33.15  53.15   21   37   58
## 16      Dep D     Workers   7.5   5.00  12.50    8    5   13
## 17      Dep D    Managers   0.5   1.60   2.10    1    2    3
## 18      Dep D  Assistants   1.0   0.00   1.60    1    0    1
## 19      Dep D   Directors   0.4   0.00   0.40    1    0    1
## 20      Dep D       Total   9.4   6.60  16.60   11    7   18
## 21      Dep E     Workers  11.8  13.75  27.55   14   16   30
## 22      Dep E    Managers  16.0  38.20  54.20   17   42   59
## 23      Dep E  Assistants   0.0   0.00   0.00    0    0    0
## 24      Dep E   Directors   0.0   0.00   0.00    0    0    0
## 25      Dep E       Total  27.8  51.95  81.75   31   58   89
## 26      Dep F     Workers   0.2   0.00   0.20    1    0    1
## 27      Dep F    Managers   0.0   0.00   0.00    0    0    0
## 28      Dep F  Assistants   0.0   0.00   0.00    0    0    0
## 29      Dep F   Directors   0.2   0.00   0.20    1    0    1
## 30      Dep F       Total   0.4   0.00   0.40    2    0    2
## 31      Total           - 108.9 198.30 311.80  119  214  339&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re almost done! We now need to make sure that the rows are in the same
order across the two tables. So we need to transform the original table from
the Word document a little bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table_1 &amp;lt;- table_1 %&amp;gt;%
  mutate(worker_type = ifelse(is.na(worker_type),
                              &amp;quot;Total&amp;quot;,
                              worker_type)) %&amp;gt;%
  mutate(department = stringr::str_remove_all(department, &amp;quot;Total – &amp;quot;),
         worker_type = ifelse(department == &amp;quot;Grand total&amp;quot;,
                              &amp;quot;-&amp;quot;,
                              worker_type),
         department = ifelse(department == &amp;quot;Grand total&amp;quot;,
                             &amp;quot;Total&amp;quot;,
                             department))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now order them the same way, and finally compare them!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(table_1, worker_type) == arrange(table_1_clean, worker_type)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       department worker_type m_fte f_fte t_fte  m_hc  f_hc  t_hc
##  [1,]       TRUE        TRUE FALSE FALSE FALSE FALSE FALSE FALSE
##  [2,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [3,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [4,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [5,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [6,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [7,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [8,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
##  [9,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [10,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [11,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [12,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [13,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [14,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [15,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [16,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [17,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [18,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [19,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [20,]       TRUE        TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
## [21,]       TRUE        TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE
## [22,]       TRUE        TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE
## [23,]       TRUE        TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE
## [24,]       TRUE        TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE
## [25,]       TRUE        TRUE FALSE FALSE FALSE FALSE FALSE FALSE
## [26,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [27,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [28,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [29,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [30,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
## [31,]       TRUE        TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see where all the &lt;code&gt;FALSE&lt;/code&gt;s are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;arrange(table_1, worker_type)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    department worker_type m_fte  f_fte  t_fte m_hc f_hc t_hc
## 1       Total           - 101.5 195.40 316.90  129  216  345
## 2       Dep A  Assistants   0.0   0.00   0.00    0    0    0
## 3       Dep B  Assistants   0.0   0.00   0.00    0    0    0
## 4       Dep C  Assistants   0.0   0.00   0.00    0    0    0
## 5       Dep D  Assistants   1.0   0.00   1.60    1    0    1
## 6       Dep E  Assistants   0.0   0.00   0.00    0    0    0
## 7       Dep F  Assistants   0.0   0.00   0.00    0    0    0
## 8       Dep A   Directors   0.2   0.00   0.20    1    0    1
## 9       Dep B   Directors   0.2   0.20   0.40    1    1    2
## 10      Dep C   Directors   0.0   0.00   0.00    0    0    0
## 11      Dep D   Directors   0.4   0.00   0.40    1    0    1
## 12      Dep E   Directors   0.0   0.00   0.00    0    0    0
## 13      Dep F   Directors   0.2   0.00   0.20    1    0    1
## 14      Dep A    Managers   3.8  19.90  15.70    4   19   19
## 15      Dep B    Managers   3.0  13.50  16.50    3   15   18
## 16      Dep C    Managers   1.0   8.95   9.95    1   11   12
## 17      Dep D    Managers   0.5   1.60   2.10    1    2    3
## 18      Dep E    Managers  16.0  38.20  54.20   17   42   59
## 19      Dep F    Managers   0.0   0.00   0.00    0    0    0
## 20      Dep A       Total  26.3  45.30  71.60   28   51   79
## 21      Dep B       Total  35.0  53.30  98.30   36   57   93
## 22      Dep C       Total  20.0  33.15  53.15   21   37   58
## 23      Dep D       Total   9.4   6.60  16.00   11    7   18
## 24      Dep E       Total  29.8  51.95  81.75   31   58   89
## 25      Dep F       Total   1.0   1.00   0.20    1    1    1
## 26      Dep A     Workers  12.3  33.40  55.70   13   36   59
## 27      Dep B     Workers  31.8  39.60  71.40   32   41   73
## 28      Dep C     Workers  19.0  24.20  43.20   20   26   46
## 29      Dep D     Workers   7.5   5.00  12.50    8    5   13
## 30      Dep E     Workers  11.8  13.75  27.55   14   16   30
## 31      Dep F     Workers   0.2   0.00   0.20    1    0    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the totals for department A and F are all wrong, and some others for
other departments as well. Obviously the grand total is this completely wrong!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If this looked complicated, let me assure you that, yes, it was. That’s quite
typical with tasks like these: if the data is not in a tidy format, you really
have to type a lot of code to make it tidy. But the advantage now is that I
could put all this code into two functions, and apply them to as many tables as
I need. This is what I did, and what I will be doing in the future as well.
Now that the code is written, I can simply keep applying it to future reports
that use the same table format.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Software engineering techniques that non-programmers who write a lot of code can benefit from — the DRY WIT approach</title>
      <link>https://www.brodrigues.co/blog/2023-03-07-dry_wit/</link>
      <pubDate>Tue, 07 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-03-07-dry_wit/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/archetypical_data_scientist.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Data scientists, statisticians, analysts, researchers, and many other
professionals write &lt;em&gt;a lot of code&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Not only do they write a lot of code, but they must also read and review a lot
of code as well. They either work in teams and need to review each other’s code,
or need to be able to reproduce results from past projects, be it for peer
review or auditing purposes. And yet, they never, or very rarely, get taught
the tools and techniques that would make the process of writing, collaborating,
reviewing and reproducing projects possible.&lt;/p&gt;
&lt;p&gt;Which is truly unfortunate because software engineers face the same challenges
and solved them decades ago. Software engineers developed a set of project
management techniques and tools that non-programmers who write a lot of code
could benefit from as well.&lt;/p&gt;
&lt;p&gt;These tools and techniques can be used right from the start of a project at a
minimal cost, such that the analysis is well-tested, well-documented,
trustworthy and reproducible &lt;em&gt;by design&lt;/em&gt;. Projects are going to be reproducible
simply because they were engineered, from the start, to be reproducible.&lt;/p&gt;
&lt;p&gt;But all these tools, frameworks and techniques boil down to two acronyms that I
like to keep in my head at all times:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DRY: Don’t Repeat Yourself;&lt;/li&gt;
&lt;li&gt;WIT: Write IT down.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DRY WIT: by systematically avoiding not to repeat yourself and
by writing everything down, projects become well-tested, well-documented,
trustworthy and reproducible by design. Why is that?&lt;/p&gt;
&lt;div id=&#34;dry-dont-repeat-yourself&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;DRY: Don’t Repeat Yourself&lt;/h2&gt;
&lt;p&gt;Let’s start with DRY: what does it mean not having to repeat oneself? It means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using functions instead of copy-and-pasting bits of code here and there;&lt;/li&gt;
&lt;li&gt;using literate programming, to avoid having to copy and paste graphs and tables into
word or pdf documents;&lt;/li&gt;
&lt;li&gt;treating code as data and making use of templating.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The most widely used programming languages for data science/statistics, Python and R,
both have first-class functions. This means that functions can be manipulated like
any other object. So something like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Reduce(`+`, seq(1:100))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5050&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the function &lt;code&gt;+&lt;/code&gt;() gets used as an argument of the higher-order &lt;code&gt;Reduce()&lt;/code&gt;
function is absolutely valid (and so is Python’s equivalent &lt;code&gt;reduce&lt;/code&gt; from
&lt;code&gt;functools&lt;/code&gt;) and avoids having to use a for-loop which can lead to other issues.
Generally speaking, the functional programming paradigm lends itself very
naturally to data analysis tasks, and in my opinion data scientists and
statisticians would benefit a lot from adopting this paradigm.&lt;/p&gt;
&lt;p&gt;Literate programming is another tool that needs to be in the toolbox of
any person analysing data. This is because at the end of the day, the results
of an analysis need to be in some form of document. Without literate programming,
this is how you would draft reports:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/b-rodrigues/rap4all/blob/master/images/report_draft_loop.png?raw=true&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;But with literate programming, this is how this loop would look like:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/b-rodrigues/rap4all/blob/master/images/md_draft_loop.png?raw=true&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://quarto.org/&#34;&gt;Quarto&lt;/a&gt; is the latest open-source scientific and technical
publishing system that leverages Pandoc and supports R, Python, Julia and
ObservableJs right out of the box.&lt;/p&gt;
&lt;p&gt;Below is a little Quarto Hello World:&lt;/p&gt;
&lt;pre class=&#34;default&#34;&gt;&lt;code&gt;---
output: pdf
---

In this example we embed parts of the examples from the
\texttt{kruskal.test} help page into a LaTeX document:

```{r}
data (airquality)
kruskal.test(Ozone ~ Month, data = airquality)
```

which shows that the location parameter of the Ozone
distribution varies significantly from month to month.
Finally we include a boxplot of the data:

```{r, echo = FALSE}
boxplot(Ozone ~ Month, data = airquality)
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compiling this document results in the following:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/b-rodrigues/rap4all/master/images/hello_rmd.PNG&#34; width=&#34;100%&#34;&gt;
&lt;figcaption&gt;
Example from Leisch’s 2002 paper.
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;Of course, you could use Python code chunks instead of R, you could also compile
this document to Word, or HTML, or anything else really. By combining code and
prose, the process of data analysis gets streamlined and we don’t need to repeat
ourselves copy and pasting images and tables into Word documents.&lt;/p&gt;
&lt;p&gt;Finally, treating code as data is also quite useful. This means that it is
possible to compute on the language itself. This is a more advanced topic, but
definitely worth the effort. As an illustration, consider the following R toy example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_and_eval &amp;lt;- function(f, ...){
  f &amp;lt;- deparse(substitute(f))
  dots &amp;lt;- list(...)
  message(&amp;quot;Evaluating: &amp;quot;, f, &amp;quot;() with arguments: &amp;quot;, deparse(dots))
  do.call(f, dots)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running this function does the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_and_eval(sqrt, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Evaluating: sqrt() with arguments: list(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.414214&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_and_eval(mean, x = c(NA, 1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Evaluating: mean() with arguments: list(x = c(NA, 1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_and_eval(mean, x = c(NA, 1, 2), na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Evaluating: mean() with arguments: list(x = c(NA, 1, 2), na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is incredibly useful when writing packages (to know more about these
techniques in the R programming language, read the chapter &lt;em&gt;Metaprogramming&lt;/em&gt; from
&lt;a href=&#34;https://adv-r.hadley.nz/metaprogramming.html&#34;&gt;Advanced R&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wit-write-it-down&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;WIT: Write IT down&lt;/h2&gt;
&lt;p&gt;Now on the WIT bit: &lt;em&gt;write it down&lt;/em&gt;. You’ve just written a function. To see if
it works correctly, you test it in the interactive console. You execute the
test, see that it works, and move on. But wait! What you just did is called a
unit test. Instead of writing that in the console and then never use it ever
again, write it down in a script. Now you’ve got a unit test for that function
that you can execute each time you update that function’s code, and make sure
that it keeps working as expected. There are many unit testing frameworks that
can help you how to write unit tests consistently and run them automatically.&lt;/p&gt;
&lt;p&gt;Documentation: write it down! How does the function work? What are its inputs?
Its outputs? What else should the user know to make it work? Very often,
documentation is but a series of comments in your scripts. That’s already nice,
but using literate programming, you could also turn these comments into proper
documentation. You could use &lt;em&gt;docstrings&lt;/em&gt; in Python or &lt;code&gt;{roxygen2}&lt;/code&gt; style
comments in R.&lt;/p&gt;
&lt;p&gt;Another classic: you correct some data manually in the raw dataset (very often a
&lt;code&gt;.csv&lt;/code&gt; or &lt;code&gt;.xlsx&lt;/code&gt; file). For example, when dealing with data on people, sex is
sometimes “M” or “F”, sometimes “Male” or “Female”, sometimes “1” or “0”. You
spot a couple of inconsistencies and decide to &lt;em&gt;quickly&lt;/em&gt; correct them by hand.
Maybe only 3 men were coded as “Male” so you simply erase the “ale” and go on
with your project. Stop!&lt;/p&gt;
&lt;p&gt;Write IT down!&lt;/p&gt;
&lt;p&gt;Write a couple of lines of code that does the replacement for you. Not only will
this leave a trace, it will ensure that when you get an update to that data in
the future you don’t have to remember to have to change it by hand.&lt;/p&gt;
&lt;p&gt;You should aim at completely eliminating any required manual intervention when
building your project. A project that can be fully run by a machine is easier to
debug, its execution can be scheduled and can be iterated over very quickly.&lt;/p&gt;
&lt;p&gt;Something else that you should write down, or rather, let another tool do it for
you: how you collaborate with your teammates. For this, you should be using
Git. Who changed what part of what function when? If the project’s code is
versioned, Git writes it down for you. You want to experiment with a new
feature? Write it down by creating a new branch and going nuts. There’s something
wrong in the code? Write it down as an issue on your versioning platform (usually
Github).&lt;/p&gt;
&lt;p&gt;There are many more topics that us disciplines of the data could learn from
software engineers. I’m currently working on a free ebook that you can read
&lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;here&lt;/a&gt; that teaches these techniques. If this post
opened your appetite, give the book a go!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What I&#39;ve learned making an .epub Ebook with Quarto</title>
      <link>https://www.brodrigues.co/blog/2023-03-03-quarto_books/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-03-03-quarto_books/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/epubcheck.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve been working on an ebook (that you can read over
&lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;here&lt;/a&gt;) made using Quarto. Since I’m also selling a
DRM-free Epub and PDF on &lt;a href=&#34;https://leanpub.com/raps-with-r/&#34;&gt;Leanpub&lt;/a&gt; I wanted to
share some tips and tricks I’ve learned to generate an Epub that passes
&lt;code&gt;epubcheck&lt;/code&gt; using Quarto.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;iframe width=&#39;160&#39; height=&#39;400&#39; src=&#39;https://leanpub.com/raps-with-r/embed&#39; frameborder=&#39;0&#39; allowtransparency=&#39;true&#39;&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Quarto is a tool made by Posit and is an &lt;em&gt;open-source scientific and technical&lt;/em&gt;
publishing tool. If you know what LaTeX is, then it should be easy for you to
grok Quarto. The idea of Quarto is that you write documents using Markdown, and
then compile these source files into either PDFs, Word documents, but also
books, web-sites, ebooks (in the Epub format) and so on… It’s quite powerful,
and you can also use programming language code chunks for literate programming.
Quarto support R, Python, Julia and ObsevableJS chunks.&lt;/p&gt;
&lt;p&gt;So, as I said, I’ve been using Quarto to write an ebook, and from a single set
of Markdown source files I can generate the website (linked above), the PDF of
the book and the Epub of the book. But you see, if you want to sell an Epub on
platforms like Leanpub, the generated Epub must pass &lt;code&gt;epubcheck&lt;/code&gt;. &lt;code&gt;epubcheck&lt;/code&gt; is
a command line application that verifies that your Epub satisfies certain
quality checks. If these quality standards are not satisfied, there is no
guarantee that Epub readers can successfully open your Epub. Leanpub actually
allows you to upload an Epub that does not pass &lt;code&gt;epubcheck&lt;/code&gt;, but they warn you
that you really should strive for publishing an Epub without any errors or
warnings raised by &lt;code&gt;epubcheck&lt;/code&gt;. For example, the first version of my Epub did not
pass &lt;code&gt;epubcheck&lt;/code&gt; and I couldn’t upload it to my Kindle.&lt;/p&gt;
&lt;p&gt;In this blog post I’ll show you what you should do to generate an Epub that
passes &lt;code&gt;epubcheck&lt;/code&gt; using Quarto.&lt;/p&gt;
&lt;div id=&#34;starting-from-the-default-template&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Starting from the default template&lt;/h2&gt;
&lt;p&gt;Start by installing Quarto by downloading the right package for your operating
system &lt;a href=&#34;https://quarto.org/docs/get-started/&#34;&gt;here&lt;/a&gt;. To start from a book template
open a terminal and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;quarto create-project example_book --type book&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s open the &lt;code&gt;_quarto.yml&lt;/code&gt; file that is inside the newly created
&lt;code&gt;example_book/&lt;/code&gt;. This is your book’s configuration file. It should look like
this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;project:
  type: book

book:
  title: &amp;quot;example_book&amp;quot;
  author: &amp;quot;Jane Doe&amp;quot;
  date: &amp;quot;3/3/2023&amp;quot;
  chapters:
    - index.qmd
    - intro.qmd
    - summary.qmd
    - references.qmd

bibliography: references.bib

format:
  html:
    theme: cosmo
  pdf:
    documentclass: scrreprt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can change whatever you like, but for our purposes, we are going to add the
&lt;code&gt;epub&lt;/code&gt; output format all the way at the bottom of the file. So change these
lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;format:
  html:
    theme: cosmo
  pdf:
    documentclass: scrreprt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;into these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;format:
  html:
    theme: cosmo
  epub:
    toc: true&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve added the &lt;code&gt;epub&lt;/code&gt; format as an output, as well as the &lt;code&gt;toc: true&lt;/code&gt; option,
which builds a table of contents. I’ve also removed the &lt;code&gt;pdf&lt;/code&gt; output because you
need to have a LaTeX distribution installed for this, and the point of this blog
post is not to talk about the PDF output (which works flawlessly by the way).
Before compiling, let’s open one of the &lt;code&gt;.qmd&lt;/code&gt; files. These files are the
Markdown source files that we need to edit in order to fill our book with
content. Let’s open &lt;code&gt;intro.qmd&lt;/code&gt; and change these lines from:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Introduction

This is a book created from markdown and executable code.

See @knuth84 for additional discussion of literate programming.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Introduction

This is a book created from markdown and executable code.

See @knuth84 for additional discussion of literate programming.

![By Boaworm - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=10649477](images/640px-Eyjafjallajokull_Gigjokull_in_ash.jpg)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Download the image from this
&lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Eyjafjallajokull_Gigjokull_in_ash.jpg/640px-Eyjafjallajokull_Gigjokull_in_ash.jpg?download&#34;&gt;link&lt;/a&gt;
and create the &lt;code&gt;images/&lt;/code&gt; folder at the root of the book, right next to the
&lt;code&gt;.qmd&lt;/code&gt; files.&lt;/p&gt;
&lt;p&gt;This syntax is the default syntax for adding pictures in a Markdown document. If
you’re an R user, you could also use an R code chunk and the function
&lt;code&gt;knitr::include_graphics()&lt;/code&gt; to achieve the same thing.&lt;/p&gt;
&lt;p&gt;Let’s compile our little example book, and then use &lt;code&gt;epubcheck&lt;/code&gt; to see what’s
wrong! Use these commands to render the book in all the formats:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd example_book/

quarto render&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see a folder called &lt;code&gt;_book&lt;/code&gt; appear on the root of your project.
Inside this folder, you will see a bunch of &lt;code&gt;.html&lt;/code&gt; files: these constitute the
web-site of your book. You can right click on &lt;code&gt;index.html&lt;/code&gt; and open it with a
web browser and see how your book, as a web-site, looks like. You could host
this book on Github pages for free!&lt;/p&gt;
&lt;p&gt;But what interests us is the &lt;code&gt;.epub&lt;/code&gt; file. If your PDF reader supports this
format, you can open it and see how it looks. On Windows you could use
SumatraPDF. I use Okular on Linux to open PDF and Epub documents. Anyways, there
doesn’t seem to be anything wrong with it. You can open it, you can read it, it
seems to be working just fine. But let’s see if &lt;code&gt;epubcheck&lt;/code&gt; thinks the same. You
can download &lt;code&gt;epubcheck&lt;/code&gt; from &lt;a href=&#34;https://www.w3.org/publishing/epubcheck/&#34;&gt;here&lt;/a&gt;.
Save the downloaded file on the root directory of the book and decompress it.
Inside the decompressed folder, you’ll see a file called &lt;code&gt;epubcheck.jar&lt;/code&gt;. Put
your epub file right next to it, in the same folder. Now, open a terminal and
navigate to the right folder and run the following command to check the epub
file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd epubcheck-5.0.0 # or whatever version it is you downloaded

java -jar epubcheck.jar example_book.epub&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see this output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Validating using EPUB version 3.3 rules.
ERROR(RSC-005): example_book.epub/EPUB/content.opf(6,39): Error while parsing file: character content of element &amp;quot;dc:date&amp;quot; invalid; must 
be a string with length at least 1 (actual length was 0)
WARNING(OPF-053): example_book.epub/EPUB/content.opf(6,39): Date value &amp;quot;&amp;quot; does not follow recommended syntax as per http://www.w3.org/TR/NOTE-datetime:zero-length string.
ERROR(RSC-005): example_book.epub/EPUB/text/ch002.xhtml(354,16): Error while parsing file: element &amp;quot;figcaption&amp;quot; not allowed here; expected the element end-tag, text, element &amp;quot;a&amp;quot;, &amp;quot;abbr&amp;quot;, &amp;quot;area&amp;quot;, &amp;quot;audio&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;bdi&amp;quot;, &amp;quot;bdo&amp;quot;, &amp;quot;br&amp;quot;, &amp;quot;button&amp;quot;, &amp;quot;canvas&amp;quot;, &amp;quot;cite&amp;quot;, &amp;quot;code&amp;quot;, &amp;quot;data&amp;quot;, &amp;quot;datalist&amp;quot;, &amp;quot;del&amp;quot;, &amp;quot;dfn&amp;quot;, &amp;quot;em&amp;quot;, &amp;quot;embed&amp;quot;, &amp;quot;epub:switch&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;iframe&amp;quot;, &amp;quot;img&amp;quot;, &amp;quot;input&amp;quot;, &amp;quot;ins&amp;quot;, &amp;quot;kbd&amp;quot;, &amp;quot;label&amp;quot;, &amp;quot;link&amp;quot;, &amp;quot;map&amp;quot;, &amp;quot;mark&amp;quot;, &amp;quot;meta&amp;quot;, &amp;quot;meter&amp;quot;, &amp;quot;ns1:math&amp;quot;, &amp;quot;ns2:svg&amp;quot;, &amp;quot;object&amp;quot;, &amp;quot;output&amp;quot;, &amp;quot;picture&amp;quot;, &amp;quot;progress&amp;quot;, &amp;quot;q&amp;quot;, &amp;quot;ruby&amp;quot;, &amp;quot;s&amp;quot;, &amp;quot;samp&amp;quot;, &amp;quot;script&amp;quot;, &amp;quot;select&amp;quot;, &amp;quot;small&amp;quot;, &amp;quot;span&amp;quot;, &amp;quot;strong&amp;quot;, &amp;quot;sub&amp;quot;, &amp;quot;sup&amp;quot;, &amp;quot;template&amp;quot;, &amp;quot;textarea&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;u&amp;quot;, &amp;quot;var&amp;quot;, &amp;quot;video&amp;quot; or &amp;quot;wbr&amp;quot; (with xmlns:ns1=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot; xmlns:ns2=&amp;quot;http://www.w3.org/2000/svg&amp;quot;) or an element from another namespace

Check finished with errors
Messages: 0 fatals / 2 errors / 1 warning / 0 infos

EPUBCheck completed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we get 2 errors and 1 warning! Let’s look at the first error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR(RSC-005): example_book.epub/EPUB/content.opf(6,39): Error while parsing file: character content of element &amp;quot;dc:date&amp;quot; invalid; must 
be a string with length at least 1 (actual length was 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first error message states that our epub does not have a valid &lt;code&gt;dc:date&lt;/code&gt;
attribute. The warning is also related to this. We can correct this by adding
this attribute in the &lt;code&gt;_quarto.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;format:
  epub:
    toc:
      true
    date:
      &amp;quot;2023-03-01&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However this is not enough. There is a bug in the current release of Quarto that
prevents this from working, even though we did what we should. However, this bug
&lt;a href=&#34;https://github.com/quarto-dev/quarto-cli/issues/4615#issuecomment-1453921865&#34;&gt;is already corrected in the development version of the next
release&lt;/a&gt;.
But until the next version of Quarto, 1.3, gets released, here is the
workaround; you need to also specify the language of the book:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;format:
  html:
    theme: cosmo
  epub:
    toc:
      true
    lang:
      en-GB
    date:
      &amp;quot;2023-03-01&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now &lt;code&gt;epubcheck&lt;/code&gt; does not complain about the date anymore!&lt;/p&gt;
&lt;p&gt;The next error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR(RSC-005): example_book.epub/EPUB/text/ch002.xhtml(354,16): Error while parsing file: element &amp;quot;figcaption&amp;quot; not allowed here; expected the element end-tag, text, element &amp;quot;a&amp;quot;, &amp;quot;abbr&amp;quot;, &amp;quot;area&amp;quot;, &amp;quot;audio&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;bdi&amp;quot;, &amp;quot;bdo&amp;quot;, &amp;quot;br&amp;quot;, &amp;quot;button&amp;quot;, &amp;quot;canvas&amp;quot;, &amp;quot;cite&amp;quot;, &amp;quot;code&amp;quot;, &amp;quot;data&amp;quot;, &amp;quot;datalist&amp;quot;, &amp;quot;del&amp;quot;, &amp;quot;dfn&amp;quot;, &amp;quot;em&amp;quot;, &amp;quot;embed&amp;quot;, &amp;quot;epub:switch&amp;quot;, &amp;quot;i&amp;quot;, &amp;quot;iframe&amp;quot;, &amp;quot;img&amp;quot;, &amp;quot;input&amp;quot;, &amp;quot;ins&amp;quot;, &amp;quot;kbd&amp;quot;, &amp;quot;label&amp;quot;, &amp;quot;link&amp;quot;, &amp;quot;map&amp;quot;, &amp;quot;mark&amp;quot;, &amp;quot;meta&amp;quot;, &amp;quot;meter&amp;quot;, &amp;quot;ns1:math&amp;quot;, &amp;quot;ns2:svg&amp;quot;, &amp;quot;object&amp;quot;, &amp;quot;output&amp;quot;, &amp;quot;picture&amp;quot;, &amp;quot;progress&amp;quot;, &amp;quot;q&amp;quot;, &amp;quot;ruby&amp;quot;, &amp;quot;s&amp;quot;, &amp;quot;samp&amp;quot;, &amp;quot;script&amp;quot;, &amp;quot;select&amp;quot;, &amp;quot;small&amp;quot;, &amp;quot;span&amp;quot;, &amp;quot;strong&amp;quot;, &amp;quot;sub&amp;quot;, &amp;quot;sup&amp;quot;, &amp;quot;template&amp;quot;, &amp;quot;textarea&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;u&amp;quot;, &amp;quot;var&amp;quot;, &amp;quot;video&amp;quot; or &amp;quot;wbr&amp;quot; (with xmlns:ns1=&amp;quot;http://www.w3.org/1998/Math/MathML&amp;quot; xmlns:ns2=&amp;quot;http://www.w3.org/2000/svg&amp;quot;) or an element from another namespace&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is related to the image. It turns out that including the image like we did
generates code that is not quite correct from the point of view of the
standard that Epubs should follow. You should know that Epubs are actually a
collection of HTML files, so you can include images by using HTML code in the
source Markdown files.&lt;/p&gt;
&lt;p&gt;If you insert the image like so, the error should disappear:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;figure&amp;gt;
    &amp;lt;img src=&amp;quot;images/640px-Eyjafjallajokull_Gigjokull_in_ash.jpg&amp;quot;
         alt=&amp;quot;By Boaworm - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=10649477&amp;quot;&amp;gt;&amp;lt;/img&amp;gt;
    &amp;lt;figcaption&amp;gt;By Boaworm - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=10649477&amp;lt;/figcaption&amp;gt;
&amp;lt;/figure&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you re-render the Epub, and try &lt;code&gt;epubcheck&lt;/code&gt; again, you should see this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java -jar epubcheck.jar example_book.epub&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Validating using EPUB version 3.3 rules.
No errors or warnings detected.
Messages: 0 fatals / 0 errors / 0 warnings / 0 infos&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;using-github-actions-to-build-the-book&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using Github Actions to build the book&lt;/h2&gt;
&lt;p&gt;Finally, as a bonus, if you’re using Github, you can also use Github Actions to
generate the web-site, as well as the Epub (and the PDF if you want). If you go
to &lt;a href=&#34;https://github.com/b-rodrigues/epubcheck_quarto_test&#34;&gt;this repository&lt;/a&gt;,
which contains the example book from this post, you can find the workflow to
automatically build the Epub and web-site from your Quarto source in the
&lt;code&gt;.github/workflows/&lt;/code&gt; folder. Create the same folder structure in your repository
and copy the &lt;code&gt;.yml&lt;/code&gt; file that is in it to these folders. You should then create
a &lt;code&gt;gh-pages&lt;/code&gt; branch and make sure that Github Actions has the required
permissions to push. For this, go to the &lt;em&gt;Settings&lt;/em&gt; menu of your repository,
then &lt;em&gt;Actions&lt;/em&gt; (listed in the menu on the left), then &lt;em&gt;General&lt;/em&gt;, and then under
&lt;em&gt;Workflow permissions&lt;/em&gt; make sure that &lt;em&gt;Read and write permissions&lt;/em&gt; is checked.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/ga_permissions.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now, each time you push, you should see your Epub get built in the &lt;code&gt;gh-pages&lt;/code&gt;
branch! If you use R code chunks, you also need to set up an action to set up R.
Take a look at the
&lt;a href=&#34;https://github.com/b-rodrigues/rap4all/blob/master/.github/workflows/quarto-publish.yml&#34;&gt;repo&lt;/a&gt;
of my book for an example.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my &lt;a href=&#34;https://www.brodrigues.co/about/books/&#34;&gt;ebooks&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MRAN is getting shutdown - what else is there for reproducibility with R, or why reproducibility is on a continuum?</title>
      <link>https://www.brodrigues.co/blog/2023-01-12-repro_r/</link>
      <pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2023-01-12-repro_r/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/sisyphus.jpg&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;you-expect-me-to-read-this-long-ass-blog-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;You expect me to read this long ass blog post?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;If you’re too busy to read this blog post, know that I respect your time. The table below
summarizes this blog post:&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;70%&#34; /&gt;
&lt;col width=&#34;29%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Need&lt;/th&gt;
&lt;th&gt;Solution&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;I want to start a project and make it reproducible.&lt;/td&gt;
&lt;td&gt;{renv} and Docker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;There’s an old script laying around that I want to run.&lt;/td&gt;
&lt;td&gt;{groundhog} and Docker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;I want to work inside an environment that&lt;/td&gt;
&lt;td&gt;Docker and the Posit&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;enables me to run code in a reproducible way.&lt;/td&gt;
&lt;td&gt;CRAN mirror.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;But this table doesn’t show the whole picture, especially the issues with relying so much on
Docker. So if you’re interesting in making science and your work reproducible and robust, my advice
is that you stop doomscrolling on social media and keep on reading. If at the end of the blog post
you think that this was a waste of time, just sent an insult my way, that’s ok.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I learnt last week that MRAN is going to get shutdown this year. For those of you that don’t know,
MRAN was a CRAN mirror managed by Microsoft. What made MRAN stand out was the fact that Microsoft
took daily snapshots of CRAN and it was thus possible to quite easily install old packages using
the &lt;code&gt;{checkpoint}&lt;/code&gt; package. This was a good thing for reproducibility, and for Windows and macOS,
it was even possible to install binary packages, so no need to compile them from source.&lt;/p&gt;
&lt;p&gt;Last year I had the opportunity to teach a course on building reproducible analytical pipelines at
the University of Luxembourg, and made my teaching material available as an ebook that you can find
&lt;a href=&#34;https://rap4mads.eu/&#34;&gt;here&lt;/a&gt;. I also wrote some blog posts about reproducibility and it looks like
I will be continuing this trend for the forseeable future.&lt;/p&gt;
&lt;p&gt;So in this blog post I’m going to show what you, as an R user, can do to make your code reproducible now
that MRAN is getting shutdown. MRAN is not the only option for reproducibility, and I’m going to
present in this blog post everything I know about other options. So if you happen to know of some solution
that I don’t discuss here, please leave a comment
&lt;a href=&#34;https://github.com/rbind/b-rodrigues.github.com/issues/5&#34;&gt;here&lt;/a&gt;. But this blog post is not just a tutorial.
I will also discuss what I think is a major risk that is coming and what, maybe, we can do to avoid it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reproducibility-is-on-a-continuum&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproducibility is on a continuum&lt;/h2&gt;
&lt;p&gt;Reproducibility is on a continuum, and depending on the nature of your project different tools are
needed. First, let’s understand what I mean by “reproducibility is on a continuum”. Let’s suppose
that you have written a script that produces some output. Here is the list of everything that can
influence the output (other than the mathematical algorithm running under the hood):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version of the programming language used;&lt;/li&gt;
&lt;li&gt;Versions of the packages/libraries of said programming language used;&lt;/li&gt;
&lt;li&gt;Operating System, and its version;&lt;/li&gt;
&lt;li&gt;Versions of the underlying system libraries (which often go hand in hand with OS version, but not necessarily).&lt;/li&gt;
&lt;li&gt;Hardware that you run all that software stack on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So by “reproducibility is on a continuum”, what I mean is that you could set up your project in a
way that none, one, two, three, four or all of the preceding items are taken into consideration when
making your project reproducible.&lt;/p&gt;
&lt;p&gt;There is, however, something else to consider. Before, I wrote “let’s suppose you have written a
script”, which means that you actually have a script laying around that was written in a particular
programming language, and which makes use of a known set of packages/libraries. So for example, if
my script uses the following R packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dplyr&lt;/li&gt;
&lt;li&gt;tidyr&lt;/li&gt;
&lt;li&gt;ggplot2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I, obviously, know this list and if I want to make my script reproducible, I should take note of
the versions of these 3 packages (and potentially of their own dependencies). However, what if you
don’t know this set of packages that are used? This happens when you want to set up an environment
that is frozen, and then distribute this environment. Developers will then all work on the same
base environment, but you cannot possibly list all the packages that are going to be used because
you have no idea what the developers will end up using (and remember that future you is included in
these developers, and you should always try to be nice to future you).&lt;/p&gt;
&lt;p&gt;So these means that we have two scenarios:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scenario 1: I have a script (or several), and want to make sure that it will always produce the same output;&lt;/li&gt;
&lt;li&gt;Scenario 2: I don’t know what I (or my colleagues) will develop, but we want to use the same environment across the organization to develop and deploy data products.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Turns out that the solutions to these two scenarios are different, but available in R, even though
we won’t soon be able to count on MRAN anymore. HOWEVER! R won’t suffice for this job.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-1-making-a-script-reproducible&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1: making a script reproducible&lt;/h2&gt;
&lt;p&gt;Ok, so let’s suppose that I want to make a script reproducible, or at least increase the probability
that others (including future me) will be able to run this script and get the exact same output as
I originally did. If you want to minimize the amount of time spent doing it, the minimum thing you
should do is use &lt;a href=&#34;https://rstudio.github.io/renv/articles/renv.html&#34;&gt;{renv}&lt;/a&gt;. &lt;code&gt;{renv}&lt;/code&gt; allows you
to create a file called &lt;code&gt;renv.lock&lt;/code&gt;. You can then distribute this file to others alongside the code
of your project, or the paper, data, whatever. Nothing else is required from you; if people have
this file, they should be able to set up an environment that would closely mimic the one that was
used to get the results originally (but ideally, you’d invest a bit more time to make your script
run anywhere, for example by avoiding setting absolute paths that only exist on your machine).&lt;/p&gt;
&lt;p&gt;Let’s take a look at such an &lt;code&gt;renv.lock&lt;/code&gt; file:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click me to see lock file
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;R&amp;quot;: {
    &amp;quot;Version&amp;quot;: &amp;quot;4.2.1&amp;quot;,
    &amp;quot;Repositories&amp;quot;: [
      {
        &amp;quot;Name&amp;quot;: &amp;quot;CRAN&amp;quot;,
        &amp;quot;URL&amp;quot;: &amp;quot;http://cran.rstudio.com&amp;quot;
      }
    ]
  },
  &amp;quot;Packages&amp;quot;: {
    &amp;quot;MASS&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;MASS&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;7.3-58.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;762e1804143a332333c054759f89a706&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;Matrix&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;Matrix&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.5-1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;539dc0c0c05636812f1080f473d2c177&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;lattice&amp;quot;
      ]
    },
    &amp;quot;R6&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;R6&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.5.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;470851b6d5d0ac559e9d01bb352b4021&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;RColorBrewer&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;RColorBrewer&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.1-3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;45f0398006e83a5b10b72a90663d8d8c&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;cli&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;cli&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;3.4.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;0d297d01734d2bcea40197bd4971a764&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;colorspace&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;colorspace&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.0-3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;bb4341986bc8b914f0f0acf2e4a3f2f7&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;digest&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;digest&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.6.29&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;cf6b206a045a684728c3267ef7596190&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;fansi&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;fansi&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.0.3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;83a8afdbe71839506baa9f90eebad7ec&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;farver&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;farver&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.1.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;8106d78941f34855c440ddb946b8f7a5&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;ggplot2&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;ggplot2&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;3.3.6&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;0fb26d0674c82705c6b701d1a61e02ea&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;MASS&amp;quot;,
        &amp;quot;digest&amp;quot;,
        &amp;quot;glue&amp;quot;,
        &amp;quot;gtable&amp;quot;,
        &amp;quot;isoband&amp;quot;,
        &amp;quot;mgcv&amp;quot;,
        &amp;quot;rlang&amp;quot;,
        &amp;quot;scales&amp;quot;,
        &amp;quot;tibble&amp;quot;,
        &amp;quot;withr&amp;quot;
      ]
    },
    &amp;quot;glue&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;glue&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.6.2&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;4f2596dfb05dac67b9dc558e5c6fba2e&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;gtable&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;gtable&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.3.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;36b4265fb818f6a342bed217549cd896&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;isoband&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;isoband&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.2.5&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;7ab57a6de7f48a8dc84910d1eca42883&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;labeling&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;labeling&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.4.2&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;3d5108641f47470611a32d0bdf357a72&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;lattice&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;lattice&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.20-45&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;CRAN&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;b64cdbb2b340437c4ee047a1f4c4377b&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;lifecycle&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;lifecycle&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.0.3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;001cecbeac1cff9301bdc3775ee46a86&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;cli&amp;quot;,
        &amp;quot;glue&amp;quot;,
        &amp;quot;rlang&amp;quot;
      ]
    },
    &amp;quot;magrittr&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;magrittr&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.0.3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;7ce2733a9826b3aeb1775d56fd305472&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;mgcv&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;mgcv&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.8-40&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;CRAN&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;c6b2fdb18cf68ab613bd564363e1ba0d&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;Matrix&amp;quot;,
        &amp;quot;nlme&amp;quot;
      ]
    },
    &amp;quot;munsell&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;munsell&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.5.0&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;6dfe8bf774944bd5595785e3229d8771&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;colorspace&amp;quot;
      ]
    },
    &amp;quot;nlme&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;nlme&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;3.1-159&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;4a0b3a68f846cb999ff0e8e519524fbb&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;lattice&amp;quot;
      ]
    },
    &amp;quot;pillar&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;pillar&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.8.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;f2316df30902c81729ae9de95ad5a608&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;cli&amp;quot;,
        &amp;quot;fansi&amp;quot;,
        &amp;quot;glue&amp;quot;,
        &amp;quot;lifecycle&amp;quot;,
        &amp;quot;rlang&amp;quot;,
        &amp;quot;utf8&amp;quot;,
        &amp;quot;vctrs&amp;quot;
      ]
    },
    &amp;quot;pkgconfig&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;pkgconfig&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.0.3&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;01f28d4278f15c76cddbea05899c5d6f&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;purrr&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;purrr&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.3.5&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;54842a2443c76267152eface28d9e90a&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;magrittr&amp;quot;,
        &amp;quot;rlang&amp;quot;
      ]
    },
    &amp;quot;renv&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;renv&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.16.0&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;CRAN&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;c9e8442ab69bc21c9697ecf856c1e6c7&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;rlang&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;rlang&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.0.6&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;4ed1f8336c8d52c3e750adcdc57228a7&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;scales&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;scales&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.2.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;906cb23d2f1c5680b8ce439b44c6fa63&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;R6&amp;quot;,
        &amp;quot;RColorBrewer&amp;quot;,
        &amp;quot;farver&amp;quot;,
        &amp;quot;labeling&amp;quot;,
        &amp;quot;lifecycle&amp;quot;,
        &amp;quot;munsell&amp;quot;,
        &amp;quot;rlang&amp;quot;,
        &amp;quot;viridisLite&amp;quot;
      ]
    },
    &amp;quot;tibble&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;tibble&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;3.1.8&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;56b6934ef0f8c68225949a8672fe1a8f&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;fansi&amp;quot;,
        &amp;quot;lifecycle&amp;quot;,
        &amp;quot;magrittr&amp;quot;,
        &amp;quot;pillar&amp;quot;,
        &amp;quot;pkgconfig&amp;quot;,
        &amp;quot;rlang&amp;quot;,
        &amp;quot;vctrs&amp;quot;
      ]
    },
    &amp;quot;utf8&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;utf8&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;1.2.2&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;c9c462b759a5cc844ae25b5942654d13&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;vctrs&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;vctrs&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.5.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;970324f6572b4fd81db507b5d4062cb0&amp;quot;,
      &amp;quot;Requirements&amp;quot;: [
        &amp;quot;cli&amp;quot;,
        &amp;quot;glue&amp;quot;,
        &amp;quot;lifecycle&amp;quot;,
        &amp;quot;rlang&amp;quot;
      ]
    },
    &amp;quot;viridisLite&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;viridisLite&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;0.4.1&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;62f4b5da3e08d8e5bcba6cac15603f70&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    },
    &amp;quot;withr&amp;quot;: {
      &amp;quot;Package&amp;quot;: &amp;quot;withr&amp;quot;,
      &amp;quot;Version&amp;quot;: &amp;quot;2.5.0&amp;quot;,
      &amp;quot;Source&amp;quot;: &amp;quot;Repository&amp;quot;,
      &amp;quot;Repository&amp;quot;: &amp;quot;RSPM&amp;quot;,
      &amp;quot;Hash&amp;quot;: &amp;quot;c0e49a9760983e81e55cdd9be92e7182&amp;quot;,
      &amp;quot;Requirements&amp;quot;: []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;as you can see this file lists the R version that was used as well as the different libraries for a
project. Versions of the libraries are also listed, where they came from (CRAN or Github for
example) and these libraries’ requirements as well. So someone who wants to run the original script
in a similar environment has all the info needed to do it. &lt;code&gt;{renv}&lt;/code&gt; also provides a simple way to
install all of this. Simply put the &lt;code&gt;renv.lock&lt;/code&gt; file in the same folder as the original script and
run &lt;code&gt;renv::restore()&lt;/code&gt;, and the right packages with the right versions get automagically installed
(and without interfering with your system-wide, already installed library of packages). The “only”
difficulty that you might have is installing the right version of R. If this is a recent
enough version of R, this shouldn’t be a problem, but installing old software might be difficult.
For example installing R version 2.5 might, or might not, be possible depending on your operating system
(I don’t like microsoft windows, but generally speaking it is quite easy to install very old
software on it, which in the case of Linux distros can be quite difficult. So I guess on windows
this could work more easily). Then there’s also the system libraries that your script might need, and it might
also be difficult to install these older versions. So that’s why I said that providing the
&lt;code&gt;renv.lock&lt;/code&gt; file is the bare minimum. But before seeing how we can deal with that, let’s discuss a
scenario 1bis, which is the case where you want to run an old script (say, from 5 years ago), but
there’s no &lt;code&gt;renv.lock&lt;/code&gt; file to be found.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-1bis-old-script-no-renv.lock-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1bis: old script, no renv.lock file&lt;/h2&gt;
&lt;p&gt;For these cases I would have used &lt;code&gt;{checkpoint}&lt;/code&gt;, but as explained in the intro MRAN is getting
shutdown, and with it out of the picture &lt;code&gt;{checkpoint}&lt;/code&gt; will cease to work.&lt;/p&gt;
&lt;p&gt;The way &lt;code&gt;{checkpoint}&lt;/code&gt; worked is that you would simply add the following line at the very top of
the script in question:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;checkpoint::checkpoint(&amp;quot;2018-12-12&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and this would download the packages needed for the script from that specific date and run your
script. Really, really useful. But unfortunately, Microsoft decided that MRAN should get the axe.
So what else is there? While researching for this blog post, I learned about &lt;code&gt;{groundhog}&lt;/code&gt; which
supposedly provides the same functionality. Suppose I have a script from 5 years ago that loads the
following libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By rewriting this like so (and installing &lt;code&gt;{groundhog}&lt;/code&gt; beforehand):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;groundhog.library(&amp;quot;
    library(purrr)
    library(ggplot2)&amp;quot;,
    &amp;quot;2017-10-04&amp;quot;,
    tolerate.R.version = &amp;quot;4.2.2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{purrr}&lt;/code&gt; and &lt;code&gt;{ggplot2}&lt;/code&gt; get downloaded as they were on the date I provided. If you want to know
what I had to use the “tolerate.R.version” option, this is because if you try to run it without it,
you get the following very useful message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---------------------------------------------------------------------------
|IMPORTANT.
|    Groundhog says: you are using R-4.2.2, but the version of R current 
|    for the entered date, &amp;#39;2017-10-04&amp;#39;, is R-3.4.x. It is recommended 
|    that you either keep this date and switch to that version of R, or 
|    you keep the version of R you are using but switch the date to 
|    between &amp;#39;2022-04-22&amp;#39; and &amp;#39;2023-01-08&amp;#39;. 
|
|    You may bypass this R-version check by adding: 
|    `tolerate.R.version=&amp;#39;4.2.2&amp;#39;`as an option in your groundhog.library() 
|    call. Please type &amp;#39;OK&amp;#39; to confirm you have read this message. 
|   &amp;gt;ok&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s is pretty neat, as it tells you “hey, getting the right packages is good, but if your R
version is not the same, you’re not guaranteed to get the same results back, and this might not
even work at all”.&lt;/p&gt;
&lt;p&gt;So, here’s what happens when I try to install these packages (on my windows laptop, as most people
would do), without installing the right version of R as suggested by &lt;code&gt;{groundhog}&lt;/code&gt;:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click me to see lock file
&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;+ Will now attempt installing 5 packages from source.

groundhog says: Installing &amp;#39;magrittr_1.5&amp;#39;, package #1 (from source) out of 5 needed
&amp;gt; As of 16:12, the best guess is that all 5 packages will install around 16:14
trying URL &amp;#39;https://packagemanager.rstudio.com/all/latest/src/contrib/Archive/magrittr/magrittr_1.5.tar.gz&amp;#39;
Content type &amp;#39;application/x-tar&amp;#39; length 200957 bytes (196 KB)
downloaded 196 KB


groundhog says: Installing &amp;#39;rlang_0.1.2&amp;#39;, package #2 (from source) out of 5 needed
&amp;gt; As of 16:12, the best guess is that all 5 packages will install around 16:14
trying URL &amp;#39;https://packagemanager.rstudio.com/all/latest/src/contrib/Archive/rlang/rlang_0.1.2.tar.gz&amp;#39;
Content type &amp;#39;application/x-tar&amp;#39; length 200867 bytes (196 KB)
downloaded 196 KB


groundhog says: Installing &amp;#39;Rcpp_0.12.13&amp;#39;, package #3 (from source) out of 5 needed
&amp;gt; As of 16:13, the best guess is that all 5 packages will install around 16:14
trying URL &amp;#39;https://packagemanager.rstudio.com/all/latest/src/contrib/Archive/Rcpp/Rcpp_0.12.13.tar.gz&amp;#39;
Content type &amp;#39;application/x-tar&amp;#39; length 3752364 bytes (3.6 MB)
downloaded 3.6 MB

Will try again, now showing all installation output.
trying URL &amp;#39;https://packagemanager.rstudio.com/all/latest/src/contrib/Archive/Rcpp/Rcpp_0.12.13.tar.gz&amp;#39;
Content type &amp;#39;application/x-tar&amp;#39; length 3752364 bytes (3.6 MB)
downloaded 3.6 MB

* installing *source* package &amp;#39;Rcpp&amp;#39; ...
** package &amp;#39;Rcpp&amp;#39; successfully unpacked and MD5 sums checked
staged installation is only possible with locking
** using non-staged installation
** libs
g++ -std=gnu++11  -I&amp;quot;c:/Users/Bruno/AppData/Roaming/R-42~1.2/include&amp;quot; -DNDEBUG -I../inst/include/    -I&amp;quot;c:/rtools42/x86_64-w64-mingw32.static.posix/include&amp;quot;     -O2 -Wall  -mfpmath=sse -msse2 -mstackrealign  -c Date.cpp -o Date.o
In file included from ../inst/include/RcppCommon.h:67,
                 from ../inst/include/Rcpp.h:27,
                 from Date.cpp:31:
../inst/include/Rcpp/sprintf.h: In function &amp;#39;std::string Rcpp::sprintf(const char*, ...)&amp;#39;:
../inst/include/Rcpp/sprintf.h:30:12: warning: unnecessary parentheses in declaration of &amp;#39;ap&amp;#39; [-Wparentheses]
   30 |     va_list(ap);
      |            ^~~~
../inst/include/Rcpp/sprintf.h:30:12: note: remove parentheses
   30 |     va_list(ap);
      |            ^~~~
      |            -  -
In file included from ../inst/include/Rcpp.h:77,
                 from Date.cpp:31:
../inst/include/Rcpp/Rmath.h: In function &amp;#39;double R::pythag(double, double)&amp;#39;:
../inst/include/Rcpp/Rmath.h:222:60: error: &amp;#39;::Rf_pythag&amp;#39; has not been declared; did you mean &amp;#39;pythag&amp;#39;?
  222 |     inline double pythag(double a, double b)    { return ::Rf_pythag(a, b); }
      |                                                            ^~~~~~~~~
      |                                                            pythag
make: *** [c:/Users/Bruno/AppData/Roaming/R-42~1.2/etc/x64/Makeconf:260: Date.o] Error 1
ERROR: compilation failed for package &amp;#39;Rcpp&amp;#39;
* removing &amp;#39;C:/Users/Bruno/Documents/R_groundhog/groundhog_library/R-4.2/Rcpp_0.12.13/Rcpp&amp;#39;
The package &amp;#39;Rcpp_0.12.13&amp;#39; failed to install!
groundhog says:
The package may have failed to install because you are using R-4.2.2
which is at least one major update after the date you entered &amp;#39;2017-10-04&amp;#39;.
You can try using a more recent date in your groundhog.library() command, 
or run it with the same date using &amp;#39;R-3.4.4&amp;#39;
Instructions for running older versions of R: 
    http://groundhogr.com/many

----------------   The package purrr_0.2.3 did NOT install.  Read above for details  -----------------

Warning message:
In utils::install.packages(url, repos = NULL, lib = snowball$installation.path[k],  :
  installation of package &amp;#39;C:/Users/Bruno/AppData/Local/Temp/RtmpyKYXFd/downloaded_packages/Rcpp_0.12.13.tar.gz&amp;#39; had non-zero exit status
&amp;gt; &lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;As you can see it failed, very likely because I don’t have the right development libraries
installed on my windows laptop, due to the version mismatch that &lt;code&gt;{groundhog}&lt;/code&gt; complained about. I
also tried on my Linux workstation, and got the same outcome. In any case, I want to stress that
this is not &lt;code&gt;{groundhog}&lt;/code&gt;’s fault, but this due to the fact that I was here only concerned with
packages; as I said multiple times now, reproducibility is on an continuum, and you also need to
deal with OS and system libraries. So for now, we only got part of the solution.&lt;/p&gt;
&lt;p&gt;By the way, you should know 3 more things about &lt;code&gt;{groundhog}&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the earliest available date is, in theory, any date. However, according to its author, &lt;code&gt;{groundhog}&lt;/code&gt; should work reliably with a date as early as “2015-04-16”. That’s because the oldest R version &lt;code&gt;{groundhog}&lt;/code&gt; is compatible with is R 3.2. However, again according to its author, it should be possible to patch &lt;code&gt;{groundhog}&lt;/code&gt; to work with any earlier versions of R.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;{groundhog}&lt;/code&gt;’s developer is &lt;a href=&#34;https://github.com/CredibilityLab/groundhog/issues/83#issuecomment-1379932166&#34;&gt;planning&lt;/a&gt; to save the binary packages off MRAN so that &lt;code&gt;{groundhog}&lt;/code&gt; will continue offering binary packages once MRAN is out of the picture, which will make installing these packages more reliable.&lt;/li&gt;
&lt;li&gt;On Windows and macOS, &lt;code&gt;{groundhog}&lt;/code&gt; installs binary packages if they’re available (which basically is always the case, in the example above it was not the case because I was using Posit’s CRAN mirror, and I don’t think they have binary packages for Windows that are that old. But if using another mirror, that should not be a problem). So if you install the right version of R, you’re almost guaranteed that it’s going to work. But, there is always a but, this also depends on hardware now. I’ll explain in the last part of this blog post, so read on.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-to-the-rescue&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Docker to the rescue&lt;/h2&gt;
&lt;p&gt;The full solution in both scenarios involves Docker. If you are totally unfamiliar with Docker, you
can imagine that Docker makes it easy to set up a Linux virtual machine and run it. In Docker, you
use Dockerfiles (which are configuration files) to define Docker &lt;em&gt;images&lt;/em&gt; and you can then run
&lt;em&gt;containers&lt;/em&gt; (your VMs, if you wish) based on that image. Inside that Dockerfile you can declare
which operating system you want to use and what you want to run inside of it. For example, here’s a
very simple Dockerfile that prints “Hello from Docker” on the Ubuntu operating system (a popular
Linux distribution):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM ubuntu:latest

RUN echo &amp;quot;Hello, World!&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You then need to build the image as defined from this Dockerfile. (Don’t try to follow along for now
with your own computer; I’ll link to resources below so that you can get started if you’re
interested. What matters is that you understand &lt;em&gt;why&lt;/em&gt; Docker is needed).&lt;/p&gt;
&lt;p&gt;Building the image can be achieved by running this command where the Dockerfile is located:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t hello .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then run a container from this image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm -d --name hello_container hello&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Sending build context to Docker daemon  2.048kB
Step 1/2 : FROM ubuntu:latest
 ---&amp;gt; 6b7dfa7e8fdb
Step 2/2 : RUN echo &amp;quot;Hello, World!&amp;quot;
 ---&amp;gt; Running in 5dfbff5463cf
Hello, World!
Removing intermediate container 5dfbff5463cf
 ---&amp;gt; c14004cd1801
Successfully built c14004cd1801
Successfully tagged hello:latest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see “Hello, World!” inside your terminal. Ok so this is the very basics. Now why is that useful? It turns
out that there’s the so-called Rocker project, and this project provides a collection of Dockerfiles for current, but also older
versions of R. So if we go back to our &lt;code&gt;renv.lock&lt;/code&gt; file from before, we can see which R version was used (it was R 4.2.1) and
define a new Dockerfile that builds upon the
&lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.2.1.Dockerfile&#34;&gt;Dockerfile from the Rocker project for R version 4.2.1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s first start by writing a very simple script. Suppose that this is the script that we want to make reproducible:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
library(ggplot2)

data(mtcars)

myplot &amp;lt;- ggplot(mtcars) +
  geom_line(aes(y = hp, x = mpg))

ggsave(&amp;quot;/home/project/output/myplot.pdf&amp;quot;, myplot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s assume that I did my homework and that the &lt;code&gt;renv.lock&lt;/code&gt; file from before is actually
the one that was generated at the time this script was written. In that case, you could write a
Dockerfile with the correct version of R and use the &lt;code&gt;renv.lock&lt;/code&gt; file to install the right
packages. This Dockerfile would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:4.2.1

RUN mkdir /home/project

RUN mkdir /home/project/output

COPY renv.lock /home/project/renv.lock

COPY script.R /home/project/script.R

RUN R -e &amp;quot;install.packages(&amp;#39;renv&amp;#39;)&amp;quot;

RUN R -e &amp;quot;setwd(&amp;#39;/home/project/&amp;#39;);renv::restore(confirm = FALSE)&amp;quot;

CMD R -e &amp;quot;source(&amp;#39;/home/project/script.R&amp;#39;)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to put the &lt;code&gt;renv.lock&lt;/code&gt; file, as well as the script &lt;code&gt;script.R&lt;/code&gt; in the same folder as the Dockerfile,
and then build and run the image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Build it with
docker build -t project .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;run the container (and mount a volume to get the image back – don’t worry if you don’t know what volumes are,
I’ll link resources at the end):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm -d --name project_container -v /path/to/your/project/output:/home/project/output:rw project&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even if you’ve never seen a Dockerfile in your life, you likely understand what is going on here:
the first line pulls a Docker image that contains R version 4.2.1 pre-installed on Ubuntu. Then, we
create a directory to hold our files, we copy said files in the directory, and then run several R
commands to install the packages as defined in the &lt;code&gt;renv.lock&lt;/code&gt; file and run our script in an
environment that not only has the right versions of the packages but also the right version of R.
This script then saves the plot in a folder called &lt;code&gt;output/&lt;/code&gt;, which we link to a folder also called
&lt;code&gt;output/&lt;/code&gt; but on our machine, so that we can then look at the generated plot (this is what &lt;code&gt;-v /path/to/your/project/output:/home/project/output:rw&lt;/code&gt; does). Just as this script saves a plot, it
could be doing any arbitrarily complex thing, like compiling an Rmarkdown file, running a model,
etc, etc.&lt;/p&gt;
&lt;p&gt;Here’s a short video of this process in action:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=E3E0yd6aFss&#34; title=&#34;renv Docker demo&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/E3E0yd6aFss/0.jpg&#34; alt=&#34;Link to renv and Docker demo&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now, let’s do the same thing but for our scenario 1bis that relied on &lt;code&gt;{groundhog}&lt;/code&gt;. Before writing the
Dockerfile down, here’s how you should change the script. Add these lines at the very top:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;groundhog::set.groundhog.folder(&amp;quot;/home/groundhog_folder&amp;quot;)

groundhog::groundhog.library(&amp;quot;
    library(purrr)
    library(ggplot2)&amp;quot;,
    &amp;quot;2017-10-04&amp;quot;
    )

data(mtcars)

myplot &amp;lt;- ggplot(mtcars) +
  geom_line(aes(y = hp, x = mpg))

ggsave(&amp;quot;/home/project/output/myplot.pdf&amp;quot;, myplot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also created a new script that installs the dependencies of my script when building my Dockerfile. This
way, when I run the container, nothing gets installed anymore. Here’s what this script looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;groundhog::set.groundhog.folder(&amp;quot;/home/groundhog_folder&amp;quot;)

groundhog::groundhog.library(&amp;quot;
    library(purrr)
    library(ggplot2)&amp;quot;,
    &amp;quot;2017-10-04&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s exactly the beginning from the main script. Now here comes the Dockerfile, and this time it’s going to
be a bit more complicated:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:3.4.4

RUN echo &amp;quot;options(repos = c(CRAN=&amp;#39;https://packagemanager.rstudio.com/cran/latest&amp;#39;), download.file.method = &amp;#39;libcurl&amp;#39;)&amp;quot; &amp;gt;&amp;gt; /usr/local/lib/R/etc/Rprofile.site

RUN mkdir /home/project

RUN mkdir /home/groundhog_folder

RUN mkdir /home/project/output

COPY script.R /home/project/script.R

COPY install_deps.R /home/project/install_deps.R

RUN R -e &amp;quot;install.packages(&amp;#39;groundhog&amp;#39;);source(&amp;#39;/home/project/install_deps.R&amp;#39;)&amp;quot;

CMD R -e &amp;quot;source(&amp;#39;/home/project/script.R&amp;#39;)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see from the first line, this time we’re pulling an image that comes with R 3.4.4. This
is because that version of R was the current version as of 2017-10-04, the date we assumed this
script was written on. Because this is now quite old, we need to add some more stuff to the
Dockerfile to make it work. First, I change the repositories to the current mirror from
&lt;a href=&#34;https://packagemanager.rstudio.com/client/#/repos/2/overview&#34;&gt;Posit&lt;/a&gt;. This is because the
repositories from this image are set to MRAN at a fixed date. This was done at the time for
reproducibility, but now MRAN is getting shutdown, so we need to change the repositories or else
our container will not be able to download packages. Also, &lt;code&gt;{groundhog}&lt;/code&gt; will take care of
installing the right package versions. Then I create the necessary folders and run the
&lt;code&gt;install_deps.R&lt;/code&gt; script which is the one that will install the packages. This way, the packages get
installed when building the Docker image, and not when running the container, which is preferable.
Finally, the main script gets run, and an output gets produced. Here’s a video showing this
process:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=g0eG1OvXl9s&#34; title=&#34;renv Docker demo&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/g0eG1OvXl9s/0.jpg&#34; alt=&#34;Link to the groundhog and Docker demo&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now all of this may seem complicated, and to be honest it is. Reproducibility is no easy task, but I hope that
I’ve convinced you that by combining &lt;code&gt;{renv}&lt;/code&gt; and Docker, or &lt;code&gt;{groundhog}&lt;/code&gt; and Docker it is possible to rerun
any analysis. But you do have to be familiar with these tools, and there’s also another issue by using Docker.
Docker works on Windows, macOS and Linux, but the container that runs must be a Linux distribution, usually Ubuntu.
But what if the original analysis was done on Windows and macOS? This can be a problem if the script relies on some
Windows or macOS specific things, which even for a language available on all platforms like R can happen. For example,
I’ve recently noticed that the &lt;code&gt;tar()&lt;/code&gt; function in R, which is used to decompress &lt;code&gt;tar.gz&lt;/code&gt; files, behaves differently
on Windows than on Linux. So ideally, even if you’re running your analysis on Windows, you should then try
to distribute a working Dockerfile alongside your paper (if you’re a researcher, or if you’re working in the private
sector, you should do the same for each project). Of course, that is quite demanding, and you would need to
learn about these tools, or hire someone to do that for you… But a natural question is then, well, “why
use Docker at all? Since it’s easy to install older versions of R on Windows and macOS, wouldn’t an &lt;code&gt;renv.lock&lt;/code&gt;
file suffice? Or even just &lt;code&gt;{groundhog}&lt;/code&gt; which is arguably even easier to use?”&lt;/p&gt;
&lt;p&gt;Well, more on this later. I still need to discuss scenario 2 first.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-2-offering-an-environment-that-is-made-for-reproducibility&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 2: offering an environment that is made for reproducibility&lt;/h2&gt;
&lt;p&gt;Ok, so this one is easier. In this scenario, you have no idea what people are going to use, so you
cannot generate an &lt;code&gt;renv.lock&lt;/code&gt; file beforehand, and &lt;code&gt;{groundhog}&lt;/code&gt; is of no help either, because,
well, there’s no scripts yet to actually make reproducible. This is the situation I’ve had for this
project that I’ve discussed at the end of last year, on &lt;a href=&#34;https://www.brodrigues.co/blog/2022-12-21-longevity/&#34;&gt;code
longevity&lt;/a&gt; of the R programming language. The
solution is to write a Dockerfile that people can modify and run; this in turn produces some
results that can then be shared. This Dockerfile pulls from another Dockerfile, and that other
Dockerfile is made for reproducibility. How? Because that other Dockerfile is based on Ubuntu
22.04, compiles R 4.2.2 from source, and sets the repositories to
&lt;a href=&#34;https://packagemanager.rstudio.com/cran/__linux__/jammy/2022-11-21&#34; class=&#34;uri&#34;&gt;https://packagemanager.rstudio.com/cran/__linux__/jammy/2022-11-21&lt;/a&gt; . This way, the packages get
downloaded exactly as they were on November 21st 2022. So every time this image defined from this
Dockerfile gets built, we get exactly the same environment.&lt;/p&gt;
&lt;p&gt;It should also be noted that this solution can be used in the case of scenario 1bis. Let’s say I
have a script from August 2018; by using a Docker image that ships the current version of R at that
time (which should be R version 3.5.x) and Ubuntu (which at the time was 18.04, codenamed Bionic
Beaver) and then using the Posit package manager at a frozen date, for example
&lt;a href=&#34;https://packagemanager.rstudio.com/cran/__linux__/bionic/2018-08-16&#34; class=&#34;uri&#34;&gt;https://packagemanager.rstudio.com/cran/__linux__/bionic/2018-08-16&lt;/a&gt; I should be able to reproduce
an environment that is close enough. However the problem is that Posit’s package manager earliest
available date is Octobre 2017, so anything before that would not be possible to reproduce.&lt;/p&gt;
&lt;p&gt;Ok, great, here are the solutions for reproducibility. But there are still problems.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-single-point-of-failure-docker&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A single point of failure: Docker&lt;/h2&gt;
&lt;p&gt;Let’s be blunt: having Docker as the common denominator in all these solutions is a problem. This is
because Docker represents a single point of failure. But the problem is not Docker itself, but the
infrastructure.&lt;/p&gt;
&lt;p&gt;Let me explain: Docker is based on many different open source parts, and that’s great. There’s also
Podman, which is basically a drop-in replacement (when combined with other tools) made by Red Hat,
which is completely open source as well. So the risk does not come from there, because even if for
some reason Docker would disappear, or get abandoned or whatever, we could still work with Podman,
and it would likely be possible to create a fork from Docker.&lt;/p&gt;
&lt;p&gt;But the issue is the infrastructure. For now, using Docker and more importantly hosting images is
free for personal use, education, open source communities and small businesses. So this means that
a project like Rocker likely pays nothing for hosting all the images they produce (but who knows, I
may be wrong on this). And Rocker makes a lot of images. See, at the top of the Dockerfiles I’ve used
in this blog post, there’s always a statement like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:4.2.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as explained before, this states that a pre-built image that ships R version 4.2.1 on Ubuntu gets downloaded.
But from where? This image gets downloaded from Docker Hub, see
&lt;a href=&#34;https://hub.docker.com/layers/rocker/r-ver/4.2.1/images/sha256-3636493af7028d899a6598ee4aabe70d231fb0ff60f61a70f8ea0ea24a51c3e6?context=explore&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This means that you can download this pre-built image and don’t need to build it each time you need
to work with it. You can simply use that as a base for your work, like the image built for reproducibility
described in scenario 2. But what happens if at some point in the future Docker changes its licensing
model? What if they still have a free tier, but massively limit the amount of images that get
hosted for free? What if they get rid of the free tier entirely? This is a massive risk that needs to be
managed in my opinion. There is the option of the Rocker project hosting the images themselves.
It is possible to create your own, self-hosted Docker registry and not use Docker
Hub, after all. But this is costly not only in terms of storage, but also of manpower to maintain all this.
But maybe worse than that is: what if at some point in the future you cannot rebuild these
images, at all? You would need to make sure that these pre-built images do not get lost. And this is
already happening because of MRAN getting shutdown. In this blog post I’ve used the
&lt;code&gt;rocker/r-ver:3.4.4&lt;/code&gt; image to run code from 2017. The problem is that if you look at its
Dockerfile, you see that building this image &lt;a href=&#34;https://github.com/rocker-org/rocker-versioned/blob/1920e7cfc757bad02d041a0bddec1a18b1ebc4c1/r-ver/3.4.4.Dockerfile#L118&#34;&gt;requires
MRAN&lt;/a&gt;.
So in other words, once MRAN is offline, it won’t be possible to rebuild this image, and the Rocker
project will need to make sure that the pre-built image that is currently available on Docker Hub
stays available forever. Because if not, it would be quite hard to rerun code from, say, 2017. Same
goes for Posit’s package manager. Posit’s package manager could be used as a drop-in replacement
for MRAN, but for how long? Even though Posit is a very responsible company, I believe that it is
dangerous that such a crucial service is managed by only one company.&lt;/p&gt;
&lt;p&gt;And rebuilding old images will be necessary. This is now the part where I answer the question from above:&lt;/p&gt;
&lt;p&gt;“why use Docker at all? Since it’s easy to install older versions of R on Windows and macOS, wouldn’t an &lt;code&gt;renv.lock&lt;/code&gt;
file suffice? Or even just &lt;code&gt;{groundhog}&lt;/code&gt; which is arguably even easier to use?”&lt;/p&gt;
&lt;p&gt;The problem is hardware. You see, Apple has changed hardware architecture recently, their new computers
switched from Intel based hardware to their own proprietary architecture (Apple Silicon) based on the ARM specification.
And what does that mean concretely? It means that all the binary packages that were built for Intel based
Apple computers cannot work on their new computers. Which means that if you have a recent M1 Macbook and
need to install old CRAN packages (for example, by using &lt;code&gt;{groundhog}&lt;/code&gt;), these need to be compiled to work
on M1. You cannot even install older versions of R, unless you also compile those from source! Now I have
read about a compatibility layer called Rosetta which enables to run binaries compiled for the Intel architecture
on the ARM architecture, and maybe this works well with R and CRAN binaries compiled
for Intel architecture. Maybe, I don’t know. But my point is that you never know what might come in the future,
and thus needing to be able to compile from source is important, because compiling from source is what
requires the least amount of dependencies that are outside of your control. Relying on binaries is not future-proof.&lt;/p&gt;
&lt;p&gt;And for you Windows users, don’t think that the preceding paragraph does not concern you. I think that it is
very likely that Microsoft will push in the future for OEM manufacturers to develop more ARM based computers.
There is already an ARM version of Windows after all, and it has been around for quite some time, and I think
that Microsoft will not kill that version any time in the future.
This is because ARM is much more energy efficient than other architectures, and any manufacturer can
build its own ARM cpus by purchasing a license, which can be quite interesting. For example in the case
of Apple silicon cpus, Apple can now get exactly the cpus they want for their machines and make their
software work seamlessly with it. I doubt that others will pass the chance to do the same.&lt;/p&gt;
&lt;p&gt;Also, something else that might happen is that we might move towards more and more cloud based computing,
but I think that this scenario is less likely than the one from before. But who knows. And in that case
it is quite likely that the actual code will be running on Linux servers that will likely be ARM based
because of energy costs. Here again, if you want to run your historical code, you’ll have to compile
old packages and R versions from source.&lt;/p&gt;
&lt;p&gt;Basically, binary packages are in my opinion not a future-proof option, so that’s why something like
Docker will stay, and become ever more relevant. But as I argued before, that’s a single point of failure.&lt;/p&gt;
&lt;p&gt;But there might be a way we can solve this and not have to rely on Docker at all.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;guix-toward-practical-transparent-verifiable-and-long-term-reproducible-research&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Guix: &lt;em&gt;toward practical transparent verifiable and long-term reproducible research&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;The title of this section is the same as the title from a research paper published in 2022 that you
can read &lt;a href=&#34;https://www.nature.com/articles/s41597-022-01720-9#Abs1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This paper presents and shows how to use Guix, which is a tool to build, from scratch and in a
reproducible manner, the computational environment that was used to run some code for research. Very
importantly, Guix doesn’t rely on containers, virtual machines or anything like that. From my,
albeit still limited, understanding of how it works, Guix requires some recipes telling it how it
should build software. Guix integrates with CRAN, so it’s possible to tell Guix “hey, could you
build ggplot2” and Guix does as instructed. It builds &lt;code&gt;{ggplot2}&lt;/code&gt; and all the required
dependencies. And what’s great about Guix is that it’s also possible to build older versions of
software.&lt;/p&gt;
&lt;p&gt;The authors illustrate this by reproducing results from a 2019 paper, by recreating the environment
used at the time, 3 years later.&lt;/p&gt;
&lt;p&gt;This could be a great solution, because it would always allow the recreation of computational
environments from source. So architecture changes would not be a problem, making Guix quite future
proof. The issue I’ve found though, is that Guix only works on Linux. So if you’re working on
Windows or macOS, you would need Docker to recreate a computational environment with Guix. So you
could think that we’re back to square one, but actually no. Because you could always have a Linux
machine or server that you would use for reproducibility, on which Linux is installed, thus
eliminating the need for Docker, thus removing that risk entirely.&lt;/p&gt;
&lt;p&gt;I’m currently exploring Guix and will report on it in greater detail in the future. In the
meantime, I hope to have convinced you that, while reproducibility is no easy task, the tools that
are currently available can help you set up reproducible project. However, for something to be and
stay truly reproducible, some long term maintenance is also required.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So here we are, these are, as far as I know, the options to make your code reproducible. But it is
no easy task and it takes time. Unfortunately, many scientists are not really concerned with making
their code reproducible, simply because there is no real incentive for them to do it. And it’s
a task that is becoming more and more complex as there are other risks that need to be managed,
like the transition from Intel based architectures for cpus towards ARM. I’m pretty sure there
are many scientists who have absolutely no idea what Intel based cpus or ARM cpus or Rosetta or whatever
are. So telling them they need to make their code reproducible is one thing, telling them they
need to make it so future proof that architecture changes won’t matter is like asking for the Moon.&lt;/p&gt;
&lt;p&gt;So research software engineers will become more and more crucial, and should be integrated to research
teams to deal with this question (and this also holds true for the private sector; there should be someone
whose job is make code reproducible across the organization).&lt;/p&gt;
&lt;p&gt;Anyways, if you read until here, I appreciate it. This was a long blog post. If you want to know more, you can read
this &lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;other blog post&lt;/a&gt; of mine that explains how to use Docker,
and also this &lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-30-pipelines-as/&#34;&gt;other blog post&lt;/a&gt;
that explains why Docker &lt;em&gt;is not&lt;/em&gt; optional (but now that I’ve discovered Guix, maybe it’s Guix that is not
optional).&lt;/p&gt;
&lt;p&gt;By the way, if you want to grab the scripts and Dockerfiles from this blog post, you can get them
&lt;a href=&#34;https://github.com/b-rodrigues/repro_r&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Code longevity of the R programming language</title>
      <link>https://www.brodrigues.co/blog/2022-12-21-longevity/</link>
      <pubDate>Wed, 21 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-12-21-longevity/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/spelunky.jpg&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve been working on a way to evaluate how old R code runs on the current version of R, and
am now ready to share some results. It all started with this tweet:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href = &#34;https://twitter.com/brodriguesco/status/1588088437655093250?s=20&amp;t=-8DPAVEpMEcAuxy8Q2sAQw&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/tweet_old_code.png&#34; width=&#34;70%&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The problem is that you have to find old code laying around. Some people have found old code they
wrote a decade or more ago and tried to rerun it; there’s &lt;a href=&#34;https://notstatschat.rbind.io/2022/10/14/code-archaeology-polynomial-distributed-lags/&#34;&gt;this blog
post&lt;/a&gt; by
Thomas Lumley and &lt;a href=&#34;https://www.jumpingrivers.com/blog/r-from-the-turn-of-the-century/&#34;&gt;this other
one&lt;/a&gt; by Colin Gillespie that I
find fascinating, but ideally we’d have more than a handful of old scripts laying around. This is
when Dirk Eddelbuettel suggested this:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href = &#34;https://twitter.com/eddelbuettel/status/1588149491772923907?s=20&amp;t=-8DPAVEpMEcAuxy8Q2sAQw&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/tweet_dirk.png&#34; width=&#34;70%&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And this is what I did. I wrote a lot of code to achieve this graph here:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href = &#34;https://github.com/b-rodrigues/code_longevity&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/r_longevity.png&#34; width=&#34;70%&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This graph shows the following: for each version of R, starting with R version 0.6.0 (released in
1997), how well the examples that came with a standard installation of R run on the current version
of R (version 4.2.2 as of writing). These are the examples from the default packages like &lt;code&gt;{base}&lt;/code&gt;,
&lt;code&gt;{stats}&lt;/code&gt;, &lt;code&gt;{stats4}&lt;/code&gt;, and so on. Turns out that more than 75% of the example code from version
0.6.0 still works on the current version of R. A small fraction output a message (which doesn’t
mean the code doesn’t work), some 5% raise a warning, which again doesn’t necessarily mean that the
code doesn’t work, and finally around 20% or so errors. As you can see, the closer we get to the
current release, the less errors get raised.&lt;/p&gt;
&lt;p&gt;(But something important should be noted: just because some old piece of code runs without error,
doesn’t mean that the result is exactly the same. There might be cases where the same function
returns different results on different versions of R.)&lt;/p&gt;
&lt;p&gt;Then, once I had this graph, I had to continue with packages. How well do old examples
from any given package run on the current version of the same package?&lt;/p&gt;
&lt;p&gt;What I came up with is a Docker image that runs this for you, and even starts a Shiny app
to let you explore the results. All you have to do is edit one line in the Dockerfile.
This Docker image uses a lot of code from other projects, and I even had to write a package
for this, called &lt;code&gt;{wontrun}&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;the-wontrun-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The {wontrun} package&lt;/h2&gt;
&lt;p&gt;The problem I needed to solve was how to easily run examples from archived packages. So I
needed to first have an easy way to download them, then extract the examples, and then run them. So
to help me with this I wrote the &lt;code&gt;{wontrun}&lt;/code&gt; package (thanks again to
&lt;a href=&#34;https://fediscience.org/@dmi3kno/109296599193965025&#34;&gt;Deemah&lt;/a&gt; for suggesting the name and making
the hex logo!). To be honest, the quality of this package could be improved. Documentation is still
lacking, and the package only seems to work on Linux (but that’s not an issue, since it really only
makes sense to use it within Docker). In any case, this package has a function to download the
archived source code for a given package, using the &lt;code&gt;get_archived_sources()&lt;/code&gt; function. This
function takes the name of a package as an input and returns a data frame with the archived sources
and the download links to them. To actually download the source packages, the &lt;code&gt;get_examples()&lt;/code&gt;
function is used. This function extracts the examples from the &lt;code&gt;man/&lt;/code&gt; folder included in source
packages, and converts the examples into scripts. Remember that example files are in the &lt;code&gt;.Rd&lt;/code&gt; format,
which is some kind of markup language format. Thankfully, there’s a function called &lt;code&gt;Rd2ex()&lt;/code&gt; from
the &lt;code&gt;{tools}&lt;/code&gt; package which I use to convert &lt;code&gt;.Rd&lt;/code&gt; files into &lt;code&gt;.R&lt;/code&gt; scripts.&lt;/p&gt;
&lt;p&gt;Then, all that there is to do is to run these scripts. But that’s not as easy as one might think.
This is becuse I first need to make sure that the latest version of the package is installed, and
ideally, I don’t want to pollute my library with packages that I never use but only wanted to
assess for their code longevity. I also need to make sure that I’m running all these scripts &lt;em&gt;all
else being equal&lt;/em&gt;: so same version of R, same version of the current packages and same operating
system. That why I needed to use Docker for this. Also, all the required dependencies to run the
examples should get installed as well. Sometimes, some examples load data from another package.
So for this, I’m using the &lt;code&gt;renv::dependencies()&lt;/code&gt; function which scans a file for calls to
&lt;code&gt;library()&lt;/code&gt; or &lt;code&gt;package::function()&lt;/code&gt; to list the dependencies and then install them.
This all happens automatically.&lt;/p&gt;
&lt;p&gt;To conclude this section: I cannot stress how much I’m relying on work by other people for this.
This is the NAMESPACE file of the &lt;code&gt;{wontrun}&lt;/code&gt; package (I’m only showing the import statements):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;importFrom(callr,r_vanilla)
importFrom(ctv,ctv)
importFrom(dplyr,filter)
importFrom(dplyr,group_by)
importFrom(dplyr,mutate)
importFrom(dplyr,rename)
importFrom(dplyr,select)
importFrom(dplyr,ungroup)
importFrom(furrr,future_map2)
importFrom(future,multisession)
importFrom(future,plan)
importFrom(janitor,clean_names)
importFrom(lubridate,year)
importFrom(lubridate,ymd)
importFrom(lubridate,ymd_hm)
importFrom(magrittr,&amp;quot;%&amp;gt;%&amp;quot;)
importFrom(pacman,p_load)
importFrom(pkgsearch,cran_package)
importFrom(purrr,keep)
importFrom(purrr,map)
importFrom(purrr,map_chr)
importFrom(purrr,map_lgl)
importFrom(purrr,pluck)
importFrom(purrr,pmap_chr)
importFrom(purrr,possibly)
importFrom(renv,dependencies)
importFrom(rlang,`!!`)
importFrom(rlang,cnd_message)
importFrom(rlang,quo)
importFrom(rlang,try_fetch)
importFrom(rvest,html_nodes)
importFrom(rvest,html_table)
importFrom(rvest,read_html)
importFrom(stringr,str_extract)
importFrom(stringr,str_remove_all)
importFrom(stringr,str_replace)
importFrom(stringr,str_trim)
importFrom(tibble,as_tibble)
importFrom(tidyr,unnest)
importFrom(tools,Rd2ex)
importFrom(withr,with_package)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s a lot of packages, most of them from Posit. What can I say, these packages are great! Even
if I could reduce the number of dependencies from &lt;code&gt;{wontrun}&lt;/code&gt;, I honestly cannot be bothered, I’ve
been spoilt by the quality of Posit packages.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;docker-for-reproducibility&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Docker for reproducibility&lt;/h2&gt;
&lt;p&gt;The Dockerfile I wrote is based on Ubuntu 22.04, compiles R 4.2.2 from source, and sets the
repositories to &lt;a href=&#34;https://packagemanager.rstudio.com/cran/__linux__/jammy/2022-11-21&#34; class=&#34;uri&#34;&gt;https://packagemanager.rstudio.com/cran/__linux__/jammy/2022-11-21&lt;/a&gt; . This way, the
packages get downloaded exactly as they were on November 21st 2022. This ensures that if readers of
this blog post want to run this to assess the code longevity of some R packages, we can compare
results and be certain that any conditions raised are not specific to any difference in R or
package version. It should be noted that this Dockerfile is based on the work of the Rocker
project, and more specifically their &lt;a href=&#34;https://rocker-project.org/images/versioned/r-ver.html&#34;&gt;versioned
images&lt;/a&gt; which are recommended when
reproducibility is needed. Becuse the code runs inside Docker, it doesn’t matter if the &lt;code&gt;{wontrun}&lt;/code&gt;
package only runs on Linux (I think that this is the case because of the &lt;code&gt;untar()&lt;/code&gt; function which I
use to decompress the downloaded compressed archives from CRAN, and which seems to
have a different behaviour on Linux vs Windows. No idea how this function behaves on macOS).&lt;/p&gt;
&lt;p&gt;The image defined by this Dockerfile is quite heavy, because I also installed all possible dependencies
required to run R packages smoothly. This is because even though the Posit repositories install
compiled packages on Linux, shared libraries are still needed for the packages to run.&lt;/p&gt;
&lt;p&gt;Here is what the Dockerfile looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM brodriguesco/wontrun:r4.2.2

# This gets the shiny app
RUN git clone https://github.com/b-rodrigues/longevity_app.git

# These are needed for the Shiny app
RUN R -e &amp;quot;install.packages(c(&amp;#39;dplyr&amp;#39;, &amp;#39;forcats&amp;#39;, &amp;#39;ggplot2&amp;#39;, &amp;#39;shiny&amp;#39;, &amp;#39;shinyWidgets&amp;#39;, &amp;#39;DT&amp;#39;))&amp;quot;

RUN mkdir /home/intermediary_output/
RUN mkdir /home/output/

COPY wontrun.R /home/wontrun.R

# Add one line per package you want to asses
RUN Rscript &amp;#39;/home/wontrun.R&amp;#39; dplyr 6
RUN Rscript &amp;#39;/home/wontrun.R&amp;#39; haven 6

CMD mv /home/intermediary_output/* /home/output/ &amp;amp;&amp;amp; R -e &amp;#39;shiny::runApp(&amp;quot;/longevity_app&amp;quot;, port = 1506, host = &amp;quot;0.0.0.0&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see it starts by pulling an image from Docker Hub called &lt;code&gt;wontrun:r4.2.2&lt;/code&gt;. This is the
image based on Ubuntu 22.04 with R compiled from source and all dependencies pre-installed.
(This Dockerfile is available &lt;a href=&#34;https://github.com/b-rodrigues/code_longevity/tree/master/wontrun_dockerfile&#34;&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Then my Shiny app gets cloned, the required packages for the app to run get installed, and some
needed directories get made. Now comes the interesting part; a script called &lt;code&gt;wontrun.R&lt;/code&gt; gets copied.
This is what the script looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#!/usr/bin/env Rscript
args &amp;lt;- commandArgs(trailingOnly = TRUE)

library(wontrun)

packages_sources &amp;lt;- get_archived_sources(args[1])

out &amp;lt;- wontrun(packages_sources ,
               ncpus = args[2],
               setup = TRUE,
               wontrun_lib = &amp;quot;/usr/local/lib/R/site-library/&amp;quot;)

saveRDS(object = out,
        file = paste0(&amp;quot;/home/intermediary_output/&amp;quot;, args[1], &amp;quot;.rds&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This script uses the &lt;code&gt;{wontrun}&lt;/code&gt; package to get the archived sources of a package of interest,
and the examples get executed and results tallied using the &lt;code&gt;wontrun()&lt;/code&gt; function. The results
then get saved into an &lt;code&gt;.rds&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Calling this script is done with this line in the Dockerfile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RUN Rscript &amp;#39;/home/wontrun.R&amp;#39; dplyr 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;6&lt;/code&gt; get passed down to the &lt;code&gt;wontrun.R&lt;/code&gt; script as a list called &lt;code&gt;args&lt;/code&gt;. So
&lt;code&gt;args[1]&lt;/code&gt; is the “dplyr” string, and &lt;code&gt;args[2]&lt;/code&gt; is 6. This means that the examples from
archived versions of the &lt;code&gt;{dplyr}&lt;/code&gt; package will get assessed on the current version of
&lt;code&gt;{dplyr}&lt;/code&gt; using 6 cores. You can add as many lines as you want and thus assess as many
packages as you want. Once you’re done with editing the Dockerfile, you can build the image;
this will actually run the code, so depending on how many packages you want to assess and the
complexity of the examples, this may take some hours. To build the image run this in a console:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t code_longevity_packages .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, you still need to actually run a container based on this image. Running the container will
move the &lt;code&gt;.rds&lt;/code&gt; files from the container to your machine so you can actually get to the results,
and it will also start a Shiny app in which you will be able to upload the &lt;code&gt;.rds&lt;/code&gt; file and
explore the results. Run the container with (and don’t forget to change &lt;code&gt;path/to/repository/&lt;/code&gt; with
the correct path on your machine):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm --name code_longevity_packages_container -v /path/to/repository/code_longevity_packages/output:/home/output:rw -p 1506:1506 code_longevity_packages&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Go over to &lt;code&gt;http://localhost:1506/&lt;/code&gt; to start the Shiny app and explore the results:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/code_longevity.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-collaborative-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A collaborative project&lt;/h2&gt;
&lt;p&gt;Now it’s your turn: are you curious about the code longevity of one particular package? Then
fork the repository, edit the Dockerfile, build, run and do a pull request! It’d be great
to have an overview of the code longevity of as many packages as possible. I thought about
looking at the longevity of several packages that form a group, like the tidyverse packages
or packages from CRAN Task views. Please also edit the &lt;code&gt;package_list.txt&lt;/code&gt; file which
lists packages for which we already have results. Find the repository here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/b-rodrigues/code_longevity_packages&#34; class=&#34;uri&#34;&gt;https://github.com/b-rodrigues/code_longevity_packages&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;By the way, if you want the results of the language itself (so the results of running the examples
of &lt;code&gt;{base}&lt;/code&gt;, &lt;code&gt;{stats}&lt;/code&gt;, etc), go &lt;a href=&#34;https://github.com/b-rodrigues/code_longevity/blob/master/docker/output/objects/base_runs&#34;&gt;here&lt;/a&gt; and click “download”.&lt;/p&gt;
&lt;p&gt;Looking forward to your pull requests!&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Functional programming explains why containerization is needed for reproducibility</title>
      <link>https://www.brodrigues.co/blog/2022-11-30-pipelines-as/</link>
      <pubDate>Wed, 30 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-11-30-pipelines-as/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dino.png&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve had some discussions online and in the real world about &lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-16-open_source_repro/&#34;&gt;this blog post&lt;/a&gt;
and I’d like to restate why containerization is needed for reproducibility, and do so from the
lens of functional programming.&lt;/p&gt;
&lt;p&gt;When setting up a pipeline, wether you’re a functional programming enthusiast or not,
you’re aiming at setting it up in a way that this pipeline is the composition of (potentially)
many referentially transparent and pure functions.&lt;/p&gt;
&lt;p&gt;As a reminder:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;referentially transparent functions are functions that always return the same output for
the same given input. So for example &lt;code&gt;f(x, y):=x+y&lt;/code&gt; is referentially transparent, but &lt;code&gt;h(x):=x+y&lt;/code&gt;
is not. Because &lt;code&gt;y&lt;/code&gt; is not an input of &lt;code&gt;h&lt;/code&gt;, &lt;code&gt;h&lt;/code&gt; will look for &lt;code&gt;y&lt;/code&gt; in the global environment.
Depending on the value of y, &lt;code&gt;h(1)&lt;/code&gt; might equal 10 one day, but 100 the next.
Let’s say that &lt;code&gt;f(1, 10)&lt;/code&gt; is always equal to 11. Because this is true, you could replace &lt;code&gt;f(1, 10)&lt;/code&gt;
everywhere it appears with 11. But consider the following example of a function that is not referentially
transparent, &lt;code&gt;rnorm()&lt;/code&gt;. Try &lt;code&gt;rnorm(1)&lt;/code&gt; several times… It will always give a different result! This is because
&lt;code&gt;rnorm()&lt;/code&gt; looks for the seed in the global environment and uses that to generate a random number.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pure functions are functions without side effects. So a function just does its thing, and does
not interact with anything else; doesn’t change anything in the global environment, doesn’t print
anything on screen, doesn’t write anything to disk. Basically, pure functions are functions that
do nothing else but computing stuff. Now this may seem limiting, and to some extent it is, so we will
need to relax this a bit: we’ll be ok with functions that output stuff, but only the very last function
in the pipeline will be allowed to do it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To be pure, a function needs to be referentially transparent.&lt;/p&gt;
&lt;p&gt;Ok so now that we know what referentially transparent and pure functions are, let’s explain
why we want a pipeline to be a composition of such functions.
Function composition is an operation that takes two functions &lt;em&gt;g&lt;/em&gt; and &lt;em&gt;f&lt;/em&gt; and
returns a new function &lt;em&gt;h&lt;/em&gt; such that &lt;code&gt;h(x) = g(f(x))&lt;/code&gt;. Formally:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h = g ∘ f such that h(x) = g(f(x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;∘&lt;/code&gt; is the composition operator. You can read &lt;code&gt;g ∘ f&lt;/code&gt; as &lt;em&gt;g after f&lt;/em&gt;. In R,
you can compose functions very easily, simply by using |&amp;gt; or %&amp;gt;%:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h &amp;lt;- f |&amp;gt; g&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;f |&amp;gt; g&lt;/code&gt; can be read as &lt;em&gt;f then g&lt;/em&gt;, which is equivalent to &lt;em&gt;g after f&lt;/em&gt; (ok, using &lt;code&gt;|&amp;gt;&lt;/code&gt; is chaining
rather than composing functions, but the net effect is the same).&lt;/p&gt;
&lt;p&gt;So &lt;code&gt;h&lt;/code&gt; would be our complete pipeline, which would be the composition, or chaining, of as many
functions as needed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h &amp;lt;- a |&amp;gt; b |&amp;gt; c |&amp;gt; d ... |&amp;gt; z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If all the functions are pure (and referentially transparent) then we’re assured that &lt;code&gt;h&lt;/code&gt; will
always produce the same outputs for the same inputs. As stated above, &lt;code&gt;z&lt;/code&gt; will be allowed to not
be pure an actually output something (like a rendered Quarto document) to disk. Ok so that’s great,
and all, but why does the title of this blog post say that containerization is needed?&lt;/p&gt;
&lt;p&gt;The problem is that all the functions we use have “hidden” inputs, and are never truly
referentially transparent. These inputs are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version of R (or whatever programming language you’re using)&lt;/li&gt;
&lt;li&gt;Versions of the packages you’re using&lt;/li&gt;
&lt;li&gt;Operating system and its version (and all the different operating system dependencies that get used at run- or compile time)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, let’s take a look at this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(x){
  if (c(TRUE, FALSE)) x 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which will return the following on R 4.1 (which was released on May 2021):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;[1] 1
Warning message:
In if (c(TRUE, FALSE)) 1 :
  the condition has length &amp;gt; 1 and only the first element will be used&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So a result 1 and a warning. On R 4.2.2 (the current version as of writing), the exact same
call returns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Error in if (c(TRUE, FALSE)) 1 : the condition has length &amp;gt; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These types of breaking changes are rare in R, at least to my knowledge (I’m actually looking into
this in greater detail, 2023 will likely be the year I show my findings), but in this case it
illustrates my point: code that was behaving in a certain way started behaving in another way, even
though nothing changed. What changed was the version of R, even though the function itself was pure.
This wouldn’t be so surprising if instead of &lt;code&gt;f(x)&lt;/code&gt;, the function was something like &lt;code&gt;f(x, r_version)&lt;/code&gt;.
In this case, the calls above would be something like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(1, r_version = &amp;quot;4.1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and this would always return:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;[1] 1
Warning message:
In if (c(TRUE, FALSE)) 1 :
  the condition has length &amp;gt; 1 and only the first element will be used&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but changing the call to this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(1, r_version = &amp;quot;4.2.2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;would return the error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Error in if (c(TRUE, FALSE)) 1 : the condition has length &amp;gt; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;regardless of the version of R we’re running, so our function would be referentially transparent.&lt;/p&gt;
&lt;p&gt;Alas, this is not possible, at least not like this.&lt;/p&gt;
&lt;p&gt;Hence why tools like Docker, Podman (a Docker alternative) or Guix (which I learned about recently
but never used, yet, and as far as I know, not a containerization solution, but a solution actually
based on functional programming) are crucial to ensure that your pipeline is truly reproducible.
Basically, using Docker you turn the hidden inputs defined before (versions of tools and OS)
explicit. Take a look at this Dockerfile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FROM rocker/r-ver:4.1.0

RUN R -e &amp;quot;f &amp;lt;- function(x){if (c(TRUE, FALSE)) x};f(1)&amp;quot;

CMD [&amp;quot;R&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;here’s what happens when you build it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;➤ docker build -t my_pipeline .&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Sending build context to Docker daemon  2.048kB
Step 1/3 : FROM rocker/r-ver:4.1.0
4.1.0: Pulling from rocker/r-ver

eaead16dc43b: Already exists 
35eac095fa03: Pulling fs layer
c0088a79f8ab: Pulling fs layer
28e8d0ade0c0: Pulling fs layer
Digest: sha256:860c56970de1d37e9c376ca390617d50a127b58c56fbb807152c2e976ce02002
Status: Downloaded newer image for rocker/r-ver:4.1.0
 ---&amp;gt; d83268fb6cda
Step 2/3 : RUN R -e &amp;quot;f &amp;lt;- function(x){if (c(TRUE, FALSE)) x};f(1)&amp;quot;
 ---&amp;gt; Running in a158e4ab474f

R version 4.1.0 (2021-05-18) -- &amp;quot;Camp Pontanezen&amp;quot;
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type &amp;#39;license()&amp;#39; or &amp;#39;licence()&amp;#39; for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type &amp;#39;contributors()&amp;#39; for more information and
&amp;#39;citation()&amp;#39; on how to cite R or R packages in publications.

Type &amp;#39;demo()&amp;#39; for some demos, &amp;#39;help()&amp;#39; for on-line help, or
&amp;#39;help.start()&amp;#39; for an HTML browser interface to help.
Type &amp;#39;q()&amp;#39; to quit R.

&amp;gt; f &amp;lt;- function(x){if (c(TRUE, FALSE)) x};f(1)
[1] 1
Warning message:
In if (c(TRUE, FALSE)) x :&amp;gt; 
&amp;gt; 

  the condition has length &amp;gt; 1 and only the first element will be used
Removing intermediate container a158e4ab474f
 ---&amp;gt; 49e2eb20a535
Step 3/3 : CMD [&amp;quot;R&amp;quot;]
 ---&amp;gt; Running in ccda657c4d95
Removing intermediate container ccda657c4d95
 ---&amp;gt; 5a432adbe6ff
Successfully built 5a432adbe6ff
Successfully tagged my_package:latest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as you can read from above, this starts the container with R version 4.1.0 and runs the code
in it. We get back our result with the warning (it should be noted that in practice, you would
structure your Dockerfile differently for running an actual pipeline).&lt;/p&gt;
&lt;p&gt;This Dockerfile starts by using rocker/r-ver:4.1 as a basis. You can find this
image in the &lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.1.0.Dockerfile&#34;&gt;versioned&lt;/a&gt;
repository from the Rocker Project. This base image starts off from Ubuntu Focal Fossa
so (Ubuntu version 20.04), uses R version 4.1.0 and even uses frozen CRAN repository as
of 2021-08-09. It then runs our pipeline (or in this case, our simple function) in this, fixed
environment. Our function essentially became &lt;code&gt;f(x, os_version, r_version, packages_version)&lt;/code&gt; instead of
just &lt;code&gt;f(x)&lt;/code&gt;. By changing the first statement of the Dockerfile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FROM rocker/r-ver:4.1.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FROM rocker/r-ver:3.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we can even do some archaeology and run the pipeline on R version 3.5.0! This has great potential
and hopefully one day Docker or similar solution will become just another tool in scientists/analysts
toolbox.&lt;/p&gt;
&lt;p&gt;If you want to start using Docker for your projects, I’ve written this
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-11-19-raps/&#34;&gt;tutorial&lt;/a&gt; and even a whole
&lt;a href=&#34;https://rap4mads.eu/&#34;&gt;ebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducibility with Docker and Github Actions for the average R enjoyer</title>
      <link>https://www.brodrigues.co/blog/2022-11-19-raps/</link>
      <pubDate>Sat, 19 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-11-19-raps/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/raps.png&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This blog post is a summary of Chapters 9 and 10 of this
&lt;a href=&#34;https://rap4mads.eu/self-contained-raps-with-docker.html&#34;&gt;ebook&lt;/a&gt; I wrote for a course&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The goal is the following: we want to write a pipeline that produces some plots. We want
the code to be executed inside a Docker container for reproducibility, and we want this container
to get executed on Github Actions. Github Actions is a &lt;em&gt;Continuous Integration and Continuous Delivery&lt;/em&gt;
service from Github that allows you to execute arbitrary code on events (like pushing code to a repo).
It’s pretty neat. For example, you could be writing a paper using Latex and get the pdf compiled
on Github Actions each time you push, without needing to have to do it yourself. Or if you are developing
an R package, unit tests could get executed each time you push code, so you don’t have to do it manually.&lt;/p&gt;
&lt;p&gt;This blog post will assume that you are familiar with R and are comfortable with it, as well
as Git and Github.&lt;/p&gt;
&lt;p&gt;It will also assume that you’ve at least heard of Docker and have it already installed on your computer,
but ideally, you’ve already played a bit around with Docker.
If you’re a total Docker beginner, this tutorial might be a bit too esoteric.&lt;/p&gt;
&lt;p&gt;Let’s start by writing a pipeline that works on our machines using the &lt;code&gt;{targets}&lt;/code&gt; package.&lt;/p&gt;
&lt;div id=&#34;getting-something-working-on-your-machine&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting something working on your machine&lt;/h2&gt;
&lt;p&gt;So, let’s say that you got some nice code that you need to rerun every month, week, day, or even
hour. Or let’s say that you’re a researcher that is concerned with reproducibility.
Let’s also say that you want to make sure that this code always produces the same result
(let’s say it’s some plots that need to get remade once some data is refreshed).&lt;/p&gt;
&lt;p&gt;Ok, so first of all, you really want your workflow to be defined using the &lt;code&gt;{targets}&lt;/code&gt; package.
If you’re not familiar with &lt;code&gt;{targets}&lt;/code&gt;, this will serve as a micro introduction, but you
really should read the &lt;code&gt;{targets}&lt;/code&gt; manual, at least the
&lt;a href=&#34;https://books.ropensci.org/targets/walkthrough.html&#34;&gt;walkthrough&lt;/a&gt; (watch the 4 minute video).
&lt;code&gt;{targets}&lt;/code&gt; is a build automation tool that you should definitely add to your toolbox.&lt;/p&gt;
&lt;p&gt;Let’s define a workflow that does the following: data gets read, data gets filtered, data gets
plotted. What’s the data about? Unemployment in Luxembourg. Luxembourg is a little Western European
country that looks like a shoe and is &lt;a href=&#34;https://raw.githubusercontent.com/rbind/b-rodrigues.github.com/master/static/img/rhode_island.png&#34;&gt;about the size of .98 Rhode Islands&lt;/a&gt;
from which yours truly hails from. Did you know that Luxembourg was a monarchy, and the last
Grand-Duchy in the World? I bet you did not know that. Also, what you should know to understand the
script below is that the country of Luxembourg is divided into Cantons, and each Cantons into
Communes. Basically, if Luxembourg was the USA, Cantons would be States and Communes would be
Counties (or Parishes or Boroughs). What’s confusing is that “Luxembourg” is also the name
of a Canton, and of a Commune (which also has the status of a city).&lt;/p&gt;
&lt;p&gt;Anyways, here’s how my script looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(targets)
library(dplyr)
library(ggplot2)
source(&amp;quot;functions.R&amp;quot;)


list(
    tar_target(
        unemp_data,
        get_data()
    ),

    tar_target(
        lux_data,
        clean_unemp(unemp_data,
                    place_name_of_interest = &amp;quot;Luxembourg&amp;quot;,
                    level_of_interest = &amp;quot;Country&amp;quot;,
                    col_of_interest = active_population)
    ),

    tar_target(
        canton_data,
        clean_unemp(unemp_data,
                    level_of_interest = &amp;quot;Canton&amp;quot;,
                    col_of_interest = active_population)
    ),

    tar_target(
        commune_data,
        clean_unemp(unemp_data,
                    place_name_of_interest = c(&amp;quot;Luxembourg&amp;quot;,
                                               &amp;quot;Dippach&amp;quot;,
                                               &amp;quot;Wiltz&amp;quot;,
                                               &amp;quot;Esch/Alzette&amp;quot;,
                                               &amp;quot;Mersch&amp;quot;),
                    col_of_interest = active_population)
    ),

    tar_target(
        lux_plot,
        make_plot(lux_data)
    ),

    tar_target(
        canton_plot,
        make_plot(canton_data)
    ),

    tar_target(
        commune_plot,
        make_plot(commune_data)
    ),

    tar_target(
        luxembourg_saved_plot,
        save_plot(&amp;quot;fig/luxembourg.png&amp;quot;, lux_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        canton_saved_plot,
        save_plot(&amp;quot;fig/canton.png&amp;quot;, canton_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        commune_saved_plot,
        save_plot(&amp;quot;fig/commune.png&amp;quot;, commune_plot),
        format = &amp;quot;file&amp;quot;
    )


)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because this is a &lt;code&gt;{targets}&lt;/code&gt; script, this needs to be saved inside a file called &lt;code&gt;_targets.R&lt;/code&gt;.
Each &lt;code&gt;tar_target()&lt;/code&gt; object defines a target that will get built once we run the pipeline.
The first element of &lt;code&gt;tar_target()&lt;/code&gt; is the name of the target, the second line a call to a function
that returns the first element and in the last three targets &lt;code&gt;format = &#34;file&#34;&lt;/code&gt; is used to indicate
that this target saves an output to disk (as a file).&lt;/p&gt;
&lt;p&gt;The fourth line of the script sources a script called &lt;code&gt;functions.R&lt;/code&gt;. This script should be placed
next to the &lt;code&gt;_targets.R&lt;/code&gt; script and should look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# clean_unemp() is a function inside a package I made. Because I don&amp;#39;t want you to install
# the package if you&amp;#39;re following along, I&amp;#39;m simply sourcing it:

source(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/myPackage/main/R/functions.R&amp;quot;)

# The cleaned data is also available in that same package. But again, because I don&amp;#39;t want you
# to install a package just for a blog post, here is the script to clean it.
# Don&amp;#39;t waste time trying to understand it, it&amp;#39;s very specific to the data I&amp;#39;m using
# to illustrate the concept of reproducible analytical pipelines. Just accept this data 
# as given.

# This is a helper function to clean the data
clean_data &amp;lt;- function(x){
  x %&amp;gt;%
    janitor::clean_names() %&amp;gt;%
    mutate(level = case_when(
             grepl(&amp;quot;Grand-D.*&amp;quot;, commune) ~ &amp;quot;Country&amp;quot;,
             grepl(&amp;quot;Canton&amp;quot;, commune) ~ &amp;quot;Canton&amp;quot;,
             !grepl(&amp;quot;(Canton|Grand-D.*)&amp;quot;, commune) ~ &amp;quot;Commune&amp;quot;
           ),
           commune = ifelse(grepl(&amp;quot;Canton&amp;quot;, commune),
                            stringr::str_remove_all(commune, &amp;quot;Canton &amp;quot;),
                            commune),
           commune = ifelse(grepl(&amp;quot;Grand-D.*&amp;quot;, commune),
                            stringr::str_remove_all(commune, &amp;quot;Grand-Duche de &amp;quot;),
                            commune),
           ) %&amp;gt;%
    select(year,
           place_name = commune,
           level,
           everything())
}

# This reads in the data.
get_data &amp;lt;- function(){
  list(
    &amp;quot;https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2013.csv&amp;quot;,
    &amp;quot;https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2014.csv&amp;quot;,
    &amp;quot;https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2015.csv&amp;quot;,
    &amp;quot;https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2016.csv&amp;quot;,
  ) |&amp;gt;
    purrr::map_dfr(readr::read_csv) %&amp;gt;%
    purrr::map_dfr(clean_data)
}

# This plots the data
make_plot &amp;lt;- function(data){
  ggplot(data) +
    geom_col(
      aes(
        y = active_population,
        x = year,
        fill = place_name
      )
    ) +
    theme(legend.position = &amp;quot;bottom&amp;quot;,
          legend.title = element_blank())
}

# This saves plots to disk
save_plot &amp;lt;- function(save_path, plot){
  ggsave(save_path, plot)
  save_path
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What you could do instead of having a &lt;code&gt;functions.R&lt;/code&gt; script that you source like this, is put
everything inside a package that you then host on Github. But that’s outside the scope of this
blog post. Put these scripts inside a folder, open an R session
inside that folder, and run the pipeline using &lt;code&gt;targets::tar_make()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;targets::tar_make()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/
Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

• start target unemp_data
• built target unemp_data [1.826 seconds]
• start target canton_data
• built target canton_data [0.038 seconds]
• start target lux_data
• built target lux_data [0.034 seconds]
• start target commune_data
• built target commune_data [0.043 seconds]
• start target canton_plot
• built target canton_plot [0.007 seconds]
• start target lux_plot
• built target lux_plot [0.006 seconds]
• start target commune_plot
• built target commune_plot [0.003 seconds]
• start target canton_saved_plot
Saving 7 x 7 in image
• built target canton_saved_plot [0.425 seconds]
• start target luxembourg_saved_plot
Saving 7 x 7 in image
• built target luxembourg_saved_plot [0.285 seconds]
• start target commune_saved_plot
Saving 7 x 7 in image
• built target commune_saved_plot [0.291 seconds]
• end pipeline [3.128 seconds]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now see a &lt;code&gt;fig/&lt;/code&gt; folder in the root of your project with the plots. Sweet.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;making-sure-this-is-reproducible&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making sure this is reproducible&lt;/h2&gt;
&lt;p&gt;Now what we would like to do is make sure that this pipeline will, for the same inputs,
returns the same outputs FOREVER. If I’m running this in 10 years on R version 6.9, I want
the exact same plots back. So the idea is to actually never run this on whatever version
of R will be available in 10 years, but keep rerunning it, &lt;em&gt;ad vitam æternam&lt;/em&gt; on whatever
environment I’m using now to type this blog post. So for this, I’m going to use Docker.&lt;/p&gt;
&lt;p&gt;(If, like me, you’re an average functional programming enjoyer, then this means getting
rid of the hidden state of our pipeline. The hidden global state is
the version of R and packages used to run the pipeline.)&lt;/p&gt;
&lt;p&gt;What’s Docker? Docker is a way to run a Linux computer inside your computer (Linux or not). That
computer is not real, but real enough for our purposes. Ever heard of virtual machines? Basically
the same thing, but without the overhead of actually setting up and running a virtual machine.&lt;/p&gt;
&lt;p&gt;You can write a simple text file that defines what your machine is, and what it should run.
Thankfully, we don’t need to start from scratch and can use the amazing
&lt;a href=&#34;https://rocker-project.org/&#34;&gt;Rocker project&lt;/a&gt; that provides many, many, images for us to start
playing with Docker. What’s a Docker image? A definition of a computer/machine. Which is a text file.
Don’t ask why it’s called an image. Turns out the Rocker project has a page specifically
on &lt;a href=&#34;https://rocker-project.org/use/reproducibility.html&#34;&gt;reproducibility&lt;/a&gt;. Their advice can be
summarised as follows: if you’re aiming at setting up a reproducible pipeline, use a version-stable
image. This means that if you start from such an image, the exact same R version will always be used
to run your pipeline. Plus, the RStudio Public Package Manager (RSPM), frozen at a specific date, will
be used to fetch the packages needed for your pipeline. So, not only is the R version frozen,
but the exact same packages will always get installed (as long as the RSPM exists, hopefully for a long
time).&lt;/p&gt;
&lt;p&gt;Now, I’ve been talking about a script that defines an image for some time. This script is called
a &lt;code&gt;Dockerfile&lt;/code&gt;, and you can find the versioned &lt;code&gt;Dockerfiles&lt;/code&gt;
&lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/tree/master/dockerfiles&#34;&gt;here&lt;/a&gt;. As you can see
there are many &lt;code&gt;Dockerfile&lt;/code&gt;s, each defining a Linux machine and with several
things pre-installed. Let’s take a look at the image
&lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.2.1.Dockerfile&#34;&gt;r-ver_4.2.1.Dockerfile&lt;/a&gt;.
What’s interesting here are the following lines (let’s ignore the others):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;8 ENV R_VERSION=4.2.1

16 ENV CRAN=https://packagemanager.rstudio.com/cran/__linux__/focal/2022-10-28&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last characters of that link are a date. This means that if you use this for your project,
packages will be downloaded as they were on the October 28th, 2022, and the R version used
will always be version 4.2.1.&lt;/p&gt;
&lt;p&gt;Ok so, how do we use this?&lt;/p&gt;
&lt;p&gt;Let’s add a &lt;code&gt;Dockerfile&lt;/code&gt; to our project. Simply create a text file called &lt;code&gt;Dockerfile&lt;/code&gt; and add the
following lines in it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:4.2.1

RUN R -e &amp;quot;install.packages(c(&amp;#39;dplyr&amp;#39;, &amp;#39;purrr&amp;#39;, &amp;#39;readr&amp;#39;, &amp;#39;stringr&amp;#39;, &amp;#39;ggplot2&amp;#39;, &amp;#39;janitor&amp;#39;, &amp;#39;targets&amp;#39;))&amp;quot;

RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R

CMD R -e &amp;quot;targets::tar_make()&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before continuing, I should explain what the first line does:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:4.2.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simply means that we are using the image
&lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.2.1.Dockerfile&#34;&gt;from before&lt;/a&gt; as a base.
This image is itself based on &lt;em&gt;Ubuntu Focal&lt;/em&gt;, see its first line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM ubuntu:focal&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ubuntu is a very popular, likely the most popular, Linux distribution. So the versioned image
is built on top of Ubuntu 20.04 codenamed Focal Fossa (which is a long term support release),
and our image is built on top of that. To make sense of all this, you can take a look at the table
&lt;a href=&#34;https://github.com/rocker-org/rocker-versioned2/wiki/Versions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So now that we’ve written this &lt;code&gt;Dockerfile&lt;/code&gt;, we need to build the image. This can be done inside
a terminal with the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t my_pipeline .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tells Docker to build an image called &lt;code&gt;my_pipeline&lt;/code&gt; using the Dockerfile in the current directory
(hence the &lt;code&gt;.&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;But, here’s what happens when we try to run the pipeline (I’ll be showing the command
to run the pipeline below):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; targets::tar_make()
Error in dyn.load(file, DLLpath = DLLpath, ...) : 
  unable to load shared object &amp;#39;/usr/local/lib/R/site-library/igraph/libs/igraph.so&amp;#39;:
  libxml2.so.2: cannot open shared object file: No such file or directory
Calls: loadNamespace ... asNamespace -&amp;gt; loadNamespace -&amp;gt; library.dynam -&amp;gt; dyn.load
Execution halted&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get a nasty error message; apparently some library, &lt;code&gt;libxml2.so&lt;/code&gt; cannot be found.
So we need to change our &lt;code&gt;Dockerfile&lt;/code&gt;, and add the following lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM rocker/r-ver:4.2.1

RUN apt-get update &amp;amp;&amp;amp; apt-get install -y \
    libxml2-dev \
    libglpk-dev \
    libxt-dev

RUN R -e &amp;quot;install.packages(c(&amp;#39;dplyr&amp;#39;, &amp;#39;purrr&amp;#39;, &amp;#39;readr&amp;#39;, &amp;#39;stringr&amp;#39;, &amp;#39;ggplot2&amp;#39;, &amp;#39;janitor&amp;#39;, &amp;#39;targets&amp;#39;))&amp;quot;

RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R

CMD R -e &amp;quot;targets::tar_make()&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve added these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RUN apt-get update &amp;amp;&amp;amp; apt-get install -y \
    libxml2-dev \
    libglpk-dev \
    libxt-dev&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this runs the &lt;code&gt;apt-get update&lt;/code&gt; and &lt;code&gt;apt-get install&lt;/code&gt; commands. Aptitude is Ubuntu’s package manager
and is used to install software. The three pieces of software I installed will avoid
further issues. &lt;code&gt;libxml2-dev&lt;/code&gt; is for the error message I’ve pasted here, while the
other two avoid further error messages. One last thing before we rebuild th image:
we actually need to change the &lt;code&gt;_targets.R&lt;/code&gt; file a bit. Let’s take a look at our
&lt;code&gt;Dockerfile&lt;/code&gt; again, there’s three lines I haven’t commented:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line creates the &lt;code&gt;fig/&lt;/code&gt; folder in the &lt;code&gt;home/&lt;/code&gt; directory, and the &lt;code&gt;COPY&lt;/code&gt;
statements copy the files into the Docker image, so that they’re actually available
inside the Docker. I also need to tell &lt;code&gt;_targets&lt;/code&gt; to save the figures into the
&lt;code&gt;home/fig&lt;/code&gt; folder. So simply change the last three targets from this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tar_target(
        luxembourg_saved_plot,
        save_plot(&amp;quot;fig/luxembourg.png&amp;quot;, lux_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        canton_saved_plot,
        save_plot(&amp;quot;fig/canton.png&amp;quot;, canton_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        commune_saved_plot,
        save_plot(&amp;quot;fig/commune.png&amp;quot;, commune_plot),
        format = &amp;quot;file&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tar_target(
        luxembourg_saved_plot,
        save_plot(&amp;quot;/home/fig/luxembourg.png&amp;quot;, lux_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        canton_saved_plot,
        save_plot(&amp;quot;/home/fig/canton.png&amp;quot;, canton_plot),
        format = &amp;quot;file&amp;quot;
    ),

    tar_target(
        commune_saved_plot,
        save_plot(&amp;quot;/home/fig/commune.png&amp;quot;, commune_plot),
        format = &amp;quot;file&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so now we’re ready to rebuild the image:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker build -t my_pipeline .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and we can now run it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm --name my_pipeline_container -v /path/to/fig:/home/fig my_pipeline&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt; runs a container based on the image you defined. &lt;code&gt;--rm&lt;/code&gt; means that the container
should be removed once it stops, &lt;code&gt;--name&lt;/code&gt; gives it a name, here &lt;code&gt;my_pipeline_container&lt;/code&gt; (this is
not really needed here, because the container stops and gets removed once it’s done running), and
&lt;code&gt;-v&lt;/code&gt; mounts a volume, which is a fancy way of saying that the folder &lt;code&gt;/path/to/fig/&lt;/code&gt;, which is a
real folder on your computer, is a portal to the folder &lt;code&gt;/home/fig/&lt;/code&gt; (which we created in the
&lt;code&gt;Dockerfile&lt;/code&gt;). This means that whatever gets saved inside &lt;code&gt;home/fig/&lt;/code&gt; inside the Docker container
gets also saved inside &lt;code&gt;/path/to/fig&lt;/code&gt; on your computer. The last argument &lt;code&gt;my_pipeline&lt;/code&gt; is simply
the Docker image you built before. You should see the three plots magically appearing in
&lt;code&gt;/path/to/fig&lt;/code&gt; once the container is done running. The other neat thing is that you can upload this
image to Docker Hub, for free (to know how to do this, check out this
&lt;a href=&#34;https://rap4mads.eu/self-contained-raps-with-docker.html#building-a-truly-reproducible-pipeline&#34;&gt;section&lt;/a&gt;
of the course I teach on this). This way, if other people want to run it, they could do so by
running the same command as above, but replacing &lt;code&gt;my_pipeline&lt;/code&gt; by
&lt;code&gt;your_username_on_docker_hub/image_name_on_docker_hub&lt;/code&gt;. People could even create new images based
on this image, by using &lt;code&gt;FROM your_username_on_docker_hub/image_name_on_docker_hub&lt;/code&gt; at the
beginning of their &lt;code&gt;Dockerfile&lt;/code&gt;s. If you want an example of a pipeline that starts off from such an
image, you can check out this
&lt;a href=&#34;https://github.com/b-rodrigues/dockerized_pipeline_demo/tree/main&#34;&gt;repository&lt;/a&gt;. This repository
tells you how can run a reproducible pipeline by simply cloning it, building the image (which only
takes a few seconds because all software is already installed in the image that I start from) and
then running it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-this-on-github-actions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Running this on Github Actions&lt;/h2&gt;
&lt;p&gt;Ok, so now, let’s suppose that we got an image on Docker Hub that contains all the dependencies
required for our pipeline, and let’s say that we create a Github repository containing a
&lt;code&gt;Dockerfile&lt;/code&gt; that pulls from this image, as well as the required scripts for our pipeline.
Basically, this is what I did &lt;a href=&#34;https://github.com/b-rodrigues/dockerized_pipeline_demo/tree/main&#34;&gt;here&lt;/a&gt;
(the same repository that I linked above already). If you take a look at the first line of the
&lt;code&gt;Dockerfile&lt;/code&gt; in it, you will see this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM brodriguesco/r421_rap:version1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that the image that gets built from this &lt;code&gt;Dockerfile&lt;/code&gt; starts off from &lt;a href=&#34;https://hub.docker.com/layers/brodriguesco/r421_rap/version1/images/sha256-9b8cdaaaf14828468f6c3136c6e2916d3a6efe9c654a97a2a0d12d5d9e5b9ccc?context=repo&#34;&gt;this image
I’ve uploaded on Docker
Hub&lt;/a&gt;, this way each time the image gets rebuilt,
because the dependencies are already installed, it’s going to be fast.
Ok, so now what I want is the following: each time I change a file, be it the &lt;code&gt;Dockerfile&lt;/code&gt;, or the
&lt;code&gt;_targets.R&lt;/code&gt; script, commit my changes and push them, I want Github Actions to rebuild the image,
run the container, and give me the plots back.&lt;/p&gt;
&lt;p&gt;This means that I can focus on coding, Github Actions will take care of the boring stuff.&lt;/p&gt;
&lt;p&gt;To do this, start by creating a &lt;code&gt;.github/&lt;/code&gt; directory on the root of your Github repo, and
inside of it, add a &lt;code&gt;.workflows&lt;/code&gt; directory, and add a file in it called something like
&lt;code&gt;docker-build-run.yml&lt;/code&gt;. What matters is that this file ends in &lt;code&gt;.yml&lt;/code&gt;. This is what the
file I use to define the actions I’ve described above looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: Docker Image CI

on:
  push:
    branches: [ &amp;quot;main&amp;quot; ]
  pull_request:
    branches: [ &amp;quot;main&amp;quot; ]

jobs:

  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Build the Docker image
      run: docker build -t my-image-name .
    - name: Docker Run Action
      run: docker run --rm --name my_pipeline_container -v /github/workspace/fig/:/home/graphs/:rw my-image-name
    - uses: actions/upload-artifact@v3
      with:
        name: my-figures
        path: /github/workspace/fig/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line defines the name of the job, here &lt;code&gt;Docker Image CI&lt;/code&gt;.
The lines state when this should get executed: whenever there’s a push on or pull request on &lt;code&gt;main&lt;/code&gt;.
The job itself runs on an Ubuntu VM (so Github Actions starts an Ubuntu VM that will pull a Docker
image itself running Ubuntu…).
Then, there’s the &lt;code&gt;steps&lt;/code&gt; statement. For now, let’s focus on the &lt;code&gt;run&lt;/code&gt; statements inside &lt;code&gt;steps&lt;/code&gt;,
because these should be familiar:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;run: docker build -t my-image-name .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;run: docker run --rm --name my_pipeline_container -v /github/workspace/fig/:/home/graphs/:rw my-image-name&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only new thing here, is that the path “on our machine” has been changed to &lt;code&gt;/github/workspace/&lt;/code&gt;.
This is the home directory of your repository, so to speak. Now there’s the &lt;code&gt;uses&lt;/code&gt; keyword that’s new:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uses: actions/checkout@v3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This action checkouts your repository inside the VM, so the files in the repo are available inside the VM.
Then, there’s this action here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- uses: actions/upload-artifact@v3
  with:
    name: my-figures
    path: /github/workspace/fig/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This action takes what’s inside &lt;code&gt;/github/workspace/fig/&lt;/code&gt; (which will be the output of our pipeline)
and makes the contents available as so-called “artifacts”. Artifacts are the outputs of your
workflow, and will be made available as &lt;code&gt;zip&lt;/code&gt; files for download.
In our case, as stated, the output of the pipeline.
It is thus possible to rerun our workflow in the cloud. This has the
advantage that we can now focus on simply changing the code, and not have to bother with
useless manual steps. For example, let’s change this target in the &lt;code&gt;_targets.R&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tar_target(
    commune_data,
    clean_unemp(unemp_data,
                place_name_of_interest = c(&amp;quot;Luxembourg&amp;quot;, &amp;quot;Dippach&amp;quot;, 
                                           &amp;quot;Wiltz&amp;quot;, &amp;quot;Esch/Alzette&amp;quot;, 
                                           &amp;quot;Mersch&amp;quot;, &amp;quot;Dudelange&amp;quot;),
                col_of_interest = active_population)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve added “Dudelange” to the list of communes to plot. Let me push this change to the repo now,
and let’s take a look at the artifacts. The video below summarises the process:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/ga_3.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As you can see in the video, the &lt;code&gt;_targets.R&lt;/code&gt; script was changed, and the changes pushed to Github.
This triggered the action we’ve defined before. The plots (artifacts) get refreshed, and we can
download them. We see then that Dudelange was added in the &lt;code&gt;communes.png&lt;/code&gt; plot!&lt;/p&gt;
&lt;p&gt;If you enjoyed this blog post and want more of this, I wrote a whole &lt;a href=&#34;https://rap4mads.eu/&#34;&gt;ebook on it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Open source is a hard requirement for reproducibility</title>
      <link>https://www.brodrigues.co/blog/2022-11-16-open_source_repro/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-11-16-open_source_repro/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/tux_tired_of_reproducibility_crisis.png&#34; title = &#34;Tux is tired of the reproducibility crisis&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Open source is a hard requirement for reproducibility.&lt;/p&gt;
&lt;p&gt;No ifs nor buts. And I’m not only talking about the code you typed for your research
paper/report/analysis. I’m talking about the whole ecosystem that you used to type your code.&lt;/p&gt;
&lt;p&gt;(I won’t be talking about making the data available, because I think this is another blog post on its own.)&lt;/p&gt;
&lt;p&gt;Is your code open? That’s good. But is it code for a proprietary program, like STATA, SAS or
MATLAB? Then your project is not reproducible. It doesn’t matter if this code is well documented
and written and available on Github. This project is not reproducible.&lt;/p&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;Because there is on way to re-execute your code with the exact same version of this proprietary
program down the line. As I’m writing these lines, MATLAB, for example, is at version R2022b. And
it is very unlikely that you can buy version, say, R2008a. Maybe you can. Maybe MATLAB offers this
option. But maybe they don’t. And maybe if they do today, they won’t in the future. There’s no
guarantee. And if you’re running old code written for version R2008a, there’s no guarantee that it
will produce the exact same results on version 2022b. And let’s not even mention the toolboxes (if
you’re not familiar with MATLAB’s toolboxes, they’re the equivalent of packages or libraries in
other programming languages). These evolve as well, and there’s no guarantee that you can purchase
older versions of said toolboxes. And also, is a project truly reproducible (even if old programs
can be purchased) if it’s behind a paywall?&lt;/p&gt;
&lt;p&gt;And let me be clear, what I’m describing here with MATLAB could also be said for any other
proprietary programs still commonly (unfortunately) used in research and in statistics (like STATA
or SAS).&lt;/p&gt;
&lt;p&gt;Then there’s another problem: let’s suppose you’ve written a nice, thoroughly tested and documented
script, and made it available on Github (and let’s even assume that the data is available for
people to freely download, and that the paper is open access). Let’s assume further that you’ve
used R or Python, or any other open source programming language. Could this study/analysis be said to be
reproducible? Well, if the analysis ran on a proprietary operating system, then the conclusion is:
your project is not reproducible.&lt;/p&gt;
&lt;p&gt;This is because the operating system the code runs on can also influence the reproducibility of the
project. There are some specificities in operating systems that may make certain things work
differently. Admittedly, this is in practice rarely a problem, but
&lt;a href=&#34;https://github.com/numpy/numpy/issues/9187&#34;&gt;it does happen&lt;/a&gt;, especially if you’re working with very high
precision floating point arithmetic.&lt;/p&gt;
&lt;p&gt;So where does that leave us? Basically, for something to be truly reproducible, it has to respect
the following bullet points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source code must obviously to be available and thoroughly tested and document;&lt;/li&gt;
&lt;li&gt;To be written with an open source programming language (nocode tools are by default non-reproducible and belong in the trash);&lt;/li&gt;
&lt;li&gt;The project needs to be run on an open source operating system.&lt;/li&gt;
&lt;li&gt;(Data and paper need obviously to be accessible as well)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the whole thing would ideally be packaged using Docker or Podman. This means that someone could
run an analysis in a single command, like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run --rm --name my_analysis_container researchers_name/reproducible_project&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;code&gt;reproducible_project&lt;/code&gt; is a Docker image, which would not only be based (very often) on the
Ubuntu operating system (the most popular Linux distribution) but also contain, already installed
and ready-to-use, the required programming language and the required libraries to run the project.
Also, usually, the researcher would have added the required scripts and commands such that the
command above, automatically, and without any further input, reruns the whole analysis. The entry
cost to Docker (or similar tools) might seem high, but it is worth it, and the only way to have a
truly 100% reproducible pipeline. If you’re using the R programming language for your analyses, you
can use the pre-built Docker images from the amazing &lt;a href=&#34;https://rocker-project.org/&#34;&gt;Rocker project&lt;/a&gt;.
If you’re interested, I show how you can build a reproducible pipeline using these images &lt;a href=&#34;https://rap4mads.eu/self-contained-raps-with-docker.html&#34;&gt;in this
chapter of my course I teach at university&lt;/a&gt;
(as of writing this blog post, this chapter is not complete yet, but it will be by Sunday evening
at the latest, as I have to teach this on Monday morning at the University).&lt;/p&gt;
&lt;p&gt;Open source programming languages and libraries can be dockerized and the Docker images can be
distributed. Maybe one day we will always have a Docker image alongside a research paper.&lt;/p&gt;
&lt;p&gt;One can dream.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to deal with annoying medium sized data inside a Shiny app</title>
      <link>https://www.brodrigues.co/blog/2022-10-31-optim_shiny/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-10-31-optim_shiny/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/deja_vu.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This blog post is taken from a chapter of my ebook on building reproducible analytical pipelines, which you can
read &lt;a href=&#34;https://rap4mads.eu&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you want to follow along, you can start by downloading the data I use
&lt;a href=&#34;https://mega.nz/file/l1IxHYIT#mZkeQOVpMc9XymMNtDY687sHEZHoIvDcUOm-4AwK6OI&#34;&gt;here&lt;/a&gt;.
This is a smaller dataset made from the one you can get
&lt;a href=&#34;https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HG7NV7&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Uncompressed it’ll be a 2.4GB file. Not big data in any sense, but big enough to be annoying to
handle without the use of some optimization strategies (I’ve seen such data described as medium
sized data before.).&lt;/p&gt;
&lt;p&gt;One such strategy is only letting the computations run once the user gives the green light by
clicking on an action button. The next obvious strategy is to use packages that are optimized for
speed. It turns out that the functions we have seen until now (note from the author: &lt;em&gt;the functions
we have seen until now&lt;/em&gt; if you’re on of my students that’s sitting in the course where I teach
this), from packages like &lt;code&gt;{dplyr}&lt;/code&gt; and the like, are not the fastest. Their ease of use and
expressiveness come at a speed cost. So we will need to switch to something faster. We will do the
same to read in the data.&lt;/p&gt;
&lt;p&gt;This faster solution is the &lt;code&gt;{arrow}&lt;/code&gt; package, which is an interface to the
&lt;a href=&#34;https://arrow.apache.org/faq/&#34;&gt;Arrow software developed by Apache&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The final strategy is to enable caching in the app.&lt;/p&gt;
&lt;p&gt;So first, install the &lt;code&gt;{arrow}&lt;/code&gt; package by running &lt;code&gt;install.packages(&#34;arrow&#34;)&lt;/code&gt;. This will compile
&lt;code&gt;libarrow&lt;/code&gt; from source on Linux and might take some time, so perhaps go grab a coffee. On other
operating systems, I guess that a binary version gets installed.&lt;/p&gt;
&lt;p&gt;Before building the app, let me perform a very simple benchmark. The script below reads in the data,
then performs some aggregations. This is done using standard &lt;code&gt;{tidyverse}&lt;/code&gt; functions, but also
using &lt;code&gt;{arrow}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start_tidy &amp;lt;- Sys.time()
  # {vroom} is able to read in larger files than {readr}
  # I could not get this file into R using readr::read_csv
  # my RAM would get maxed out
  air &amp;lt;- vroom::vroom(&amp;quot;data/combined&amp;quot;)

  mean_dep_delay &amp;lt;- air |&amp;gt;
    dplyr::group_by(Year, Month, DayofMonth) |&amp;gt;
    dplyr::summarise(mean_delay = mean(DepDelay, na.rm = TRUE))
end_tidy &amp;lt;- Sys.time()

time_tidy &amp;lt;- end_tidy - start_tidy


start_arrow &amp;lt;- Sys.time()
  air &amp;lt;- arrow::open_dataset(&amp;quot;data/combined&amp;quot;, format = &amp;quot;csv&amp;quot;)

  mean_dep_delay &amp;lt;- air |&amp;gt;
    dplyr::group_by(Year, Month, DayofMonth) |&amp;gt;
    dplyr::summarise(mean_delay = mean(DepDelay, na.rm = TRUE))
end_arrow &amp;lt;- Sys.time()

end_tidy - start_tidy
end_arrow - start_arrow&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The “tidy” approach took 17 seconds, while the arrow approach took 6 seconds. This is an impressive
improvement, but put yourself in the shoes of a user who has to wait 6 seconds for each query. That
would get very annoying, very quickly. So the other strategy that we will use is to provide some visual
cue that computations are running, and then we will go one step further and use caching of results
in the Shiny app.&lt;/p&gt;
&lt;p&gt;But before we continue, you may be confused by the code above. After all, I told you before that
functions from &lt;code&gt;{dplyr}&lt;/code&gt; and the like were not the fastest, and yet, I am using them in the arrow
approach as well, and they now run almost 3 times as fast. What’s going on? What’s happening here,
is that the &lt;code&gt;air&lt;/code&gt; object that we read using &lt;code&gt;arrow::open_dataset&lt;/code&gt; is not a dataframe, but an &lt;code&gt;arrow&lt;/code&gt;
dataset. These are special, and work in a different way. But that’s not what’s important: what’s important
is that the &lt;code&gt;{dplyr}&lt;/code&gt; api can be used to work with these &lt;code&gt;arrow&lt;/code&gt; datasets. This means that functions
from &lt;code&gt;{dplyr}&lt;/code&gt; change the way they work depending on the type of the object their dealing with.
If it’s a good old regular data frame, some C++ code gets called to perform the computations. If it’s
an &lt;code&gt;arrow&lt;/code&gt; dataset, &lt;code&gt;libarrow&lt;/code&gt; and its black magic get called instead to perform the computations.
If you’re familiar with the concept of
&lt;a href=&#34;https://en.wikipedia.org/wiki/Polymorphism_(computer_science)&#34;&gt;polymorphism&lt;/a&gt; this is it
(think of &lt;code&gt;+&lt;/code&gt; in Python: &lt;code&gt;1+1&lt;/code&gt; returns &lt;code&gt;2&lt;/code&gt;, &lt;code&gt;&#34;a&#34;+&#34;b&#34;&lt;/code&gt; returns &lt;code&gt;&#34;a+b&#34;&lt;/code&gt;. A different computation
gets performed depending on the type of the function’s inputs).&lt;/p&gt;
&lt;p&gt;Let’s now build a basic version of the app, only
using &lt;code&gt;{arrow}&lt;/code&gt; functions for speed. This is the global file:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(arrow)
library(dplyr)
library(rlang)
library(DT)

air &amp;lt;- arrow::open_dataset(&amp;quot;data/combined&amp;quot;, format = &amp;quot;csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ui will be quite simple:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ui &amp;lt;- function(request){
  fluidPage(

    titlePanel(&amp;quot;Air On Time data&amp;quot;),

    sidebarLayout(

      sidebarPanel(
        selectizeInput(&amp;quot;group_by_selected&amp;quot;, &amp;quot;Variables to group by:&amp;quot;,
                       choices = c(&amp;quot;Year&amp;quot;, &amp;quot;Month&amp;quot;, &amp;quot;DayofMonth&amp;quot;, &amp;quot;Origin&amp;quot;, &amp;quot;Dest&amp;quot;),
                       multiple = TRUE,
                       selected = c(&amp;quot;Year&amp;quot;, &amp;quot;Month&amp;quot;),
                       options = list(
                         plugins = list(&amp;quot;remove_button&amp;quot;),
                         create = TRUE,
                         persist = FALSE # keep created choices in dropdown
                       )
                       ),
        hr(),
        selectizeInput(&amp;quot;var_to_average&amp;quot;, &amp;quot;Select variable to average by groups:&amp;quot;,
                       choices = c(&amp;quot;ArrDelay&amp;quot;, &amp;quot;DepDelay&amp;quot;, &amp;quot;Distance&amp;quot;),
                       multiple = FALSE,
                       selected = &amp;quot;DepDelay&amp;quot;,
                       ),
        hr(),
        actionButton(inputId = &amp;quot;run_aggregation&amp;quot;,
                     label = &amp;quot;Click here to run aggregation&amp;quot;),
        hr(),
        bookmarkButton()
      ),

      mainPanel(
        DTOutput(&amp;quot;result&amp;quot;)
      )
    )
  )

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And finally the server:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;server &amp;lt;- function(session, input, output) {

  # Numbers get crunched only when the user clicks on the action button
  grouped_data &amp;lt;- eventReactive(input$run_aggregation, {
    air %&amp;gt;%
      group_by(!!!syms(input$group_by_selected)) %&amp;gt;%
      summarise(result = mean(!!sym(input$var_to_average),
                              na.rm = TRUE)) %&amp;gt;%
      as.data.frame()
  })

  output$result &amp;lt;- renderDT({
    grouped_data()
  })

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;mean()&lt;/code&gt; expect bare variable names, I convert them from strings to
symbols using &lt;code&gt;rlang::syms()&lt;/code&gt; and &lt;code&gt;rlang::sym()&lt;/code&gt;. The difference between the two is that
&lt;code&gt;rlang::syms()&lt;/code&gt; is required when a list of strings gets passed down to the function (remember
that the user must select several variables to group by), and this is also why &lt;code&gt;!!!&lt;/code&gt; are needed
(to unquote the list of symbols). Finally, the computed data must be converted back to a
data frame using &lt;code&gt;as.data.frame()&lt;/code&gt;. This is actually when the computations happen. &lt;code&gt;{arrow}&lt;/code&gt; collects
all the aggregations but does not perform anything until absolutely required. Let’s see the app
in action:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/shiny_3.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, in terms of User Experience (UX) this is quite poor. When the user clicks on the button
nothing seems to be going on for several seconds, until the table appears. Then, when the user
changes some options and clicks again on the action button, it looks like the app is crashing.&lt;/p&gt;
&lt;p&gt;Let’s add some visual cues to indicate to the user that something is happening when the button gets
clicked. For this, we are going to use the &lt;code&gt;{shinycssloaders}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;shinycssloaders&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and simply change the ui to this (and don’t forget to load &lt;code&gt;{shinycssloaders}&lt;/code&gt; in the global script!):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ui &amp;lt;- function(request){
  fluidPage(

    titlePanel(&amp;quot;Air On Time data&amp;quot;),

    sidebarLayout(

      sidebarPanel(
        selectizeInput(&amp;quot;group_by_selected&amp;quot;, &amp;quot;Variables to group by:&amp;quot;,
                       choices = c(&amp;quot;Year&amp;quot;, &amp;quot;Month&amp;quot;, &amp;quot;DayofMonth&amp;quot;, &amp;quot;Origin&amp;quot;, &amp;quot;Dest&amp;quot;),
                       multiple = TRUE,
                       selected = c(&amp;quot;Year&amp;quot;, &amp;quot;Month&amp;quot;),
                       options = list(
                         plugins = list(&amp;quot;remove_button&amp;quot;),
                         create = TRUE,
                         persist = FALSE # keep created choices in dropdown
                       )
                       ),
        hr(),
        selectizeInput(&amp;quot;var_to_average&amp;quot;, &amp;quot;Select variable to average by groups:&amp;quot;,
                       choices = c(&amp;quot;ArrDelay&amp;quot;, &amp;quot;DepDelay&amp;quot;, &amp;quot;Distance&amp;quot;),
                       multiple = FALSE,
                       selected = &amp;quot;DepDelay&amp;quot;,
                       ),
        hr(),
        actionButton(inputId = &amp;quot;run_aggregation&amp;quot;,
                     label = &amp;quot;Click here to run aggregation&amp;quot;),
        hr(),
        bookmarkButton()
      ),

      mainPanel(
        # We add a tabsetPanel with two tabs. The first tab show the plot made using ggplot
        # the second tab shows the plot using g2r
        DTOutput(&amp;quot;result&amp;quot;) |&amp;gt;
          withSpinner()
      )
    )
  )

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only difference with before is that now the &lt;code&gt;DTOutput()&lt;/code&gt; right at the end gets passed down
to &lt;code&gt;withSpinner()&lt;/code&gt;. There are several spinners that you can choose, but let’s simply use the
default one. This is how the app looks now:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/shiny_4.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Now the user gets a visual cue that something is happening. This makes waiting more bearable,
but even better than waiting with a spinner is no waiting at all. For this, we are going to enable caching
of results. There are several ways that you can cache results inside your app. You can enable
the cache on a per-user and per-session basis, or only on a per-user basis. But I think that
in our case here, the ideal caching strategy is to keep the cache persistent, and available
across sessions. This means that each computation done by any user will get cached and available
to any other user. In order to achieve this, you simply have to install the &lt;code&gt;{cachem}&lt;/code&gt; packages
add the following lines to the global script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shinyOptions(cache = cachem::cache_disk(&amp;quot;./app-cache&amp;quot;,
                                        max_age = Inf))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By setting the &lt;code&gt;max_age&lt;/code&gt; argument to &lt;code&gt;Inf&lt;/code&gt;, the cache will never get pruned. The maximum size
of the cache, by default is 1GB. You can of course increase it.&lt;/p&gt;
&lt;p&gt;Now, you must also edit the server file like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;server &amp;lt;- function(session, input, output) {

  # Numbers get crunched only when the user clicks on the action button
  grouped_data &amp;lt;- reactive({
    air %&amp;gt;%
      group_by(!!!syms(input$group_by_selected)) %&amp;gt;%
      summarise(result = mean(!!sym(input$var_to_average),
                              na.rm = TRUE)) %&amp;gt;%
      as.data.frame()
  }) %&amp;gt;%
    bindCache(input$group_by_selected,
              input$var_to_average) %&amp;gt;%
    bindEvent(input$run_aggregation)

  output$result &amp;lt;- renderDT({
    grouped_data()
  })

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve had to change &lt;code&gt;eventReactive()&lt;/code&gt; to &lt;code&gt;reactive()&lt;/code&gt;, just like in the app where we don’t use an
action button to run computations (note of the author: in the ebook, there is an example of an app
with this action button. This is what I’m referring to here). Then, we pass the reactive object to
&lt;code&gt;bindCache()&lt;/code&gt;. &lt;code&gt;bindCache()&lt;/code&gt; also takes the &lt;code&gt;inputs&lt;/code&gt; as arguments. These are used to generate cache
keys to retrieve the correct objects from cache. Finally, we pass all this to &lt;code&gt;bindEvent()&lt;/code&gt;. This
function takes the input referencing the action button. This is how we can now bind the
computations to the button once again. Let’s test our app now. You will notice that the first time
we choose certain options, the computations will take time, as before. But if we perform the same
computations again, then the results will be shown instantly:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/shiny_5.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, once I go back to a computation that was done in the past, the table appears
instantly. At the end of the video I open a terminal and navigate to the directory of the app,
and show you the cache. There are several &lt;code&gt;.Rds&lt;/code&gt; objects, these are the final data frames that
get computed by the app. If the user wants to rerun a previous computation, the correct data frame
gets retrieved, making it look like the computation happened instantly, and with another added
benefit: as discussed above, the cache is persistent between sessions, so even if the user
closes the browser and comes back later, the cache is still there, and other users will also
benefit from the cache.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Linux Live USB as a statistical programming dev environment</title>
      <link>https://www.brodrigues.co/blog/2022-10-29-mkusb_minp/</link>
      <pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-10-29-mkusb_minp/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;video width=&#34;640&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/tux_usb_ubuntu_startup.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This blog post is divided in two parts: in the first part I’ll show you how
to create a Linux Live USB with persistent storage that can be used as
development environment, and in the second part I’ll show you the easiest
way to set up RStudio and R in Ubuntu.&lt;/p&gt;
&lt;div id=&#34;making-your-own-portable-development-environment-based-on-ubuntu-or-debian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making your own, portable, development environment based on Ubuntu or Debian&lt;/h2&gt;
&lt;p&gt;I’m currently teaching a course at the University of Luxembourg, which
focuses on setting up reproducible analytical pipelines (if you’re
interested, you can find the course notes &lt;a href=&#34;https://rap4mads.eu/&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The problem is that my work laptop runs Windows, and I didn’t want to teach
on Windows since I make heavy use of the command line. Plus I don’t have
admin rights on this machine, so installing what I needed would have been a pain.
I also don’t have a personal laptop, so I use my wife’s laptop. However, the
laptop is completely full of pictures of our kids, so I couldn’t install what I needed…
This is when I thought about making a persistent live USB with Kubuntu on it
(Kubuntu is a variant of Ubuntu with KDE as the desktop manager instead of Gnome)
with all the software I needed (R, Quarto, RStudio basically). It works quite well, and
was also quite easy to do. But what is a live USB anyways?
A live USB is a full Linux installation on a USB stick, that you can use to test
different Linux distributions or even to install said distribution on computers.&lt;/p&gt;
&lt;p&gt;The first step is to get a USB stick. Those are quite cheap nowadays, but you’ll
need at least one with 8GB of space, and ideally USB 3 (you probably can’t find
any USB 2 these days anyways). I’ve bought a 32GB one for 10€.&lt;/p&gt;
&lt;p&gt;Then, we need to install Ubuntu on it. I’ll be using Kubuntu 22.04, which is an LTS
release. I would always recommend an LTS release for something like crafting
a development environment. So if you’re reading this in the future, and there’s a new
LTS (could be 24.04, 26.04, etc), you’d need to get that one.&lt;/p&gt;
&lt;p&gt;Creating a live USB is quite simple, but the issue if you create a live USB using the standard
methods is that whatever you do on it once you’re logged in will get erased after rebooting. A
persistent live USB, I’m sure you’ve guessed it, keeps your changes even after rebooting, which
means that you basically end up with a portable development environment. Note however that only
Ubuntu (and variants) or Debian can be used to create persistent live USBs.&lt;/p&gt;
&lt;p&gt;You can create persistent live USB from another Linux distro, Windows or macOS.&lt;/p&gt;
&lt;p&gt;If you’re already running Ubuntu on your pc, you might want to take a look at &lt;a href=&#34;https://help.ubuntu.com/community/mkusb#Persistent_live_systems&#34;&gt;this
page&lt;/a&gt;. You’ll need to install a
tool called &lt;code&gt;mkusb&lt;/code&gt;. If you’re not running Ubuntu, but find this tool in your distribution’s
package manager, I guess you’re good to go as well. In my case, I’m running opensuse tumbleweed,
and could not find this program in the opensuse’s repositories. So I’ve used this
&lt;a href=&#34;https://help.ubuntu.com/community/mkusb/minp&#34;&gt;guide&lt;/a&gt; that shows how to achieve the same thing
using a very simple to use shell script which you can get
&lt;a href=&#34;https://help.ubuntu.com/community/mkusb/minp?action=AttachFile&amp;amp;do=view&amp;amp;target=mkusb-minp&#34;&gt;here&lt;/a&gt;
called &lt;code&gt;mkusb-minp&lt;/code&gt;. So in my case, I simply
had to stick the USB stick in my computer, find out where it was mounted by running &lt;code&gt;df&lt;/code&gt; in bash
(in my case it was in &lt;code&gt;/dev/sdd&lt;/code&gt;), download Kubuntu’s iso image and run the following in my
terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo ./mkusb-minp -p kubuntu-22.04.1-desktop-amd64.iso /dev/sdX&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(&lt;code&gt;/dev/sdX&lt;/code&gt;: replace the X by the right letter, for me it was &lt;code&gt;/dev/sdd&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;If you’re using Windows, you can install &lt;a href=&#34;https://rufus.ie/en/#&#34;&gt;Rufus&lt;/a&gt; to create
a persistent live USB.&lt;/p&gt;
&lt;p&gt;It would seem that for macOS the process is a bit more involved, but I’ve found this
&lt;a href=&#34;https://sebay.github.io/posts/create-live-persistent-ubuntu-usb-on-mac/&#34;&gt;blog post&lt;/a&gt;
that explains the process.&lt;/p&gt;
&lt;p&gt;Once the process is finished, you can boot into your live USB key. For this, you might
need to press &lt;code&gt;delete&lt;/code&gt; or &lt;code&gt;F2&lt;/code&gt; when your computer starts booting to access the
&lt;a href=&#34;https://www.computerhope.com/jargon/b/boot_menu.htm&#34;&gt;boot menu&lt;/a&gt;.
You can then choose to boot from your USB device.&lt;/p&gt;
&lt;p&gt;Wait a bit and at some point you should see a prompt asking you if you want to
try or install Ubuntu. Choose &lt;code&gt;Try Ubuntu&lt;/code&gt;:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/try_ubuntu.png&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And then wait some minutes. Yes booting takes some time because you’re loading an entire
operating system from a USB stick (hence why it’s a good idea to go with a USB 3 stick).
After some time you should see a new window:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/try_ubuntu2.png&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once again, try Ubuntu, wait a bit, and that’s it you’re inside your dev environment!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-r-and-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setting up R and RStudio&lt;/h2&gt;
&lt;p&gt;Now that you’re inside your dev environment, you actually need to start adding some
tools. Let’s start by adding R. The easiest way that I found is to use the
&lt;a href=&#34;https://eddelbuettel.github.io/r2u/&#34;&gt;r2u project&lt;/a&gt; by
&lt;a href=&#34;https://github.com/eddelbuettel&#34;&gt;Dirk Eddelbuettel&lt;/a&gt;. If you’re on Ubuntu 22.04,
run &lt;a href=&#34;https://github.com/eddelbuettel/r2u/blob/master/inst/scripts/add_cranapt_jammy.sh&#34;&gt;this script&lt;/a&gt;,
as explained in the tutorial. This will add the required repositories that will install
binary versions of R packages in mere seconds. The script will also
add a repository to install the most recent version of R, so once the script is done running,
install R and the &lt;code&gt;{tidyverse}&lt;/code&gt; (or any other package) with the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install --no-install-recommends r-base r-cran-tidyverse&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then install other packages from R using &lt;code&gt;install.packages(&#34;package_name&#34;)&lt;/code&gt; as usual,
and this will also make use of the &lt;code&gt;r2u&lt;/code&gt; repositories.&lt;/p&gt;
&lt;p&gt;All that’s missing now is RStudio (if you use RStudio). Surprisingly, when I set up my live USB
two weeks ago, the current version of RStudio for Ubuntu would not install. This is apparently
fixed with the daily versions which you can get &lt;a href=&#34;https://dailies.rstudio.com/&#34;&gt;here&lt;/a&gt;. But
before that, do try to install the stable version. If you’re reading this sometime in the future,
maybe the issue I encountered has been fixed. Download RStudio from
&lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/#download&#34;&gt;here&lt;/a&gt;, and then double click on the
downloaded &lt;code&gt;.deb&lt;/code&gt; package. If you see this message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The following packages have unmet dependencies:
 rstudio : Depends: libssl1.0.0 but it is not installable or
                    libssl1.0.2 but it is not installable or
                    libssl1.1 but it is not installable
           Recommends: r-base (&amp;gt;= 3.0.1) but it is not going to be installed
E: Unable to correct problems, you have held broken packages.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then this means that the problem has not been fixed. In that case, run the following line to
repair everything:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update --fix-missing&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should put you back into a clean state. So to continue, install a daily build from the link above.
Simply click on the Ubuntu 22 button to download the daily. Unfortunately daily builds can be unstable
and are usually used for testing purposes. So hopefully Posit will fix this soon.&lt;/p&gt;
&lt;p&gt;Of course, if you’re using the
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-05-19-spacemacs/&#34;&gt;greatest IDE ever made&lt;/a&gt; instead of RStudio,
you won’t have this issue.&lt;/p&gt;
&lt;p&gt;You can now keep installing things, for example &lt;a href=&#34;https://quarto.org/docs/get-started/&#34;&gt;Quarto&lt;/a&gt;, or
Python, or, or, or… there are no limits, and performance, as you would have noticed is great, because
the operating system has access to all the resources from your machine. A persistent live USB is a
great solution if you need a portable dev environment and don’t want/can’t use Docker for example.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://fosstodon.org/@brodriguesco&#34;&gt;Mastodon&lt;/a&gt; or &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R, its license and my take on it</title>
      <link>https://www.brodrigues.co/blog/2022-10-23-licenses/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-10-23-licenses/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/free_software.png&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Foreword: This is not a tutorial nor anything like that. I’m going to talk about free software,
open source, and their licenses. I’m going to give my (non-)expert opinion on it. You may find,
after having finished reading this post, that I wasted your time. So only read if by some miracle
the first sentence of the foreword excited you. If not, close this tab and go back now. It’s not
too late.&lt;/p&gt;
&lt;p&gt;Foreword 2: I’ve updated the post on October 24th with an additional meme, clarifications and a link
to an interesting stackexchange discussion.&lt;/p&gt;
&lt;div id=&#34;free-software-aint-free&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Free software ain’t free&lt;/h2&gt;
&lt;p&gt;Let me first re-iterate that free software and open source are not the same thing. Free software is
open source, but not every piece of open source software is free. Open source means that the source
code of a piece of software is available and can be consulted without much hurdles. It also means,
usually, that you can take these pieces of software, modify them, and redistribute them without
much hurdles either.&lt;/p&gt;
&lt;p&gt;Free software is like open source software, but it’s much more restrictive. That may seem
surprising, because there’s the word &lt;em&gt;free&lt;/em&gt; in there, so how could it be more restrictive than open
source software? Consider the following: I can take a piece of open source software (typically
licensed under something like the &lt;a href=&#34;https://en.wikipedia.org/wiki/MIT_License&#34;&gt;MIT licenses&lt;/a&gt; or the
&lt;a href=&#34;https://en.wikipedia.org/wiki/BSD_licenses&#34;&gt;BSD licenses&lt;/a&gt;) and re-release it with a proprietary
license and sell it. I don’t actually even need to change anything substantial to the source code.
I take that piece of software (which I may or may not modify), repackage it under a new name and
sell it. Free software allows all of this as well (I literally could sell the Linux kernel on this
website if I found people willing to pay me for it), but what it does not allow is only this: I
cannot distribute (by selling or for free) the program without its source code. So if I sold the
Linux kernel on here, I would need to also give out a copy of the source code with it, and this
obviously would also still be necessary if I actually changed something to the source code of the
Linux kernel.&lt;/p&gt;
&lt;p&gt;R is licensed under a Free Software license, the &lt;a href=&#34;https://en.wikipedia.org/wiki/GNU_General_Public_License#Version_2&#34;&gt;GPL
v2&lt;/a&gt;, which means that it’s
illegal for anyone to rebrand it, package it and sell it without providing the source code of their
(modified) version of R. Thanks to something like the GPL, it is impossible for companies to employ
what is called
&lt;a href=&#34;https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish&#34;&gt;Embrace, Extend and Extinguish&lt;/a&gt;, which is a strategy
that Microsoft used in the past. It consists in embracing a piece of software, extending it with
proprietary bits of code and technology, use their dominant position on the desktop to impose their
new version that relies on proprietary bits (or which is 100% proprietary) and then &lt;em&gt;extinguish&lt;/em&gt;
the open source version (in the sense that no one will use it anymore because it virtually became
incompatible with the newly imposed Microsoft version).&lt;/p&gt;
&lt;p&gt;Now some of you may now be thinking that I’m stuck in the 90’s, after all, Microsoft have been the
good guys for a decade now. They contribute to open source software (not free software), have
bought Github and have not ruined it (yet) and they even included the possibility to run Linux
inside Windows using WSL. So what am I afraid of? Why don’t I trust them?&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/multimillion.jpg&#34; width=&#34;100%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;all-licenses-have-their-place-but&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;All licenses have their place, but…&lt;/h2&gt;
&lt;p&gt;The thing is, I shouldn’t have to trust anyone not to fuck up a piece of free software. Maybe the
current management of Microsoft is not hostile to free software, but maybe that’ll change in the
future. That’s not really the point. The point is that I don’t need to have to trust them, and I’m
happy that a &lt;em&gt;fundamental, crucial&lt;/em&gt; piece of software like R uses something like the GPL. But that
doesn’t mean that everything should be licensed under the GPL. For example, as far as I know, every
package of the &lt;code&gt;{tidyverse}&lt;/code&gt; uses an MIT license. So just because R is licensed under the GPL
doesn’t mean that its packages all have to be GPL. But I must also admit that while I see why a
company like Posit releases their packages under a permissive license, I don’t see why an
independent developer would do that. I absolutely do not see what independent developers gain from
releasing the code of their packages under anything else than the GPL. (As an aside, go read
&lt;a href=&#34;https://www.cs.vu.nl/~ast/intel/&#34;&gt;this&lt;/a&gt;… code under a permissive license taken from an
independent developer? check. Nothing was given back to the community? check. The code in question
was used for nefarious purposes? check. Original developer on massive amounts of copium? check).
But, to be fair, I have a grand total of two (2) packages on CRAN that likely get less than 10
downloads a year, so what do I know. One of the arguments I’ve heard is that the GPL is not really
free, because it restricts users from taking the code and releasing it under a proprietary license,
so &lt;em&gt;akshually&lt;/em&gt; the MIT/BSD licenses are really the free ones, and if I like freedom so much I
should be using FreeBSD instead of a Linux distro and release my packages under a MIT/BSD license.
I want to ask people that make this argument if they would allow the Nazi party to make a come back
in their countries legislature, then.&lt;/p&gt;
&lt;p&gt;That being said, I do release stuff with permissive licenses. For example the content of this blog
or for the courses I teach are under the &lt;a href=&#34;http://www.wtfpl.net/txt/copying/&#34;&gt;WTFPL&lt;/a&gt;, which is, I
would say, the only acceptable permissive license for independent developers. If the name of the
license was not explicit enough, the comic below illustrates what the WPTFL is all about:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wtfpl-strip.jpg&#34; width=&#34;100%&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;can-r-be-used-to-write-proprietary-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Can R be used to write proprietary code&lt;/h2&gt;
&lt;p&gt;Yes, you can write proprietary code using R. Microsoft has done so, for example their
&lt;code&gt;{RevoUtilsMath}&lt;/code&gt; package is, as far as I know, proprietary, and I’m sure that it includes some R
code. I’m pretty sure it would also be possible to even build a proprietary program that would
require the R interpreter to be bundled to run. As long as the developers of this tool would:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Release their modified version of R with it (if they modified it);&lt;/li&gt;
&lt;li&gt;Tell their users that their program runs with R, and thus also distribute R and its license;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R could likely be downloaded at install time in cases like this, again, as long as the users
get notified that it’s needed. I doubt that the rest of the program would need to be licensed
under the GPL, since no code of R itself has been modified.&lt;/p&gt;
&lt;p&gt;But I’m not that certain on this last point, so any comments welcome
(on &lt;a href=&#34;https://github.com/rbind/b-rodrigues.github.com/issues/4&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;EDIT: There’s this interesting discussion on stackexchange &lt;a href=&#34;https://opensource.stackexchange.com/questions/7078/is-it-legal-to-use-gpl-code-in-a-proprietary-closed-source-program-by-putting-i&#34;&gt;here&lt;/a&gt;
and it would seem that the answer is not clearcut, but, it depends. Hence why companies
prefer working using permissive licenses, to avoid these types of discussions.&lt;/p&gt;
&lt;p&gt;That’s it, that’s the blog post. Thank GNU for the GPL.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why and how to use JS in your Shiny app</title>
      <link>https://www.brodrigues.co/blog/2022-10-01-why_js_shiny/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-10-01-why_js_shiny/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/pointing_tags_script.png&#34; title = &#34;The gist of this blog post&#34; width=&#34;70%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-snake-biting-its-own-tail&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The snake biting its own tail&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Disclaimer: I’m a beginner at JS, so don’t ask me about the many intricacies of JS.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’ve been working on a Shiny app for work these past few weeks, and had to use
Javascript to solve a very specific issue I encountered. Something for which, as far as I know,
there is no other solution than using Javascript. The problem had to do with dynamically changing
the UI of an app. The way to usually achieve this is using &lt;code&gt;renderUI()/uiOutput()&lt;/code&gt;. For example,
consider the following little app (if you don’t want to run it, watch the video below):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(ggplot2)

data(mtcars)

ui &amp;lt;- fluidPage(
  selectInput(&amp;quot;var&amp;quot;, &amp;quot;Select variable:&amp;quot;, choices = colnames(mtcars)),
  uiOutput(&amp;quot;welcome&amp;quot;),
  plotOutput(&amp;quot;my_plot&amp;quot;)
)

server &amp;lt;- function(input, output) {

  output$welcome &amp;lt;- renderUI({
      tags$div(paste0(&amp;quot;Welcome to my award-winning app! Currently showing variable: &amp;quot;, input$var))
  })

  output$my_plot &amp;lt;- renderPlot({
        ggplot(data = mtcars) +
          geom_bar(aes_string(y = input$var))
      })
}

shinyApp(ui, server)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, when the user chooses a new variable, the plot gets updated of course, but the
welcome message changes as well. Normally, the UI of a Shiny app gets rendered once, at startup,
and stays fixed. But thanks to &lt;code&gt;renderUI()/uiOutput()&lt;/code&gt;, it is possible to change UI elements on the
fly, and anything can go inside of &lt;code&gt;renderUI()/uiOutput()&lt;/code&gt;, it can be something much more
complex than a simple message like in my example above.&lt;/p&gt;
&lt;p&gt;So, why did I need to use Javascript to basically achieve the same thing? The reason is that
I am currently using &lt;a href=&#34;https://rinterface.github.io/bs4Dash/index.html&#34;&gt;&lt;code&gt;{bs4Dash}&lt;/code&gt;&lt;/a&gt;,
an amazing package to build Shiny dashboard using Bootstrap 4. &lt;code&gt;{bs4Dash}&lt;/code&gt; comes with many
neat features, one of them being improved &lt;code&gt;box()&lt;/code&gt;es (improved when compared to the &lt;code&gt;box()&lt;/code&gt;es
from &lt;code&gt;{shinydashboard}&lt;/code&gt;). These improved boxes allow you to do something like this
(if you don’t want to run it, watch the video below):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(ggplot2)
library(bs4Dash)

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = &amp;quot;Welcome to my award-winning dashboard!&amp;quot;,
        color = &amp;quot;primary&amp;quot;
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      box(
        plotOutput(&amp;quot;my_plot&amp;quot;),
        title = &amp;quot;This is where I will put the title, but bear with me.&amp;quot;,
        width = 12,
        sidebar = boxSidebar(
          id = &amp;quot;sidebarid&amp;quot;,
          startOpen = TRUE,
          selectInput(&amp;quot;var&amp;quot;, &amp;quot;Select variable:&amp;quot;, choices = colnames(mtcars))
          ))
    ),
    controlbar = dashboardControlbar(),
    title = &amp;quot;DashboardPage&amp;quot;
  ),
  server = function(input, output, session) {

    output$my_plot &amp;lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

  }
)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_2.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Each box can have a side bar, and these side bars can contain toggles specific to the graph. If you
click outside the side bar, the side bar closes; to show the side bar, click on the little gears in
the top right corner of the side bar. Ok we’re almost done with the setup: see how the box can have
a title? Let’s make it change like before; for this, because the title is part of the &lt;code&gt;box()&lt;/code&gt;
function, I need to re-render the whole box (if you don’t want to run it, watch the video below):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(ggplot2)
library(bs4Dash)

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = &amp;quot;Welcome to my award-winning dashboard!&amp;quot;,
        color = &amp;quot;primary&amp;quot;
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      uiOutput(&amp;quot;my_dynamic_box&amp;quot;)
    ),
    controlbar = dashboardControlbar(),
    title = &amp;quot;DashboardPage&amp;quot;
  ),
  server = function(input, output, session) {

    output$my_plot &amp;lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

    output$my_dynamic_box &amp;lt;- renderUI({
      box(
        plotOutput(&amp;quot;my_plot&amp;quot;),
        title = paste0(&amp;quot;Currently showing variable:&amp;quot;, input$var),
        width = 12,
        sidebar = boxSidebar(
          id = &amp;quot;sidebarid&amp;quot;,
          startOpen = TRUE,
          selectInput(&amp;quot;var&amp;quot;, &amp;quot;Select variable:&amp;quot;, choices = colnames(mtcars))
        ))
    })
  }
)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_3.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Now try changing variables and see what happens… as soon as you change the value in the
&lt;code&gt;selectInput()&lt;/code&gt;, it goes back to selecting &lt;code&gt;mpg&lt;/code&gt;! The reason is because the whole box gets
re-rendered, including the &lt;code&gt;selectInput()&lt;/code&gt;, and its starting, default, value (even if we did not
specify one, this value is simply the first element of &lt;code&gt;colnames(mtcars)&lt;/code&gt; which happens to be
&lt;code&gt;mpg&lt;/code&gt;). So now you see the problem; I have to re-render part of the UI, but doing so puts the
&lt;code&gt;selectInput()&lt;/code&gt; on its default value… so I need to be able to only to re-render the title, not the
whole box (or move the &lt;code&gt;selectInput()&lt;/code&gt; outside the boxes, but that was not an acceptable solution
in my case).&lt;/p&gt;
&lt;p&gt;So there we have it, we’re done with the problem statement. Now on to the solution.&lt;/p&gt;
&lt;div id=&#34;update&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;It turns out that it’s not needed to use JS for this special use case! &lt;code&gt;{bs4Dash}&lt;/code&gt; comes
with a function, called &lt;code&gt;updateBox()&lt;/code&gt; which updates a targeted box. You can read about
it &lt;a href=&#34;https://rinterface.github.io/bs4Dash/reference/box.html&#34;&gt;here&lt;/a&gt;. Thanks to
&lt;code&gt;{bs4Dash}&lt;/code&gt;’s author,
&lt;a href=&#34;https://twitter.com/divadnojnarg/status/1576210017497550849?s=20&amp;amp;t=wz3NfqHB4SWtcVAUH_KPRA&#34;&gt;David Granjon&lt;/a&gt;
for the heads-up!&lt;/p&gt;
&lt;p&gt;Well, even though my specific use case does not actually need Javascript, you can continue
reading, because in case your use case does not have an happy ending like mine, the blog
post is still relevant!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;javascript-to-the-rescue&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Javascript to the rescue&lt;/h2&gt;
&lt;p&gt;Let me be very clear: I know almost nothing about Javascript. I just knew a couple of things:
Javascript can be used for exactly what I needed to do (change part of the UI), and it does so by
making use of the DOM (which I also knew a little bit about). The DOM is a tree-like representation
of a webpage. So you have your webpage’s header, body, footer, and inside of the body, for example,
in my case here, we have a box with a title. That title has an address, if you will, represented by
one of the branches of the DOM. At least, that’s the way I understand it.&lt;/p&gt;
&lt;p&gt;In any case, it is possible to integrate JS scripts inside any Shiny app. So here’s what I thought
I would do: I would create the title of my box as a reactive value inside the server part of my
app, and would then pass this title to a JS script which would then, using the DOM, knock at the
door of the box and give it its new title. Easier written in plain English than in R/JS though. But
surprisingly enough, it didn’t turn out to be that complicated, and even someone (me) with only a very,
very, shallow knowledge of JS could do it in less than an hour. First thing’s first, we need to
read this documentation:
&lt;a href=&#34;https://shiny.rstudio.com/articles/communicating-with-js.html&#34;&gt;Communicating with Shiny via JavaScript&lt;/a&gt;,
especially the second part, &lt;em&gt;From R to JavaScript&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Because we won’t re-render the whole box, let’s simply reuse the app from before, in which the
box is static. The script is below, but first read the following lines, then take
a look at the script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I have defined a JS script outside the app, called &lt;code&gt;box_title_js&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Read the title of the box;&lt;/li&gt;
&lt;li&gt;In the server, there is now an &lt;code&gt;observeEvent()&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;In the UI you’ll see the following line (inside the box’s definition): &lt;code&gt;tags$script(box_title_js)&lt;/code&gt;, which executes the JS script &lt;code&gt;box_title_js&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The script knows which element to change thanks to &lt;code&gt;$(&#34;#box_plot h3&#34;)&lt;/code&gt;. That’s a bit
of jQuery, which comes bundled with Shiny. jQuery allows you to query elements of the
DOM. If you know nothing about it, like me, you should read
&lt;a href=&#34;https://book.javascript-for-r.com/shiny-tips.html#shiny-tips-jQuery&#34;&gt;this&lt;/a&gt;. This should
give you the basic knowledge such that you’ll eventually somehow manage to select
the element you actually want to change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(ggplot2)
library(bs4Dash)

# This is the bit of JS that will update the title
# From what I could gather, $(bla bla) references the object,
# here the title, and `.html()` is a getter/setter.
# So $(&amp;quot;#box_plot h3&amp;quot;).html() means &amp;quot;take whatever is called #box_plot h3
# (h3 is the class of the title, meaning, it’s a header3 bit of text)
# and set its html to whatever string is inside `html()`&amp;quot;
box_title_js &amp;lt;- &amp;#39;
  Shiny.addCustomMessageHandler(&amp;quot;box_title&amp;quot;, function(title) {
    $(&amp;quot;#box_plot h3&amp;quot;).html(title)
  });
&amp;#39;

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = &amp;quot;Welcome to my award-winning dashboard!&amp;quot;,
        color = &amp;quot;primary&amp;quot;
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      box(id = &amp;quot;box_plot&amp;quot;, #We need to give the box an ID now, to help query it
        plotOutput(&amp;quot;my_plot&amp;quot;),
        tags$script(box_title_js), #Integration of the JS script into the app
        title = &amp;quot;This title will change dynamically. You won’t even see this sentence!&amp;quot;,
        width = 12,
        sidebar = boxSidebar(
          id = &amp;quot;sidebarid&amp;quot;,
          startOpen = TRUE,
          selectInput(&amp;quot;var&amp;quot;, &amp;quot;Select variable:&amp;quot;, choices = colnames(mtcars))
        ))
    ),
    controlbar = dashboardControlbar(),
    title = &amp;quot;DashboardPage&amp;quot;
  ),
  server = function(input, output, session) {

    # The following lines put the title together, and send them to the JS script
    observe({
      session$sendCustomMessage(
                &amp;quot;box_title&amp;quot;,
                paste0(&amp;quot;Currently showing variable:&amp;quot;, input$var)
              )
    })

    output$my_plot &amp;lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

  }
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The video below shows how the app works:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_4.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The idea is as follows: a bit of code puts the title together in the server part of your app.
This title gets sent to a JS script that you define somewhere where the UI and the server
part know about it (for example, in your &lt;code&gt;global.R&lt;/code&gt; file). In the UI you can now integrate
the JS script using &lt;code&gt;tags$script()&lt;/code&gt;. And you’re done!&lt;/p&gt;
&lt;p&gt;Just for fun, let’s have a more complex example; I’ll change the background color of the box
using JS as well, but depending on the selected column, the color will be different.
For this, I only need to change the JS script. Using a simple if-then-else statement, I
set the background color of the box to red if the selected column is &lt;code&gt;mpg&lt;/code&gt;, else I set
it to blue. The way I do this, is by using jQuery again to target the element I want to change,
in this case, the object with the id “box_plot” and of class “.card-body”. Take a look
at the script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(ggplot2)
library(bs4Dash)

# This is the bit of JS that will update the title
# From what I could gather, $(bla bla) references the object,
# here the title, and `.html()` is a getter/setter.
# So $(&amp;quot;#box_plot h3&amp;quot;).html() means &amp;quot;take whatever is called #box_plot h3
# (h3 is the class of the title, meaning, it’s a header3 bit of text)
# and set its html to whatever string is inside `html()`&amp;quot;
box_title_js &amp;lt;- &amp;#39;
  Shiny.addCustomMessageHandler(&amp;quot;box_title&amp;quot;, function(title) {
  if(title.includes(&amp;quot;mpg&amp;quot;)){
    colour = &amp;quot;red&amp;quot;
  } else {
    colour = &amp;quot;blue&amp;quot;
  }
    $(&amp;quot;#box_plot h3&amp;quot;).html(title)
    $(&amp;quot;#box_plot .card-body&amp;quot;).css(&amp;quot;background-color&amp;quot;, colour)
  });
&amp;#39;

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = &amp;quot;Welcome to my award-winning dashboard!&amp;quot;,
        color = &amp;quot;primary&amp;quot;
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      box(id = &amp;quot;box_plot&amp;quot;, #We need to give the box an ID now, to help query it
        plotOutput(&amp;quot;my_plot&amp;quot;),
        tags$script(box_title_js), #Integration of the JS script into the app
        title = &amp;quot;This title will change dynamically. You won’t even see this sentence!&amp;quot;,
        width = 12,
        sidebar = boxSidebar(
          id = &amp;quot;sidebarid&amp;quot;,
          startOpen = TRUE,
          selectInput(&amp;quot;var&amp;quot;, &amp;quot;Select variable:&amp;quot;, choices = colnames(mtcars))
        ))
    ),
    controlbar = dashboardControlbar(),
    title = &amp;quot;DashboardPage&amp;quot;
  ),
  server = function(input, output, session) {

    # The following lines put the title together, and send them to the JS script
    observe({
      session$sendCustomMessage(
                &amp;quot;box_title&amp;quot;,
                paste0(&amp;quot;Currently showing variable:&amp;quot;, input$var)
              )
    })

    output$my_plot &amp;lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

  }
)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_5.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;How did I know that I needed to target &lt;code&gt;card-body&lt;/code&gt;? To find out, go to your browser, right
click on the box and select &lt;code&gt;Inspect&lt;/code&gt; (sometimes &lt;code&gt;inspect element&lt;/code&gt;).
Navigating through the source of your app in this way
allows you to find the classes and ids of things you need to target, which you then can use
as a query. You can even try changing stuff in real time, as the video below shows:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/why_js_shiny_6.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;It’s actually scary what you can achieve with only some cursory knowledge of JS. I’m sure nothing
bad ever happens because clueless beginners like me start playing around with JS.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s the fastest way to search and replace strings in a data frame?</title>
      <link>https://www.brodrigues.co/blog/2022-07-23-grepl_vs_stringi/</link>
      <pubDate>Sat, 23 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-07-23-grepl_vs_stringi/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.craiyon.com/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wojak_violin.jpg&#34; title = &#34;Made by DALL-E mini&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve tweeted this:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Just changed like 100 grepl calls to stringi::stri_detect and my pipeline now runs 4 times faster &lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt;
&lt;/p&gt;
— Bruno Rodrigues (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1549659454483857409?ref_src=twsrc%5Etfw&#34;&gt;July 20, 2022&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;much discussed ensued. Some people were surprised, because in their experience, &lt;code&gt;grepl()&lt;/code&gt;
was faster than alternatives, especially if you set the &lt;code&gt;perl&lt;/code&gt; parameter in &lt;code&gt;grepl()&lt;/code&gt; to &lt;code&gt;TRUE&lt;/code&gt;.
My use case was quite simple; I have a relatively large data set (half a million lines) with
one column with several misspelling of city names. So I painstakingly wrote some code
to correct the spelling of the major cities (those that came up often enough to matter. Minor
cities were set to “Other”. Sorry, &lt;a href=&#34;https://en.wikipedia.org/wiki/Wiltz&#34;&gt;Wiltz&lt;/a&gt;!)&lt;/p&gt;
&lt;p&gt;So in this short blog post, I benchmark some code to see if what I did the other day was a fluke.
Maybe something weird with my R installation on my work laptop running Windows 10 somehow
made &lt;code&gt;stri_detect()&lt;/code&gt; run faster than &lt;code&gt;grepl()&lt;/code&gt;? I don’t even know if something like that is
possible. I’m writing these lines on my Linux machine, unlike the code I run at work.
So maybe if I find some differences, they could be due to the different OS running.
I don’t want to have to deal with Windows on my days off (for my blood pressure’s sake),
so I’m not running this benchmark on my work laptop. So that part we’ll never know.&lt;/p&gt;
&lt;p&gt;Anyways, let’s start by getting some data. I’m not commenting the code below, because that’s not
the point of this post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(stringi)
library(stringr)
library(re2)

adult &amp;lt;- vroom::vroom(
  &amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data&amp;quot;
)

adult_colnames &amp;lt;- readLines(
  &amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names&amp;quot;
)

adult_colnames &amp;lt;- adult_colnames[97:110] %&amp;gt;%
  str_extract(&amp;quot;.*(?=:)&amp;quot;) %&amp;gt;%
  str_replace_all(&amp;quot;-&amp;quot;, &amp;quot;_&amp;quot;)

adult_colnames &amp;lt;- c(adult_colnames, &amp;quot;wage&amp;quot;)

colnames(adult) &amp;lt;- adult_colnames

adult&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32,560 × 15
##      age workclass    fnlwgt educa…¹ educa…² marit…³ occup…⁴ relat…⁵ race  sex  
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
##  1    50 Self-emp-no…  83311 Bachel…      13 Marrie… Exec-m… Husband White Male 
##  2    38 Private      215646 HS-grad       9 Divorc… Handle… Not-in… White Male 
##  3    53 Private      234721 11th          7 Marrie… Handle… Husband Black Male 
##  4    28 Private      338409 Bachel…      13 Marrie… Prof-s… Wife    Black Fema…
##  5    37 Private      284582 Masters      14 Marrie… Exec-m… Wife    White Fema…
##  6    49 Private      160187 9th           5 Marrie… Other-… Not-in… Black Fema…
##  7    52 Self-emp-no… 209642 HS-grad       9 Marrie… Exec-m… Husband White Male 
##  8    31 Private       45781 Masters      14 Never-… Prof-s… Not-in… White Fema…
##  9    42 Private      159449 Bachel…      13 Marrie… Exec-m… Husband White Male 
## 10    37 Private      280464 Some-c…      10 Marrie… Exec-m… Husband Black Male 
## # … with 32,550 more rows, 5 more variables: capital_gain &amp;lt;dbl&amp;gt;,
## #   capital_loss &amp;lt;dbl&amp;gt;, hours_per_week &amp;lt;dbl&amp;gt;, native_country &amp;lt;chr&amp;gt;, wage &amp;lt;chr&amp;gt;,
## #   and abbreviated variable names ¹​education, ²​education_num, ³​marital_status,
## #   ⁴​occupation, ⁵​relationship
## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now write the functions used for benchmarking. There will be 5 of them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One using &lt;code&gt;grepl()&lt;/code&gt; without any fancy options;&lt;/li&gt;
&lt;li&gt;One using &lt;code&gt;grepl()&lt;/code&gt; where &lt;code&gt;perl&lt;/code&gt; is set to &lt;code&gt;TRUE&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;One that uses &lt;code&gt;stringi::stri_detect()&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;One that uses &lt;code&gt;stringr::str_detect()&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;One that uses &lt;code&gt;re2::re2_detect()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below you can read the functions. They’re all pretty much the same, only the function
looking for the string changes. These functions look for a string in the &lt;code&gt;marital_status&lt;/code&gt;
variable and create a new variable with a corresponding integer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;with_grepl &amp;lt;- function(dataset){
  dataset |&amp;gt;
    mutate(married = case_when(
             grepl(&amp;quot;Married&amp;quot;, marital_status) ~ 1,
             grepl(&amp;quot;married&amp;quot;, marital_status) ~ 2,
             TRUE ~ 3)
           )
}

with_grepl_perl &amp;lt;- function(dataset){
  dataset |&amp;gt;
    mutate(married = case_when(
             grepl(&amp;quot;Married&amp;quot;, marital_status, perl = TRUE) ~ 1,
             grepl(&amp;quot;married&amp;quot;, marital_status, perl = TRUE) ~ 2,
             TRUE ~ 3)
           )
}

with_stringi &amp;lt;- function(dataset){
  dataset |&amp;gt;
    mutate(married = case_when(
             stri_detect(marital_status, regex = &amp;quot;Married&amp;quot;) ~ 1,
             stri_detect(marital_status, regex = &amp;quot;married&amp;quot;) ~ 2,
             TRUE ~ 3)
           )
}

with_stringr &amp;lt;- function(dataset){
  dataset |&amp;gt;
    mutate(married = case_when(
             str_detect(marital_status, &amp;quot;Married&amp;quot;) ~ 1,
             str_detect(marital_status, &amp;quot;married&amp;quot;) ~ 2,
             TRUE ~ 3)
           )
}

with_re2 &amp;lt;- function(dataset){
  dataset |&amp;gt;
    mutate(married = case_when(
             re2_detect(marital_status, &amp;quot;Married&amp;quot;) ~ 1,
             re2_detect(marital_status, &amp;quot;married&amp;quot;) ~ 2,
             TRUE ~ 3)
           )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I make extra sure these functions actually return the exact same thing. So for this
I’m running them once on the data and use &lt;code&gt;testthat::expect_equal()&lt;/code&gt;. It’s a bit
unwieldy, so if you have a better way of doing this, please let me know.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_grepl &amp;lt;- function(){
  with_grepl(adult) %&amp;gt;%
    count(married, marital_status)
}

one &amp;lt;- run_grepl()

run_grepl_perl &amp;lt;- function(){
  with_grepl_perl(adult) %&amp;gt;%
    count(married, marital_status)
}

two &amp;lt;- run_grepl_perl()

run_stringi &amp;lt;- function(){
  with_stringi(adult) %&amp;gt;%
    count(married, marital_status)
}

three &amp;lt;- run_stringi()

run_stringr &amp;lt;- function(){
  with_stringr(adult) %&amp;gt;%
    count(married, marital_status)
}

four &amp;lt;- run_stringr()

run_re2 &amp;lt;- function(){
  with_re2(adult) %&amp;gt;%
    count(married, marital_status)
}

five &amp;lt;- run_re2()

one_eq_two &amp;lt;- testthat::expect_equal(one, two)
one_eq_three &amp;lt;- testthat::expect_equal(one, three)
three_eq_four &amp;lt;- testthat::expect_equal(three, four)

testthat::expect_equal(
            one_eq_two,
            one_eq_three
          )

testthat::expect_equal(
            one_eq_three,
            three_eq_four
          )

testthat::expect_equal(
            one,
            five)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;testthat::expect_equal()&lt;/code&gt; does not complain, so I’m pretty sure my functions, while different,
return the exact same thing. Now, we’re ready for the benchmark itself. Let’s run these
function 500 times using &lt;code&gt;{microbenchmark}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;microbenchmark::microbenchmark(
     run_grepl(),
     run_grepl_perl(),
     run_stringi(),
     run_stringr(),
     run_re2(),
     times = 500
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##              expr      min       lq     mean   median       uq      max neval
##       run_grepl() 24.37832 24.89573 26.64820 25.50033 27.05967 115.0769   500
##  run_grepl_perl() 19.03446 19.41323 20.91045 19.89093 21.16683 104.3917   500
##     run_stringi() 23.01141 23.40151 25.00304 23.82441 24.83598 104.8065   500
##     run_stringr() 22.98317 23.44332 25.32851 23.92721 25.18168 145.5861   500
##         run_re2() 22.22656 22.60817 24.07254 23.05895 24.22048 108.6825   500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There you have it folks! The winner is &lt;code&gt;grepl()&lt;/code&gt; with &lt;code&gt;perl = TRUE&lt;/code&gt;, and then it’s
pretty much tied between &lt;code&gt;stringi()&lt;/code&gt;, &lt;code&gt;stringr()&lt;/code&gt; and &lt;code&gt;re2()&lt;/code&gt; (maybe there’s a slight edge
for &lt;code&gt;re2()&lt;/code&gt;) and &lt;code&gt;grepl()&lt;/code&gt; without &lt;code&gt;perl = TRUE&lt;/code&gt; is last. But don’t forget that this is running
on my machine with Linux installed on it; maybe you’ll get different results on different
hardware and OSs! So if you rely a lot on &lt;code&gt;grepl()&lt;/code&gt; and other such string manipulation
function, maybe run a benchmark on your hardware first. How come switching from &lt;code&gt;grepl()&lt;/code&gt;
(without &lt;code&gt;perl = TRUE&lt;/code&gt; though) to &lt;code&gt;stri_detect()&lt;/code&gt; made my pipeline at work run 4 times
faster I don’t know. Maybe it has also to do with the size of the data, and the complexity
of the regular expression used to detect the problematic strings?&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R will always be arcane to those who do not make a serious effort to learn it...</title>
      <link>https://www.brodrigues.co/blog/2022-06-02-arcane/</link>
      <pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-06-02-arcane/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://adv-r.hadley.nz/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/third_impact.png&#34; title = &#34;You need to put in the effort&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;R will always be arcane to those who do not make a serious effort to learn it.
It is &lt;strong&gt;not&lt;/strong&gt; meant to be intuitive and easy for casual users to just plunge into.
It is far too complex and powerful for that.
But the rewards are great for serious data analysts who put in the effort.&lt;/p&gt;
&lt;footer&gt;
— Berton Gunter R-help August 2007
&lt;/footer&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’ve posted this quote on twitter the other day and it sparked some discussion. Personally I agree
with this quote, and I’ll explain why.&lt;/p&gt;
&lt;p&gt;Just like any tool aimed at professionals, R requires people to spend time to actually master it.
There is no ifs or buts. Just like I don’t want a casual carpenter doing my carpentry, or a casual
electrician doing the wiring in my house, I don’t think anyone should want to be a casual R user.
Now of course, depending on your needs, you might not need to learn everything the language has to
offer. I certainly don’t know everything R has to offer, far from it. But whatever task you need to
fulfill, take the time to learn the required syntax and packages. As Berton Gunter said in 2007,
&lt;em&gt;the rewards are great&lt;/em&gt; if you put in the effort. You need to create top notch plots? Master
&lt;code&gt;{ggplot2}&lt;/code&gt;. Need to create top notch web apps? &lt;code&gt;{shiny}&lt;/code&gt;, and so on and so forth… you get the
idea. But as a shiny expert, you might not need to know, nor care, about R’s object oriented
capabilities for example.&lt;/p&gt;
&lt;p&gt;That’s fine.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Evelyn Hall: I would like to know how (if) I can extract some of the information from the summary of my nlme.&lt;/p&gt;
&lt;p&gt;Simon Blomberg: This is R. There is no if. Only how.&lt;/p&gt;
&lt;footer&gt;
— Evely Hall and Simon ’Yoda’ Blomberg, R-help April 2005
&lt;/footer&gt;
&lt;/blockquote&gt;
&lt;p&gt;I remember being extremely frustrated when I started to learn R, not because the language was
overly complex, (even if that was the case in the beginning, but honestly, that’s true for any
language, even for supposedly piss-easy languages &lt;a href=&#34;https://twitter.com/Aella_Girl/status/1522633160483385345&#34;&gt;like
Python&lt;/a&gt;) but because my professors kept
saying “no need to learn the language in great detail, we’re economists after all, not
programmers”. That didn’t seem right, and now that I’ve been working with R for years (and with
economists for some time as well), it certainly is important, even for economists, to be quite
fluent in at least one programming language like R. How fluent should you be? Well, enough that you
can test new ideas, or explore new data without much googling nor friction. Your creativity and
curiosity cannot be limited by your lack of knowledge of the tools you need to use.&lt;/p&gt;
&lt;p&gt;Some people posit that the &lt;code&gt;{tidyverse}&lt;/code&gt; (and Rstudio, the GUI interface) made R more accessible.
I’d say yes and no. On one hand, the tidyverse has following nice things going for it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consistent api across packages. That definitely makes R easier to learn!&lt;/li&gt;
&lt;li&gt;Made the &lt;code&gt;%&amp;gt;%&lt;/code&gt; operator famous, which improves readability.&lt;/li&gt;
&lt;li&gt;Top notch documentation, and also many packages come with books that you can read online for free! That certainly makes R easier to learn.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(and Rstudio was the first, really good, GUI for R).&lt;/p&gt;
&lt;p&gt;But while this is all true, on the other hand, the &lt;code&gt;{tidyverse}&lt;/code&gt; also makes it possible to write
code like this (I’ll be using the &lt;code&gt;package::function()&lt;/code&gt; to make the origin of the functions clear):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(purrr)
library(ggfortify) # Not part of the tidyverse, but needed to make ggplot2::autoplot work on lm
library(ggplot2)
library(broom) # Not part of the tidyverse, but adheres to the *tidy* principles

result &amp;lt;- mtcars %&amp;gt;%
  dplyr::group_nest(am) %&amp;gt;%
  dplyr::mutate(models = purrr::map(data, ~lm(hp ~ mpg + cyl, data = .))) %&amp;gt;%
  dplyr::mutate(diag_plots = purrr::map(models, ggplot2::autoplot)) %&amp;gt;%
  dplyr::mutate(model_summary = purrr::map(models, broom::tidy))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;result&lt;/code&gt; is now a data frame with several columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 5
##      am                data models diag_plots model_summary   
##   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;lt;tibble[,10]&amp;gt;&amp;gt; &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;     &amp;lt;list&amp;gt;          
## 1     0           [19 × 10] &amp;lt;lm&amp;gt;   &amp;lt;ggmltplt&amp;gt; &amp;lt;tibble [3 × 5]&amp;gt;
## 2     1           [13 × 10] &amp;lt;lm&amp;gt;   &amp;lt;ggmltplt&amp;gt; &amp;lt;tibble [3 × 5]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;am&lt;/code&gt; defines the groups, and then &lt;code&gt;data&lt;/code&gt;, &lt;code&gt;models&lt;/code&gt; and &lt;code&gt;model_summary&lt;/code&gt; are list-columns containing
complex objects (data frames, models, and plots, respectively). And don’t get me wrong here,
this is not code that I made look complicated on purpose. This type of workflow is &lt;em&gt;canon&lt;/em&gt;
in the tidyverse lore. This is how you can avoid for loops and keep every result together neatly
in a single object.&lt;/p&gt;
&lt;p&gt;Let’s look at another esoteric example: imagine I want to publish a paper and am only interested in
the coefficients of the model where the p-value is less than .05 (lol):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  dplyr::group_nest(am) %&amp;gt;%
  dplyr::mutate(models = purrr::map(data, ~lm(hp ~ mpg + cyl, data = .))) %&amp;gt;%
  dplyr::mutate(model_summary = purrr::map(models, broom::tidy)) %&amp;gt;%
  dplyr::mutate(model_summary = purrr::map(model_summary, \(x)(filter(x, p.value &amp;lt; .05))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 4
##      am                data models model_summary   
##   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;lt;tibble[,10]&amp;gt;&amp;gt; &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;          
## 1     0           [19 × 10] &amp;lt;lm&amp;gt;   &amp;lt;tibble [2 × 5]&amp;gt;
## 2     1           [13 × 10] &amp;lt;lm&amp;gt;   &amp;lt;tibble [1 × 5]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve mapped an anomymous function to the model summary, to filter out p-values greater than .05.
Do you think this looks comprehensible to the beginner? I don’t think so. But I also don’t think that
the beginners must stay beginners, and this is what matters.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Actually, I see it as part of my job to inflict R on people who are perfectly happy to have never heard of it.
Happiness doesn’t equal proficient and efficient.
In some cases the proficiency of a person serves a greater good than their momentary happiness.&lt;/p&gt;
&lt;footer&gt;
— Patrick Burns, R-help April 2005
&lt;/footer&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’d argue that R, as arcane as it is (or not), is very likely one of the easiest languages to
learn, and this is because there are a lot, and I mean a lot, of resources online:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Free books (just take a look at the &lt;a href=&#34;https://www.bigbookofr.com/&#34;&gt;big book of R&lt;/a&gt; to find everything you need)&lt;/li&gt;
&lt;li&gt;Youtube channels dedicated to R (I’m shamelessly plugging &lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;mine&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Packages with great documentation (take a look at the &lt;a href=&#34;https://easystats.github.io/easystats/&#34;&gt;easystats&lt;/a&gt; suite for an example,
or &lt;a href=&#34;https://vincentarelbundock.github.io/modelsummary/index.html&#34;&gt;modelsummary&lt;/a&gt; and &lt;a href=&#34;https://vincentarelbundock.github.io/marginaleffects/&#34;&gt;marginaleffects&lt;/a&gt;, both by Vincent Arel Bundock, and I’m not citing many, many others here)&lt;/li&gt;
&lt;li&gt;Slack channels where you can get help&lt;/li&gt;
&lt;li&gt;The community of R users on twitter (check out the &lt;a href=&#34;https://twitter.com/hashtag/rstats&#34;&gt;#RStats&lt;/a&gt; hashtag)&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;https://community.rstudio.com/#&#34;&gt;RStudio Community forums&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;And of course, the good old &lt;a href=&#34;https://stat.ethz.ch/mailman/listinfo/r-help&#34;&gt;R-help mailing list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And that’s only the free stuff. If you can afford it, there’s plenty of courses available as well.
But no amount of free or paid content will be enough if you don’t invest enough time to learn the language,
and this is true of &lt;em&gt;anything&lt;/em&gt;. There are no secret recipes.&lt;/p&gt;
&lt;p&gt;P.S.: I got all these quotes from the &lt;code&gt;{fortunes}&lt;/code&gt; &lt;a href=&#34;https://cran.r-project.org/web/packages/fortunes/index.html&#34;&gt;package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some learnings from functional programming you can use to write safer programs</title>
      <link>https://www.brodrigues.co/blog/2022-05-26-safer_programs/</link>
      <pubDate>Thu, 26 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-05-26-safer_programs/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;320&#34; height=&#34;240&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/american_psycho.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-number-1-make-functions-fail-early&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning number 1: make functions fail early&lt;/h2&gt;
&lt;p&gt;When writing your own functions, avoid conversion of types without warning.
For example, this function only works on characters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar &amp;lt;- function(x, result = 0){

  if(x == &amp;quot;&amp;quot;){
    result
  } else {
    result &amp;lt;- result + 1
    split_x &amp;lt;- strsplit(x, split = &amp;quot;&amp;quot;)[[1]]
    my_nchar(paste0(split_x[-1],
                    collapse = &amp;quot;&amp;quot;), result)
  }

}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar(&amp;quot;100000000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar(100000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in strsplit(x, split = &amp;quot;&amp;quot;) : non-character argument&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It may tempting to write functions that accept a lot of different types of inputs, because it
seems convenient and you’re a lazy ding-dong:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar2 &amp;lt;- function(x, result = 0){

  # What could go wrong?
  x &amp;lt;- as.character(x)

  if(x == &amp;quot;&amp;quot;){
    result
  } else {
    result &amp;lt;- result + 1
    split_x &amp;lt;- strsplit(x, split = &amp;quot;&amp;quot;)[[1]]
    my_nchar2(paste0(split_x[-1],
                    collapse = &amp;quot;&amp;quot;), result)
  }

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should avoid doing this, because this can have unforseen consequences:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar2(10000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you think that this example is far-fetched, you’d be surprised to learn that this is exactly
what &lt;code&gt;nchar()&lt;/code&gt;, the built-in function to count characters, does:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar(&amp;quot;10000000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar(10000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(thanks to &lt;a href=&#34;https://twitter.com/cararthompson/status/1525114767614087169?s=20&amp;amp;t=tP8Wh8Iy25bWUC1y3Qk5oQ&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@cararthompson&lt;/span&gt;&lt;/a&gt; for pointing this out on twitter)&lt;/p&gt;
&lt;p&gt;You can also add guards to be extra safe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar2 &amp;lt;- function(x, result = 0){

  if(!isTRUE(is.character(x))){
    stop(paste0(&amp;quot;x should be of type &amp;#39;character&amp;#39;, but is of type &amp;#39;&amp;quot;,
                typeof(x), &amp;quot;&amp;#39; instead.&amp;quot;))
  } else if(x == &amp;quot;&amp;quot;){
    result
  } else {
    result &amp;lt;- result + 1
    split_x &amp;lt;- strsplit(x, split = &amp;quot;&amp;quot;)[[1]]
    my_nchar2(paste0(split_x[-1],
                     collapse = &amp;quot;&amp;quot;), result)
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar2(&amp;quot;10000000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;compare to this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_nchar2(10000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in my_nchar2(1000):
x should be of type &amp;#39;character&amp;#39;, but is of type &amp;#39;double&amp;#39; instead.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this doesn’t really help here, because our function is already safe (it only handles
characters, since &lt;code&gt;strsplit()&lt;/code&gt; only handles characters), but in other situations this could
be helpful (and at least we customized the error message). Since it can be quite tedious
to write all these &lt;code&gt;if...else...&lt;/code&gt; statements, you might want to take a look at
&lt;code&gt;purrr::safely()&lt;/code&gt; (and &lt;code&gt;purrr::possibly()&lt;/code&gt;),
the &lt;a href=&#34;https://armcn.github.io/maybe/&#34;&gt;{maybe}&lt;/a&gt; package, or the
&lt;a href=&#34;https://github.com/moodymudskipper/typed&#34;&gt;{typed}&lt;/a&gt; package, or even
&lt;a href=&#34;https://b-rodrigues.github.io/chronicler/&#34;&gt;my package&lt;/a&gt; for that matter.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-number-2-make-your-functions-referentially-transparent-and-as-pure-as-possible&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning number 2: Make your functions referentially transparent (and as pure as possible)&lt;/h2&gt;
&lt;p&gt;Any variable used by a function should be one of its parameters. Don’t do this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(x){
  x + y
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function has only one parameter, &lt;code&gt;x&lt;/code&gt;, and so depends on &lt;code&gt;y&lt;/code&gt; outside of this scope.
This function is unpredictable, because the result it provides depends on the value of &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;See what happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I called &lt;code&gt;f&lt;/code&gt; twice with &lt;code&gt;10&lt;/code&gt; and got two results (because I changed the value of &lt;code&gt;y&lt;/code&gt;
without showing you). In very long scripts, having functions like this depending on
values in the global environment is a recipe for disaster. It’s better to make this
function referentially transparent; some very complicated words to describe a very
simple concept:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(x, y){
  x + y
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just give &lt;code&gt;f&lt;/code&gt; a second parameter, and you’re good to go.&lt;/p&gt;
&lt;p&gt;Something else your functions shouldn’t do is changing stuff outside of its scope:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(x, y){
  result &amp;lt;&amp;lt;- x + y
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at variables in global environment before calling &lt;code&gt;f&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;f&amp;quot;         &amp;quot;my_nchar&amp;quot;  &amp;quot;my_nchar2&amp;quot; &amp;quot;view&amp;quot;      &amp;quot;view_xl&amp;quot;   &amp;quot;y&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s call it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(1, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let’s have a good look at the global environment again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;f&amp;quot;         &amp;quot;my_nchar&amp;quot;  &amp;quot;my_nchar2&amp;quot; &amp;quot;result&amp;quot;    &amp;quot;view&amp;quot;      &amp;quot;view_xl&amp;quot;  
## [7] &amp;quot;y&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now see that &lt;code&gt;result&lt;/code&gt; has been defined in the global environment:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like before, if your functions change stuff outside their scope, this is
a recipe for disaster. You have to be very careful and know exactly what you’re doing
if you want to use &lt;code&gt;&amp;lt;&amp;lt;-&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So it’s better to write your function like this, and call it like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(x, y){
  x + y
}

result &amp;lt;- f(1, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-number-3-make-your-functions-do-one-thing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning number 3: make your functions do one thing&lt;/h2&gt;
&lt;p&gt;Try to write small functions that do just one thing. This make them easier to
document, test and simply wrap your head around. You can then pipe your function
one after the other to get stuff done:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a |&amp;gt;
  f() |&amp;gt;
  g() |&amp;gt;
  h()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You have of course to make sure that the output of &lt;code&gt;f()&lt;/code&gt; is of the correct type,
so that &lt;code&gt;g()&lt;/code&gt; then knows how to handle it. In some cases, you really need a function
to do several things to get the output you want. In that case, still write small
functions to handle every aspect of the whole algorithm, and then write a function
that calls each function. And if needed, you can even provide functions as arguments
to other functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h &amp;lt;- function(x, y, f, g){
  f(x) + g(y)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes &lt;code&gt;h()&lt;/code&gt; a higher-order function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-number-4-use-higher-order-functions-to-abstract-loops-away&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning number 4: use higher-order functions to abstract loops away&lt;/h2&gt;
&lt;p&gt;Loops are hard to write. Higher order function are really cool though:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Reduce(`+`, seq(1:100))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5050&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Reduce()&lt;/code&gt; is a higher-order function that takes a function (here &lt;code&gt;+&lt;/code&gt;) and a list
of inputs compatible with the function. So &lt;code&gt;Reduce()&lt;/code&gt; performs this operation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Reduce(`+`, seq(1:100))

100 + Reduce(`+`, seq(2:100))
100 + 99 + Reduce(`+`, seq(3:100))
100 + 99 + 98 + Reduce(`+`, seq(4:100))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This avoids having to write a loop, which can go wrong for many reasons (typos,
checking input types, depending on variables outside the global environment…
basically anything I mentioned already).&lt;/p&gt;
&lt;p&gt;There’s also &lt;code&gt;purrr::reduce()&lt;/code&gt; if you prefer the &lt;code&gt;tidyverse&lt;/code&gt; ecosystem. Higher-order
functions are super flexible; all that matters is that the function you give to &lt;code&gt;reduce()&lt;/code&gt;
knows what the do with the elements in the list.&lt;/p&gt;
&lt;p&gt;Another higher-order function you should know about is &lt;code&gt;purrr::map()&lt;/code&gt; (or &lt;code&gt;lapply()&lt;/code&gt; if
your prefer &lt;code&gt;base&lt;/code&gt; functions):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purrr::map(list(mtcars, iris), nrow)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 32
## 
## [[2]]
## [1] 150&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This loops a function (here &lt;code&gt;nrow()&lt;/code&gt;) over a list of whatevers (here data frames). Super
flexible once again.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;optional-learning-number-5-use-recursion-to-avoid-loops-further&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(Optional) Learning number 5: use recursion to avoid loops further&lt;/h2&gt;
&lt;p&gt;The following function calls itself and reverses a string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rev_char &amp;lt;- function(x){

  try({
    if(x == &amp;quot;&amp;quot;){
      &amp;quot;&amp;quot;
    } else {
      split_x &amp;lt;- strsplit(x, split = &amp;quot;&amp;quot;)[[1]]

      len_x &amp;lt;- length(split_x)

      paste0(split_x[len_x],
             rev_char(paste0(split_x[1:len_x-1],
                             collapse = &amp;quot;&amp;quot;)))
    }
  }, stop(paste0(&amp;quot;x should be of type &amp;#39;character&amp;#39;, but is of type &amp;#39;&amp;quot;,
                 typeof(x), &amp;quot;&amp;#39; instead.&amp;quot;)))

}

rev_char(&amp;quot;abc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;cba&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I say that this is optional, because while it might sometimes be easier to
use recursion to define a functions, this is not always the case, and (in the case of R)
runs slower than using a loop. If you’re interested in learning more about &lt;code&gt;map()&lt;/code&gt;
and &lt;code&gt;reduce()&lt;/code&gt;, I wrote
several blog posts on it &lt;a href=&#34;https://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/&#34;&gt;here&lt;/a&gt;,
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-01-05-lists_all_the_way2/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/&#34;&gt;here&lt;/a&gt;
and some youtube videos as well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3xIKZbZKCWQ&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=3xIKZbZKCWQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=WjtXc4OXZuk&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=WjtXc4OXZuk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vxaKamox_CQ&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=vxaKamox_CQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=H3ao7LzcvW8&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=H3ao7LzcvW8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vtxb1j0aqJM&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=vtxb1j0aqJM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=F2U-l3IcCtc&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=F2U-l3IcCtc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gVW9KfkJIrQ&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=gVW9KfkJIrQ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FanU60pjmt0&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=FanU60pjmt0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=DERMZi3Ck20&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=DERMZi3Ck20&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Get packages that introduce unique syntax adopted less?</title>
      <link>https://www.brodrigues.co/blog/2022-05-21-heavy_syntax/</link>
      <pubDate>Sat, 21 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-05-21-heavy_syntax/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;
&lt;a href=&#34;https://cran.r-project.org/src/contrib/Archive/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/packages.jpg&#34; title = &#34;The CRAN archive will always be there, at least&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have this hypothesis that packages that introduce a unique syntax, or a workflow change,
get adopted less by users, even if what these packages do is super useful.
I’m going to discuss two examples of packages that I think are really, really useful, but sometimes
I wonder how many R users use them, or would use them if they were aware these packages existed.
I myself, only use one of them!&lt;/p&gt;
&lt;p&gt;The first package is &lt;a href=&#34;https://github.com/moodymudskipper/typed&#34;&gt;&lt;code&gt;{typed}&lt;/code&gt;&lt;/a&gt; which introduces a type
system for R. No more silent conversion to and from types without your knowing! If you don’t
know what a type system is, consider the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar(&amp;quot;100000000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you get “9” back, no problem. But if you do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar(100000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You get 5 back… what in the Lord’s name happened here? What happened is that the number 100000000 was
converted to a character implicitly. But because of all these 0’s, this is what happened:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.character(100000000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1e+08&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It gets converted to a character alright, but scientific notation gets used! So yes,
1e+08 is 5 characters long… Ideally &lt;code&gt;nchar()&lt;/code&gt; would at least warn you that
this conversion is happening, or maybe even error. After all, it’s called &lt;code&gt;nchar()&lt;/code&gt; not &lt;code&gt;nnumeric()&lt;/code&gt; or
whatever. (Thanks to
&lt;a href=&#34;https://twitter.com/cararthompson/status/1525114767614087169?s=20&amp;amp;t=oEOD1Vf7q9l0ZpdVLyDeUw&#34;&gt;&lt;code&gt;@cararthompson&lt;/code&gt;&lt;/a&gt;
for this!)&lt;/p&gt;
&lt;p&gt;A solution could be to write a wrapper around it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar2 &amp;lt;- function(x, ...){
  stopifnot(&amp;quot;x is not a character&amp;quot; = is.character(x))

  nchar(x, ...)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this function is safe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nchar2(123456789)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## [1] Error in nchar2(123456789) : x is not a character&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{typed}&lt;/code&gt; makes writing safe functions like this easier.
Using &lt;code&gt;{typed}&lt;/code&gt; you can write the wrapper like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(typed, warn.conflicts = FALSE) 

strict_nchar &amp;lt;- ? function(x = ? Character(), ...){

  nchar(x, ...)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{typed}&lt;/code&gt; introduces &lt;code&gt;?&lt;/code&gt; (masking the base &lt;code&gt;?&lt;/code&gt; function to read a function’s docs) allowing you
to set the type the function’s arguments. It’s also possible to set the return type of the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;strict_nchar &amp;lt;- Integer() ? function(x = ? Character(), ...){

  nchar(x, ...)

}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;strict_nchar(&amp;quot;10000000&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very useful if you want to write safe functions in a very concise and clean way.&lt;/p&gt;
&lt;p&gt;The second kind of package I was thinking about are packages like &lt;code&gt;{targets}&lt;/code&gt;, which force users to
structure their projects in a very specific way. I really like &lt;code&gt;{targets}&lt;/code&gt; and have been using it for quite
some time. &lt;code&gt;{targets}&lt;/code&gt; takes inspiration from build automation tools from the software development world
and introduces the concept of build automation in R. If you’re a linux user, you’ve probably dealt with
&lt;code&gt;Makefile&lt;/code&gt;s (especially if you’ve been using linux for more than 10 years), and &lt;code&gt;{targets}&lt;/code&gt; works in
a similar way; by writing a script in which you define &lt;em&gt;targets&lt;/em&gt;, these get built in a reproducible way.
If you’d like to see it in action, take a look at &lt;a href=&#34;https://www.youtube.com/watch?v=FvJ4xRGiEgw&#34;&gt;this video&lt;/a&gt;
of mine. As useful as it is, I can imagine that some potential users will end up not adopting it, because
&lt;code&gt;{targets}&lt;/code&gt; really does things in a very unique and different way. Most people do not know what build
automation tools are, and the cost of adopting &lt;code&gt;{targets}&lt;/code&gt; seems disproportionally higher to its benefits
(but believe me, it is well worth the cost!).&lt;/p&gt;
&lt;p&gt;Now here’s the meat of the post: I think that packages like these, even though they’re very useful,
get adopted less by users than other packages, that either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;do not introduce a unique way of doing things;&lt;/li&gt;
&lt;li&gt;for which alternatives are available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The reason, I believe, is that users do not feel comfortable adopting a unique syntax and way of doing
things that impact their code so much, because if these libraries get abandoned, users will need
to completely rewrite their scripts. And this is especially true when the two conditions above are not
verified.&lt;/p&gt;
&lt;p&gt;Take &lt;code&gt;{dplyr}&lt;/code&gt;: one could argue that it introduces both a unique syntax, and a very specific
workflow/way of doing things:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     filter, lag&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
 filter(am == 0) %&amp;gt;%
 group_by(cyl) %&amp;gt;%
 summarise(mean_hp = mean(hp))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##     cyl mean_hp
##   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1     4    84.7
## 2     6   115. 
## 3     8   194.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But there are alternatives to it (a lot of &lt;code&gt;{dplyr}&lt;/code&gt; functionality is covered by &lt;code&gt;base&lt;/code&gt; functions already,
and there’s also &lt;code&gt;{data.table}&lt;/code&gt;), so IF &lt;code&gt;{dplyr}&lt;/code&gt; would get abandoned by Rstudio (which will never
happen, but let’s assume for the sake of argument), users &lt;em&gt;could&lt;/em&gt; switch to &lt;code&gt;{data.table}&lt;/code&gt;. Not so with
more niche packages like the ones discussed above.
Also, even &lt;code&gt;{dplyr}&lt;/code&gt;’s unique syntax making heavy use of &lt;code&gt;%&amp;gt;%&lt;/code&gt; is not so unique anymore, since
the release of R 4.1. A base approach to the above snippet would be:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars |&amp;gt;
  subset(am == 0) |&amp;gt;
  with(aggregate(hp, by = list(cyl), mean))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Group.1         x
## 1       4  84.66667
## 2       6 115.25000
## 3       8 194.16667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before R 4.1, looking at &lt;code&gt;{dplyr}&lt;/code&gt; chains felt like looking at a completely different language than
base R, but now with the introduction of &lt;code&gt;|&amp;gt;&lt;/code&gt; not so anymore. The other thing packages like &lt;code&gt;{dplyr}&lt;/code&gt;
have going for them, even when they introduce a completely new syntax, and do not have any alternative
like &lt;code&gt;{ggplot2}&lt;/code&gt; (I don’t consider &lt;code&gt;base&lt;/code&gt; plotting an alternative to &lt;code&gt;{ggplot2}&lt;/code&gt;, because it works
in a completely different way) is that they have big teams and/or companies behind them, like Rstudio.
So users feel much more confident adopting such packages, than if they’re written by a very small
team (sometimes even just one person).&lt;/p&gt;
&lt;p&gt;The reason I’m thinking about all this, is because I
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-05-18-cran_0_2_0/&#34;&gt;recently released a package&lt;/a&gt; that raises
all of the above red flags:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;new syntax (makes heavy use of a new pipe &lt;code&gt;%&amp;gt;=%&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;forces a new workflow on users;&lt;/li&gt;
&lt;li&gt;developed by a single dude in his free time who isn’t even a programmer (me).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If I was a potential interested user, I honestly don’t know if I’d adopt this package for anything
critical. I might play around with it a bit, but using that in production? What if the author (me)
gets sick of it after a few months/years? Even I, as the author, cannot guarantee today that this
package will still be maintained in 2 years. So users that might have important stuff running which uses my
package are now screwed. I think that the only way for such packages to succeed, is if a sizeable
community gathers around it and if the team of developers expands, and ideally, if it gets backed
by a company (like Rstudio with all their packages, or rOpenSci &lt;a href=&#34;https://docs.ropensci.org/targets/&#34;&gt;does for
&lt;code&gt;{targets}&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To be clear, I am NOT complaining about free and open source software: these problems also exist
with proprietary software. If a company builds something and they decide to abandon it, that’s it,
it’s over. If there are no alternatives to it, users are screwed just as well. And companies can also
go bankrupt or &lt;em&gt;change focus on other more profitable projects&lt;/em&gt;.
At least with free and open source software, if the author of a package has had enough
and decides to not maintain anymore, there is still the possibility of someone else taking it over,
and this someone else might be a user! There is also the possibility of running old R version with
older versions of packages, even if they’re abandoned, using Docker. So maybe it’s not so bad.&lt;/p&gt;
&lt;p&gt;What do you think? I’d be curious to hear your thoughts. Tell me what you think on
&lt;a href=&#34;https://github.com/b-rodrigues/fp_in_R_discussion/issues/2&#34;&gt;this github issue I opened&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Oh and by the way, IF you’re using &lt;code&gt;{chronicler}&lt;/code&gt; after reading this, really, thank you.&lt;/p&gt;
&lt;p&gt;
Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!
&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>chronicler is now available on CRAN</title>
      <link>https://www.brodrigues.co/blog/2022-05-18-cran_0_2_0/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-05-18-cran_0_2_0/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://b-rodrigues.github.io/chronicler/&#34;&gt;
&lt;img src=&#34;https://b-rodrigues.github.io/chronicler/reference/figures/hex.png&#34; title = &#34;chronicler&#39;s hex logo&#34; height=&#34;400px&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I am very happy to annouce that the &lt;code&gt;{chronicler}&lt;/code&gt; package, which I’ve been working on for the past
3 months has been released on CRAN. Install it with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;chronicler&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{chronicler}&lt;/code&gt; allows you to create objects that carry a log
with them. Here is an example of an object that has been created using &lt;code&gt;{chronicler}&lt;/code&gt;, and saved
using &lt;code&gt;saveRDS()&lt;/code&gt; (which we now load back into our session using &lt;code&gt;readRDS()&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(chronicler)

my_df &amp;lt;- readRDS(&amp;quot;path/to/my_df.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Printing &lt;code&gt;my_df&lt;/code&gt; shows the following output:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OK! Value computed successfully:
## ---------------
## Just
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55  
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log(.c).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;my_df&lt;/code&gt; is made up of two parts, one is a data set, and the other is the log. If you wish
to know how this data set was created, you can call &lt;code&gt;read_log(my_df)&lt;/code&gt; (this function will
be renamed to &lt;code&gt;read.log()&lt;/code&gt; in the next release, to avoid clashing with &lt;code&gt;readr::read_log()&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(my_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                  
## [2] &amp;quot;OK! select(height,mass,species,sex) ran successfully at 2022-05-18 10:56:52&amp;quot;    
## [3] &amp;quot;OK! group_by(species,sex) ran successfully at 2022-05-18 10:56:52&amp;quot;              
## [4] &amp;quot;OK! filter(sex != \&amp;quot;male\&amp;quot;) ran successfully at 2022-05-18 10:56:52&amp;quot;            
## [5] &amp;quot;OK! summarise(mean(mass, na.rm = TRUE)) ran successfully at 2022-05-18 10:56:52&amp;quot;
## [6] &amp;quot;Total running time: 0.185953617095947 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you want to get the dataset out of the &lt;code&gt;{chronicler}&lt;/code&gt; “box”, you can do so with &lt;code&gt;pick(my_df, &#34;value&#34;)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(my_df, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To know more about all the package has to offer, read the
&lt;a href=&#34;https://b-rodrigues.github.io/chronicler/&#34;&gt;readme&lt;/a&gt; and the
&lt;a href=&#34;https://b-rodrigues.github.io/chronicler/articles/&#34;&gt;vignettes&lt;/a&gt; on the package’s website. I’m
already working on the next release, where I plan to add the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rename &lt;code&gt;read_log()&lt;/code&gt; to &lt;code&gt;read.log()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Make &lt;code&gt;{chronicler}&lt;/code&gt; work with &lt;code&gt;{ggplot2}&lt;/code&gt; (as described &lt;a href=&#34;https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot/&#34;&gt;here&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Introduce functions to save &lt;code&gt;{chronicler}&lt;/code&gt; objects as &lt;code&gt;.csv&lt;/code&gt; or &lt;code&gt;.xlsx&lt;/code&gt; files to disk (if the underlying value is a &lt;code&gt;data.frame&lt;/code&gt;, as in the example above)&lt;/li&gt;
&lt;li&gt;Anything else I think of between now and then!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m really looking forward to see how people are going to use this package for their work,
personally I’ve been mixing &lt;code&gt;{chronicler}&lt;/code&gt; with &lt;code&gt;{targets}&lt;/code&gt; to build very robust pipelines to build
&lt;code&gt;chronicle&lt;/code&gt; objects!&lt;/p&gt;
&lt;div id=&#34;thanks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thanks&lt;/h2&gt;
&lt;p&gt;I’d like to thank &lt;a href=&#34;https://github.com/armcn&#34;&gt;armcn&lt;/a&gt;, &lt;a href=&#34;https://github.com/Kupac&#34;&gt;Kupac&lt;/a&gt; for their
blog posts (&lt;a href=&#34;https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/&#34;&gt;here&lt;/a&gt;) and packages
(&lt;a href=&#34;https://armcn.github.io/maybe/&#34;&gt;maybe&lt;/a&gt;) which inspired me to build this package. Thank you as
well to
&lt;a href=&#34;https://community.rstudio.com/t/help-with-writing-a-custom-pipe-and-environments/133447/2?u=brodriguesco&#34;&gt;TimTeaFan&lt;/a&gt;
for his help with writing the &lt;code&gt;%&amp;gt;=%&lt;/code&gt; infix operator,
&lt;a href=&#34;https://community.rstudio.com/t/best-way-to-catch-rlang-errors-consistently/131632/5?u=brodriguesco&#34;&gt;nigrahamuk&lt;/a&gt;
for showing me a nice way to catch errors, and finally
&lt;a href=&#34;https://community.rstudio.com/t/how-to-do-call-a-dplyr-function/131396/2?u=brodriguesco&#34;&gt;Mwavu&lt;/a&gt;
for pointing me towards the right direction with an issue I’ve had as I started working on this
package. Thanks to &lt;a href=&#34;https://twitter.com/putosaure&#34;&gt;Putosaure&lt;/a&gt; for designing the hex logo,
and of course to every single person that makes free and open source software possible.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Self-documenting {ggplot}s thanks to the power of monads!</title>
      <link>https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot/</link>
      <pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/monoids_endofunctors.jpg&#34; title = &#34;How it feels to implement your own monad&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Hey kid, fancy some self-documenting &lt;code&gt;{ggplots}&lt;/code&gt; like this one:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Just read on!&lt;/p&gt;
&lt;p&gt;I’ve been working hard on a package that I’ve called &lt;code&gt;{chronicler}&lt;/code&gt; (read my post on it
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-04-04-chron_post/&#34;&gt;here&lt;/a&gt;) which allows you to
attach a log to the objects you create, thus making it easy to know how some data (for example)
has been created. Here’s a quick example and intro to the main features:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages(
  library(dplyr)
)
library(chronicler)

# record() decorates functions so they provide enriched output
r_group_by &amp;lt;- record(group_by)
r_select &amp;lt;- record(select)
r_summarise &amp;lt;- record(summarise)
r_filter &amp;lt;- record(filter)

output_pipe &amp;lt;- starwars %&amp;gt;%
  r_select(height, mass, species, sex) %&amp;gt;=% # &amp;lt;- this is a special pipe operator to handle `chronicle` objects
  r_group_by(species, sex) %&amp;gt;=%
  r_filter(sex != &amp;quot;male&amp;quot;) %&amp;gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;output_pipe&lt;/code&gt; not only has the result of all the &lt;code&gt;{dplyr}&lt;/code&gt; operations, but also carries a log
with it. Let’s print the object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;output_pipe&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OK! Value computed successfully:
## ---------------
## Just
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55  
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log(.c).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Accessing the value is possible with &lt;code&gt;pick(&#34;value&#34;)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(output_pipe, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you can read the log with &lt;code&gt;read_log()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(output_pipe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                  
## [2] &amp;quot;OK! select(height,mass,species,sex) ran successfully at 2022-05-15 17:10:43&amp;quot;    
## [3] &amp;quot;OK! group_by(species,sex) ran successfully at 2022-05-15 17:10:43&amp;quot;              
## [4] &amp;quot;OK! filter(sex != \&amp;quot;male\&amp;quot;) ran successfully at 2022-05-15 17:10:43&amp;quot;            
## [5] &amp;quot;OK! summarise(mean(mass, na.rm = TRUE)) ran successfully at 2022-05-15 17:10:43&amp;quot;
## [6] &amp;quot;Total running time: 0.0434844493865967 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to understand how this works, I suggest you read the blog post I linked above but also
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-04-11-monads/&#34;&gt;this one&lt;/a&gt;, where I explain the nitty gritty,
theoretical details behind what &lt;code&gt;{chronicler}&lt;/code&gt; does. To make a long story short, &lt;code&gt;{chronicler}&lt;/code&gt;
uses an advanced functional programming concept called a monad. And using the power of monads,
I can now make self-documenting &lt;code&gt;{ggplot2}&lt;/code&gt; graphs.&lt;/p&gt;
&lt;p&gt;The idea was to be able to build a plot in a way similar to how I built that dataset just above,
and have a log of how it was created attached to it. The issue is that the function that
&lt;em&gt;transforms&lt;/em&gt; functions to &lt;code&gt;chronicler&lt;/code&gt; functions, &lt;code&gt;record()&lt;/code&gt;, does not work on &lt;code&gt;{ggplot2}&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;This is because the way you create &lt;code&gt;{ggplot2}&lt;/code&gt; graphs is by adding layers on top of each other:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(mtcars) +
  geom_point(aes(mpg, hp))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;+&lt;/code&gt; here acts as a way to “add” the &lt;code&gt;geom_point(mpg, hp)&lt;/code&gt; layer on top of the &lt;code&gt;ggplot(mtcars)&lt;/code&gt; layer.
I remember reading some tweets, quite some time ago, from people asking why &lt;code&gt;%&amp;gt;%&lt;/code&gt; couldn’t work with
&lt;code&gt;{ggplot2}&lt;/code&gt; and if Hadley Wickham, the developer of &lt;code&gt;{ggplot2}&lt;/code&gt;, was considering making something like this
work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mtcars) %&amp;gt;%
  geom_point(aes(mpg, hp))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;because people kept forgetting using &lt;code&gt;+&lt;/code&gt; and kept using &lt;code&gt;%&amp;gt;%&lt;/code&gt;. The thing is, &lt;code&gt;%&amp;gt;%&lt;/code&gt; and &lt;code&gt;+&lt;/code&gt; do very
different things. &lt;code&gt;%&amp;gt;%&lt;/code&gt; takes its first argument and passes it as the first argument of its second
argument, in other words this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a %&amp;gt;% f(b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is exactly the same as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f(a, b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not what &lt;code&gt;{ggplot2}&lt;/code&gt; functions do. When you call &lt;code&gt;+&lt;/code&gt; on &lt;code&gt;{ggplot2}&lt;/code&gt; objects, this is NOT what happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;geom_point(ggplot(mtcars), aes(mpg, hp))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that’s why &lt;code&gt;%&amp;gt;%&lt;/code&gt; cannot be used with &lt;code&gt;{ggplot2}&lt;/code&gt; functions, and that’s also why the functions I developed
in &lt;code&gt;{chronicle}&lt;/code&gt; could not handle &lt;code&gt;{ggplot2}&lt;/code&gt; functions either. So I had to provide new functions. The first
function I developed is called &lt;code&gt;ggrecord()&lt;/code&gt; and it decorates &lt;code&gt;{ggplot2}&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_ggplot &amp;lt;- ggrecord(ggplot)
r_geom_point &amp;lt;- ggrecord(geom_point)
r_labs &amp;lt;- ggrecord(labs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the output of these functions are not &lt;code&gt;ggplot&lt;/code&gt; objects anymore, but chronicle objects. So to make
layering them possible, I also needed to rewrite &lt;code&gt;+&lt;/code&gt;. I called my rewritten &lt;code&gt;+&lt;/code&gt; like this: &lt;code&gt;%&amp;gt;+%&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- r_ggplot(mtcars) %&amp;gt;+%
  r_geom_point(aes(y = mpg, x = hp)) %&amp;gt;+%
  r_labs(title = &amp;quot;Self-documenting ggplot!\nLook at the bottom right&amp;quot;,
         caption = &amp;quot;This is an example caption&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s first take a look at &lt;code&gt;a&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OK! Ggplot computed successfully:
## ---------------
## Just&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log(.c).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As before expected, &lt;code&gt;a&lt;/code&gt; is now an object of type &lt;code&gt;{chronicle}&lt;/code&gt;, where its “value” is a &lt;code&gt;ggplot&lt;/code&gt; object.
But where is the self-documenting part?
For this, you use the last piece of the puzzle, &lt;code&gt;document_gg()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;document_gg(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## OK! Ggplot computed successfully:
## ---------------
## Just&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2022-05-15-self_doc_ggplot_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log(.c).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The caption now contains the log of the plot, making it easily reproducible!&lt;/p&gt;
&lt;p&gt;This is still in very early development, but if you want to try it out, you’ll need to try the &lt;code&gt;dev&lt;/code&gt;
branch of &lt;a href=&#34;https://github.com/b-rodrigues/chronicler/tree/dev&#34;&gt;the package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Any feedback, comments, ideas, pull requests, more than welcome.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why you should(n&#39;t) care about Monads if you&#39;re an R programmer</title>
      <link>https://www.brodrigues.co/blog/2022-04-11-monads/</link>
      <pubDate>Mon, 11 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-04-11-monads/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/pondering.jpg&#34; title = &#34;How it feels to implement your own monad&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Update: I also made a video out of this blog post; watch it on &lt;a href=&#34;https://www.youtube.com/watch?v=Hlypj6-n51c&#34;&gt;youtube&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;introduction-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction: functions&lt;/h2&gt;
&lt;p&gt;To understand Monads, I think it’s useful to first think about functions; why do we use functions?
Why don’t we simply write scripts with the required operations one after the other? For instance,
to compute the average height by species in a data set of individuals from
the famous space opera “Star Wars”, we could very well write this code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages(library(dplyr))

data(starwars)

sum_humans &amp;lt;- 0
sum_others &amp;lt;- 0
n_humans &amp;lt;- 0
n_others &amp;lt;- 0

for(i in seq_along(1:nrow(starwars))){

  if(!is.na(unlist(starwars[i, &amp;quot;species&amp;quot;])) &amp;amp;
     unlist(starwars[i, &amp;quot;species&amp;quot;]) == &amp;quot;Human&amp;quot;){
    if(!is.na(unlist(starwars[i, &amp;quot;height&amp;quot;]))){
      sum_humans &amp;lt;- sum_humans + unlist(starwars[i, &amp;quot;height&amp;quot;])
      n_humans &amp;lt;- n_humans + 1
    } else {

      0

    }

  } else {
    if(!is.na(unlist(starwars[i, &amp;quot;height&amp;quot;]))){
      sum_others &amp;lt;- sum_others + unlist(starwars[i, &amp;quot;height&amp;quot;])
      n_others &amp;lt;- n_others + 1
    } else {
      0
    }
  }
}

mean_height_humans &amp;lt;- sum_humans/n_humans
mean_height_others &amp;lt;- sum_others/n_others&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, we &lt;em&gt;could&lt;/em&gt; do it like this, but we definitely shouldn’t:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;what this code does is not immediately obvious. If the code blocks aren’t commented, readers of this code will have to read line by line to understand what is going on;&lt;/li&gt;
&lt;li&gt;this code is not reusable. If now I need the average height by species and sex, I need to copy and
paste the code, and modify it, and in some cases modify it substantially;&lt;/li&gt;
&lt;li&gt;this code handles missing values in a cumbersome way, with nested &lt;code&gt;if...else...&lt;/code&gt;s;&lt;/li&gt;
&lt;li&gt;this code is not easy to test;&lt;/li&gt;
&lt;li&gt;this code cannot be composed (meaning, chained) with other code without substantially altering it (to be precise, chaining and composing are two different things, strictly speaking, but for simplicity’s sake, let’s just assume it is the same. Whenever I’m talking about “composing” something, I mean “chaining” something.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But it’s not just shortcomings, this &lt;em&gt;imperative&lt;/em&gt; code has one advantage; it uses only some very fundamental
building blocks: &lt;code&gt;if...else...&lt;/code&gt;, for loops and that’s almost it (it does use some functions provided
by a base installation of R, namely &lt;code&gt;is.na()&lt;/code&gt;, &lt;code&gt;!()&lt;/code&gt;, &lt;code&gt;unlist()&lt;/code&gt; and &lt;code&gt;[()&lt;/code&gt;, so strictly speaking,
the code above is not purely imperative, but maybe closer to being procedural?).&lt;/p&gt;
&lt;p&gt;Using functions solves all the issues from imperative programming. Here is a base solution to the
problem above, using a declarative, or functional, approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aggregate(starwars$height,
          by = list(starwars$species == &amp;quot;Human&amp;quot;),
          FUN = \(x)(mean(x, na.rm = TRUE)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Group.1        x
## 1   FALSE 172.4043
## 2    TRUE 176.6452&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code has many advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;what this code does is obvious, but only if you know what &lt;code&gt;aggregate()&lt;/code&gt; does. But if you read its
documentation you’ll know, and you’ll know every time you’ll see &lt;code&gt;aggregate()&lt;/code&gt; unlike a loop
like the loop above where you’ll have to read it each time to understand;&lt;/li&gt;
&lt;li&gt;this code is reusable. Replace the data frame by another, and that’s it;&lt;/li&gt;
&lt;li&gt;Missing values are now ignored easily using the &lt;code&gt;na.rm&lt;/code&gt; argument of &lt;code&gt;mean()&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;this code is easy to test (using unit tests);&lt;/li&gt;
&lt;li&gt;this code can be composed, for instance like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aggregate(starwars$height,
          by = list(starwars$species == &amp;quot;Human&amp;quot;),
          FUN = \(x)(mean(x, na.rm = TRUE))) |&amp;gt;
  setNames(c(&amp;quot;is_human&amp;quot;, &amp;quot;mean_height&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   is_human mean_height
## 1    FALSE    172.4043
## 2     TRUE    176.6452&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The issue with the functional approach (at least that’s the issue that many people I spoke to about
this raise) is that… in some way people that don’t like this approach feel like they “lose”
control over what’s going on. You don’t know what happens inside these functions. I remember, while
working my first job, that my boss required that I don’t use any functions nor packages, but
instead write all the loops explicitely, because she wanted to understand what was going on (of
course, I completely ignored this request and just did as I pleased). As discussed above, the
imperative approach requires minimum knowledge of the language, and almost anyone with an ounce of
programming experience can understand imperative code. That’s not the case with a functional
approach. Readers will have to be familiar with the individual functions like &lt;code&gt;aggregate()&lt;/code&gt;, but
also anonymous functions (I had to use &lt;code&gt;\(x)(mean(x, na.rm = TRUE))&lt;/code&gt; to set &lt;code&gt;na.rm = TRUE&lt;/code&gt;, which
is &lt;code&gt;FALSE&lt;/code&gt; by default) and also &lt;code&gt;|&amp;gt;&lt;/code&gt; for composition/chaining.&lt;/p&gt;
&lt;p&gt;It may same more complex, and maybe it is, but the advantages far outweigh the shortcoming.&lt;/p&gt;
&lt;p&gt;For completeness, here is a &lt;code&gt;{dplyr}&lt;/code&gt; version:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starwars %&amp;gt;%
  group_by(is_human = species == &amp;quot;Human&amp;quot;) %&amp;gt;%
  summarise(mean_height = mean(height, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##   is_human mean_height
##   &amp;lt;lgl&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 FALSE           172.
## 2 TRUE            177.
## 3 NA              181.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{dplyr}&lt;/code&gt; code is even more concise than base functional code. Here again, users will have to know
about the individual functions and &lt;code&gt;%&amp;gt;%&lt;/code&gt;. But personally, I think that the only hurdle is
understanding what &lt;code&gt;%&amp;gt;%&lt;/code&gt; does, and once you know this, &lt;code&gt;{dplyr}&lt;/code&gt; code can be understood quite easily,
thanks to very explicit function names.&lt;/p&gt;
&lt;p&gt;So functions are great. They’re easy to test, easy to document, easy to package, easy to reuse, and
easy to compose. Composition is really important. For example, let’s go back to the imperative
code, and put the result in a neat data frame object, like the functional solutions do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_humans &amp;lt;- 0
sum_others &amp;lt;- 0
n_humans &amp;lt;- 0
n_others &amp;lt;- 0

for(i in seq_along(1:nrow(starwars))){

  if(!is.na(unlist(starwars[i, &amp;quot;species&amp;quot;])) &amp;amp;
     unlist(starwars[i, &amp;quot;species&amp;quot;]) == &amp;quot;Human&amp;quot;){
    if(!is.na(unlist(starwars[i, &amp;quot;height&amp;quot;]))){
      sum_humans &amp;lt;- sum_humans + unlist(starwars[i, &amp;quot;height&amp;quot;])
      n_humans &amp;lt;- n_humans + 1
    } else {

      0

    }

  } else {
    if(!is.na(unlist(starwars[i, &amp;quot;height&amp;quot;]))){
      sum_others &amp;lt;- sum_others + unlist(starwars[i, &amp;quot;height&amp;quot;])
      n_others &amp;lt;- n_others + 1
    } else {
      0
    }
  }
}

mean_height_humans &amp;lt;- sum_humans/n_humans
mean_height_others &amp;lt;- sum_others/n_others

# These two lines are new
data.frame(list(&amp;quot;is_human&amp;quot; = c(TRUE, FALSE),
           &amp;quot;mean_height&amp;quot; = c(mean_height_others, mean_height_humans)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   is_human mean_height
## 1     TRUE    172.9400
## 2    FALSE    176.6452&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s just two lines (right at the end), but the implications are huge; because imperative code
cannot be composed, I had to write separate code to put the result into a data frame. More code
that I need to write, more opportunities for mistakes. I actually did a mistake, did you notice? This
kind of mistake could go unnoticed for eons. But if you use functions, you don’t have this problem,
and can focus on getting (even complex) things done:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starwars %&amp;gt;%
  filter(skin_color == &amp;quot;light&amp;quot;) %&amp;gt;%
  select(species, sex, mass) %&amp;gt;%
  group_by(sex, species) %&amp;gt;%
  summarise(
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&amp;gt;%
  select(-species) %&amp;gt;%
  tidyr::pivot_longer(-sex, names_to = &amp;quot;statistic&amp;quot;, values_to = &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;sex&amp;#39;. You can override using the `.groups`
## argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Needless to say, trying to write the above code using only for loops and &lt;code&gt;if...else...&lt;/code&gt; is not
something I’d wish to do, especially passing the result of all the &lt;code&gt;{dplyr}&lt;/code&gt; calls to &lt;code&gt;pivot_longer()&lt;/code&gt;.
Creating that last data frame by hand is error prone, and there would definitely be mistakes in there.&lt;/p&gt;
&lt;p&gt;I hope I don’t need to convince you any more that functions are great, and that one of the great
things they offer is their ability to be chained, or composed. But strictly speaking, you don’t need
them. You &lt;em&gt;could&lt;/em&gt; write your code without any function whatsoever, and use the most basic building
blocks there are (loops and &lt;code&gt;if...else...&lt;/code&gt; and little more). However, doing this would result in
much messier code. It’s the same with monads. You can live without them. But there will be situations
where not using them will result in messier code.&lt;/p&gt;
&lt;p&gt;One more thing: as I was writing this blog post, I happened on this tweet:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt; question: What wheel are they trying to re-invent? &lt;a href=&#34;https://t.co/tsoAfCHroK&#34;&gt;pic.twitter.com/tsoAfCHroK&lt;/a&gt;&lt;/p&gt;&amp;mdash; Tokhir Dadaev (@zx8754) &lt;a href=&#34;https://twitter.com/zx8754/status/1513080736785604611?ref_src=twsrc%5Etfw&#34;&gt;April 10, 2022&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;This is a fine example of all that I’ve been discussing until now. The person who wrote this code was
very likely trying to get the diagonal elements of a matrix. That person was likely a beginner in
R and used for loops to try to get the answer. We have all been there; what I’m trying to articulate
is this: imperative programming can be useful, but it can get messy very quickly…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;when-functions-are-not-enough&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;When functions are not enough&lt;/h2&gt;
&lt;p&gt;Functions are awesome, but there are situations which functions simply can’t easily deal with.
Situations in which you would like your functions to do a little extra more, and the only way
forward you see is to rewrite them to do something totally unrelated. For example, suppose you
would like to time your code. Most people would to something such as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic &amp;lt;- Sys.time()
starwars %&amp;gt;%
  filter(skin_color == &amp;quot;light&amp;quot;) %&amp;gt;%
  select(species, sex, mass) %&amp;gt;%
  group_by(sex, species) %&amp;gt;%
  summarise(
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&amp;gt;%
  select(-species) %&amp;gt;%
  tidyr::pivot_longer(-sex, names_to = &amp;quot;statistic&amp;quot;, values_to = &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;sex&amp;#39;. You can override using the `.groups`
## argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toc &amp;lt;- Sys.time()

(running_time &amp;lt;- toc - tic)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 0.04228544 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could totally do that. But now you’re back to square one. You have to deal with this tic-toc
nonsense separately, have to keep track it, overburdening you mentally and polluting your code.
To keep track of it, you’ll want to add the running times in a separate data frame, in which
you could have all the running times of all your operations you need to run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.frame(list(&amp;quot;operations&amp;quot; = seq(1:3),
                &amp;quot;running_time&amp;quot; = c(running_time, running_time * 2, running_time * 3)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   operations    running_time
## 1          1 0.04228544 secs
## 2          2 0.08457088 secs
## 3          3 0.12685633 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This data frame is the consequence of this tic-toc nonsense not being composable and now you have
to deal with it, but you don’t want to. So what now? You might be tempted to do something like
this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic_filter &amp;lt;- function(...){

  tic &amp;lt;- Sys.time()

  result &amp;lt;- filter(...)

  toc &amp;lt;- Sys.time()

  message(&amp;quot;Running time: &amp;quot;, toc - tic)

  return(result)

}

starwars %&amp;gt;%
  tic_filter(species == &amp;quot;Human&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Running time: 0.00481176376342773&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 35 × 14
##    name     height  mass hair_color skin_color eye_color birth_year sex   gender
##    &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
##  1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…
##  2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…
##  3 Leia Or…    150    49 brown      light      brown           19   fema… femin…
##  4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…
##  5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…
##  6 Biggs D…    183    84 black      light      brown           24   male  mascu…
##  7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…
##  8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…
##  9 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…
## 10 Han Solo    180    80 brown      fair       brown           29   male  mascu…
## # … with 25 more rows, and 5 more variables: homeworld &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;,
## #   films &amp;lt;list&amp;gt;, vehicles &amp;lt;list&amp;gt;, starships &amp;lt;list&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But that’s actually worse: not only do you have to change all the functions you need, and wrap them
around tic-toc, but the running time is only shown as a message, so you can’t reuse it.
You could then try to rewrite the function like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic_filter &amp;lt;- function(...){

  tic &amp;lt;- Sys.time()

  result &amp;lt;- filter(...)

  toc &amp;lt;- Sys.time()

  running_time &amp;lt;- toc - tic

  list(&amp;quot;result&amp;quot; = result,
       &amp;quot;running_time&amp;quot; = running_time)

}

starwars %&amp;gt;%
  tic_filter(species == &amp;quot;Human&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## # A tibble: 35 × 14
##    name     height  mass hair_color skin_color eye_color birth_year sex   gender
##    &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
##  1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…
##  2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…
##  3 Leia Or…    150    49 brown      light      brown           19   fema… femin…
##  4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…
##  5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…
##  6 Biggs D…    183    84 black      light      brown           24   male  mascu…
##  7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…
##  8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…
##  9 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…
## 10 Han Solo    180    80 brown      fair       brown           29   male  mascu…
## # … with 25 more rows, and 5 more variables: homeworld &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;,
## #   films &amp;lt;list&amp;gt;, vehicles &amp;lt;list&amp;gt;, starships &amp;lt;list&amp;gt;
## 
## $running_time
## Time difference of 0.004878759 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At least now you save the running time along with the object. But the problem of rewriting many
functions remains, and these rewritten &lt;code&gt;{dplyr}&lt;/code&gt; functions now return a list, and not a data frame
anymore so something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starwars %&amp;gt;%
  tic_filter(species == &amp;quot;Human&amp;quot;) %&amp;gt;%
  tic_select(species, sex)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;wouldn’t work, because &lt;code&gt;tic_select()&lt;/code&gt; expects a data frame, not a list where the first element
is a data frame and the second a double.&lt;/p&gt;
&lt;p&gt;So what else can be done? Perhaps you’d be tempted to use a global variable for this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic_filter &amp;lt;- function(..., running_time = 0){

  tic &amp;lt;- Sys.time()

  result &amp;lt;- filter(...)

  toc &amp;lt;- Sys.time()

  running_time &amp;lt;&amp;lt;- toc - tic + running_time

  result

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Functions written like this would save the running time in a global variable called &lt;code&gt;running_time&lt;/code&gt;
and each of them would take turns overwriting it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;running_time &amp;lt;- 0

one &amp;lt;- starwars %&amp;gt;%
  tic_filter(species == &amp;quot;Human&amp;quot;, running_time = running_time)

running_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 0.00490284 secs&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;two &amp;lt;- one %&amp;gt;%
  tic_select(species, sex, running_time = running_time)

running_time&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 0.007258415 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(I defined &lt;code&gt;tic_select()&lt;/code&gt; but am not showing it here.)&lt;/p&gt;
&lt;p&gt;This has the advantage that the wrapped functions now return data frames as well, and can thus
be composed/chained. But these functions are not pure functions, because they change something
(the global variable &lt;code&gt;running_time&lt;/code&gt;) outside their scope. Impure functions can be tricky; for instance
here, because the code keeps overwriting the same variable, if you run the whole script and then
separate chunks to try some things, &lt;code&gt;running_time&lt;/code&gt; will keep getting incremented. Once again, you
have to be extra careful and keep track of it, once again overburdening you mentally.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;The solution to this problem looks like one of the previous things we tried, namely:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic_filter &amp;lt;- function(...){

  tic &amp;lt;- Sys.time()

  result &amp;lt;- filter(...)

  toc &amp;lt;- Sys.time()

  running_time &amp;lt;- toc - tic

  list(&amp;quot;result&amp;quot; = result,
       &amp;quot;running_time&amp;quot; = running_time)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While it is true that it returns a list, this function has the yuge advantage of being pure. But
still, we need to solve two problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how to avoid having to rewrite every function;&lt;/li&gt;
&lt;li&gt;how to compose these functions so that the output of one function can be ingested as the input of the next.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Solving the first problem consists in writing a new function that builds functions, what Hadley Wickham
calls &lt;a href=&#34;https://adv-r.hadley.nz/function-factories.html&#34;&gt;function factories&lt;/a&gt;. Let’s try:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;timeit &amp;lt;- function(.f, ..., running_time = 0){

  function(..., .running_time = running_time){

    tic &amp;lt;- Sys.time()

    result &amp;lt;- .f(...)

    toc &amp;lt;- Sys.time()

    list(result = result,
         running_time = toc - tic + .running_time)
  }


}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;timeit()&lt;/code&gt; is a function that takes a function (and its arguments as an input), and returns a new
function. This function returns the result of the original function (&lt;code&gt;.f&lt;/code&gt;) evaluated on its arguments
(&lt;code&gt;...&lt;/code&gt;) as well as the time it took to run as a list. You’ll notice as well that this function
takes another argument, called &lt;code&gt;running_time&lt;/code&gt; with a default value of 0. This will become useful
below, for now, ignore it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_sqrt &amp;lt;- timeit(sqrt)

t_sqrt(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 3.162278
## 
## $running_time
## Time difference of 8.34465e-06 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s great, but we can’t compose these functions. This fails:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_log &amp;lt;- timeit(log)

10 |&amp;gt;
  t_sqrt() |&amp;gt;
  t_log()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Error in .f(...) : non-numeric argument to mathematical function&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;because &lt;code&gt;t_log()&lt;/code&gt; expects a number, not a list. The solution? Write another functions to help!
Let’s call this function bind:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind &amp;lt;- function(.l, .f, ...){

  .f(.l$result, ..., .running_time = .l$running_time)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;bind()&lt;/code&gt; takes a list object returned by a timed function (&lt;code&gt;.l&lt;/code&gt;, with elements &lt;code&gt;$result&lt;/code&gt; and &lt;code&gt;$running_time&lt;/code&gt;)
and applies another timed function &lt;code&gt;.f()&lt;/code&gt; to the &lt;code&gt;$result&lt;/code&gt; element of &lt;code&gt;.l&lt;/code&gt; as well as any further
arguments &lt;code&gt;...&lt;/code&gt; and finally sets the &lt;code&gt;running_time&lt;/code&gt; argument of &lt;code&gt;.f&lt;/code&gt; equal to &lt;code&gt;.l$running_time&lt;/code&gt;.
&lt;code&gt;.l$running_time&lt;/code&gt; is the running time of the previous timed function call, so now this running time
gets added to the running time of &lt;code&gt;.f&lt;/code&gt; (see the definition of the list of &lt;code&gt;timeit()&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;An example might help:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_log &amp;lt;- timeit(log)

10 |&amp;gt;
  t_sqrt() |&amp;gt;
  bind(t_log)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 1.151293
## 
## $running_time
## Time difference of 8.368492e-05 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What’s nice with this solution, is that it works with any function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_filter &amp;lt;- timeit(filter)
t_select &amp;lt;- timeit(select)
t_group_by &amp;lt;- timeit(group_by)
t_summarise &amp;lt;- timeit(summarise)
t_p_longer &amp;lt;- timeit(tidyr::pivot_longer)

starwars %&amp;gt;%
  t_filter(skin_color == &amp;quot;light&amp;quot;) %&amp;gt;% # no need to use bind here
  bind(t_select, species, sex, mass) %&amp;gt;%
  bind(t_group_by, sex, species) %&amp;gt;%
  bind(t_summarise,
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&amp;gt;%
  bind(t_select, -species) %&amp;gt;%
  bind(t_p_longer, -sex, names_to = &amp;quot;statistic&amp;quot;, values_to = &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;sex&amp;#39;. You can override using the `.groups`
## argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120  
## 
## $running_time
## Time difference of 0.09293914 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is some overhead compared to the solution that simply calls &lt;code&gt;tic&lt;/code&gt; at the beginning of
all the &lt;code&gt;{dplyr}&lt;/code&gt; calls and then &lt;code&gt;toc&lt;/code&gt; at the end, but this overhead becomes negligible the longer
the base operations run for. And now the advantage is that you don’t have to think about keeping
track of running times. Re-running separate chunks will also not interfere with the running time
of any other chunk.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;monads&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monads&lt;/h2&gt;
&lt;p&gt;So here we are, ready to learn what monads are, or rather, we’re done, because you already know
what monads are. The solution described before is a monad:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a function factory to create functions that return a special, wrapped value (here it simply was a list of elements &lt;code&gt;$result&lt;/code&gt; and &lt;code&gt;$running_time&lt;/code&gt;). This wrapped value is also called a monadic value.&lt;/li&gt;
&lt;li&gt;a function to compose, or chain, these special functions together.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some other pieces can be added to the list, and one would need to check so-called monadic laws to make
extra sure we’re dealing with a monad, but that’s outside the scope of this blog post.&lt;/p&gt;
&lt;p&gt;There are many monads, for instance the so-called &lt;code&gt;Maybe&lt;/code&gt; monad, available on R thanks to
&lt;a href=&#34;https://twitter.com/armcn_&#34;&gt;Andrew McNeil&lt;/a&gt; who implemented this monad as an R
&lt;a href=&#34;https://armcn.github.io/maybe/&#34;&gt;package&lt;/a&gt;. I have also developed a monad for logging (which
also logs execution time), which I called &lt;code&gt;{chronicler}&lt;/code&gt;, read more about it
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-04-04-chron_post/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To conclude, why did I title this post &lt;em&gt;why you should(n’t) care about Monads if you’re an R programmer&lt;/em&gt;?
The reason is that you can live without monads. However, certain things will be more complex if you
don’t know about monads or if you don’t want to use them, just like functions. If for some reason
you don’t use functions in your code, your life will be more complicated. So should you go ahead
and start using monads in your code? Well, maybe (hehe) you should, especially if you’re doing the
same thing over and over again, like timing your code. Maybe using a monad to time your code could
be a nice solution, especially if you’ve been burned in the past by using the other, sub-optimal
solutions?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extra-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Extra reading&lt;/h2&gt;
&lt;p&gt;If this blog post was not enough to satiate your curiosity, here are some more nice resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/kupac&#34;&gt;Laszlo Kupcsik&lt;/a&gt; great
&lt;a href=&#34;https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/&#34;&gt;blog post&lt;/a&gt; on the maybe monad,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/armcn_&#34;&gt;Andrew McNeil&lt;/a&gt; implementation of the &lt;code&gt;Maybe&lt;/code&gt; monad as a
&lt;a href=&#34;https://armcn.github.io/maybe/&#34;&gt;package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;this nice &lt;a href=&#34;https://www.youtube.com/watch?v=C2w45qRc3aU&#34;&gt;video&lt;/a&gt;
by &lt;a href=&#34;https://www.youtube.com/channel/UCUdkjbeIFea0qUSgwR1CUOg&#34;&gt;Studying With Alex&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;and of course, the GOAT, &lt;a href=&#34;https://twitter.com/BartoszMilewski&#34;&gt;Bartosz Milewski’s&lt;/a&gt;
Category Theory For Programmers on &lt;a href=&#34;https://www.youtube.com/watch?v=I8LbkfSSR58&amp;amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_&#34;&gt;YouTube&lt;/a&gt; if you really want to go into the nitty-gritty theoretical details of functional programming.&lt;/li&gt;
&lt;li&gt;There’s also this very accessible and nice blog post,
&lt;a href=&#34;https://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html&#34;&gt;Functors, applicatives and monads in pictures&lt;/a&gt; which I highly recommend.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The {chronicler} package, an implementation of the logger monad in R</title>
      <link>https://www.brodrigues.co/blog/2022-04-04-chron_post/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-04-04-chron_post/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.haskell.org/Monad_laws&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/monads.jpg&#34; title = &#34;Believe me, the reward is not so great without the struggle. - Wilma Rudolph&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2022-02-18-loudly/&#34;&gt;Back in February&lt;/a&gt; I discussed a package I was working on
which allowed users to add logging to function calls. I named the package &lt;code&gt;{loudly}&lt;/code&gt; but decided
to rename it to &lt;a href=&#34;https://github.com/b-rodrigues/chronicler&#34;&gt;&lt;code&gt;{chronicler}&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have been working on it for the past few weeks, and I think that a CRAN release could happen soon.&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;So what does &lt;code&gt;{chronicler}&lt;/code&gt; do? &lt;code&gt;{chronicler}&lt;/code&gt; allows you do decorate functions, so that they
provide enhanced output:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(chronicler)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rlang&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_sqrt &amp;lt;- record(sqrt)

a &amp;lt;- r_sqrt(1:5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Object &lt;code&gt;a&lt;/code&gt; is now an object of class &lt;code&gt;chronicle&lt;/code&gt;. Let’s print &lt;code&gt;a&lt;/code&gt; to the terminal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ Value computed successfully:
## ---------------
## [1] 1.000000 1.414214 1.732051 2.000000 2.236068
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log().&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as the output says, &lt;code&gt;a&lt;/code&gt; is an object of type &lt;code&gt;chronicle&lt;/code&gt;. Let’s use &lt;code&gt;read_log()&lt;/code&gt; as suggested:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                      
## [2] &amp;quot;✔ sqrt(1:5) ran successfully at 2022-04-01 21:14:28&amp;quot;
## [3] &amp;quot;Total running time: 0.000240325927734375 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The log tells us how &lt;code&gt;a&lt;/code&gt; was built, and it’s especially useful for objects that are the result
of many function calls:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_sqrt &amp;lt;- record(sqrt)
r_exp &amp;lt;- record(exp)
r_mean &amp;lt;- record(mean)

b &amp;lt;- 1:10 |&amp;gt;
  r_sqrt() |&amp;gt;
  bind_record(r_exp) |&amp;gt;
  bind_record(r_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The log gives all the details:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(b)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                           
## [2] &amp;quot;✔ sqrt(1:10) ran successfully at 2022-04-01 21:14:28&amp;quot;    
## [3] &amp;quot;✔ exp(.c$value) ran successfully at 2022-04-01 21:14:28&amp;quot; 
## [4] &amp;quot;✔ mean(.c$value) ran successfully at 2022-04-01 21:14:28&amp;quot;
## [5] &amp;quot;Total running time: 0.00820255279541016 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The end result, or what is called &lt;code&gt;value&lt;/code&gt; can be obtained using &lt;code&gt;pick()&lt;/code&gt; (you could also use &lt;code&gt;a$value&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(a, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.000000 1.414214 1.732051 2.000000 2.236068&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(b, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11.55345&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;composing-decorated-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Composing decorated functions&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;bind_record()&lt;/code&gt; is used to pass the output from one decorated function to the next:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages(
  library(dplyr)
)

r_group_by &amp;lt;- record(group_by)
r_select &amp;lt;- record(select)
r_summarise &amp;lt;- record(summarise)
r_filter &amp;lt;- record(filter)

output &amp;lt;- starwars %&amp;gt;%
  r_select(height, mass, species, sex) %&amp;gt;%
  bind_record(r_group_by, species, sex) %&amp;gt;%
  bind_record(r_filter, sex != &amp;quot;male&amp;quot;) %&amp;gt;%
  bind_record(r_summarise,
              mass = mean(mass, na.rm = TRUE)
              )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                         
## [2] &amp;quot;✔ select(.,height,mass,species,sex) ran successfully at 2022-04-01 21:14:28&amp;quot;           
## [3] &amp;quot;✔ group_by(.c$value,species,sex) ran successfully at 2022-04-01 21:14:28&amp;quot;              
## [4] &amp;quot;✔ filter(.c$value,sex != \&amp;quot;male\&amp;quot;) ran successfully at 2022-04-01 21:14:28&amp;quot;            
## [5] &amp;quot;✔ summarise(.c$value,mean(mass, na.rm = TRUE)) ran successfully at 2022-04-01 21:14:28&amp;quot;
## [6] &amp;quot;Total running time: 0.11384654045105 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The value can then be saved in a new variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(my_df &amp;lt;- pick(output, &amp;quot;value&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can save the &lt;code&gt;output&lt;/code&gt; object with &lt;code&gt;saveRDS()&lt;/code&gt; and share it; your colleague can then read the log
to learn how the object was created.&lt;/p&gt;
&lt;p&gt;This package also ships with a dedicated pipe, &lt;code&gt;%&amp;gt;=%&lt;/code&gt; which you can use instead of &lt;code&gt;bind_record()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;output_pipe &amp;lt;- starwars %&amp;gt;%
  r_select(height, mass, species, sex) %&amp;gt;=%
  r_group_by(species, sex) %&amp;gt;=%
  r_filter(sex != &amp;quot;male&amp;quot;) %&amp;gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(output_pipe, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;condition-handling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Condition handling&lt;/h2&gt;
&lt;p&gt;By default, errors and warnings get caught and composed in the log:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;errord_output &amp;lt;- starwars %&amp;gt;%
  r_select(height, mass, species, sex) %&amp;gt;=%
  r_group_by(species, sx) %&amp;gt;=% # typo, &amp;quot;sx&amp;quot; instead of &amp;quot;sex&amp;quot;
  r_filter(sex != &amp;quot;male&amp;quot;) %&amp;gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;errord_output&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✖ Value computed unsuccessfully:
## ---------------
## [1] NA
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, &amp;quot;value&amp;quot;).
## To read the log of this object, call read_log().&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reading the log tells you which function failed, and with which error message:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_log(errord_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                                                                                                                                    
## [2] &amp;quot;✔ select(.,height,mass,species,sex) ran successfully at 2022-04-01 21:14:28&amp;quot;                                                                                                                      
## [3] &amp;quot;✖ group_by(.c$value,species,sx) ran unsuccessfully with following exception: Must group by variables found in `.data`.\n✖ Column `sx` is not found. at 2022-04-01 21:14:28&amp;quot;                       
## [4] &amp;quot;✖ filter(.c$value,sex != \&amp;quot;male\&amp;quot;) ran unsuccessfully with following exception: no applicable method for &amp;#39;filter&amp;#39; applied to an object of class \&amp;quot;logical\&amp;quot; at 2022-04-01 21:14:28&amp;quot;               
## [5] &amp;quot;✖ summarise(.c$value,mean(mass, na.rm = TRUE)) ran unsuccessfully with following exception: no applicable method for &amp;#39;summarise&amp;#39; applied to an object of class \&amp;quot;logical\&amp;quot; at 2022-04-01 21:14:28&amp;quot;
## [6] &amp;quot;Total running time: 0.163575887680054 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to only capture errors, or catpure errors, warnings and messages using
the &lt;code&gt;strict&lt;/code&gt; parameter of &lt;code&gt;record()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Only errors:

r_sqrt &amp;lt;- record(sqrt, strict = 1)

# Nothing will be captured here, since sqrt(-10) returns a NA and a warning
r_sqrt(-10) |&amp;gt;
  read_log()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in .f(...): NaNs produced&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                     
## [2] &amp;quot;✖ sqrt(-10) ran unsuccessfully with following exception: NA at 2022-04-01 21:14:28&amp;quot;
## [3] &amp;quot;Total running time: 0.000255584716796875 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Errors and warnings:

r_sqrt &amp;lt;- record(sqrt, strict = 2)

# The warning gets captured
r_sqrt(-10) |&amp;gt;
  read_log()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                                
## [2] &amp;quot;✖ sqrt(-10) ran unsuccessfully with following exception: NaNs produced at 2022-04-01 21:14:28&amp;quot;
## [3] &amp;quot;Total running time: 0.00019383430480957 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Errors, warnings and messages

my_f &amp;lt;- function(x){
  message(&amp;quot;this is a message&amp;quot;)
  10
}

record(my_f, strict = 3)(10) |&amp;gt;
                         read_log()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Complete log:&amp;quot;                                                                                     
## [2] &amp;quot;✖ my_f(10) ran unsuccessfully with following exception: this is a message\n at 2022-04-01 21:14:28&amp;quot;
## [3] &amp;quot;Total running time: 0.000336408615112305 secs&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;advanced-logging&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Advanced logging&lt;/h2&gt;
&lt;p&gt;You can provide a function to &lt;code&gt;record()&lt;/code&gt;, which will be evaluated on the output. This makes it possible
to, for example, monitor the size of a data frame throughout the pipeline. In the example below I
provide &lt;code&gt;dim()&lt;/code&gt;, which will return the dimensions of the data frame, as an argument to &lt;code&gt;record()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_group_by &amp;lt;- record(group_by)
r_select &amp;lt;- record(select, .g = dim)
r_summarise &amp;lt;- record(summarise, .g = dim)
r_filter &amp;lt;- record(filter, .g = dim)

output_pipe &amp;lt;- starwars %&amp;gt;%
  r_select(height, mass, species, sex) %&amp;gt;=%
  r_group_by(species, sex) %&amp;gt;=%
  r_filter(sex != &amp;quot;male&amp;quot;) %&amp;gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;$log_df&lt;/code&gt; element of a &lt;code&gt;chronicle&lt;/code&gt; object contains detailed information. In most cases you
don’t need to worry about it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pick(output_pipe, &amp;quot;log_df&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 × 8
##   outcome   `function` arguments message start_time          end_time           
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;dttm&amp;gt;              &amp;lt;dttm&amp;gt;             
## 1 ✔ Success select     &amp;quot;.,heigh… NA      2022-04-01 21:14:28 2022-04-01 21:14:28
## 2 ✔ Success group_by   &amp;quot;.c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:28
## 3 ✔ Success filter     &amp;quot;.c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:29
## 4 ✔ Success summarise  &amp;quot;.c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:29
## # … with 2 more variables: run_time &amp;lt;drtn&amp;gt;, g &amp;lt;list&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but if you want to look at the output of &lt;code&gt;.g&lt;/code&gt;, then you have to grab it and see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I coerce it to a data.frame just for the output here on my blog, to make the column `g` readable
as.data.frame(output_pipe$log_df[, c(&amp;quot;function&amp;quot;, &amp;quot;g&amp;quot;)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    function     g
## 1    select 87, 4
## 2  group_by    NA
## 3    filter 23, 4
## 4 summarise  9, 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the dimension of the dataframe was (87, 4) after the call to &lt;code&gt;select()&lt;/code&gt;, (23, 4)
after the call to &lt;code&gt;filter()&lt;/code&gt; and finally (9, 3) after the call to &lt;code&gt;summarise()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;monads&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monads&lt;/h2&gt;
&lt;p&gt;This package implements a logger monad. I might talk about monads in the future, but probably in a
video; if you don’t know what monads are, don’t worry, no one really knows. Legend has it that to
truly understand what monads are you have to have a PhD in computer science and have been born in
the former Soviet Union. But to make things simple, you can think of a monad as a way to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;embelish functions to provide additional output without having to touch the function’s core behaviour&lt;/li&gt;
&lt;li&gt;a way to compose these functions and work with the embelished outputs (also called monadic values)&lt;/li&gt;
&lt;li&gt;monadic values are basically containers that contain the actual value of the function evaluated on its inputs and something else (here, a log)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Monads are quite useful in some programming languanges, like Haskell. Not so much in R, but I think
that the logger monad I propose here can be quite useful. So let me know if you find it useful or if
you have suggestions!&lt;/p&gt;
&lt;p&gt;You can install &lt;code&gt;{chronicler}&lt;/code&gt; from its &lt;a href=&#34;https://github.com/b-rodrigues/chronicler&#34;&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Capture errors, warnings and messages</title>
      <link>https://www.brodrigues.co/blog/2022-03-12-purely/</link>
      <pubDate>Sat, 12 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-03-12-purely/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vUvut7jOPgs&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/pure.jpg&#34; title = &#34;Hell is side effects&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In my &lt;a href=&#34;https://www.youtube.com/watch?v=vUvut7jOPgs&#34;&gt;last video&lt;/a&gt; I tried to add a feature to my
{loud} package (more info &lt;a href=&#34;https://b-rodrigues.github.io/loud/&#34;&gt;here&lt;/a&gt;) and I succeeded. But in
succeeding in realised that I would need to write a bit more code than what I expected. To make
a long story short: it is possible to capture errors using &lt;code&gt;purrr::safely()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
safe_log &amp;lt;- safely(log)

a &amp;lt;- safe_log(&amp;quot;10&amp;quot;)

str(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ result: NULL
##  $ error :List of 2
##   ..$ message: chr &amp;quot;non-numeric argument to mathematical function&amp;quot;
##   ..$ call   : language .Primitive(&amp;quot;log&amp;quot;)(x, base)
##   ..- attr(*, &amp;quot;class&amp;quot;)= chr [1:3] &amp;quot;simpleError&amp;quot; &amp;quot;error&amp;quot; &amp;quot;condition&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;a&lt;/code&gt; is now a list with elements &lt;code&gt;$result&lt;/code&gt; and &lt;code&gt;$error&lt;/code&gt;. If everything goes right, &lt;code&gt;$result&lt;/code&gt; holds
the result of the operation, and if everything goes wrong, &lt;code&gt;$result&lt;/code&gt; is &lt;code&gt;NULL&lt;/code&gt; but &lt;code&gt;$error&lt;/code&gt; now
contains the error message. This is especially useful in non-interactive contexts. There is
another similar function in &lt;code&gt;{purrr}&lt;/code&gt; called &lt;code&gt;quietly()&lt;/code&gt;, which captures warnings and messages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quiet_log &amp;lt;- quietly(log)

b &amp;lt;- quiet_log(-10)

str(b)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ result  : num NaN
##  $ output  : chr &amp;quot;&amp;quot;
##  $ warnings: chr &amp;quot;NaNs produced&amp;quot;
##  $ messages: chr(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as you can see, providing a negative number to &lt;code&gt;log()&lt;/code&gt; does not cause an error, but simply a
warning. A result of &lt;code&gt;NaN&lt;/code&gt; is returned (you can try with &lt;code&gt;log(-10)&lt;/code&gt; in your console). &lt;code&gt;quietly()&lt;/code&gt;
captures the warning message and returns a list of 4 elements, &lt;code&gt;$result&lt;/code&gt;, &lt;code&gt;$output&lt;/code&gt;, &lt;code&gt;$warnings&lt;/code&gt;
and &lt;code&gt;$messages&lt;/code&gt;. The problem here, is that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;safe_log(-10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in .Primitive(&amp;quot;log&amp;quot;)(x, base): NaNs produced&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] NaN
## 
## $error
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;returns something useless: &lt;code&gt;$result&lt;/code&gt; is &lt;code&gt;NaN&lt;/code&gt; (because that’s what &lt;code&gt;log()&lt;/code&gt; returns for negative
numbers) but &lt;code&gt;$error&lt;/code&gt; is &lt;code&gt;NULL&lt;/code&gt; since no error was thrown, but only a warning! We have a similar
problem with &lt;code&gt;quiet_log()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quiet_log(&amp;quot;10&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in .Primitive(&amp;quot;log&amp;quot;)(x, base) : 
  non-numeric argument to mathematical function&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;here, the error message is thrown, but not captured, since &lt;code&gt;quietly()&lt;/code&gt; does not capture error messages.&lt;/p&gt;
&lt;p&gt;So, are we back to square one? Not necessarily, since you could compose both functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_log &amp;lt;- quietly(safely(log))

a2 &amp;lt;- pure_log(-10)

str(a2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ result  :List of 2
##   ..$ result: num NaN
##   ..$ error : NULL
##  $ output  : chr &amp;quot;&amp;quot;
##  $ warnings: chr &amp;quot;NaNs produced&amp;quot;
##  $ messages: chr(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b2 &amp;lt;- pure_log(&amp;quot;10&amp;quot;)

str(b2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ result  :List of 2
##   ..$ result: NULL
##   ..$ error :List of 2
##   .. ..$ message: chr &amp;quot;non-numeric argument to mathematical function&amp;quot;
##   .. ..$ call   : language .Primitive(&amp;quot;log&amp;quot;)(x, base)
##   .. ..- attr(*, &amp;quot;class&amp;quot;)= chr [1:3] &amp;quot;simpleError&amp;quot; &amp;quot;error&amp;quot; &amp;quot;condition&amp;quot;
##  $ output  : chr &amp;quot;&amp;quot;
##  $ warnings: chr(0) 
##  $ messages: chr(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, in the case of &lt;code&gt;a2&lt;/code&gt;, the warning was captured, and in the case of &lt;code&gt;b2&lt;/code&gt; the error
was captured. The problem, is that the resulting object is quite complex. It’s a list where
&lt;code&gt;$result&lt;/code&gt; is itself a list in case of a warning, or &lt;code&gt;$error&lt;/code&gt; is a list in case of an error.&lt;/p&gt;
&lt;p&gt;I tried to write a function that would decorate a function (as do &lt;code&gt;safely()&lt;/code&gt; and &lt;code&gt;quietly()&lt;/code&gt;), which
in turn would then return a simple list and capture, errors, warnings and messages. I came up with
this code, after re-reading &lt;em&gt;Advanced R&lt;/em&gt;, in particular this
&lt;a href=&#34;https://adv-r.hadley.nz/conditions.html&#34;&gt;chapter&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purely &amp;lt;- function(.f){

  function(..., .log = &amp;quot;Log start...&amp;quot;){

    res &amp;lt;- rlang::try_fetch(
                    rlang::eval_bare(.f(...)),
                    error = function(err) err,
                    #rlang_error = function(rlerr) rlerr,
                    warning = function(warn) warn,
                    message = function(message) message,
                    )

    final_result &amp;lt;- list(
      result = NULL,
      log = NULL
    )

    final_result$result &amp;lt;- if(any(c(&amp;quot;error&amp;quot;, &amp;quot;rlang_error&amp;quot;, &amp;quot;warning&amp;quot;, &amp;quot;message&amp;quot;) %in% class(res))){
                             NA
                           } else {
                             res
                           }

    final_result$log &amp;lt;- if(any(c(&amp;quot;error&amp;quot;, &amp;quot;rlang_error&amp;quot;, &amp;quot;warning&amp;quot;, &amp;quot;message&amp;quot;) %in% class(res))){
                          #res$message
                          purrr::pluck(res, &amp;quot;message&amp;quot;, .default = &amp;quot;undefined error&amp;quot;)
                        } else {
                          NA
                        }
    final_result
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f_m &amp;lt;- function(x){
  message(&amp;quot;this is a message&amp;quot;)
  str(x)
}

f_w &amp;lt;- function(x){
  warning(&amp;quot;this is a warning&amp;quot;)
  str(x)

}

f_e &amp;lt;- function(){
  stop(&amp;quot;This is an error&amp;quot;)

}

pure_fm &amp;lt;- purely(f_m)
pure_fw &amp;lt;- purely(f_w)
pure_fe &amp;lt;- purely(f_e)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Messages get captured:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_fm(10) |&amp;gt;
  str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ result: logi NA
##  $ log   : chr &amp;quot;this is a message\n&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as do warnings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_fw(10) |&amp;gt;
  str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ result: logi NA
##  $ log   : chr &amp;quot;this is a warning&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as do errors:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_fe() |&amp;gt;
  str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ result: logi NA
##  $ log   : chr &amp;quot;This is an error&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The structure of the result is always &lt;code&gt;$result&lt;/code&gt; and &lt;code&gt;$log&lt;/code&gt;. In case everything goes well
&lt;code&gt;$result&lt;/code&gt; holds the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_log &amp;lt;- purely(log)

pure_log(c(1,10))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 0.000000 2.302585
## 
## $log
## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And another example, with a more complex call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_mean &amp;lt;- purely(mean)

pure_mean(c(1,10, NA), na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 5.5
## 
## $log
## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But in case something goes wrong, the error message will get captured.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages(library(dplyr))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {paint} masked print.tbl_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pure_select &amp;lt;- purely(select)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try here to select a column that does not exist:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_mtcars &amp;lt;- mtcars %&amp;gt;%
  pure_select(hp, am, bm) #bm does not exist

str(clean_mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
##  $ result: logi NA
##  $ log   : chr &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare to what happens with &lt;code&gt;select()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_mtcars2 &amp;lt;- mtcars %&amp;gt;%
  select(hp, am, bm) #bm does not exist&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in `select()`:
! Can&amp;#39;t subset columns that don&amp;#39;t exist.
✖ Column `bm` doesn&amp;#39;t exist.
Backtrace:
  1. mtcars %&amp;gt;% select(hp, am, bm)
...
...&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;update-2022-03-13&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Update 2022-03-13&lt;/h2&gt;
&lt;p&gt;After writing this post I realised that the error message of select does not get captured.
This is the only example I’ve found where the error message does not get caught. This
seems to be related to the fact that tidyverse function have their own class of error
messages that inherit from &lt;code&gt;error&lt;/code&gt;. For some reason, there are no issues with other
functions, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;purely(group_by)(mtcars, bm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] NA
## 
## $log
##                                             
## &amp;quot;Must group by variables found in `.data`.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will need to solve this…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;post-continued&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Post continued…&lt;/h2&gt;
&lt;p&gt;The code (and thus the pipeline) completely fails! I’ve added this function to my
&lt;a href=&#34;https://b-rodrigues.github.io/loud/&#34;&gt;{loud}&lt;/a&gt; package, but the biggest benefit of all this is that the
main function of the package, &lt;code&gt;loudly()&lt;/code&gt; now uses &lt;code&gt;purely()&lt;/code&gt; under the hood to provide more useful
log messages in case of failure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressPackageStartupMessages(library(loud))

loud_sqrt &amp;lt;- loudly(sqrt)
loud_mean &amp;lt;- loudly(mean)
loud_exp &amp;lt;- loudly(exp)


result_pipe &amp;lt;- -1:-10 |&amp;gt;
  loud_mean() %&amp;gt;=% # This results in a negative number...
  loud_sqrt() %&amp;gt;=% # which sqrt() does not know how to handle
  loud_exp()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we now inspect &lt;code&gt;result_pipe&lt;/code&gt;, we find a complete log of what went wrong:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result_pipe&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## NULL
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                                                                                                            
## [2] &amp;quot;✔ mean(-1:-10) started at 2022-03-13 14:17:30 and ended at 2022-03-13 14:17:30&amp;quot;                                                                                          
## [3] &amp;quot;✖ CAUTION - ERROR: sqrt(.l$result) started at 2022-03-13 14:17:30 and failed at 2022-03-13 14:17:30 with following message: NaNs produced&amp;quot;                               
## [4] &amp;quot;✖ CAUTION - ERROR: exp(.l$result) started at 2022-03-13 14:17:30 and failed at 2022-03-13 14:17:30 with following message: non-numeric argument to mathematical function&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to know more about &lt;code&gt;{loud}&lt;/code&gt;, I suggest you read
&lt;a href=&#34;https://www.brodrigues.co/blog/2022-02-18-loudly/&#34;&gt;my previous blog post&lt;/a&gt; and if you need a more
realistic example, take a look at
&lt;a href=&#34;https://b-rodrigues.github.io/loud/articles/real-world-example.html&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you try it, please let me know!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Add logging to your functions using my newest package `{loud}`</title>
      <link>https://www.brodrigues.co/blog/2022-02-18-loudly/</link>
      <pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2022-02-18-loudly/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/tuba.jpg&#34; title = &#34;I have nothing to add&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;update-loud-has-been-superseded-by-chronicle-read-about-it-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;UPDATE: {loud} has been superseded by {chronicle}, read about it &lt;a href=&#34;https://www.brodrigues.co/blog/2022-04-04-chron_post/&#34;&gt;here&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is a short blog post to announce the early alpha, hyper unstable, use at your own peril,
package I’ve been working on for the past 6 hours or so
(actually longer if I add all the research/study time).
This package provides the function &lt;code&gt;loudly()&lt;/code&gt; which allows you to do cool stuff like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First two lines install the package
# install.packages(&amp;quot;devtools&amp;quot;)
# devtools::install_github(&amp;quot;b-rodrigues/loud&amp;quot;)
library(loud)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rlang&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loud_sqrt &amp;lt;- loudly(sqrt)

loud_sqrt(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
##  [9] 3.000000 3.162278
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                
## [2] &amp;quot;✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, I start by applying &lt;code&gt;loudly()&lt;/code&gt; to a function, and then I can use this function
as usual. Not only do I get the result, but also a logging message telling me which function and
which arguments got used, and when the computation started and ended.&lt;/p&gt;
&lt;p&gt;It is also possible to chain operations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loud_sqrt &amp;lt;- loudly(sqrt)
loud_exp &amp;lt;- loudly(exp)
loud_mean &amp;lt;- loudly(mean)

1:10 |&amp;gt;
  loud_sqrt() |&amp;gt;
  bind_loudly(loud_exp) |&amp;gt;
  bind_loudly(loud_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 11.55345
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                     
## [2] &amp;quot;✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;     
## [3] &amp;quot;✔ exp(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot; 
## [4] &amp;quot;✔ mean(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice that here I have to use another function called &lt;code&gt;bind_loudly()&lt;/code&gt;. The reason is because
&lt;em&gt;loud&lt;/em&gt; functions return a list. The first element of that list is the result of the function
applied to the inputs, and the second element is the log message. So &lt;code&gt;bind_loudly()&lt;/code&gt; passes the
first element of the output of &lt;code&gt;loud_sqrt()&lt;/code&gt; to the actual function &lt;code&gt;exp()&lt;/code&gt; and also passes the
second element, this time the log message, to the part of the function that concatenates the log
messages.&lt;/p&gt;
&lt;p&gt;This works with any function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loud_group_by &amp;lt;- loudly(group_by)
loud_select &amp;lt;- loudly(select)
loud_summarise &amp;lt;- loudly(summarise)
loud_filter &amp;lt;- loudly(filter)

starwars %&amp;gt;%
  loud_select(height, mass, species, sex) %&amp;gt;%
  bind_loudly(loud_group_by, species, sex) %&amp;gt;%
  bind_loudly(loud_filter, sex != &amp;quot;male&amp;quot;) %&amp;gt;%
  bind_loudly(loud_summarise,
              mass = mean(mass, na.rm = TRUE)
              )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55  
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                                                   
## [2] &amp;quot;✔ select(.,height,mass,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;            
## [3] &amp;quot;✔ group_by(.l$result,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;              
## [4] &amp;quot;✔ filter(.l$result,sex != \&amp;quot;male\&amp;quot;) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;            
## [5] &amp;quot;✔ summarise(.l$result,mean(mass, na.rm = TRUE)) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not perfect however. You’ll notice that the last log message states:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summarise(.l$result,mean(mass, na.rm = TRUE)) ....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ideally I would like for it to say:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summarise(.l$result,mass = mean(mass, na.rm = TRUE)) ....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, I’ve added a pipe operator so you don’t need to use &lt;code&gt;bind_loudly()&lt;/code&gt; if you don’t
want to:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1:10 |&amp;gt;
  loud_sqrt() %&amp;gt;=%
  loud_exp() %&amp;gt;=%
  loud_mean()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## [1] 11.55345
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                     
## [2] &amp;quot;✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;     
## [3] &amp;quot;✔ exp(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot; 
## [4] &amp;quot;✔ mean(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this operator does not work well with &lt;code&gt;{dplyr}&lt;/code&gt; functions. See here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starwars %&amp;gt;%
  loud_select(height, mass, species, sex) %&amp;gt;=%
  loud_group_by(species, sex) %&amp;gt;=%
  loud_filter(sex != &amp;quot;male&amp;quot;) %&amp;gt;=%
  loud_summarise(mass = mean(mass, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi&amp;#39;lek    female           55  
## 
## $log
## [1] &amp;quot;Log start...&amp;quot;                                                                                                   
## [2] &amp;quot;✔ select(.,height,mass,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;            
## [3] &amp;quot;✔ group_by(.l$result,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;              
## [4] &amp;quot;✔ filter(.l$result,sex != \&amp;quot;male\&amp;quot;) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;            
## [5] &amp;quot;✔ summarise(.l$result,mean(mass, na.rm = TRUE)) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you look at the result, you’ll see that it is not equal to the obtained with &lt;code&gt;bind_loudly()&lt;/code&gt;,
and if you look at the last logging message you’ll see why. Instead of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summarise(.l$result,mean(mass, na.rm = TRUE)) ....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the message states:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summarise(.l$result,mass,TRUE) started at&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I know where the problem is (it’s due to some regex fuckery) so I think that I should be able
to correct this in the coming days. Ideally, in the future, I would also like for the users to
provide their own log messages.&lt;/p&gt;
&lt;p&gt;The package has a website with a vignette that shows another interesting example
&lt;a href=&#34;https://b-rodrigues.github.io/loud/articles/real-world-example.html&#34;&gt;here&lt;/a&gt;.
Source code can be found &lt;a href=&#34;https://github.com/b-rodrigues/loud&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is almost certain that function names will change, maybe even the package name itself.
Contributions, bug reports, suggestions, etc, welcome of course.&lt;/p&gt;
&lt;p&gt;A final word: this is the result of me exploring more advanced functional programming
concepts and discussing with really nice people like
&lt;a href=&#34;https://twitter.com/ShinyD3js&#34;&gt;Andrew R Mcneil&lt;/a&gt;,
&lt;a href=&#34;https://twitter.com/kupac&#34;&gt;Laszlo Kupcsik&lt;/a&gt;. Andrew wrote a cool package called
&lt;a href=&#34;https://armcn.github.io/maybe/&#34;&gt;maybe&lt;/a&gt; and Laszlo a super cool blog post
explaining what monads are &lt;a href=&#34;https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll be writing a blog post on monads, in particular the maybe monad soonish.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to write code that returns (Rmarkdown) code</title>
      <link>https://www.brodrigues.co/blog/2021-12-17-expand_knitr/</link>
      <pubDate>Fri, 17 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-12-17-expand_knitr/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Fractal&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/fractal_doge.gif&#34; title = &#34;Nature is fractal&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;One of the most useful aspects of using a programming language instead of… well, not using a programming language,
is that you can write code in a way that minimizes, and ideally, eliminates the need to repeat yourself.&lt;/p&gt;
&lt;p&gt;For instance, you can write a function to show you a frequency table, like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suppressMessages(library(dplyr))

create_table &amp;lt;- function(dataset, var){

  var &amp;lt;- enquo(var)

  dataset %&amp;gt;%
    count(!!var) %&amp;gt;%
    knitr::kable()

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And can now get some fancy looking tables by simply writing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_table(mtcars, cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;cyl&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If I want such tables for hundreds of columns, I can use this function and loop over the columns and
not have to write the code inside the body of the function over and over again. You’ll notice that
the function &lt;code&gt;create_table()&lt;/code&gt; makes use of some advanced programming techniques I have discussed
&lt;a href=&#34;https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/&#34;&gt;here&lt;/a&gt;.
There’s also an alternative way of programming with &lt;code&gt;{dplyr}&lt;/code&gt;, using the &lt;code&gt;{{}}&lt;/code&gt; construct I
discussed &lt;a href=&#34;https://www.brodrigues.co/blog/2019-06-20-tidy_eval_saga/&#34;&gt;here&lt;/a&gt;, but I couldn’t get
what I’m going to show you here to work with &lt;code&gt;{{}}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Recently, I had to create a Rmarkdown document with many sections, where each section title was
a question from a survey and the content was a frequency table. I wanted to write a fuction that
would create a section with the right question title, and then show the table, and I wanted to
then call this function over all the questions from the survey and have my document automatically
generated.&lt;/p&gt;
&lt;p&gt;The result should look like &lt;a href=&#34;https://dazzling-thompson-964d5b.netlify.app/&#34;&gt;this&lt;/a&gt;,
but it would be a PDF instead of HTML.&lt;/p&gt;
&lt;p&gt;Let’s first load the data and see how it looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(purrr)
library(readr)

suppressMessages(
  survey_data &amp;lt;- read_csv(
    &amp;quot;https://gist.githubusercontent.com/b-rodrigues/0c2249dec5a9c9477e0d1ad9964a1340/raw/873bcc7532b8bad613235f029884df1d0b947c90/survey_example.csv&amp;quot;
  )
)

glimpse(survey_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 4
## $ `Random question?`                         &amp;lt;chr&amp;gt; &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, …
## $ `Copy of Random question?`                 &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, …
## $ `Copy of Copy of Random question?`         &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;…
## $ `Copy of Copy of Copy of Random question?` &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each column name is the question, and each row is one answer to the survey question.
To create the document I showed above, you’d probably write something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
## Random question?

` ``{r}

create_table(survey_data, `Random question?`)

` ``

## Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Random question?`)

` ``

## Copy of Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Copy of Random question?`)

` ``

## Copy of Copy of Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Copy of Copy of Random question?`)

` ``
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this gets tedious very quickly, especially if you have 100’s of variables. So
how to not repeat yourself? The solution has two steps; first you should try to automate what you
have as much as possible. Ideally, you don’t want to have to write the complete question every
time. So first, let’s replace the questions by simpler variable names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;questions &amp;lt;- colnames(survey_data)

codes &amp;lt;- paste0(&amp;quot;var_&amp;quot;, seq(1, length(questions)))

lookup &amp;lt;- bind_cols(&amp;quot;codes&amp;quot; = codes, &amp;quot;questions&amp;quot; = questions)

colnames(survey_data) &amp;lt;- codes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;lookup&lt;/code&gt; is a data frame with the questions and their respective codes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lookup&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [4, 2] 
## codes     chr var_1 var_2 var_3 var_4
## questions chr Random question? Copy of Random question? Cop~&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and our data now has simpler variable names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(survey_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 4
## $ var_1 &amp;lt;chr&amp;gt; &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, NA, &amp;quot;no&amp;quot;, NA, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;,…
## $ var_2 &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, NA, &amp;quot;yes&amp;quot;, NA, &amp;quot;n…
## $ var_3 &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;,…
## $ var_4 &amp;lt;chr&amp;gt; &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;, &amp;quot;no&amp;quot;,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doing this allows us to replace the source code of our Rmarkdown like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## `r lookup$questions[grepl(&amp;quot;var_1&amp;quot;, lookup$codes)]`

` ``{r}
create_table(survey_data, var_1)
` ``&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This already makes things easier, as now you only have to change &lt;code&gt;var_1&lt;/code&gt; to &lt;code&gt;var_2&lt;/code&gt; to &lt;code&gt;var_3&lt;/code&gt;…
the inline code gets executed and the right title (the question text) appears. But how to go
further? I don’t want to have to copy and paste this and change &lt;code&gt;var_1&lt;/code&gt; to &lt;code&gt;var_2&lt;/code&gt; etc… So the
second step of the two-step solution is to use a function called &lt;code&gt;knitr_expand()&lt;/code&gt; described
&lt;a href=&#34;https://bookdown.org/yihui/rmarkdown-cookbook/knit-expand.html&#34;&gt;here&lt;/a&gt;. The idea of
&lt;code&gt;knitr::knitr_expand()&lt;/code&gt; is that it uses some Rmd source as a template, and also allows the user to define
some variables that will be replaced at compile time. Simple examples are available
&lt;a href=&#34;https://cran.r-project.org/web/packages/knitr/vignettes/knit_expand.html&#34;&gt;here&lt;/a&gt;. I want to build
upon that, because I need to pass my variable (in this case &lt;code&gt;var_1&lt;/code&gt; for instance) to my function
&lt;code&gt;create_table()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The solution is to write another function that uses &lt;code&gt;knitr::knitr_expand()&lt;/code&gt;. This is how
it could look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_table &amp;lt;- function(dataset, var){

  dataset %&amp;gt;%
    count(!!var) %&amp;gt;%
    knitr::kable()

}


return_section &amp;lt;- function(var){

  a &amp;lt;- knitr::knit_expand(text = c(&amp;quot;## {{question}}&amp;quot;,   create_table(survey_data, var)),
                          question =  lookup$questions[grepl(quo_name(var), lookup$codes)])

  cat(a, sep = &amp;quot;\n&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I needed to edit &lt;code&gt;create_table()&lt;/code&gt; a little bit, and remove the line &lt;code&gt;var &amp;lt;- enquo(var)&lt;/code&gt;. This
is because now, I won’t be passing a variable down to the function, but a quosure, and there is
a very good reason for it, you’ll see. &lt;code&gt;return_section()&lt;/code&gt; makes use of &lt;code&gt;knitr_expand()&lt;/code&gt;,
and the &lt;code&gt;text =&lt;/code&gt; argument is the template that will get expanded. &lt;code&gt;{{question}}&lt;/code&gt; will get
replaced by the variable I defined which is the code I wrote above to automatically get the
question text. Finally, &lt;code&gt;var&lt;/code&gt; will get replaced by the variable I pass to the function.&lt;/p&gt;
&lt;p&gt;First, let’s get it running on one single variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;return_section(quo(var_1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ## Random question?
## |var_1 |  n|
## |:-----|--:|
## |no    | 40|
## |yes   | 44|
## |NA    | 16|&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you see, I had to use &lt;code&gt;quo(var_1)&lt;/code&gt; and not only &lt;code&gt;var_1&lt;/code&gt;. But apart from this, the function seems
to work well. Putting this in an Rmarkdown document would create a section with the question as
the text of the section and a frequency table as the body. I could now copy and paste this and
only have to change &lt;code&gt;var_1&lt;/code&gt;. But I don’t want to have to copy and paste! So the idea would be
to loop the function over a list of variables.&lt;/p&gt;
&lt;p&gt;I have such a list already:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;var_1&amp;quot; &amp;quot;var_2&amp;quot; &amp;quot;var_3&amp;quot; &amp;quot;var_4&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it’s not a list of quosures, but a list of strings, and this is not going to work (it will
return an error):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;walk(codes, return_section)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(I’m using &lt;code&gt;walk()&lt;/code&gt; instead of &lt;code&gt;map()&lt;/code&gt; because &lt;code&gt;return_section()&lt;/code&gt; doesn’t return an object, but only
shows something on screen. This is called a side effect, and &lt;code&gt;walk()&lt;/code&gt; allows you to loop properly
over functions that only return side effects).&lt;/p&gt;
&lt;p&gt;The problem I have now is to convert strings to quosures. This is possible using &lt;code&gt;rlang::sym()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sym_codes &amp;lt;- map(codes, sym)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now I’m done:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;walk(sym_codes, return_section)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ## Random question?
## |var_1 |  n|
## |:-----|--:|
## |no    | 40|
## |yes   | 44|
## |NA    | 16|
## ## Copy of Random question?
## |var_2 |  n|
## |:-----|--:|
## |no    | 52|
## |yes   | 32|
## |NA    | 16|
## ## Copy of Copy of Random question?
## |var_3 |  n|
## |:-----|--:|
## |no    | 46|
## |yes   | 47|
## |NA    |  7|
## ## Copy of Copy of Copy of Random question?
## |var_4 |  n|
## |:-----|--:|
## |no    | 48|
## |yes   | 42|
## |NA    | 10|&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Putting this in an Rmarkdown source create a PDF (or Word, or HTML) document with one section per
question, and without have to do copy-pasting which is quite error-prone. Here is the final
Rmarkdown &lt;a href=&#34;https://gist.github.com/b-rodrigues/843011bb863f27a8fe7f299e13eb4491&#34;&gt;file&lt;/a&gt;. You’ll
notice that the last chunk has the option &lt;code&gt;results = &#39;asis&#39;&lt;/code&gt;, which is needed for this trick
to work.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Speedrunning row-oriented workflows</title>
      <link>https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows/</link>
      <pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=1UkeFwJ-yHI&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/cringe_speedrun.png&#34; title = &#34;Doom&#39;s first level in 8 seconds&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;If you haven’t, you should read &lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast/&#34;&gt;this&lt;/a&gt; first. This is part two.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Speedrunning is the… hrm… - sport? art? - of playing games from start to finish as fast as
possible. Speedrunning requires an insane amount of knowledge of the game being played, as well
as an enourmous amount of skill. Also, contrary to what you might think, it is a community effort.
Players do speedrun the game alone, and it is a ferocious competition, each one of them aiming for the
top spot on the leaderboards. But discovering the strategies that will allow the top players to shave
off, sometimes literally, hundredths of seconds from the previous world record require many, many,
people from the speedrunning community trying to break the games in new ways, or testing how fast
&lt;em&gt;theoretical&lt;/em&gt; strategies using computers that play the game perfectly are (these type of speedruns
are called TAS, for Tool Assisted Speedrun, and are a very important part of the speedrunning effort).&lt;/p&gt;
&lt;p&gt;If you read until here, I commend you dear reader, and thank you for not having already closed the
tab. The meat of the post is coming.&lt;/p&gt;
&lt;p&gt;If you don’t know anything about speedrunning, I can only urge you to watch
&lt;a href=&#34;https://www.youtube.com/watch?v=7rIJNT7dCmE&#34;&gt;this video&lt;/a&gt; about the story of the
Super Mario Bros. World Records. If you’re more into Doom, then watch
&lt;a href=&#34;https://www.youtube.com/watch?v=rqbc4nTivlg&#34;&gt;this video&lt;/a&gt; abut the history of Doom 2 World Records.
It really is worth your time, believe me.&lt;/p&gt;
&lt;p&gt;Anyways, why am I talking about this? What is the point of this blog post? Isn’t this a blog about
&lt;em&gt;Econometrics and Free Software&lt;/em&gt; (lol)?&lt;/p&gt;
&lt;p&gt;The reason I’m talking about speedrunning in video games, is because my
&lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast/&#34;&gt;previous blog post&lt;/a&gt;
sparked an interesting discussion on &lt;a href=&#34;https://twitter.com/brodriguesco/status/1434076568649969665&#34;&gt;twitter&lt;/a&gt;,
which very much reminded me of what you’d see in the speedrunning community.&lt;/p&gt;
&lt;p&gt;Just like in speedrunning, I tried to play a game which consisted in running an arbitrary
function over the rows of a data frame, and employed some basic strategies for it.
As a reminder, here is the example code with the top two strategies: using &lt;code&gt;apply()&lt;/code&gt; and a combination
of &lt;code&gt;asplit()&lt;/code&gt; and &lt;code&gt;map()&lt;/code&gt; (I won’t be showing all the code here, it’s the same as in the
&lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast/&#34;&gt;previous blog post&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_apply &amp;lt;- function(dataset, my_function = my_function){

  dataset %&amp;gt;%
    mutate(score = apply(., MARGIN = 1, my_function))

}

run_map &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    mutate(score = map_dbl(asplit(., 1), .f = my_function))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, just as a reminder, here is the &lt;code&gt;rowwise()&lt;/code&gt; approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_rowwise &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    rowwise() %&amp;gt;%
    mutate(score = my_function(c_across(everything()))) %&amp;gt;%
    ungroup()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is, AFAIK, the &lt;em&gt;official&lt;/em&gt; tidyverse-approach, but not the fastest. However, while it is slower
than the two approaches above, it does have the advantage that you can run the function over the
rows, but only by using certain columns instead of all of them. For example, to apply the function
over only the columns that start with the letter “c” (and for each row), you could write this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_rowwise &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    rowwise() %&amp;gt;%
    mutate(score = my_function(c_across(starts_with(&amp;quot;c&amp;quot;)))) %&amp;gt;%
    ungroup()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not possible with the two fast approaches, &lt;code&gt;run_map()&lt;/code&gt; and &lt;code&gt;run_apply()&lt;/code&gt;. These two approaches
do run quite fast, but in the twitter discussion I linked above, many more
suggestions were made, and some are likely faster, so let’s see! There’s first an approach
using &lt;code&gt;pmap()&lt;/code&gt; proposed by both &lt;a href=&#34;https://twitter.com/lgaborini/status/1434138358381481989&#34;&gt;&lt;code&gt;@lgaborini&lt;/code&gt;&lt;/a&gt;
and &lt;a href=&#34;https://twitter.com/JoeWasserman/status/1434175452457930755&#34;&gt;&lt;code&gt;@&lt;/code&gt;JoeWasserman&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_pmap &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    mutate(score = pmap_dbl(., .f = lift_vd(my_function)))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I won’t go into the details here of how and why this works. For more details,
&lt;a href=&#34;https://github.com/jennybc/row-oriented-workflows/blob/master/ex09_row-summaries.md#how-to-use-an-arbitrary-function-inside-pmap&#34;&gt;click here&lt;/a&gt;.
In any case, this does not run faster that the two approaches listed above. But it does run faster
than using &lt;code&gt;rowwise()&lt;/code&gt; and also allows for selecting columns over which to run the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_pmap &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    mutate(score = pmap_dbl(select(., matches(&amp;quot;.(4|5|6)&amp;quot;)), .f = lift_vd(mean)))

}

run_pmap(dataset) %&amp;gt;%
  head&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 7
##       x1     x2     x3    x4    x5     x6 score
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.0644 0.789  0.489  0.665 0.664 0.230  0.520
## 2 0.771  0.209  0.443  0.248 0.756 0.0164 0.340
## 3 0.342  0.0382 0.619  0.196 0.115 0.783  0.365
## 4 0.638  0.915  0.0472 0.891 0.346 0.639  0.625
## 5 0.0366 0.601  0.426  0.421 0.835 0.906  0.721
## 6 0.0465 0.937  0.260  0.803 0.376 0.330  0.503&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So this is quite useful!&lt;/p&gt;
&lt;p&gt;There was another proposal, a pure base approach, by &lt;a href=&#34;https://twitter.com/grant_mcdermott/status/1434278563994169344&#34;&gt;&lt;code&gt;@grant_mcdermott&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_pure_base &amp;lt;- function(dataset, my_function = my_function){
  dataset |&amp;gt;
    within({score = sapply(asplit(dataset, 1), my_function)})
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It even uses the new, shiny (haha), native pipe, |&amp;gt;! I have not benchmarked this yet, as I’m writing
this, so let’s see…&lt;/p&gt;
&lt;p&gt;Finally, there is also a &lt;code&gt;{data.table}&lt;/code&gt; approach, proposed by
&lt;a href=&#34;https://twitter.com/thatpinkney/status/1434289185532297219?s=20&#34;&gt;&lt;code&gt;@thatpinkney&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)

run_dt2 &amp;lt;- function(dataset, my_function = my_function){

  dataset &amp;lt;- as.data.table(dataset)
  dataset[, rowid := .I]
  dataset[, &amp;quot;:=&amp;quot; (score = melt(dataset, id.vars = &amp;quot;rowid&amp;quot;)[, my_function(value), by = rowid][, V1],
                  rowid = NULL)]

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem of this approach, at least to me, is that I do not know &lt;code&gt;{data.table}&lt;/code&gt;, which
is the reason why I did not include it in the previous blog post. But I have read many times
that &lt;code&gt;{data.table}&lt;/code&gt; is blazing fast, so I definitely should learn at least some basics!&lt;/p&gt;
&lt;p&gt;Now is benchmarking time. Let’s see (I’m not considering &lt;code&gt;run_pmap()&lt;/code&gt;, because I already benchmarked
it before writing this blog post, and know that it runs slower than the &lt;code&gt;run_map()&lt;/code&gt; or &lt;code&gt;run_apply()&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_datasets &amp;lt;- map(seq(2, 5), ~init_pop(objective_function = my_function,
                                          pop_size = `^`(10, .x)))


run_benchmarks &amp;lt;- function(dataset, times = 5){
  microbenchmark::microbenchmark(
                    run_apply(dataset, my_function = my_function),
                    run_pure_base(dataset, my_function = my_function),
                    run_dt2(dataset, my_function = my_function),
                    run_map(dataset, my_function = my_function),
                    times = times,
                    unit = &amp;quot;s&amp;quot;
                  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_results &amp;lt;- map(list_datasets, run_benchmarks)

benchmark_data &amp;lt;- map2(.x = benchmark_results, .y = 10^seq(2, 5), .f = ~mutate(tibble(.x), pop_size = .y)) %&amp;gt;%
  bind_rows() %&amp;gt;%
  mutate(expr = str_remove_all(expr, &amp;quot;\\(.*\\)&amp;quot;)) %&amp;gt;%
  group_by(expr, pop_size) %&amp;gt;%
  mutate(time_seconds = time/10^9) %&amp;gt;%
  summarise(fastest_run = min(time_seconds),
            average_run = mean(time_seconds),
            slowest_run = max(time_seconds))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;expr&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_data %&amp;gt;%
  ggplot(aes(y = average_run, x = pop_size)) +
  geom_ribbon(aes(ymin = fastest_run, ymax = slowest_run, fill = expr), alpha = .6) +
  geom_line(aes(group = expr, col = expr)) +
  ylab(&amp;quot;Seconds&amp;quot;) +
  xlab(&amp;quot;Rows in the dataset&amp;quot;) +
  ggtitle(&amp;quot;Speed of rowwise operations using different methods&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These are really interesting results! The &lt;em&gt;pure&lt;/em&gt; base solution runs almost as fast as the one
that uses &lt;code&gt;asplit()&lt;/code&gt; and &lt;code&gt;map()&lt;/code&gt;. The one that uses &lt;code&gt;apply()&lt;/code&gt; only is a close second, but
all these strategies get obliterated by the &lt;code&gt;{data.table}&lt;/code&gt; solution!&lt;/p&gt;
&lt;p&gt;So, what have we learned?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all, the #RStats community is really great! I’m really blown away by the interest that my previous blog post generated and by the very interesting discussion that ensued.&lt;/li&gt;
&lt;li&gt;Second, if speed is really paramount to solving your problem, you’d probably want to use &lt;code&gt;{data.table}&lt;/code&gt;. It does seem to be incredibly fast!&lt;/li&gt;
&lt;li&gt;Third, and final point, if you need to run rowwise operations, but only over certain columns, use &lt;code&gt;pmap()&lt;/code&gt; instead of &lt;code&gt;rowwise()&lt;/code&gt; - &lt;code&gt;across()&lt;/code&gt; - &lt;code&gt;everything()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The quest for fast(er?) row-oriented workflows</title>
      <link>https://www.brodrigues.co/blog/2021-09-04-quest_fast/</link>
      <pubDate>Sat, 04 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-09-04-quest_fast/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=erlWsquoHlM&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/bell_curve_tidyverse.png&#34; title = &#34;Like and subscribe&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Part 2 of this blog post is available &lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows/&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The past few weeks I have been exploring the speed of R. It started with &lt;a href=&#34;https://www.youtube.com/watch?v=erlWsquoHlM&#34;&gt;this video&lt;/a&gt;
in which I explained that R is not necessarily slower than any other interpreted language, as long
as you’re using the built-in, optimized functions. However should you write your own implementation
of an algorithm, especially if that algorithm requires the use of one (or more…) loops, it’ll
run slowly. As I’ve also mentioned in two other videos, &lt;a href=&#34;https://www.youtube.com/watch?v=3xIKZbZKCWQ&#34;&gt;here&lt;/a&gt;
and &lt;a href=&#34;https://www.youtube.com/watch?v=vxaKamox_CQ&#34;&gt;here&lt;/a&gt; there are many ways to avoid loops, and
you should do so if possible.&lt;/p&gt;
&lt;p&gt;To continue exploring this is in more detail, I’ve written two very basic implementations of a
genetic algorithm. The first version uses only &lt;code&gt;{tidyverse}&lt;/code&gt; functions and the other only base R
functions. My intuition was that base would be faster, but the code would likely be less
“readable” (I discuss this code in greater detail in a series of videos, you can watch
&lt;a href=&#34;https://www.youtube.com/watch?v=bNh2WDdRleI&#34;&gt;part 1&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=KynDephKNz4&#34;&gt;part 2&lt;/a&gt;
if you’re interested in the nitty-gritty details). Code readability is quite subjective, but I think
that there are some general “truths” regarding it, namely that it seems to often be that case that
fast code is code that is “less” readable, and vice-versa. This blog post explores this trade-off
in the context of row-oriented workflows.&lt;/p&gt;
&lt;p&gt;Once I was done writing the two versions of the genetic algorithm for the video
(a &lt;code&gt;{tidyverse}&lt;/code&gt; one and a base one), I profiled the code
and realised that, yes base was much much faster, but also that the reason the &lt;code&gt;{tidyverse}&lt;/code&gt; version
was running so slowly was because of one single row-based operation. Trying to replace this row-based
operation, but remaining inside the &lt;code&gt;{tidyverse}&lt;/code&gt; made for an interesting challenge. I will
explain what I did in this blog post, so first let’s set up the example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s first generate some data. For this, I’m going to use a function I wrote for my genetic
algorithm. I won’t explain how it works, so if you’re curious, you can watch the videos
I mention in the introduction where this is all explained in detail:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;init_pop &amp;lt;- function(objective_function, pop_size = 100, upper_bound = 1, lower_bound = 0){

  parameters &amp;lt;- formals(objective_function)[[1]] %&amp;gt;%
    eval

  purrr::rerun(length(parameters), runif(n = pop_size,
                                         min = lower_bound,
                                         max = upper_bound)) %&amp;gt;%
    dplyr::bind_cols() %&amp;gt;%
    janitor::clean_names()

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes another function, the objective function to be optimized, as an argument,
and checks how many parameters this objective functions has, and generates a population of random
solutions (if you don’t understand what this all means don’t worry. What matters is that this
generates a random dataset whith as many columns as the objective function has arguments).&lt;/p&gt;
&lt;p&gt;The next function is my objective function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_function &amp;lt;- function(x = c(0, 0, 0, 0, 0, 0)){
  x1 &amp;lt;- x[1]
  x2 &amp;lt;- x[2]
  x3 &amp;lt;- x[3]
  x4 &amp;lt;- x[4]
  x5 &amp;lt;- x[5]
  x6 &amp;lt;- x[6]

  -(x1**2 + x2 - 11)**2 - (x1 + x2**2 - 7)**2 - (x3**3 + x4 - 11)**2 - (x5 + x6**2 - 7)**2
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(This is not the same as in the videos, which only has two arguments.)&lt;/p&gt;
&lt;p&gt;Let’s generate some data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- init_pop(my_function) %&amp;gt;%
  as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1        x2          x3        x4         x5        x6
## 1 0.3045714 0.1436057 0.003754794 0.9144551 0.53070392 0.6127125
## 2 0.3155244 0.8890011 0.556325257 0.5688512 0.02928638 0.5626903
## 3 0.8363487 0.6361570 0.667718047 0.4704217 0.10547741 0.5278469
## 4 0.8207208 0.1286540 0.189744816 0.3309174 0.76311349 0.7019268
## 5 0.7244419 0.1284358 0.235967085 0.8444759 0.38697023 0.9818212
## 6 0.2882561 0.9702481 0.983408531 0.1510577 0.84844059 0.7678110&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, on the actual problem: I need to add another column, with the value of &lt;code&gt;my_function()&lt;/code&gt;,
evaluated on a per row basis. As an example, for the first row, this would be the result of:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_function(dataset[1, ])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1
## 1 -299.2624&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many people would probably solve this using a for loop, so let’s write a function to do just that
(benchmarking will make it easier if the code is inside a function):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_loop &amp;lt;- function(dataset, my_function = my_function){

  dataset$score &amp;lt;- 0

  for(i in seq(1, nrow(dataset))){

    dataset$score[i] &amp;lt;- my_function(dataset[i, ])
  }

  dataset

}


run_loop(dataset, my_function = my_function) %&amp;gt;%
  head&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1        x2          x3        x4         x5        x6     score
## 1 0.3045714 0.1436057 0.003754794 0.9144551 0.53070392 0.6127125 -299.2624
## 2 0.3155244 0.8890011 0.556325257 0.5688512 0.02928638 0.5626903 -284.4934
## 3 0.8363487 0.6361570 0.667718047 0.4704217 0.10547741 0.5278469  -275.027
## 4 0.8207208 0.1286540 0.189744816 0.3309174 0.76311349 0.7019268 -288.6529
## 5 0.7244419 0.1284358 0.235967085 0.8444759 0.38697023 0.9818212 -281.0109
## 6 0.2882561 0.9702481 0.983408531 0.1510577 0.84844059 0.7678110 -261.1376&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The advantage of loops is that you don’t need to really know a lot about R to get it done; if you’ve
learned some programming language some time during your studies, you learned about for loops.
But they’re generally slower than other methods and error-prone (typos for example, or if you’re
looping over several indeces, it can get quite complex…). And they’re, in my humble opinion,
not always very easy to understand. This is not the case here, because it is quite a simple example,
but often, it can get quite confusing to understand what is going on.&lt;/p&gt;
&lt;p&gt;So what would be a more “R-specific” way of doing it (specific in the sense that it is not a
universal solution like a for-loop), and which avoids using a loop?
&lt;code&gt;apply()&lt;/code&gt; would here be the best candidate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;apply(dataset, MARGIN = 1, FUN = my_function)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] -299.2624 -284.4934 -275.0270 -288.6529 -281.0109 -261.1376 -293.7069
##   [8] -264.7833 -270.6977 -258.5214 -299.6117 -275.8491 -306.8555 -284.7410
##  [15] -298.6167 -299.2872 -294.9865 -264.5808 -272.8924 -289.5542 -306.3602
##  [22] -293.4290 -305.9189 -276.9193 -286.1938 -291.7530 -289.3610 -290.8470
##  [29] -303.5995 -261.4664 -280.6596 -287.2716 -282.6859 -293.5323 -304.2287
##  [36] -286.9913 -258.3523 -275.9231 -304.3919 -250.9952 -286.7151 -255.0904
##  [43] -312.2109 -254.5034 -255.9284 -287.8201 -285.9853 -290.8199 -309.0086
##  [50] -311.4288 -271.1889 -299.3821 -290.1711 -281.0423 -294.1406 -275.8203
##  [57] -274.1912 -257.7994 -308.3508 -271.5294 -293.3045 -296.9122 -277.8800
##  [64] -296.9870 -314.1470 -270.0065 -288.3262 -252.3774 -263.9164 -286.9263
##  [71] -302.5980 -281.0731 -269.0754 -301.6335 -294.3153 -268.4932 -263.6926
##  [78] -306.9723 -271.8796 -292.6175 -294.0995 -303.4289 -280.5853 -277.6487
##  [85] -262.2476 -310.0217 -281.7774 -292.7697 -295.8509 -269.0880 -253.2403
##  [92] -279.8632 -293.0479 -258.1470 -303.6226 -306.4314 -293.4026 -275.8508
##  [99] -269.6470 -285.0784&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Appending this to a dataframe can be done within a &lt;code&gt;mutate()&lt;/code&gt; call (here again I’m encapsulating
this inside a function, for benchmarking purposes):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_apply &amp;lt;- function(dataset, my_function = my_function){

  dataset %&amp;gt;%
    mutate(score = apply(., MARGIN = 1, my_function))

}

run_apply(dataset, my_function = my_function) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1        x2          x3        x4         x5        x6     score
## 1 0.3045714 0.1436057 0.003754794 0.9144551 0.53070392 0.6127125 -299.2624
## 2 0.3155244 0.8890011 0.556325257 0.5688512 0.02928638 0.5626903 -284.4934
## 3 0.8363487 0.6361570 0.667718047 0.4704217 0.10547741 0.5278469 -275.0270
## 4 0.8207208 0.1286540 0.189744816 0.3309174 0.76311349 0.7019268 -288.6529
## 5 0.7244419 0.1284358 0.235967085 0.8444759 0.38697023 0.9818212 -281.0109
## 6 0.2882561 0.9702481 0.983408531 0.1510577 0.84844059 0.7678110 -261.1376&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;MARGIN = 1&lt;/code&gt; means that the function is applied on the rows, whereas &lt;code&gt;MARGIN = 2&lt;/code&gt; would apply the
function over columns.&lt;/p&gt;
&lt;p&gt;In terms of readability, I think that this is maybe a bit less readable than the for-loop, just
because for-loops as very very ubiquitous. But it’s super simple once you understand how &lt;code&gt;apply()&lt;/code&gt; works.&lt;/p&gt;
&lt;p&gt;Now, what would be a &lt;code&gt;{tidyverse}&lt;/code&gt;-only approach? And why would you want to do a &lt;code&gt;{tidyverse}&lt;/code&gt;-only
approach anyways? Generally, I would argue that scripts written using &lt;code&gt;{tidyverse}&lt;/code&gt; functions and style are
easier to read. For example, I tweeted this code snippet some time ago:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::shortcode(&amp;quot;tweet&amp;quot;,
                    &amp;quot;1431718740341764099&amp;quot;
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I don&amp;#39;t see how one could prefer base  &lt;a href=&#34;https://twitter.com/hashtag/RStats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#RStats&lt;/a&gt;&lt;br&gt;&lt;br&gt;but then again, there&amp;#39;s people out there who like licorice candies... &lt;a href=&#34;https://t.co/bwW74SRDrN&#34;&gt;pic.twitter.com/bwW74SRDrN&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bruno Rodrigues (@brodriguesco@fosstodon.org) (@brodriguesco) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1431718740341764099?ref_src=twsrc%5Etfw&#34;&gt;August 28, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;and in my opinion the example in my tweet shows clearly that the &lt;code&gt;{tidyverse}&lt;/code&gt; code is more easily
understood and readable. Of course, some people disagree…
However, in this case here, I’m not sure that a &lt;code&gt;{tidyverse}&lt;/code&gt; approach &lt;em&gt;would be more readable&lt;/em&gt;.
The solution using &lt;code&gt;apply()&lt;/code&gt; seems to me to be quite good. Let’s see how the &lt;code&gt;{tidyverse}&lt;/code&gt; approach,
which leverages &lt;code&gt;rowwise()&lt;/code&gt;, looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_rowwise &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    rowwise() %&amp;gt;%
    mutate(score = my_function(c_across(everything()))) %&amp;gt;%
    ungroup()
}

run_rowwise(dataset, my_function = my_function) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 7
##      x1    x2      x3    x4     x5    x6 score
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.305 0.144 0.00375 0.914 0.531  0.613 -299.
## 2 0.316 0.889 0.556   0.569 0.0293 0.563 -284.
## 3 0.836 0.636 0.668   0.470 0.105  0.528 -275.
## 4 0.821 0.129 0.190   0.331 0.763  0.702 -289.
## 5 0.724 0.128 0.236   0.844 0.387  0.982 -281.
## 6 0.288 0.970 0.983   0.151 0.848  0.768 -261.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This runs, but much, much, more slower than with &lt;code&gt;apply()&lt;/code&gt; (but faster than a for-loop, as we
shall see) . Plus, it does look much, much
more complicated than the simple &lt;code&gt;apply()&lt;/code&gt; version! So why do it like this? You even need several
functions
- &lt;code&gt;rowwise()&lt;/code&gt;, &lt;code&gt;c_across()&lt;/code&gt; and &lt;code&gt;everything()&lt;/code&gt; - to make it work! So why? Well, there is one use
case in which this approach enables you to do something that I don’t think is possible (or at least
easily possible) with &lt;code&gt;apply()&lt;/code&gt; which is applying the function, but only over certain columns. For example,
if you want to apply the function only over the columns which names all start with the letter “c”,
you could write something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  rowwise() %&amp;gt;%
  mutate(score = mean(c_across(starts_with(&amp;quot;c&amp;quot;)))) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 × 12
##      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb score
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  21       6  160    110  3.9   2.62  16.5     0     1     4     4   5  
##  2  21       6  160    110  3.9   2.88  17.0     0     1     4     4   5  
##  3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1   2.5
##  4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1   3.5
##  5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2   5  
##  6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1   3.5
##  7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4   6  
##  8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2   3  
##  9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2   3  
## 10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4   5  
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this is not needed here, so &lt;code&gt;apply()&lt;/code&gt; clearly wins in terms readability (and speed as well).
But in cases like the above, where you need to compute only over several columns, I think that the
&lt;code&gt;{tidyverse}&lt;/code&gt; version not only is very readible, but actually offers a solution to the problem. I’m
not quite sure you could solve this easily with base, but please prove me wrong.&lt;/p&gt;
&lt;p&gt;In any case, there’s another way to approach our original problem using &lt;code&gt;{tidyverse}&lt;/code&gt; functions,
but we still need the help of a base function.&lt;/p&gt;
&lt;p&gt;The next approach uses the fact that &lt;code&gt;map()&lt;/code&gt; needs both a list and a function as an input. As a
refresher, here’s how map works:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We have a list

my_list &amp;lt;- list(&amp;quot;a&amp;quot; = 2,
                &amp;quot;b&amp;quot; = 4)

# and we have a function, say sqrt, which we want to apply to each element of this list

map(my_list, sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 1.414214
## 
## $b
## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So what we need is a way to mimick the basic approach which works on one “element” (in this case,
a row of the dataframe), and extend that idea to a “list of rows”.
Now, the issue is that a dataframe is actually a list of columns, not rows. So if you’re using
&lt;code&gt;map()&lt;/code&gt; over a dataframe, you will be looping over the columns, not the rows, as in the
example below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This applies the function class() to each colum of mtcars
mtcars %&amp;gt;%
  map(class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $mpg
## [1] &amp;quot;numeric&amp;quot;
## 
## $cyl
## [1] &amp;quot;numeric&amp;quot;
## 
## $disp
## [1] &amp;quot;numeric&amp;quot;
## 
## $hp
## [1] &amp;quot;numeric&amp;quot;
## 
## $drat
## [1] &amp;quot;numeric&amp;quot;
## 
## $wt
## [1] &amp;quot;numeric&amp;quot;
## 
## $qsec
## [1] &amp;quot;numeric&amp;quot;
## 
## $vs
## [1] &amp;quot;numeric&amp;quot;
## 
## $am
## [1] &amp;quot;numeric&amp;quot;
## 
## $gear
## [1] &amp;quot;numeric&amp;quot;
## 
## $carb
## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the question becomes; is there a way to turn a dataframe, which is a list of columns,
into a list of rows? Yes, there is, using &lt;code&gt;asplit()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;asplit(mtcars, MARGIN = 1) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`Mazda RX4`
##    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb 
##  21.00   6.00 160.00 110.00   3.90   2.62  16.46   0.00   1.00   4.00   4.00 
## 
## $`Mazda RX4 Wag`
##     mpg     cyl    disp      hp    drat      wt    qsec      vs      am    gear 
##  21.000   6.000 160.000 110.000   3.900   2.875  17.020   0.000   1.000   4.000 
##    carb 
##   4.000 
## 
## $`Datsun 710`
##    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb 
##  22.80   4.00 108.00  93.00   3.85   2.32  18.61   1.00   1.00   4.00   1.00 
## 
## $`Hornet 4 Drive`
##     mpg     cyl    disp      hp    drat      wt    qsec      vs      am    gear 
##  21.400   6.000 258.000 110.000   3.080   3.215  19.440   1.000   0.000   3.000 
##    carb 
##   1.000 
## 
## $`Hornet Sportabout`
##    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb 
##  18.70   8.00 360.00 175.00   3.15   3.44  17.02   0.00   0.00   3.00   2.00 
## 
## $Valiant
##    mpg    cyl   disp     hp   drat     wt   qsec     vs     am   gear   carb 
##  18.10   6.00 225.00 105.00   2.76   3.46  20.22   1.00   0.00   3.00   1.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;asplit()&lt;/code&gt; splits a dataframe along rows (with the MARGIN argument set to 1) or along columns
(with MARGIN = 2). As you can see with the code above, the &lt;code&gt;mtcars&lt;/code&gt; dataset is now a list of
rows. Each element of this list is a single vector of values.
Now that my dataframe is now a list of rows, well, I can simply use &lt;code&gt;map()&lt;/code&gt; to apply any function
over its rows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_map &amp;lt;- function(dataset, my_function = my_function){
  dataset %&amp;gt;%
    mutate(score = map_dbl(asplit(., 1), .f = my_function))
}

run_map(dataset, my_function = my_function) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          x1        x2          x3        x4         x5        x6     score
## 1 0.3045714 0.1436057 0.003754794 0.9144551 0.53070392 0.6127125 -299.2624
## 2 0.3155244 0.8890011 0.556325257 0.5688512 0.02928638 0.5626903 -284.4934
## 3 0.8363487 0.6361570 0.667718047 0.4704217 0.10547741 0.5278469 -275.0270
## 4 0.8207208 0.1286540 0.189744816 0.3309174 0.76311349 0.7019268 -288.6529
## 5 0.7244419 0.1284358 0.235967085 0.8444759 0.38697023 0.9818212 -281.0109
## 6 0.2882561 0.9702481 0.983408531 0.1510577 0.84844059 0.7678110 -261.1376&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we now have 4 approaches to solve the issue:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;run_loop()&lt;/code&gt;: uses a for-loop&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_apply()&lt;/code&gt;: uses &lt;code&gt;apply()&lt;/code&gt;, a base R function&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_rowwise()&lt;/code&gt;: a “pure” &lt;code&gt;{tidyverse}&lt;/code&gt; approach&lt;/li&gt;
&lt;li&gt;&lt;code&gt;run_map()&lt;/code&gt;: a cross between a &lt;code&gt;{tidyverse}&lt;/code&gt; and a base approach&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s set up a function to run some benchmarks and see which runs faster.
I’ll create a list of increasingly large data frames over which I’ll run all the above functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_datasets &amp;lt;- map(seq(2, 5), ~init_pop(objective_function = my_function,
                                          pop_size = `^`(10, .x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function below will run the benchmarks over all the data frames:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_benchmarks &amp;lt;- function(dataset, times = 5){
  microbenchmark::microbenchmark(
                    run_loop(dataset, my_function = my_function),
                    run_apply(dataset, my_function = my_function),
                    run_rowwise(dataset, my_function = my_function),
                    run_map(dataset, my_function = my_function),
                    times = times,
                    unit = &amp;quot;s&amp;quot;
                  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll run this in parallel using &lt;code&gt;{furrr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(furrr)

plan(multisession, workers = 2)

benchmark_results &amp;lt;- future_map(list_datasets, run_benchmarks)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_data &amp;lt;- map2(.x = benchmark_results, .y = 10^seq(2, 5), .f = ~mutate(tibble(.x), pop_size = .y)) %&amp;gt;%
  bind_rows() %&amp;gt;%
  mutate(expr = str_remove_all(expr, &amp;quot;\\(.*\\)&amp;quot;)) %&amp;gt;%  
  group_by(expr, pop_size) %&amp;gt;%
  mutate(time_seconds = time/10^9) %&amp;gt;%
  summarise(fastest_run = min(time_seconds),
            average_run = mean(time_seconds),
            slowest_run = max(time_seconds))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;expr&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_data %&amp;gt;%
  ggplot(aes(y = average_run, x = pop_size)) +
  geom_ribbon(aes(ymin = fastest_run, ymax = slowest_run, fill = expr), alpha = .6) +
  geom_line(aes(group = expr, col = expr)) +
  ylab(&amp;quot;Seconds&amp;quot;) +
  xlab(&amp;quot;Rows in the dataset&amp;quot;) +
  ggtitle(&amp;quot;Speed of rowwise operations using different methods&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Using a for-loop for row-wise operations is clearly the slowest solution. Let’s take a closer
look at the remaining 3 options:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_data %&amp;gt;%
  filter(!grepl(&amp;quot;loop&amp;quot;, expr)) %&amp;gt;% 
  ggplot(aes(y = average_run, x = pop_size)) +
  geom_ribbon(aes(ymin = fastest_run, ymax = slowest_run, fill = expr), alpha = .6) +
  ylab(&amp;quot;Seconds&amp;quot;) +
  xlab(&amp;quot;Rows in the dataset&amp;quot;) +
  ggtitle(&amp;quot;Speed of rowwise operations using different methods&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rowwise()&lt;/code&gt; loses here, but unless you have to literally run such code hundreds of times, it is still
tolerable. Gives you enough time to browse some memes. But if you have to run such operations
millions of times, you might want to look at either using &lt;code&gt;apply()&lt;/code&gt; or the other approach that uses
&lt;code&gt;asplit()&lt;/code&gt; and &lt;code&gt;map()&lt;/code&gt;. Let’s take a closer look at these two:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;benchmark_data %&amp;gt;%
  filter(!grepl(&amp;quot;loop|rowwise&amp;quot;, expr)) %&amp;gt;%
  ggplot(aes(y = average_run, x = pop_size)) +
  geom_ribbon(aes(ymin = fastest_run, ymax = slowest_run, fill = expr), alpha = .6) +
  geom_line(aes(group = expr, col = expr)) +
  ylab(&amp;quot;Seconds&amp;quot;) +
  xlab(&amp;quot;Rows in the dataset&amp;quot;) +
  ggtitle(&amp;quot;Speed of rowwise operations using different methods&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-09-04-quest_fast_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, the fastest run using &lt;code&gt;map()&lt;/code&gt; was faster than the fastest run using &lt;code&gt;apply()&lt;/code&gt;,
but on average, both methods seem to be equivalent. In conclusion, if you need speed and you
need to compute over every column &lt;code&gt;apply()&lt;/code&gt; is a clear winner. But if you need row-wise operations,
but only on a subset of columns, &lt;code&gt;rowwise()&lt;/code&gt;, even though it is slow, seems to be the only solution.&lt;/p&gt;
&lt;p&gt;I wonder if there is a way to use &lt;code&gt;c_across()&lt;/code&gt; with the &lt;code&gt;map()&lt;/code&gt; approach, and potentially have
the benefits of &lt;code&gt;map()&lt;/code&gt; (as fast as &lt;code&gt;apply()&lt;/code&gt;) and &lt;code&gt;rowwise()&lt;/code&gt; (computing only over certain
columns…). Another subject to explore later.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Part 2 of this blog post is available &lt;a href=&#34;https://www.brodrigues.co/blog/2021-09-05-speedrunning_rows/&#34;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is it worth the weight?</title>
      <link>https://www.brodrigues.co/blog/2021-07-30-worth_weight/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-07-30-worth_weight/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Jt0w9YP_wZ0&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/gaben.jpg&#34; title = &#34;Will we ever see Half Life 3?&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Oh man, I did it again. Grab a coffee, this is going to be a long one.&lt;/p&gt;
&lt;p&gt;Weights got me confused. The justification for using weights seems simple enough; if you’re working
with a sample in which one (or more) strata are over(under)-represented, you should compute
weighted univariate statistics. I’ve discussed this already &lt;a href=&#34;https://www.brodrigues.co/blog/2021-04-17-post_strat/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But what about regression and prediction? There does not seem to be a consensus in the literature.
So I wanted to experiment with some data and see if it would help.&lt;/p&gt;
&lt;p&gt;Spoiler alert: I’m more confused now than before, so maybe stop reading here. But maybe, by reading
this blog post, dear reader, you might spot where I am confused and help me? Any help, comments,
etc. more than welcome.&lt;/p&gt;
&lt;p&gt;Anyway, let’s start by loading the required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;dplyr&amp;quot;)
library(&amp;quot;rsample&amp;quot;)
library(&amp;quot;yardstick&amp;quot;)
library(&amp;quot;readr&amp;quot;)
library(&amp;quot;janitor&amp;quot;)
library(&amp;quot;lubridate&amp;quot;)
library(&amp;quot;broom&amp;quot;)
library(&amp;quot;purrr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and also the required dataset. This is a dataset that I have already featured in one of my previous
blog posts &lt;a href=&#34;https://www.brodrigues.co/blog/2020-02-23-synthpop/&#34;&gt;here&lt;/a&gt;, a blog post about synthetic
datasets. I’ll reuse the description from this other blog post here:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The Survey on the Population in Relation to Activity operation is a continuous source of information on the characteristics and dynamics of the labour force of the Basque Country. It records the relation to productive activity of the population resident in family households, as well as the changes produced in labour situations; it produces indicators of conjunctural variations in the evolution of the active population; it also estimates the degree of participation of the population in economically non-productive activities. It offers information on the province and capital level.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To make it easy for you to follow along, I have re-uploaded the data &lt;a href=&#34;https://raw.githubusercontent.com/rbind/b-rodrigues.github.com/master/public/assets/MICRO_PRA_2021_1.csv&#34;&gt;here&lt;/a&gt;.
For the purposes of my analysis, I’ll be focusing on the “Hours Worked” variable.
I’ll also assume that the dataset is the entire, complete population, and that I will have to deal
with unbiased, randomly sampled individuals, but also with samples that are not randomly sampled.&lt;/p&gt;
&lt;p&gt;Let’s read in the data, rename the columns and do some basic data cleaning:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;population &amp;lt;- read_csv2(&amp;quot;https://raw.githubusercontent.com/rbind/b-rodrigues.github.com/master/public/assets/MICRO_PRA_2021_1.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Using &amp;quot;&amp;#39;,&amp;#39;&amp;quot; as decimal and &amp;quot;&amp;#39;.&amp;#39;&amp;quot; as grouping mark. Use `read_delim()` for more control.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 12757 Columns: 33&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Delimiter: &amp;quot;;&amp;quot;
## chr (10): TERH, EDAD, ENRE, FOCU, BUSQ, GBUSQ, FBUSQ, DISP, PRA2, RACT
## dbl (23): NUMH, AENC, TENC, MUNI, SEXO, LNAC, NACI, LEST, SJUB, SILH, EMPTP,...&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;col_names_english &amp;lt;- c(
  &amp;quot;Household number&amp;quot;,
  &amp;quot;Year of survey&amp;quot;,
  &amp;quot;Reference quarter&amp;quot;,
  &amp;quot;Province&amp;quot;,
  &amp;quot;Capital&amp;quot;,
  &amp;quot;Sex&amp;quot;,
  &amp;quot;Place of birth&amp;quot;,
  &amp;quot;Age&amp;quot;,
  &amp;quot;Nationality&amp;quot;,
  &amp;quot;Level of education&amp;quot;,
  &amp;quot;Formal education system&amp;quot;,
  &amp;quot;Professional training&amp;quot;,
  &amp;quot;Retirement situation&amp;quot;,
  &amp;quot;Household duties situation&amp;quot;,
  &amp;quot;Part-time employment&amp;quot;,
  &amp;quot;Reason for reduced worknig hours&amp;quot;,
  &amp;quot;Job search&amp;quot;,
  &amp;quot;Reasons for seeking employment&amp;quot;,
  &amp;quot;Working hours sought&amp;quot;,
  &amp;quot;Carry out employment seeking activities&amp;quot;,
  &amp;quot;Main employment seeking method&amp;quot;,
  &amp;quot;Months seeking employment&amp;quot;,
  &amp;quot;Availability&amp;quot;,
  &amp;quot;Relation to activity (ILO)&amp;quot;,
  &amp;quot;Relation to activity&amp;quot;,
  &amp;quot;Main occupation&amp;quot;,
  &amp;quot;Main activity&amp;quot;,
  &amp;quot;Main professional situation&amp;quot;,
  &amp;quot;Main institutional sector&amp;quot;,
  &amp;quot;Type of contract&amp;quot;,
  &amp;quot;Hours worked&amp;quot;,
  &amp;quot;Relationship&amp;quot;,
  &amp;quot;Elevator&amp;quot;)

 colnames(population) &amp;lt;- col_names_english

population &amp;lt;- population %&amp;gt;%
  clean_names() %&amp;gt;%
  filter(!is.na(hours_worked)) %&amp;gt;%
  filter(!is.na(part_time_employment)) %&amp;gt;%
  mutate(part_time_employment = ifelse(part_time_employment == 1, &amp;quot;Working full time&amp;quot;, &amp;quot;Working part time&amp;quot;)) %&amp;gt;%
  mutate(type_of_contract = ifelse(is.na(type_of_contract), &amp;quot;Unknown&amp;quot;, type_of_contract)) %&amp;gt;%
  mutate(sex = ifelse(sex == 1, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;)) %&amp;gt;%
  mutate(age_group = case_when(between(age, 4, 7) ~ &amp;quot;1&amp;quot;,
                               between(age, 8, 12) ~ &amp;quot;2&amp;quot;,
                               age &amp;gt; 12 ~ &amp;quot;3&amp;quot;)) %&amp;gt;%
  mutate(type_of_contract = ifelse(type_of_contract %in% c(seq(2, 4), 6), &amp;quot;Other&amp;quot;, type_of_contract)) %&amp;gt;%  
  select(capital,
         sex,
         age_group,
         level_of_education,
         part_time_employment,
         type_of_contract,
         hours_worked) %&amp;gt;%
  mutate(across(-hours_worked, as.factor)) %&amp;gt;%
  mutate(id = row_number())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s put some data on the side, for later:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;holdout &amp;lt;- population %&amp;gt;%
  sample_n(300)

population &amp;lt;- population %&amp;gt;%
  filter(!(id %in% holdout$id))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This holdout set will be useful later on. I’m now going to compute some sampling weights. This weights
will make it easy for me to select biased samples, where part-time workers are over-represented:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
beta0 &amp;lt;- -3.6
beta1 &amp;lt;- 2.63
population &amp;lt;- population %&amp;gt;%
  mutate(pi_x = exp(beta0 + beta1 * I(part_time_employment == &amp;quot;Working part time&amp;quot;)) / (1 + exp(beta0 + beta1 * I(part_time_employment == &amp;quot;Working part time&amp;quot;))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the way, I’ve found this code &lt;a href=&#34;https://stats.stackexchange.com/questions/12857/generate-random-correlated-data-between-a-binary-and-a-continuous-variable/12858#12858&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s see what happens when I randomly sample from the population and compute some basic frequencies,
and then what happens when I sample using the weights. First, the true frequencies of part-time and
full-time workers, on the complete population:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;population %&amp;gt;%
  tabyl(part_time_employment)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  part_time_employment    n   percent
##     Working full time 4107 0.8204155
##     Working part time  899 0.1795845&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, on a random sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000) %&amp;gt;%
  tabyl(part_time_employment)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  part_time_employment   n percent
##     Working full time 823   0.823
##     Working part time 177   0.177&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretty much the same value, now what happens when I don’t have a random sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000, weight = pi_x) %&amp;gt;%
  tabyl(part_time_employment)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  part_time_employment   n percent
##     Working full time 409   0.409
##     Working part time 591   0.591&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This might seem obvious, since I have computed the weights such as to over-represent part-time
workers. But this problem also affects other variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000) %&amp;gt;%
  tabyl(sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     sex   n percent
##  Female 471   0.471
##    Male 529   0.529&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000, weight = pi_x) %&amp;gt;%
  tabyl(sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     sex   n percent
##  Female 633   0.633
##    Male 367   0.367&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because more women work part-time than men, women are now over-represented. The age structure
is also different:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000) %&amp;gt;%
  tabyl(age_group)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  age_group   n percent
##          1 181   0.181
##          2 726   0.726
##          3  93   0.093&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000, weight = pi_x) %&amp;gt;%
  tabyl(age_group)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  age_group   n percent
##          1 215   0.215
##          2 662   0.662
##          3 123   0.123&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And what about what interests us, the hours worked?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000) %&amp;gt;%
  summarise(mean(hours_worked))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   `mean(hours_worked)`
##                  &amp;lt;dbl&amp;gt;
## 1                 29.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample_n(population, 1000, weight = pi_x) %&amp;gt;%
  summarise(mean(hours_worked))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 1
##   `mean(hours_worked)`
##                  &amp;lt;dbl&amp;gt;
## 1                 23.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so this is bad, and the way to deal with it would be to computed post-stratification weights.&lt;/p&gt;
&lt;p&gt;But let’s go a bit further and see what happens if I rerun this a 1000 times. Maybe I just got
very unlucky with my non-random sample? With another sample, maybe things wouldn’t be so bad?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_mean &amp;lt;- mean(population$hours_worked)

random_samples &amp;lt;- rerun(1000, sample_n(population, 1000))

hours_worked_random_samples &amp;lt;- map_df(.x = random_samples,
                                      ~summarise(.x, mean_hours_worked = mean(hours_worked)))

hours_worked_random_samples %&amp;gt;%
  summarise(mean(mean_hours_worked), sd(mean_hours_worked))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   `mean(mean_hours_worked)` `sd(mean_hours_worked)`
##                       &amp;lt;dbl&amp;gt;                   &amp;lt;dbl&amp;gt;
## 1                      29.8                   0.393&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hours_worked_random_samples %&amp;gt;%
  ggplot() +
  geom_density(aes(x = mean_hours_worked)) +
  geom_vline(xintercept = true_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): X11 used font
## size 25 when 29 was requested&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-07-30-worth_weight_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the distribution is centered around the true mean. What about a 1000 biased samples?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;biased_samples &amp;lt;- rerun(1000, sample_n(population, 1000, weight = pi_x))

hours_worked_biased_samples &amp;lt;- map_df(.x = biased_samples,
                                      ~summarise(.x, mean_hours_worked = mean(hours_worked)))

hours_worked_biased_samples %&amp;gt;%
  summarise(mean(mean_hours_worked), sd(mean_hours_worked))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   `mean(mean_hours_worked)` `sd(mean_hours_worked)`
##                       &amp;lt;dbl&amp;gt;                   &amp;lt;dbl&amp;gt;
## 1                      23.4                   0.355&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hours_worked_biased_samples %&amp;gt;%
  ggplot() +
  geom_density(aes(x = mean_hours_worked)) +
  geom_vline(xintercept = true_mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : X11
## used font size 25 when 29 was requested&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-07-30-worth_weight_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, the average hours worked are consistently under-estimated. So it’s not a matter of being
unlucky with one particular sample.&lt;/p&gt;
&lt;p&gt;But what about other tasks, such as prediction and regression? What is the impact there?
This is where I started getting confused.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;regression-and-prediction-with-weights&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regression and prediction (with weights?)&lt;/h2&gt;
&lt;p&gt;Let me first write a function that will do a bunch of things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;split the data into training and testing sets&lt;/li&gt;
&lt;li&gt;run a linear regression&lt;/li&gt;
&lt;li&gt;predict on the testing set&lt;/li&gt;
&lt;li&gt;return the rmse, the coefficients and the model&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_regression &amp;lt;- function(dataset){

  split_unbiased_data &amp;lt;- initial_split(dataset, prop = 0.9)

  training_unbiased_data &amp;lt;- training(split_unbiased_data)

  testing_unbiased_data &amp;lt;- testing(split_unbiased_data)

  linear_model &amp;lt;- lm(hours_worked ~ capital +
                       sex +
                       age_group +
                       level_of_education +
                       part_time_employment +
                       type_of_contract,
                     data = training_unbiased_data)

  lm_predictions &amp;lt;- predict(linear_model,
                            newdata = testing_unbiased_data)

  testing_data_lm_predictions &amp;lt;- testing_unbiased_data %&amp;gt;%
    mutate(lm_pred = lm_predictions)

  lm_rmse &amp;lt;- testing_data_lm_predictions %&amp;gt;%
    rmse(hours_worked, lm_pred)

  lm_result &amp;lt;- broom::tidy(linear_model)

  tribble(~rmse, ~tidy_coeffs, ~model,
          lm_rmse$.estimate, lm_result, linear_model)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now run this on the 1000 random samples and on the 1000 non-random samples:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;many_lms &amp;lt;- map_df(.x = random_samples, ~run_regression(.x))

many_biased_lms &amp;lt;- map_df(.x = biased_samples, ~run_regression(.x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the RMSE of both models:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;many_lms %&amp;gt;%
  summarise(mean(rmse), sd(rmse))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   `mean(rmse)` `sd(rmse)`
##          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1         13.3       1.18&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;many_biased_lms %&amp;gt;%
  summarise(mean(rmse), sd(rmse))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   `mean(rmse)` `sd(rmse)`
##          &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1         12.1       1.08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So… both models perform the same? Hum. What about the coefficients? Well I don’t expect
much difference there now, but let’s see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;random_sample_coefs &amp;lt;- many_lms %&amp;gt;%
  pull(tidy_coeffs) %&amp;gt;%
  bind_rows() %&amp;gt;%
  mutate(tidy_coeffs = &amp;quot;random_sample&amp;quot;)

biased_sample_coefs &amp;lt;- many_biased_lms %&amp;gt;%
  pull(tidy_coeffs) %&amp;gt;%
  bind_rows() %&amp;gt;%
  mutate(tidy_coeffs = &amp;quot;biased_sample&amp;quot;)

true_lm &amp;lt;- lm(hours_worked ~ capital +
                       sex +
                       age_group +
                       level_of_education +
                       part_time_employment +
                       type_of_contract,
                     data = population)

true_lm_coefs &amp;lt;- broom::tidy(true_lm) %&amp;gt;%
  mutate(tidy_coeffs = &amp;quot;true&amp;quot;)

simulations &amp;lt;- bind_rows(random_sample_coefs,
          biased_sample_coefs) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the 1000 coefficients for each variable in a nice violin plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_violin(data = simulations, aes(y = estimate, x = term, fill = tidy_coeffs),
              draw_quantiles = c(0.05, 0.5, 0.95)) +
  geom_point(data = true_lm_coefs, aes(y = estimate, x = term), size = 2) +
  scale_x_discrete(guide = guide_axis(n.dodge = 4)) +
  theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : X11
## used font size 25 when 29 was requested&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-07-30-worth_weight_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The dots are the true coefficients (obtained from a linear regression on the whole data).
The coefficients from the random sample are “more often” closer
to the true coefficients, but it doesn’t seem to be a lot (the bars in the violins are the 5th,
50th and 95th percentile).&lt;/p&gt;
&lt;p&gt;Let’s now see what happens on the holdout set (using the best performing models):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_unbiased_model &amp;lt;- many_lms %&amp;gt;%
  filter(rmse == min(rmse)) %&amp;gt;%
  pull(model) %&amp;gt;%
  .[[1]]

holdout &amp;lt;- holdout %&amp;gt;%
  mutate(unbiased = predict(best_unbiased_model, newdata = holdout))

best_biased_model &amp;lt;- many_biased_lms %&amp;gt;%
  filter(rmse == min(rmse)) %&amp;gt;%
  pull(model) %&amp;gt;%
  .[[1]]

holdout &amp;lt;- holdout %&amp;gt;%
  mutate(biased = predict(best_biased_model, newdata = holdout))

holdout %&amp;gt;%
  rmse(hours_worked, unbiased)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard        13.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;holdout %&amp;gt;%
  rmse(hours_worked, biased)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard        13.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, pretty much no difference… What about hours worked?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;holdout %&amp;gt;%
  summarise(mean_true = mean(hours_worked),
            mean_unbiased = mean(unbiased),
            mean_biased = mean(biased))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##   mean_true mean_unbiased mean_biased
##       &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1      30.4          29.9        29.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Same…??? What about coefficients?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_cols(broom::tidy(best_unbiased_model),
          broom::tidy(best_biased_model)) %&amp;gt;%
  select(term...1, estimate...2, std.error...3, estimate...7, std.error...8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New names:
## * term -&amp;gt; term...1
## * estimate -&amp;gt; estimate...2
## * std.error -&amp;gt; std.error...3
## * statistic -&amp;gt; statistic...4
## * p.value -&amp;gt; p.value...5
## * ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 × 5
##    term...1                estimate...2 std.error...3 estimate...7 std.error...8
##    &amp;lt;chr&amp;gt;                          &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;
##  1 (Intercept)                   30.6           2.11        36.4           1.95 
##  2 capital2                       0.317         1.91        -3.35          1.72 
##  3 capital3                       0.501         1.90        -2.66          1.78 
##  4 capital9                       0.258         1.40        -3.45          1.32 
##  5 sexMale                        3.54          0.946       -0.649         0.915
##  6 age_group2                     0.295         1.29        -0.467         1.09 
##  7 age_group3                    -3.42          1.82        -5.55          1.45 
##  8 level_of_education2           -0.506         1.21         0.439         1.06 
##  9 level_of_education3            0.636         1.20         0.545         1.06 
## 10 part_time_employmentWo…      -13.3           1.23       -14.3           0.960
## 11 type_of_contract5             -0.646         1.20        -1.86          0.982
## 12 type_of_contractOther         -5.74          2.60        -4.98          1.63 
## 13 type_of_contractUnknown        0.378         1.18         3.17          1.25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, some differences here (especially for significant coefficients, which makes sense). So I
guess you &lt;em&gt;should&lt;/em&gt; use weights if you’re interested in the coefficients (and especially their
standard deviation). I definitely need to explore this more, and read some more.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building your own knitr compile farm on your Raspberry Pi with {plumber}</title>
      <link>https://www.brodrigues.co/blog/2021-06-04-own_knit_server/</link>
      <pubDate>Fri, 04 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-06-04-own_knit_server/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4xYu2WrygtQ&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/i_do_my_own_plumbing.png&#34; title = &#34;Always do your own plumbing&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;div id=&#34;rage-is-my-fuel&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rage is my fuel&lt;/h2&gt;
&lt;p&gt;I’ve had the &lt;code&gt;{plumber}&lt;/code&gt; package on my radar for quite some time, but never tried it. However, a
couple of weeks ago, I finally had a reason to try it out and see how the package works.&lt;/p&gt;
&lt;p&gt;One of my main problems in life is that my work laptop runs Windows, and my second problem is that
I need to compile &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; documents (via Rmarkdown) on Windows, and it’s just a pain. Not because
of Rmarkdown, nor &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt;, but because of Windows.
Windows and UTF-8 don’t mix well, and I’ve grown so frustrated that I thought about creating my own
Rmarkdown knitr compile farm using my Raspberry Pi 4 to solve this issue. The idea would be to send
in the encrypted &lt;code&gt;.Rmd&lt;/code&gt; file and get back an encrypted &lt;code&gt;.pdf&lt;/code&gt; file. Dear reader, you surely think
that this is overkill; let me assure you, it is not. I have wasted so much time on Windows because
Windows is a joke that cannot properly handle THE MOST COMMON TEXT ENCODING IN THE UNIVERSE that
this the only way out. Even Yihui Xie, the creator of the &lt;code&gt;{knitr}&lt;/code&gt; package (among many others),
wrote a blog post titled &lt;a href=&#34;https://yihui.org/en/2018/11/biggest-regret-knitr/&#34;&gt;My Biggest Regret in the knitr
Package&lt;/a&gt;, in which he explains how Windows’
crappy handling of UTF-8 made him make a regrettable decision. The issue Yihui Xie discusses is
now resolved since &lt;code&gt;{rmarkdown}&lt;/code&gt; version 2, as stated in the &lt;a href=&#34;https://rmarkdown.rstudio.com/docs/news/#rmarkdown-2-0-2019-12-12&#34;&gt;release
notes&lt;/a&gt; (ctrl-f “utf-8”), but,
for some reason, I still have problems with UTF-8 on Windows. While it is a fact that characters
like the french é, è, ô, ç etc are now properly shown in a compiled document, any such character in
a plot will not show properly, as you can see in the screenshot below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/VBVlHLV.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;I did not really ever notice this issue in the past because I wrote 100% of my documents in English, but
now that I’m a public servant in a country where French is the administrative language, man, am I
having a bad time.&lt;/p&gt;
&lt;p&gt;Now, I make sure my &lt;code&gt;.Rmd&lt;/code&gt; files are encoded in UTF-8, but I still get issues with plots. I tried
changing the graphics device to Cairo or &lt;code&gt;{ragg}&lt;/code&gt;, but I still have these issues.&lt;/p&gt;
&lt;p&gt;Who knows, maybe this is also a case of PEBKAC, but in that case it’s still Windows’ fault for
making me feel bad.&lt;/p&gt;
&lt;p&gt;Anyway, this was reason enough for me to start developing an API that would allow me to get a nice
looking PDF compiled on a serious operating system.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started-docker&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting started: Docker&lt;/h2&gt;
&lt;p&gt;I started by writing a prototype on my local machine that (sort of, but not really) worked, but to
put it on my Raspberry Pi I wanted to create a new Docker image to make deployment easier. For
this, just like I did for this &lt;a href=&#34;https://www.brodrigues.co/blog/2020-09-20-shiny_raspberry/&#34;&gt;other blog
post&lt;/a&gt;, I wrote a ’Dockerfile’ and
pushed an image to Docker Hub. The Dockerfile is heavily inspired by
&lt;a href=&#34;https://github.com/hvalev/shiny-server-arm-docker&#34;&gt;hvalev’s&lt;/a&gt; Dockerfile, and also by the official
&lt;code&gt;plumber&lt;/code&gt; one you can find &lt;a href=&#34;https://github.com/rstudio/plumber/blob/master/Dockerfile&#34;&gt;here&lt;/a&gt;. I then
built the image on my Raspberry Pi.&lt;/p&gt;
&lt;p&gt;You can use the Dockerfile to build your own image, which you can find
&lt;a href=&#34;https://github.com/b-rodrigues/tex-plumber&#34;&gt;here&lt;/a&gt;, or you can pull the one I pushed on
&lt;a href=&#34;https://hub.docker.com/r/brodriguesco/tex-plumber/&#34;&gt;Docker Hub&lt;/a&gt;.
Now, something important: this Docker image does not contain my &lt;code&gt;plumber.R&lt;/code&gt; file. So the first
time you’re going to run it, it’ll fail. You’ll need to make one further adaptation on your server
first.&lt;/p&gt;
&lt;p&gt;Put your &lt;code&gt;plumber.R&lt;/code&gt; where you want, and copy the path to the file.
For instance, suppose that you put the file at: &lt;code&gt;/path/to/your/apis/plumber.R&lt;/code&gt;.
Then, you can finally run the image like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -it -p 8000:8000 -v /path/to/your/apis:/srv/plumber/ --rm --name tex-plumber tex-plumber:latest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Docker looks for a plumber file inside &lt;code&gt;/srv/plumber/&lt;/code&gt; but that’s inside the image; this path
gets sort of linked to your &lt;code&gt;/path/to/your/apis/&lt;/code&gt; and thus the &lt;code&gt;plumber.R&lt;/code&gt; file you put there
will be run. You can also put this there beforehand, adapt the Dockerfile and then build the image.
It’s not the most elegant way to do it, but hey, I’m a beginner.&lt;/p&gt;
&lt;p&gt;These instructions are very general and independent from my API I’m discussing here. What follows
will be specific to my API.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-api-that-ingests-an-rmd-file-and-spits-out-a-compiled-document&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An API that ingests an Rmd file and spits out a compiled document&lt;/h2&gt;
&lt;p&gt;First of all, none of this would have been possible without the following Stackoverflow threads and
Github repos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/63808430/r-plumber-getting-as-excel-xlsx/63809737#63809737&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/63808430/r-plumber-getting-as-excel-xlsx/63809737#63809737&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ChrisBeeley/reports_with_plumber/blob/master/plumber.R&#34; class=&#34;uri&#34;&gt;https://github.com/ChrisBeeley/reports_with_plumber/blob/master/plumber.R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/64639748/how-to-upload-a-xlsx-file-in-plumber-api-as-a-input&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/64639748/how-to-upload-a-xlsx-file-in-plumber-api-as-a-input&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and &lt;a href=&#34;https://github.com/meztez&#34;&gt;Bruno Tremblay’s&lt;/a&gt; help on this
&lt;a href=&#34;https://community.rstudio.com/t/trying-to-understand-whats-wrong-with-my-api/106424?u=brodriguesco&#34;&gt;thread&lt;/a&gt;
I made calling for help. You’ll probably notice that the answers in the stackoverflow threads all
come from Bruno Tremblay, so a big thank you to him!&lt;/p&gt;
&lt;p&gt;With his help, I was able to clob together this API:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#* Knit Rmarkdown document
#* @param data:file The Rmd file
#* @param string The output format
#* @post /knit
# We use serializer contentType, the pdf serializer is the plot output from grDevices
# Since the content is already in the right format from render, we just need to set
# the content-type
#* @serializer contentType list(type = &amp;quot;application/gzip&amp;quot;)
function(data, output_format) { 
  # Save the RMD file to a temporary location
  rmd_doc &amp;lt;- file.path(tempdir(), names(data))
  writeBin(data[[1]], rmd_doc)
  # render document to the selected output format
  # (file will be saved side by side with source and with the right extension)
  output &amp;lt;- rmarkdown::render(rmd_doc, output_format)
  tar(&amp;quot;output.tar.gz&amp;quot;, normalizePath(output), compression = &amp;quot;gzip&amp;quot;, tar = &amp;quot;tar&amp;quot;)
  # remove files on exit
  on.exit({file.remove(rmd_doc, output, &amp;quot;output.tar.gz&amp;quot;)}, add = TRUE)
  # Include file in response as attachment
  value &amp;lt;- readBin(&amp;quot;output.tar.gz&amp;quot;, &amp;quot;raw&amp;quot;, file.info(&amp;quot;output.tar.gz&amp;quot;)$size)
  plumber::as_attachment(value, basename(&amp;quot;output.tar.gz&amp;quot;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will go inside the &lt;code&gt;plumber.R&lt;/code&gt; script. When the Docker image is running, you can hit the
endpoint &lt;code&gt;/knit&lt;/code&gt; to knit a document. But before discussing how to hit the API, let’s go through
the above code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;function(data, output_format) { 
  # Save the RMD file to a temporary location
  rmd_doc &amp;lt;- file.path(tempdir(), names(data))
  writeBin(data[[1]], rmd_doc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes two arguments: &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;output_format&lt;/code&gt;. &lt;code&gt;data&lt;/code&gt; is your Rmd file (I should
have named this better… oh well) that you will send via a POST. The Rmd will get written to a
temporary location. In a previous version of the function I’ve used &lt;code&gt;writeLines&lt;/code&gt; instead of
&lt;code&gt;writeBin&lt;/code&gt; which works as well.&lt;/p&gt;
&lt;p&gt;The next lines render the output as the provided output format (through the second argument,
&lt;code&gt;output_format&lt;/code&gt;) and the output file gets compressed to a &lt;code&gt;tar.gz&lt;/code&gt; archive. Why? The first reason
is, obviously, to save precious bandwidth. The second, most important reason, is for the API to
be able to download it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  output &amp;lt;- rmarkdown::render(rmd_doc, output_format)
  tar(&amp;quot;output.tar.gz&amp;quot;, normalizePath(output), compression = &amp;quot;gzip&amp;quot;, tar = &amp;quot;tar&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The way I understand how this works, is that if you want your API to return
an attachment, you need to set the right content type. This is done by decorating the function
with the right serializer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#* @serializer contentType list(type = &amp;quot;application/gzip&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At first I only wanted PDF files, and thus set the &lt;code&gt;pdf&lt;/code&gt; serializer. This was a mistake, as the
&lt;code&gt;pdf&lt;/code&gt; serializer is only used if the API is supposed to return a plot (in the pdf format).
When this was pointed out to me (in the Rstudio forums), Bruno Tremblay showed me the right solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#* @serializer contentType list(type = &amp;quot;application/pdf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which worked! However, I then thought about how I would make the API more flexible by allowing the
user to compile any format, and this is when I thought about compressing the file and returning
a &lt;code&gt;tar.gz&lt;/code&gt; file instead.&lt;/p&gt;
&lt;p&gt;The first line of the final lines:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  on.exit({file.remove(rmd_doc, output, &amp;quot;output.tar.gz&amp;quot;)}, add = TRUE)
  # Include file in response as attachment
  value &amp;lt;- readBin(&amp;quot;output.tar.gz&amp;quot;, &amp;quot;raw&amp;quot;, file.info(&amp;quot;output.tar.gz&amp;quot;)$size)
  plumber::as_attachment(value, basename(&amp;quot;output.tar.gz&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;simply clean up after exiting. The final lines read in the compressed file in a variable called
&lt;code&gt;variable&lt;/code&gt; which then gets downloaded automatically as an attachment.&lt;/p&gt;
&lt;p&gt;Ok, so now, how do I get a document compiled? With the following script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(httr)
library(magrittr)

my_file &amp;lt;- &amp;quot;testmark&amp;quot;

res &amp;lt;- 
  POST(
    &amp;quot;http://url_to_compile_farm:8000/knit?output_format=html_document&amp;quot;,
    body = list(
      data = upload_file(paste0(my_file, &amp;quot;.Rmd&amp;quot;), &amp;quot;text/plain&amp;quot;)
    )
  ) %&amp;gt;%
  content()

names(res)

output_filename &amp;lt;- file(paste0(my_file, &amp;quot;.tar.gz&amp;quot;), &amp;quot;wb&amp;quot;)
writeBin(object = res, con = output_filename)
close(output_filename)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This script is saved in a folder which also contains &lt;code&gt;testmark.Rmd&lt;/code&gt;, which is the Rmarkdown file
I want to compile (and which gets sent to the server as the &lt;code&gt;data&lt;/code&gt; argument).
You’ll notice in the url that the second argument from my API is defined there:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;quot;http://url_to_compile_farm:8000/knit?output_format=html_document&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you can change &lt;code&gt;html_document&lt;/code&gt; to &lt;code&gt;pdf_document&lt;/code&gt; or &lt;code&gt;word_document&lt;/code&gt; to get a PDF or Word document
respectively.&lt;/p&gt;
&lt;p&gt;I’m pretty happy with this solution, even though it’s quite rough, and still needs some adjustments.
For instance, I want to make sure that I can leave this API running without worry; so I need to build
in some authentication mechanism, which will probably be quite primitive, but perhaps good enough.
I also need to send and receive encrypted documents, and not plain text.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;further-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;p&gt;If you’re into tinkering with Raspberry Pi’s, Rstudio Server an {plumber},
&lt;a href=&#34;https://twitter.com/tyluRp&#34;&gt;Tyler Littlefield&lt;/a&gt;
has a pretty cool &lt;a href=&#34;https://github.com/tyluRp/pirate&#34;&gt;github repo&lt;/a&gt;
with lots of interesting stuff. Definitely give it a look!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dealing with non-representative samples with post-stratification</title>
      <link>https://www.brodrigues.co/blog/2021-04-17-post_strat/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-04-17-post_strat/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=eOBIIB690yE&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/bingo.png&#34; title = &#34;It could have been worse&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s go back to stats 101: what do you do if you want to know how many people like to play bingo
in a certain population? The answer, of course, is to ask a sample of people if they enjoy
playing bingo, compute the proportion and then… we’re done! Right?
Well not exactly. This works if your sample is representative, which in practice, is not often
the case.
I am not an expert of survey methods, very far from it, but I was recently confronted to a similar
issue at work. So in this blog post I want to talk about estimating a proportion using a sample
that is not representative of the population using a method called “post-stratification”.&lt;/p&gt;
&lt;p&gt;By the way, before continuing, I also made a video about this topic if you’re interested,
watch it &lt;a href=&#34;https://www.youtube.com/watch?v=eOBIIB690yE&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The data I use in this blog post is simulated; so I know the “truth”, since I made the data, and can
thus compare the results from post-stratification to the truth. At the end of the blog post, I
will post the complete source code, but for now, let’s suppose that this is my sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(survey)
library(janitor)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_sample_1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 904 x 2
##    age_group likes_bingo_1
##    &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 20-49                 0
##  2 20-49                 0
##  3 20-49                 0
##  4 20-49                 0
##  5 20-49                 0
##  6 20-49                 0
##  7 20-49                 0
##  8 20-49                 0
##  9 20-49                 0
## 10 20-49                 1
## # … with 894 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s suppose that we have asked people two questions: their age, and whether or not they like
bingo. Using this sample, I obtain the following result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- mean(my_sample_1$likes_bingo_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So according to this sample, 38.38% of people in my population like bingo.
But is that right? Let’s use the other piece of information we have: the interviewee’s ages. This
is the distribution of the age group in my sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_sample_1 %&amp;gt;%
  tabyl(age_group)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  age_group   n    percent
##        19-  40 0.04424779
##      20-49 174 0.19247788
##      50-79 540 0.59734513
##        80+ 150 0.16592920&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to compare this to the distribution of the same age groups in the population. Thankfully,
this is something that is readily available in most (all?) countries. National statistical
institutes publish such data on a yearly basis. This is the distribution in the population:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;age_distribution_population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  age_group     n    percent
##        19- 12825 0.21865516
##      20-49 25833 0.44043032
##      50-79 17779 0.30311658
##        80+  2217 0.03779793&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, our sample is completely off! Elderly people are over-represented while younger
people are under-represented. Perhaps this happened because elderly people love bingo more
than younger people and, when given the opportunity to confess their love for bingo, are more
willing to answer to a survey. Whatever the reason, it would be unreasonable to assume that the
proportion given by our sample is a good, unbiased, estimate of the true proportion in the population.&lt;/p&gt;
&lt;p&gt;What we would like to do here, is to compute weights for each individual in the sample, such that
individuals from over-represented groups contribute less to the computation of the proportion than
individuals from under-represented groups. This is where post-stratification and raking come
into play. As already said, I’m not an expert of these methods. So don’t believe that this blog
post is a tutorial. However, what I’m going to show you might come in handy.&lt;/p&gt;
&lt;p&gt;We’re going to use the &lt;code&gt;{survey}&lt;/code&gt; package to compute the weights using raking, by post-stratifying
the sample on age group. This can be done with two commands:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;unweighted_data &amp;lt;- svydesign(ids = ~1, data = my_sample_1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in svydesign.default(ids = ~1, data = my_sample_1): No weights or
## probabilities supplied, assuming equal probability&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weighted_data &amp;lt;- rake(design = unweighted_data,
                      sample.margins = list(~age_group),
                      population.margins = list(pop_marginal_age))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first function, &lt;code&gt;svydesign()&lt;/code&gt; allows you to create a new object based on your data, which
specifies the &lt;a href=&#34;https://stats.oecd.org/glossary/detail.asp?ID=3852&#34;&gt;design&lt;/a&gt; of your study. In this
case, I have used &lt;code&gt;ids = ~1&lt;/code&gt; to say “I don’t have any weights, nor anything specific to tell you”.
Next, using the &lt;code&gt;rake()&lt;/code&gt; function, I can compute the weights. For this, I need the object I created
before, the variable I want to post-stratify on, and then give a table that contains the distribution
of said variable in the population. This table looks a bit different from the one I already
showed you: it doesn’t contain the categories’ frequencies, and the variable containing the counts
is called &lt;code&gt;Freq&lt;/code&gt; (&lt;code&gt;rake()&lt;/code&gt; looks for this variable so it must be named like this):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pop_marginal_age &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   age_group  Freq
## 1       19- 12825
## 2     20-49 25833
## 3     50-79 17779
## 4       80+  2217&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now take a look at the weights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(weights(weighted_data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   14.78   32.92   32.92   64.88   32.92  320.62&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In cases where you have very high or very low weights, the literature recommends trimming them.
However, I have not seen anything very definitive on this, and it seems that practitioners rely
on rules of thumb and gut feeling to know when to trim weights. In my example here, I don’t think
it is needed, but as I said, I have no intuition for this. Anyways, we are now ready to compute the
new proportion:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;svymean(~likes_bingo_1, weighted_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  mean     SE
## likes_bingo_1 0.19343 0.0121&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is quite different from before (it was 38.38% in the “raw” sample)!
Because I have simulated the data, I can now compare to the “true” value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eusilcP %&amp;gt;%
  summarise(mean(likes_bingo_1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean(likes_bingo_1)
## 1           0.1830225&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we’re quite close!&lt;/p&gt;
&lt;p&gt;Now let’s continue a little bit, with a more complicated example. Imagine that I collected five
samples, one per week. Each sample contains totally different people (no person gets asked twice).
Also, imagine that while I’m collecting my samples and analyzing them, bingo fever is running amok
in my country, always infecting more and more people. As time passes, the proportion of people who
love bingo keeps increasing. So my population’s parameter keeps changing, and each week, when I get
a new sample, the proportion in my sample will also grow on a weekly basis.
Because of this, I have to compute weights each week. Thankfully, the distribution of age groups in
my population can be assumed to stay constant, so I don’t need to think about that.&lt;/p&gt;
&lt;p&gt;Let’s take a look at my sample which contains 5 weeks of data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;samples&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 31,590 x 3
##    age_group week            yes
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
##  1 20-49     likes_bingo_1     0
##  2 20-49     likes_bingo_2     0
##  3 20-49     likes_bingo_3     0
##  4 20-49     likes_bingo_4     0
##  5 20-49     likes_bingo_5     0
##  6 20-49     likes_bingo_1     0
##  7 20-49     likes_bingo_2     0
##  8 20-49     likes_bingo_3     0
##  9 20-49     likes_bingo_4     0
## 10 20-49     likes_bingo_5     1
## # … with 31,580 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each row is one person, and this person gets sample exactly once. The &lt;code&gt;yes&lt;/code&gt; variable collects the
answer to the question “do you like bingo?”. Let’s see how my proportion evolves through time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(samples_likes_bingo_through_time &amp;lt;- samples %&amp;gt;%
  group_by(week) %&amp;gt;%
  summarise(freq = mean(yes)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   week           freq
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
## 1 likes_bingo_1 0.256
## 2 likes_bingo_2 0.446
## 3 likes_bingo_3 0.550
## 4 likes_bingo_4 0.618
## 5 likes_bingo_5 0.662&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that it keeps increasing: this is a good sign, since we know that this is also the case
in the population. We just don’t know by how much. Let’s compute weights for each week, and then
recompute estimated proportions using these weights. In order to do this, I will write a function
that will make it easy to do just that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_weekly_weights &amp;lt;- function(sample_df){

  unweighted_data &amp;lt;- svydesign(ids = ~1, data = sample_df)

  rake(design = unweighted_data,
       sample.margins = list(~age_group),
       population.margins = list(pop_marginal_age))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function does the exact same thing as before. But it will now make it easy to apply to each
week using the &lt;code&gt;group_by&lt;/code&gt;-&lt;code&gt;nest&lt;/code&gt;-&lt;code&gt;map&lt;/code&gt; approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weighted_samples &amp;lt;- samples %&amp;gt;%
  group_nest(week) %&amp;gt;%
  mutate(weights = map(data, compute_weekly_weights)) %&amp;gt;%
  mutate(svymeans = map(weights, ~svymean(~yes, .)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in svydesign.default(ids = ~1, data = sample_df): No weights or
## probabilities supplied, assuming equal probability

## Warning in svydesign.default(ids = ~1, data = sample_df): No weights or
## probabilities supplied, assuming equal probability

## Warning in svydesign.default(ids = ~1, data = sample_df): No weights or
## probabilities supplied, assuming equal probability

## Warning in svydesign.default(ids = ~1, data = sample_df): No weights or
## probabilities supplied, assuming equal probability

## Warning in svydesign.default(ids = ~1, data = sample_df): No weights or
## probabilities supplied, assuming equal probability&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at this object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weighted_samples&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 4
##   week                    data weights    svymeans     
##   &amp;lt;chr&amp;gt;         &amp;lt;list&amp;lt;tibble&amp;gt;&amp;gt; &amp;lt;list&amp;gt;     &amp;lt;list&amp;gt;       
## 1 likes_bingo_1    [6,318 × 2] &amp;lt;srvy.ds2&amp;gt; &amp;lt;svystat [1]&amp;gt;
## 2 likes_bingo_2    [6,318 × 2] &amp;lt;srvy.ds2&amp;gt; &amp;lt;svystat [1]&amp;gt;
## 3 likes_bingo_3    [6,318 × 2] &amp;lt;srvy.ds2&amp;gt; &amp;lt;svystat [1]&amp;gt;
## 4 likes_bingo_4    [6,318 × 2] &amp;lt;srvy.ds2&amp;gt; &amp;lt;svystat [1]&amp;gt;
## 5 likes_bingo_5    [6,318 × 2] &amp;lt;srvy.ds2&amp;gt; &amp;lt;svystat [1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So for each week, I have now a &lt;code&gt;svydesign&lt;/code&gt; object and also a new, hopefully unbiased, proportion
of people who like bingo. The following lines simply but this into a nice tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weighted_samples &amp;lt;- weighted_samples %&amp;gt;%
  mutate(svymeans = map(svymeans, as_tibble)) %&amp;gt;%
  select(week, svymeans) %&amp;gt;%
  unnest(cols = svymeans) %&amp;gt;%
  rename(freq = mean,
         SE = yes) %&amp;gt;%
  mutate(is = &amp;quot;corrected_sample&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To conclude, let’s create a plot that compares the proportions computed without using weights to the
proportions computed with weights to the true values that I simulated myself. I put everything
in a data frame and the create the plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_data &amp;lt;- bind_rows(weighted_samples, # my corrected data
                      mutate(samples_likes_bingo_through_time, is = &amp;quot;raw_sample&amp;quot;), # the raw samples
                      mutate(likes_bingo_through_time, is = &amp;quot;true_value&amp;quot;)) %&amp;gt;% # the true, simulated, values
  mutate(SE = ifelse(is.na(SE), 0, SE))

ggplot(all_data) +
  geom_ribbon(aes(y = freq, x = week,
                  ymin = freq - 2*SE,
                  ymax = freq + 2*SE,
                  group = is),
              fill = &amp;quot;pink&amp;quot;,
              alpha = .3) +
  geom_line(aes(y = freq, x = week, colour = is, group = is)) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-04-17-post_strat_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that the proportions computed without weights were clearly over-estimating the true
share of bingo enthusiasts in the population. The weighted proportions are very close to the true
values and are acceptable estimates of the true proportions!&lt;/p&gt;
&lt;p&gt;If you want to take a look at the source code, go &lt;a href=&#34;https://gist.github.com/b-rodrigues/d9efe80f879f95d305cd661b63e2dee9&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The link between keyboard layouts and typing speed - Data collection phase</title>
      <link>https://www.brodrigues.co/blog/2021-03-28-survey/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-03-28-survey/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://forms.gle/vprM4C8yk1bBGCNx8&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/JXueyyT.png&#34; title = &#34;Touch typing can also help fight zombies&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’m curious about different keyboard layouts, and how that correlates with typing speed (if at all).
I prepared a little 2 minute survey, and would be very grateful if you could take it. You can
find it on this &lt;a href=&#34;https://forms.gle/vprM4C8yk1bBGCNx8&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There’s no R code in this blog post, but I’ll be analyzing the data using R, promise :)&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to treat as many files as fit on your hard disk without loops (sorta) nor running out of memory all the while being as lazy as possible</title>
      <link>https://www.brodrigues.co/blog/2021-03-19-no_loops_tidyeval/</link>
      <pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-03-19-no_loops_tidyeval/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=DERMZi3Ck20&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/30b.png&#34; title = &#34;Click to watch the Netflix adaptation of this blog post&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;tl;dr&lt;/h1&gt;
&lt;p&gt;This blog post is going to be long, and deal with many topics. But I think you’re going to enjoy
it. So get a hot beverage and relax. Take the time to read. We don’t take enough time to read
anymore. It’s a shame.
But if you’re really busy, the tl;dr is that I found out a way of combining tidy evaluation and
functional programming to analyze potentially millions of files (as many as fit on your hard disk)
without running out of memory in R. As an example, I’m going to use the 15000ish Excel files
from the Enron Corpus. It’s a pretty neat blog post, if I may say so myself, so you definitely
should read it. If at the end you think I wasted your time, you can file a complaint
&lt;a href=&#34;https://is.gd/LFX1YS&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;If you’ve been a faithful reader of this blog, or if you watch my &lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;
you’ve very likely seen me write code that looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rlang)
library(tidyxl)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_plot &amp;lt;- mtcars %&amp;gt;%
  group_nest(am) %&amp;gt;% #shortcut for group_by(am) %&amp;gt;% nest() 
  mutate(plots = map2(.y = am, .x = data, ~{ggplot(data = .x) +
                              geom_smooth(aes(y = mpg, x = hp), colour = &amp;quot;#82518c&amp;quot;) +
                                ggtitle(paste0(&amp;quot;Miles per gallon as a function of horse power for am = &amp;quot;, .y)) +
                                theme_blog()}))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new data frame that looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_plot&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##      am           data plots 
##   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;lt;tibble&amp;gt;&amp;gt; &amp;lt;list&amp;gt;
## 1     0      [19 × 10] &amp;lt;gg&amp;gt;  
## 2     1      [13 × 10] &amp;lt;gg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In three lines of code, I grouped the &lt;code&gt;mtcars&lt;/code&gt; dataframe by the variable &lt;code&gt;am&lt;/code&gt; and then created
two plots, which are contained in a new column called &lt;code&gt;plots&lt;/code&gt;. If you’re unfamiliar with R, it is
quite likely that you’ve never seen anything like this. If you have experience with functional
programming languages though, you might recognize what’s going on.
Essentially, &lt;code&gt;map2()&lt;/code&gt; &lt;em&gt;loops&lt;/em&gt; over two variables, &lt;code&gt;am&lt;/code&gt; and &lt;code&gt;data&lt;/code&gt; (this variable is not in the original
data frame, but gets created as a result of the &lt;code&gt;group_nest(am)&lt;/code&gt; call) and applies a function,
in this case a call to &lt;code&gt;ggplot()&lt;/code&gt;, to generate two plots…
If you’ve never seen this before, I invite you to read the section dedicated to this type of
workflows on my &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/functional-programming.html#list-based-workflows-for-efficiency&#34;&gt;ebook&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the plots:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_plot %&amp;gt;%
  pull(plots)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-19-no_loops_tidyeval_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39; and formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-19-no_loops_tidyeval_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The advantage of this workflow is that you don’t have to think much about anything -once you understand
how it works-. The alternative would be two create two separate data frames, and create two separate
plots. That’s a totally valid solution, unless you need to create hundreds of plots. With the
workflow above, it doesn’t matter if the &lt;code&gt;am&lt;/code&gt; variable has 2 or 2000 levels. The code would look
exactly the same.&lt;/p&gt;
&lt;p&gt;This workflow is very flexible. You can even use this approach to read in, and analyze, many, many
files. As many as, for instance, 15931 Excel files from an American oil company that went bust in
the early 2000’s, Enron.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-enron-corpus&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Enron Corpus&lt;/h1&gt;
&lt;p&gt;I won’t go into much detail about the Enron Corpus, but to make a long story short:
Big evil American oil company went bust, company emails got released for research purposes after
being purchased for 10000USD by a computer scientist, and many of these emails had Excel spreadsheets
attached to them. Other computer scientist released spreadsheets for research purposes. You can
read the whole story on &lt;a href=&#34;https://www.felienne.com/archives/3634&#34;&gt;Felienne Hermans’ blog&lt;/a&gt; (read it, it’s quite interesting).&lt;/p&gt;
&lt;p&gt;Anyways, you can now get this treasure trove of nightmarish Excel spreadsheets by clicking &lt;a href=&#34;https://figshare.com/articles/dataset/Enron_Spreadsheets_and_Emails/1221767&#34;&gt;here&lt;/a&gt;
(this is the link provided in the blog post by Felienne Hermans). I already discussed this
in a &lt;a href=&#34;https://www.brodrigues.co/blog/2020-11-21-guis_mistake/&#34;&gt;previous blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On Felienne Hermans’ blog post, you can spot the following table:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i0.wp.com/www.felienne.com/wp-content/uploads/2014/10/Table1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;I’m going to show how this table could be replicated using R and the &lt;code&gt;mutate()&lt;/code&gt;-&lt;code&gt;map()&lt;/code&gt; workflow
above.&lt;/p&gt;
&lt;p&gt;First, let’s load one single spreadsheet with &lt;code&gt;{tidyxl}&lt;/code&gt; and get some of the code ready that we
will need. Let’s get all the paths to all the files in a vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_paths &amp;lt;- list.files(path = &amp;quot;~/six_to/spreadsheets&amp;quot;,
                         pattern = &amp;quot;.xlsx&amp;quot;,
                         full.names = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s work with the first one. Let’s read it in with &lt;code&gt;{tidyxl}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(example_xlsx &amp;lt;- xlsx_cells(list_paths[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 19,859 x 21
##    sheet       address   row   col is_blank data_type error logical numeric
##    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;lgl&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 Preschedule A1          1     1 FALSE    date      &amp;lt;NA&amp;gt;  NA           NA
##  2 Preschedule B1          1     2 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  3 Preschedule C1          1     3 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  4 Preschedule D1          1     4 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  5 Preschedule E1          1     5 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  6 Preschedule F1          1     6 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  7 Preschedule G1          1     7 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  8 Preschedule H1          1     8 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
##  9 Preschedule I1          1     9 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## 10 Preschedule J1          1    10 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## # … with 19,849 more rows, and 12 more variables: date &amp;lt;dttm&amp;gt;, character &amp;lt;chr&amp;gt;,
## #   character_formatted &amp;lt;list&amp;gt;, formula &amp;lt;chr&amp;gt;, is_array &amp;lt;lgl&amp;gt;,
## #   formula_ref &amp;lt;chr&amp;gt;, formula_group &amp;lt;int&amp;gt;, comment &amp;lt;chr&amp;gt;, height &amp;lt;dbl&amp;gt;,
## #   width &amp;lt;dbl&amp;gt;, style_format &amp;lt;chr&amp;gt;, local_format_id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The beauty of &lt;code&gt;{tidyxl}&lt;/code&gt; is that it can read in a very complex and ugly Excel file without any issues.
Each cell of the spreadsheet is going to be one row of the data set, the contents of all cells is now
easily accessible. Let’s see how many sheets are in there:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_xlsx %&amp;gt;%
  summarise(n_sheets = n_distinct(sheet))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   n_sheets
##      &amp;lt;int&amp;gt;
## 1       11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;11… that’s already quite a lot. How many formulas are there per sheet?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_xlsx %&amp;gt;%
  mutate(is_formula = !is.na(formula)) %&amp;gt;%  
  group_by(sheet) %&amp;gt;%
  summarise(n_formula = sum(is_formula)) %&amp;gt;%
  arrange(desc(n_formula))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 11 x 2
##    sheet                  n_formula
##    &amp;lt;chr&amp;gt;                      &amp;lt;int&amp;gt;
##  1 Preschedule                 2651
##  2 Deals                        324
##  3 Economics                    192
##  4 Balancing                     97
##  5 Fuel                          70
##  6 Comp                           0
##  7 EPEData                        0
##  8 HeatRate                       0
##  9 spin reserve log sheet         0
## 10 Top                            0
## 11 Unit Summary                   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s a sheet in there with 2651 formulas. This is insane. Anyways, as you can see, &lt;code&gt;{tidyxl}&lt;/code&gt;
makes analyzing what’s inside such Excel files quite simple. Let’s now create functions that will
compute what we need. I won’t recreate everything from the table, but you’ll very quickly get
the idea. Let’s start with a function to count spreadsheets that contain at least one formula:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;at_least_one_formula &amp;lt;- function(x){

  (any(!is.na(x$formula)))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get the number of worksheets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sheets &amp;lt;- function(x){

  x %&amp;gt;%
    summarise(n_sheets =  n_distinct(sheet)) %&amp;gt;%
    pull(n_sheets)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And how many formulas are contained in a spreadsheet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_formulas &amp;lt;- function(x){

  x %&amp;gt;%
    mutate(is_formula = !is.na(formula)) %&amp;gt;%
    summarise(n_formula = sum(is_formula)) %&amp;gt;%
    pull(n_formula)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s stop here. We could of course continue adding functions, but that’s enough to illustrate
what’s coming.
Let’s just define one last function. This function will call all three functions defined above,
and return the result in a dataframe. You’ll see why soon enough:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_stats &amp;lt;- function(x){

  tribble(~has_formula, ~n_sheets, ~n_formulas,
          at_least_one_formula(x), n_sheets(x), n_formulas(x))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try it out on our single spreadsheet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_stats(example_xlsx)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   has_formula n_sheets n_formulas
##   &amp;lt;lgl&amp;gt;          &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1 TRUE              11       3334&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Neat.&lt;/p&gt;
&lt;p&gt;Now, let’s see how we can apply these function to 15k+ Excel spreadsheets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;no-loops-ever-allowed&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;No loops ever allowed&lt;/h1&gt;
&lt;p&gt;10 years ago, I was confronted to a similar problem. I had a pretty huge amount of files on
a computer that I needed to analyze for a chapter of my Phd thesis. The way I solved this issue
was by writing a loop that looked horrible and did what I needed on each file. It did the job, but
it did not look good, and was a nightmare whenever I needed to modify it, which I needed to do often.
I had to think about a structure to hold the results; it was a nested list with I think 4 or 5 levels,
and I had to keep track of the dimensions in my head to make sure I was writing the right result in the
right spot. It wasn’t pleasant.
Until this week, I thought that such a loop was the only real solution to such a problem.&lt;/p&gt;
&lt;p&gt;But a comment on one of my youtube video changed this:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/youtube_comment.png&#34; title = &#34;Click to watch the Netflix adaptation of this blog post&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The comment was made on &lt;a href=&#34;https://www.youtube.com/watch?v=vtxb1j0aqJM&#34;&gt;this video&lt;/a&gt; in which I create
a data set like in the introduction to this blog post, but instead of having 2 groups (and thus
2 datasets), I had 100. Now, in the video this wasn’t an issue, but what if instead of having 100
datasets, I had 15k+? And what if these datasets were quite huge? For example, the largest
spreadsheet in the Enron Corpus is 40MiB. Loading it with &lt;code&gt;{tidyxl}&lt;/code&gt; returns a tibble with 17 million
rows, and needs 2GiB of RAM in a clean R session. If you want to read in all the 15k+, you’re simply
going to run out of memory even before you could analyze anything.
As I’ve written above, the solution would be to loop over each file, do whatever I need done, and
save the results in some kind of structure (very likely some complex nested list).
Or is it the only solution?
Turns out that I tried some things out and found a solution that does not require changing my
beloved &lt;code&gt;mutate()&lt;/code&gt;-&lt;code&gt;map()&lt;/code&gt; workflow.&lt;/p&gt;
&lt;p&gt;Let’s first start by putting the paths in a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(enron &amp;lt;- enframe(list_paths, name = NULL, value = &amp;quot;paths&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15,871 x 1
##    paths                                                                        
##    &amp;lt;chr&amp;gt;                                                                        
##  1 /home/cbrunos/six_to/spreadsheets/albert_meyers__1__1-25act.xlsx             
##  2 /home/cbrunos/six_to/spreadsheets/albert_meyers__2__1-29act.xlsx             
##  3 /home/cbrunos/six_to/spreadsheets/andrea_ring__10__ENRONGAS(1200).xlsx       
##  4 /home/cbrunos/six_to/spreadsheets/andrea_ring__11__ENRONGAS(0101).xlsx       
##  5 /home/cbrunos/six_to/spreadsheets/andrea_ring__12__ENRONGAS(1200).xlsx       
##  6 /home/cbrunos/six_to/spreadsheets/andrea_ring__13__Trader &amp;amp; Products 5-15-01…
##  7 /home/cbrunos/six_to/spreadsheets/andrea_ring__14__Trader &amp;amp; Products 5-16-01…
##  8 /home/cbrunos/six_to/spreadsheets/andrea_ring__15__IFERCnov.xlsx             
##  9 /home/cbrunos/six_to/spreadsheets/andrea_ring__16__ifercdec.xlsx             
## 10 /home/cbrunos/six_to/spreadsheets/andrea_ring__17__IFERCJan.xlsx             
## # … with 15,861 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the purposes of this blog post, let’s limit ourselves to 30 spreadsheets. This won’t impact
how the code is going to work, nor memory usage. It’s just that I won’t my post to compile quickly
while I’m writing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(enron &amp;lt;- head(enron, 30)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 1
##    paths                                                                        
##    &amp;lt;chr&amp;gt;                                                                        
##  1 /home/cbrunos/six_to/spreadsheets/albert_meyers__1__1-25act.xlsx             
##  2 /home/cbrunos/six_to/spreadsheets/albert_meyers__2__1-29act.xlsx             
##  3 /home/cbrunos/six_to/spreadsheets/andrea_ring__10__ENRONGAS(1200).xlsx       
##  4 /home/cbrunos/six_to/spreadsheets/andrea_ring__11__ENRONGAS(0101).xlsx       
##  5 /home/cbrunos/six_to/spreadsheets/andrea_ring__12__ENRONGAS(1200).xlsx       
##  6 /home/cbrunos/six_to/spreadsheets/andrea_ring__13__Trader &amp;amp; Products 5-15-01…
##  7 /home/cbrunos/six_to/spreadsheets/andrea_ring__14__Trader &amp;amp; Products 5-16-01…
##  8 /home/cbrunos/six_to/spreadsheets/andrea_ring__15__IFERCnov.xlsx             
##  9 /home/cbrunos/six_to/spreadsheets/andrea_ring__16__ifercdec.xlsx             
## 10 /home/cbrunos/six_to/spreadsheets/andrea_ring__17__IFERCJan.xlsx             
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so now, in order to read in all these files, I would write the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;enron %&amp;gt;%
  mutate(datasets = map(paths, xlsx_cells))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would create a new column called &lt;code&gt;datasets&lt;/code&gt; where each element would be a complete data set.
If I run this in my 30 examples, it might be ok. But if I run it on the full thing, there’s no way
I’m not going to run out of RAM. So how to solve this issue? How to run my neat &lt;code&gt;get_stats()&lt;/code&gt;
function on all datasets if I cannot read in the data? The solution is to only read in the data
when I need it, and only one dataset at a time. The solution is to build a &lt;em&gt;lazy&lt;/em&gt; tibble. And this
is possible using &lt;code&gt;quo()&lt;/code&gt;. To quickly grasp what &lt;code&gt;quo()&lt;/code&gt; does, let’s try calling the following
expression once with, and once without &lt;code&gt;quo()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;runif(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0.98342755 0.13500737 0.06196822 0.61304269 0.30600919 0.48015570
##  [7] 0.05747049 0.04535318 0.37880304 0.70647563&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This runs &lt;code&gt;runif(10)&lt;/code&gt; returning 10 randomly generated numbers, as expected.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quo(unif(10))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;quosure&amp;gt;
## expr: ^unif(10)
## env:  global&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This instead returns a quosure, which to be honest, is a complex beast. I’m not sure I get it
myself. The definition, is that quosures are &lt;em&gt;quoted expressions that keep track of an environment&lt;/em&gt;.
For our practical purposes, we can use that to delay when the data gets read in, and that’s all
that matters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(enron &amp;lt;- enron %&amp;gt;%
   mutate(datasets = map(paths, ~quo(xlsx_cells(.)))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 2
##    paths                                                                datasets
##    &amp;lt;chr&amp;gt;                                                                &amp;lt;list&amp;gt;  
##  1 /home/cbrunos/six_to/spreadsheets/albert_meyers__1__1-25act.xlsx     &amp;lt;quosur…
##  2 /home/cbrunos/six_to/spreadsheets/albert_meyers__2__1-29act.xlsx     &amp;lt;quosur…
##  3 /home/cbrunos/six_to/spreadsheets/andrea_ring__10__ENRONGAS(1200).x… &amp;lt;quosur…
##  4 /home/cbrunos/six_to/spreadsheets/andrea_ring__11__ENRONGAS(0101).x… &amp;lt;quosur…
##  5 /home/cbrunos/six_to/spreadsheets/andrea_ring__12__ENRONGAS(1200).x… &amp;lt;quosur…
##  6 /home/cbrunos/six_to/spreadsheets/andrea_ring__13__Trader &amp;amp; Product… &amp;lt;quosur…
##  7 /home/cbrunos/six_to/spreadsheets/andrea_ring__14__Trader &amp;amp; Product… &amp;lt;quosur…
##  8 /home/cbrunos/six_to/spreadsheets/andrea_ring__15__IFERCnov.xlsx     &amp;lt;quosur…
##  9 /home/cbrunos/six_to/spreadsheets/andrea_ring__16__ifercdec.xlsx     &amp;lt;quosur…
## 10 /home/cbrunos/six_to/spreadsheets/andrea_ring__17__IFERCJan.xlsx     &amp;lt;quosur…
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This takes less than a second to run, and not just because I only have 30 paths. Even if I was
working on the complete 15k+ datasets, this would run in an instant. That’s because we’re actually
not reading in anything yet. We’re only setting the scene.&lt;/p&gt;
&lt;p&gt;The magic happens now: we’re going to now map our function that computes the stats we need.
We only need to change one thing. Let’s see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_stats &amp;lt;- function(x){

  x &amp;lt;- eval_tidy(x)

  tribble(~has_formula, ~n_sheets, ~n_formulas,
          at_least_one_formula(x), n_sheets(x), n_formulas(x))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve added this line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- eval_tidy(x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This evaluates the quosure, thus instantiating the dataset, and then proceeds to make all the
computations. Let’s see what happens when we run this on our lazy tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(enron &amp;lt;- enron %&amp;gt;%
   mutate(stats = map(datasets, get_stats)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 3
##    paths                                                  datasets  stats       
##    &amp;lt;chr&amp;gt;                                                  &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;      
##  1 /home/cbrunos/six_to/spreadsheets/albert_meyers__1__1… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  2 /home/cbrunos/six_to/spreadsheets/albert_meyers__2__1… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  3 /home/cbrunos/six_to/spreadsheets/andrea_ring__10__EN… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  4 /home/cbrunos/six_to/spreadsheets/andrea_ring__11__EN… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  5 /home/cbrunos/six_to/spreadsheets/andrea_ring__12__EN… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  6 /home/cbrunos/six_to/spreadsheets/andrea_ring__13__Tr… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  7 /home/cbrunos/six_to/spreadsheets/andrea_ring__14__Tr… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  8 /home/cbrunos/six_to/spreadsheets/andrea_ring__15__IF… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
##  9 /home/cbrunos/six_to/spreadsheets/andrea_ring__16__if… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
## 10 /home/cbrunos/six_to/spreadsheets/andrea_ring__17__IF… &amp;lt;quosure&amp;gt; &amp;lt;tibble [1 …
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What happened here is nothing short of black magic: one by one, each quosure was instantiated, and
the required stats were computed, then the dataset was thrown into the garbage before moving
on to the next quosure. This means that RAM usage was kept to a minimum, and I could have run
this over my 15k+ spreadsheets without any issue. You can watch me run similar code in
my video &lt;a href=&#34;https://youtu.be/DERMZi3Ck20?t=820&#34;&gt;here&lt;/a&gt;; I show how my RAM usage does not move
even though I’m mapping over all the Excel sheets.
The column &lt;code&gt;stats&lt;/code&gt; now holds one dataframe with one row and three columns for each Excel file.
Because &lt;code&gt;stats&lt;/code&gt; is a list-column of dataframes, we can use &lt;code&gt;unnest()&lt;/code&gt; to get to the data.
Let’s take a closer look on one dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;enron %&amp;gt;%
  head(1) %&amp;gt;%
  select(paths, stats) %&amp;gt;%
  unnest(cols = stats)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 4
##   paths                                          has_formula n_sheets n_formulas
##   &amp;lt;chr&amp;gt;                                          &amp;lt;lgl&amp;gt;          &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;
## 1 /home/cbrunos/six_to/spreadsheets/albert_meye… TRUE              11       3334&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that by using &lt;code&gt;unnest()&lt;/code&gt;, the two columns inside the nested dataframe get expanded and
become columns of the “main” dataframe.&lt;/p&gt;
&lt;p&gt;We’re done, but let’s clean up the dataset a little bit and take a look at the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  enron &amp;lt;- enron %&amp;gt;%
    mutate(excel_file = str_remove(paths, &amp;quot;/home/cbrunos/six_to/spreadsheets/&amp;quot;)) %&amp;gt;%
    select(-paths, -datasets) %&amp;gt;%
    unnest(cols = stats)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 4
##    has_formula n_sheets n_formulas excel_file                                   
##    &amp;lt;lgl&amp;gt;          &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;                                        
##  1 TRUE              11       3334 albert_meyers__1__1-25act.xlsx               
##  2 TRUE              11       3361 albert_meyers__2__1-29act.xlsx               
##  3 TRUE               4        550 andrea_ring__10__ENRONGAS(1200).xlsx         
##  4 TRUE               4        549 andrea_ring__11__ENRONGAS(0101).xlsx         
##  5 TRUE               4        550 andrea_ring__12__ENRONGAS(1200).xlsx         
##  6 FALSE              0          0 andrea_ring__13__Trader &amp;amp; Products 5-15-01 E…
##  7 FALSE              0          0 andrea_ring__14__Trader &amp;amp; Products 5-16-01 E…
##  8 TRUE               1        169 andrea_ring__15__IFERCnov.xlsx               
##  9 TRUE               1        177 andrea_ring__16__ifercdec.xlsx               
## 10 TRUE               1        162 andrea_ring__17__IFERCJan.xlsx               
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Getting some statistics is now easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;enron %&amp;gt;%
  summarise(average_n_formulas = mean(n_formulas),
            max_sheets = max(n_sheets))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   average_n_formulas max_sheets
##                &amp;lt;dbl&amp;gt;      &amp;lt;int&amp;gt;
## 1               490.         11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the way, now that we see that the code works, we can run it on all the spreadsheets simply
by not running the following line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(enron &amp;lt;- head(enron, 30)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, we can quite easily run all of this in parallel using &lt;code&gt;{furrr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(furrr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: future&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plan(multiprocess, workers = 12)

enron &amp;lt;- enframe(list_paths, name = NULL, value = &amp;quot;paths&amp;quot;)

enron &amp;lt;- head(enron, 1200) #just to compile the document faster, I only consider 1200 Excel spreadsheets

enron &amp;lt;- enron %&amp;gt;%
   mutate(datasets = map(paths, ~quo(xlsx_cells(.))))

start &amp;lt;- Sys.time()
enron &amp;lt;- enron %&amp;gt;%
  mutate(stats = future_map(datasets, get_stats))
Sys.time() - start&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 36.86839 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Same code, no parallelization (it takes longer, obviously):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;enron &amp;lt;- enframe(list_paths, name = NULL, value = &amp;quot;paths&amp;quot;)

enron &amp;lt;- head(enron, 1200)

enron &amp;lt;- enron %&amp;gt;%
   mutate(datasets = map(paths, ~quo(xlsx_cells(.))))

start &amp;lt;- Sys.time()
enron &amp;lt;- enron %&amp;gt;%
  mutate(stats = map(datasets, get_stats))
Sys.time() - start&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 1.217199 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this is pretty neat.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using explainability methods to understand (some part) of the spread of COVID-19 in a landlocked country</title>
      <link>https://www.brodrigues.co/blog/2021-03-05-covid_lu/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-03-05-covid_lu/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/b-rodrigues/covid_pred&#34;&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Luxembourg_City_pano_Wikimedia_Commons.jpg/800px-Luxembourg_City_pano_Wikimedia_Commons.jpg&#34; title = &#34;Click to go to visualisations&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;This blog post is based on an article I’m currently working on which you can find
&lt;a href=&#34;https://github.com/b-rodrigues/covid_pred&#34;&gt;here&lt;/a&gt;. Contributions more than welcome!&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;you-expect-me-to-read-all-this&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;“You expect me to read all this?”&lt;/h2&gt;
&lt;p&gt;The gist of this blog post can be summarised in the following sentence:
lagged positive cases of the neighbouring regions of Luxembourg predict weekly positive cases in Luxembourg.
But prediction is not the goal of all this, but rather, understanding. Go grab a hot beverage and
read on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Due to its quite unique characteristics, the spread of COVID-19 in a landlocked country like
Luxembourg is the exact opposite of the spread of COVID-19 that can be observed on an island
country such as New Zealand, or Madagascar. A landlocked country like Luxembourg, which is
furthermore highly dependent on foreign workers (50% of Luxembourg’s workforce are non-residents
commuters from France, Belgium and Germany), has many more difficulties to control the spread
of COVID-19 within its borders. Unlike an island country, a landlocked country that is highly tied
to its neighbours cannot simply close its borders and put a very hard lockdown in place to control
the pandemic. Or if the landlocked country does that, as soon as it opens its borders, the disease
will start spreading again. To illustrate this idea, I will discuss how COVID-19 starting
spreading, but not only within the borders of Luxembourg, but rather within the so-called Greater
Region. The Greater Region is &lt;em&gt;a space for cross-border cooperation in the heart of Europe&lt;/em&gt; and is
composed of the Grand-Duchy of Luxembourg, two Belgian Provinces, two French Départements and two
German Bundesländer.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/b-rodrigues/covid_pred/blob/master/paper/figs/commuters.png?raw=true&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The figure above shows a map of the Greater Region with the flows of daily commuters between
its constituent regions. Every day, according to this map from 2018, more than 150000 commuters
go to Luxembourg to work. In 2019, it was reported that this number reached 200000.&lt;/p&gt;
&lt;p&gt;The approach I will be using here is thus as follows: I will train a machine learning model to predict the
spread of COVID-19 in Luxembourg using openly available data on the weekly positive cases of
COVID-19. However, because of the very tight economic and social integration of Luxembourg to its
neighbours I will use as features weekly positive cases in the border regions as well as
&lt;a href=&#34;https://www.google.com/covid19/mobility/&#34;&gt;Google Mobility data&lt;/a&gt; for Luxembourg
to proxy for hard, and soft, lockdowns. I will show that lags of weekly cases in the neighbouring
regions predict cases for Luxembourg. The end goal however, is &lt;em&gt;not&lt;/em&gt; to build a model to predict
how many weekly positive cases will be detected in Luxembourg. This would be a fools errand;
in order to predict the future, the future has to look like the past, but in the case of this pandemic
there is absolutely no guarantee that the future will look like the past, and there are many reasons
for this. First of all, people are constantly adapting their behaviour, and public health policies
are also constantly being tuned, and getting sometimes more restrictive, sometimes more relaxed.
Secondly, vaccines have started being administrated and it would be impossible to predict the effect
on weekly positive cases using the approach I’m using. Finally, there’s also the threat of the
variants. Here again, it is impossible to predict which new variants could arise and how much more
contagious -and deadly- these could be.
So then, why bother? The end goal is not prediction, but explainability. Once the
model is trained, I will use explainability methods to show which variables, and their interaction
with each other, predict positive cases for Luxembourg. This will be a clear illustration of the
hypothesis that I posited at the beginning; that a landlocked country like Luxembourg which is very
tightly economically and socially integrated with its neighbours cannot fight a pandemic on its own,
but must cooperate with its neighbours. This argument can also be applied to any other country in
the same situation as Luxembourg or even to the constituent states of a federal nation. Unfortunately,
the virus does not respect the borders of sovereign nations.&lt;/p&gt;
&lt;p&gt;This blog post won’t be a tutorial, I will only present some interesting results. I think that I
will do a walkthrough tutorial of the methods that I use here in a video, as it will make things
easier to explain.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data-to-replicate-the-results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The data to replicate the results&lt;/h1&gt;
&lt;p&gt;Data on positive cases from the regions of the Greater Region was collected through each of the
countries’ open data portal. The levels of detail were heterogeneous, with Belgium and Germany
providing a high level of detail (daily cases by sex, age group, Province in the case of Belgium, and
Land- and Stadtkreise in the case of Germany), followed by France (daily cases by department and
age group), with Luxembourg providing the least amount of details; only daily cases at the national
level.
In order to simplify the process of getting the data from all these sources, I wrote an R package
called &lt;code&gt;{covidGrandeRegion}&lt;/code&gt; which can be found on the following &lt;a href=&#34;https://github.com/b-rodrigues/covidGrandeRegion&#34;&gt;github repository&lt;/a&gt;.
This R package provides several functions to download daily or weekly data, either for one single country or for
the whole of the Greater Region as well as a function to call an interactive map of the region
with a timeline, making it easy to visualise the spread of the disease through the region. It is also
possible to normalize the data by dividing the daily or weekly cases by the size of the population
in each sub-region. However, at the time of writing, there seems to be issues if you run this
on Windows, and I suspect it’s because of Windows’ limitation with UTF-8 characters. In any case, you
can also download the data from &lt;a href=&#34;https://github.com/b-rodrigues/covid_pred/blob/master/data/data_for_model.csv&#34;&gt;here&lt;/a&gt;
instead of having to install the package and run the preprocessing steps.&lt;/p&gt;
&lt;p&gt;Another variable that was included comes from the &lt;a href=&#34;https://www.google.com/covid19/mobility/&#34;&gt;Google Mobility website&lt;/a&gt;.
This data shows on a daily basis how communities move since the start of the pandemic. This data
is used here as proxy for lockdowns.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::glimpse(data.table::fread(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/covid_pred/master/data/data_for_model.csv&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 54
## Columns: 18
## $ week               &amp;lt;date&amp;gt; 2020-02-24, 2020-03-02, 2020-03-09, 2020-03-16, 20…
## $ Luxembourg         &amp;lt;dbl&amp;gt; 0.000000, 0.000000, 0.000000, 111.642081, 163.55005…
## $ lag_Belgique_01    &amp;lt;dbl&amp;gt; 0.00000000, 0.08229904, 2.57870326, 11.27496850, 32…
## $ lag_Belgique_02    &amp;lt;dbl&amp;gt; 0.00000000, 0.00000000, 0.08229904, 2.57870326, 11.…
## $ lag_Belgique_03    &amp;lt;dbl&amp;gt; 0.00000000, 0.00000000, 0.00000000, 0.08229904, 2.5…
## $ lag_Belgique_04    &amp;lt;dbl&amp;gt; 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.0…
## $ lag_Deutschland_01 &amp;lt;dbl&amp;gt; 0.0000000, 0.7085512, 2.8145229, 20.5086217, 37.356…
## $ lag_Deutschland_02 &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 0.7085512, 2.8145229, 20.5086…
## $ lag_Deutschland_03 &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 0.0000000, 0.7085512, 2.81452…
## $ lag_Deutschland_04 &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.70855…
## $ lag_France_01      &amp;lt;dbl&amp;gt; 0.000000, 0.000000, 2.418298, 42.752058, 38.649588,…
## $ lag_France_02      &amp;lt;dbl&amp;gt; 0.000000, 0.000000, 0.000000, 2.418298, 42.752058, …
## $ lag_France_03      &amp;lt;dbl&amp;gt; 0.000000, 0.000000, 0.000000, 0.000000, 2.418298, 4…
## $ lag_France_04      &amp;lt;dbl&amp;gt; 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 2…
## $ lag_stay_home_01   &amp;lt;dbl&amp;gt; 0.0000000, 1.2857143, 0.7142857, 3.8571429, 3.85714…
## $ lag_stay_home_02   &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 1.2857143, 0.7142857, 3.85714…
## $ lag_stay_home_03   &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 0.0000000, 1.2857143, 0.71428…
## $ lag_stay_home_04   &amp;lt;dbl&amp;gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 1.28571…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The target variable is &lt;code&gt;Luxembourg&lt;/code&gt; and contains the weekly positive COVID-19 cases. Then, we can
see the weekly positive cases for the French, Belgian and German constituent regions of the Greater
Region as well as the Google mobility data (four last rows). All these variables were lagged
up to four times: the idea is to show that lagged positive cases of the neighbouring regions
predict weekly positive cases in Luxembourg.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualisations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualisations&lt;/h1&gt;
&lt;p&gt;The plot below shows the epidemic curves for the Regions of the Greater Region (by country):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-05-covid_lu_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The second wave from October/November was quite bad. The German part of the Greater Region did
pretty well overall. The plot below shows the daily percentage change in time spent at home in Luxembourg
(from the Google Mobility data):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-05-covid_lu_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The lockdown from Spring 2020 appears very clearly in the data. The soft lockdown during the Christmas
holidays as well.&lt;/p&gt;
&lt;p&gt;Now armed with this data, I fit a machine learning model using the &lt;code&gt;{modeltime}&lt;/code&gt; package and the
&lt;code&gt;{tidymodels}&lt;/code&gt; framework. As I said in the beginning, I won’t go into technical details here.
I will make a video to explain exactly what I did. In the meantime, let’s take a look at what the
model predicts:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning
## -Inf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-05-covid_lu_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I did the usual stuff: split the data into a training set and a testing set (and since we’re
dealing with time series data, I respected the time structure of the data), fit the model on the
training set and saw how well it fared on the testing set. It did not bother tuning it, because,
as said previously, prediction is not really the goal, and also, the model is already doing pretty
well, which honestly surprised me.
The model I fit was an ARIMA model, quite standard in the time series literature, but then, in order
to extract even more signal from the noise, an XGBOOST model is fit on the residuals of the ARIMA
model. This is where the lagged features come into play. What’s interesting, is that the ARIMA model
has 0 for each of its hyper-parameters, meaning that the ARIMA model is essentially telling us that
the average weekly cases over the training set are the best predictor it can find.
But what about the XGBOOST part of the model? What else can be extracted? This is where explainability
comes into play. I use the &lt;code&gt;{DALEX}&lt;/code&gt; and &lt;code&gt;{DALEXtra}&lt;/code&gt; package for explainability, and show here
the variable importance plot. In the paper in the repository, I have more plots and use more
methods. But I still need to think more about it. So for this blog post, I focus on this plot
which is quite simple to interpret, and also quite telling:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2021-03-05-covid_lu_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It would seem that the single most important feature are the positive cases in Belgium (1, 2 and
3 weeks lags) and cases from the previous week in Germany.&lt;/p&gt;
&lt;p&gt;This seems to confirm the hypothesis I formulated at the beginning. I will continue exploring
this, but I am really looking for feedback as well. Tell me where I’m wrong or too optimistic!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Server(shiny)-less dashboards with R, {htmlwidgets} and {crosstalk}</title>
      <link>https://www.brodrigues.co/blog/2021-03-02-no_shiny_dashboard/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-03-02-no_shiny_dashboard/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/plotly-binding/plotly.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/typedarray/typedarray.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/crosstalk/css/crosstalk.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/crosstalk/js/crosstalk.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/plotly-main/plotly-latest.min.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/all_dashboards.png&#34; title = &#34;Noservers, soon nocode, and a bit later nocomputer&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;In this blog post, I want to discuss something that I, personally, have never seen discussed; how to create
a “serverless” (or “shinyless” you could say) dashboard using R.&lt;/p&gt;
&lt;p&gt;I made one dashboard like that, which you can find &lt;a href=&#34;https://raw.githack.com/b-rodrigues/shinyless_dashboard/master/dashboard.html&#34;&gt;here&lt;/a&gt;.
This dashboard is running on a simple, standard web server. No Shiny involved!&lt;/p&gt;
&lt;p&gt;The idea is to create a dashboard with simple tables, graphs, and filters, to communicate results without
the need for a Shiny server. The “dashboard” will be a simple html file that only needs a good old
web server. Or you could even send the rendered html file per email, and the recipient only needs
to open it using a web browser. The shortcoming of that, of course, is that this “dashboard”,
which is a simple html file will be static; no computation will be possible (well not quite as you’ll see),
so you need to precompute everything that you want to show. It won’t also be possible for the users
to enter parameters and then have graphs update automatically. For instance, you cannot let a user
choose how many days should be used in a moving average. At best, you can compute three variable,
each one with a different number of days, and then let the user choose which of these precomputed
variables should be drawn.&lt;/p&gt;
&lt;p&gt;But the first question is, why would we want, or need, something so limited?&lt;/p&gt;
&lt;p&gt;The advantage of not needing a Shiny server, is that it makes deployment much easier. If you can
“deploy” a dashboard that does not need a Shiny server, this means that you don’t need to set up…,
well a server. In an institutional setting, this can literally mean you end up saving weeks, sometimes
months, of getting the right green lights and signatures. When I worked as a consultant, deployment
was definitely the toughest problem to solve (well, toughest maybe after getting access to the data
itself). And also, this solution might not be as limited as you think. While it is true that users
cannot compute anything on the fly, it is still possible to do a lot of things, which should
in all honesty be enough for most use cases. Most users only want or need a glorified Excel
with pivot tables and pivot charts. So we’re giving them that, but in a nicer package: the dashboard can be
hosted, and users do not have writing rights. That’s honestly all I need in perhaps 90% of the situations.&lt;/p&gt;
&lt;p&gt;The solution I’m going to present was in front of me for the longest time; it’s just that I did not
put 2 and 2 together. The first part of the solution is &lt;code&gt;{flexdashboard}&lt;/code&gt;, which is the framework
allowing us to build a dashboard. Dashboards made with &lt;code&gt;{flexdashboard}&lt;/code&gt; are simple html files,
which can have Shiny elements in them, so for instance an interactive plot that gets generated once
the user has entered some input. But these dashboards don’t need to have Shiny elements in them;
&lt;code&gt;htmlwidgets&lt;/code&gt; are enough. What are &lt;code&gt;htmlwidgets&lt;/code&gt;? Take a look at the graph below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(plotly)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  plot_ly(y = ~hp, x = ~mpg, split = ~am)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No trace type specified:
##   Based on info supplied, a &amp;#39;scatter&amp;#39; trace seems appropriate.
##   Read more about this trace type -&amp;gt; https://plotly.com/r/reference/#scatter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## No scatter mode specifed:
##   Setting the mode to markers
##   Read more about this attribute -&amp;gt; https://plotly.com/r/reference/#scatter-mode&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;plotly html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;visdat&#34;:{&#34;5db310fd169f&#34;:[&#34;function () &#34;,&#34;plotlyVisDat&#34;]},&#34;cur_data&#34;:&#34;5db310fd169f&#34;,&#34;attrs&#34;:{&#34;5db310fd169f&#34;:{&#34;y&#34;:{},&#34;x&#34;:{},&#34;split&#34;:{},&#34;alpha_stroke&#34;:1,&#34;sizes&#34;:[10,100],&#34;spans&#34;:[1,20]}},&#34;layout&#34;:{&#34;margin&#34;:{&#34;b&#34;:40,&#34;l&#34;:60,&#34;t&#34;:25,&#34;r&#34;:10},&#34;xaxis&#34;:{&#34;domain&#34;:[0,1],&#34;automargin&#34;:true,&#34;title&#34;:&#34;mpg&#34;},&#34;yaxis&#34;:{&#34;domain&#34;:[0,1],&#34;automargin&#34;:true,&#34;title&#34;:&#34;hp&#34;},&#34;hovermode&#34;:&#34;closest&#34;,&#34;showlegend&#34;:true},&#34;source&#34;:&#34;A&#34;,&#34;config&#34;:{&#34;showSendToCloud&#34;:false},&#34;data&#34;:[{&#34;y&#34;:[110,175,105,245,62,95,123,123,180,180,180,205,215,230,97,150,150,245,175],&#34;x&#34;:[21.4,18.7,18.1,14.3,24.4,22.8,19.2,17.8,16.4,17.3,15.2,10.4,10.4,14.7,21.5,15.5,15.2,13.3,19.2],&#34;type&#34;:&#34;scatter&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;0&#34;,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(31,119,180,1)&#34;},&#34;xaxis&#34;:&#34;x&#34;,&#34;yaxis&#34;:&#34;y&#34;,&#34;frame&#34;:null},{&#34;y&#34;:[110,110,93,66,52,65,66,91,113,264,175,335,109],&#34;x&#34;:[21,21,22.8,32.4,30.4,33.9,27.3,26,30.4,15.8,19.7,15,21.4],&#34;type&#34;:&#34;scatter&#34;,&#34;mode&#34;:&#34;markers&#34;,&#34;name&#34;:&#34;1&#34;,&#34;marker&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;,&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;}},&#34;error_y&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;error_x&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;line&#34;:{&#34;color&#34;:&#34;rgba(255,127,14,1)&#34;},&#34;xaxis&#34;:&#34;x&#34;,&#34;yaxis&#34;:&#34;y&#34;,&#34;frame&#34;:null}],&#34;highlight&#34;:{&#34;on&#34;:&#34;plotly_click&#34;,&#34;persistent&#34;:false,&#34;dynamic&#34;:false,&#34;selectize&#34;:false,&#34;opacityDim&#34;:0.2,&#34;selected&#34;:{&#34;opacity&#34;:1},&#34;debounce&#34;:0},&#34;shinyEvents&#34;:[&#34;plotly_hover&#34;,&#34;plotly_click&#34;,&#34;plotly_selected&#34;,&#34;plotly_relayout&#34;,&#34;plotly_brushed&#34;,&#34;plotly_brushing&#34;,&#34;plotly_clickannotation&#34;,&#34;plotly_doubleclick&#34;,&#34;plotly_deselect&#34;,&#34;plotly_afterplot&#34;,&#34;plotly_sunburstclick&#34;],&#34;base_url&#34;:&#34;https://plot.ly&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;You can interact with this visualisation, and it’s 100% running in your web browser. No Shiny
involved, even though you can zoom and select different levels in the legend on the top right
(try double-clicking on the “0” level for instance). This visualisation was made with the
&lt;code&gt;{plotly}&lt;/code&gt; package, one of the many &lt;code&gt;htmlwidgets&lt;/code&gt; available. My favorite for making such visualisations
is &lt;code&gt;{echarts4r}&lt;/code&gt; which I’ve used to create the &lt;a href=&#34;https://covid-grande-region.brodrigues.co/&#34;&gt;following map&lt;/a&gt; (how-to blog post &lt;a href=&#34;https://www.brodrigues.co/blog/2021-02-06-echarts_map/&#34;&gt;here&lt;/a&gt;).
&lt;code&gt;htmlwidgets&lt;/code&gt; bring JavaScript visualisations (and other goodies) to R, and what’s really cool
about them is that they don’t need a Shiny server to run (that’s the whole point of
JavaScript, everything runs in the browser).
So this means that by combining &lt;code&gt;{flexdashboard}&lt;/code&gt; with the right &lt;code&gt;htmlwidgets&lt;/code&gt; we can create a
simple, yet useful, dashboard that can be deployed as a web page.&lt;/p&gt;
&lt;p&gt;To illustrate, I’ve made the &lt;a href=&#34;https://raw.githack.com/b-rodrigues/shinyless_dashboard/master/dashboard.html&#34;&gt;following dashboard&lt;/a&gt;, which shows tables, graphs, and even a
pivot table of COVID-19 cases and deaths of the Greater Region (to know more about the Greater
Region and why this interests me currently, you can &lt;a href=&#34;https://www.brodrigues.co/blog/2021-02-20-covid_paper/&#34;&gt;read this&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Something else I need to talk about: on the very first tab, you can see a sidebar with some
inputs that the user can interact with. For instance, the user can choose which country’s data should
appear on the table. It is also possible to filter the positive cases data (not the deaths, but
this could be added). This interaction between the sidebar and the table (which was made using
&lt;code&gt;{DT}&lt;/code&gt;) was made possible using the &lt;code&gt;{crosstalk}&lt;/code&gt; package. This package makes it possible to
link several &lt;code&gt;htmlwidgets&lt;/code&gt; together, but they have to be compatible with &lt;code&gt;{crosstalk}&lt;/code&gt;. Unfortunately, at the time
of writing, not many &lt;code&gt;htmlwidgets&lt;/code&gt; are compatible with &lt;code&gt;{crosstalk}&lt;/code&gt; (see &lt;a href=&#34;https://rstudio.github.io/crosstalk/widgets.html&#34;&gt;here&lt;/a&gt;),
but I would say that the ones that are compatible still make it possible to create some pretty
useful stuff.&lt;/p&gt;
&lt;p&gt;The only thing you need to do to link &lt;code&gt;htmlwidgets&lt;/code&gt; with each other is to convent the dataframe
holding your data to a &lt;code&gt;SharedData&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_set_shared &amp;lt;- SharedData$new(data_set)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Widgets compatible with &lt;code&gt;{crosstalk}&lt;/code&gt; can now use this &lt;code&gt;SharedData&lt;/code&gt; object instead of the regular
dataframe, and this is how you link them: through this &lt;code&gt;SharedData&lt;/code&gt; object.&lt;/p&gt;
&lt;p&gt;Another tab that uses &lt;code&gt;{crosstalk}&lt;/code&gt; is the last one, where you can take a look at the weekly
positive cases and deaths for the countries of the Greater Regions (but only for the sub-regions
of these countries composing the Greater Region). Here, the user can choose whether deaths or
positive cases should be shown. The plot updates immediately, and it’s also possible to
focus on a single country by double-clicking on it in the legend on the top-right.
Again, it’s also possible to focus on a particular month. Here I wanted to use a slicer like on the
first table, but on the date. This should work (I’m using exactly that on another dashboard I made),
but for some reason here, it would not work. The dashboard would compile without any error message
but trying to open the html file on my browser would make the browser hang. So I settled for
another type of slicer.
Something else that is quite cool; if you choose to focus on the cases, you can hover the mouse over
the bars and see how many cases there were in the sub regions in each country. For this, I had to
change the default behavior of the popup in the &lt;code&gt;{plotly}&lt;/code&gt; visualisation.&lt;/p&gt;
&lt;p&gt;Now comes the cherry on top of this already delicious cake; on the second tab, you can interact
with a pivot table! This makes it possible to, for instance, see how many deaths there were in each
country, region or sub-region, on a weekly basis. You can even switch from a table to several
types of visualisations! This pivot table is made possible using the very nice &lt;code&gt;{rpivotTable}&lt;/code&gt;
package. This package is honestly nuts. It feels like it shouldn’t work so well, and yet, it does
work beautifully. Seriously, play around with it in the &lt;a href=&#34;https://raw.githack.com/b-rodrigues/shinyless_dashboard/master/dashboard.html#weekly-covid-19-cases-and-deaths-detected-by-country-pivot-table&#34;&gt;dashboard&lt;/a&gt;, it’s pure magic.&lt;/p&gt;
&lt;p&gt;One final note; on the top right of the dashboard you can click on “Source Code” and read the
dashboard’s source code. You will notice that I use two functions, &lt;code&gt;tar_load()&lt;/code&gt; and &lt;code&gt;tar_read()&lt;/code&gt;
that can be found in the &lt;code&gt;{targets}&lt;/code&gt; package. I will be explaining what that is exactly in a
subsequent blog post, or perhaps a video on my &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/videos&#34;&gt;youtube channel&lt;/a&gt;.
You can also see how the inputs in the sidebar work, and how they are linked (through the &lt;code&gt;SharedData&lt;/code&gt;
object) to the visualisations they control.&lt;/p&gt;
&lt;p&gt;In any case, I’m quite happy that I found the possibility to develop dashboards without the need
of a server, where all the logic is handled client-side by the web browser. I think that this
definitely can help many of you that need to communicate results fast to stakeholders without the
need to deploy a full server, which can often take quite a long time.&lt;/p&gt;
&lt;div id=&#34;bonus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus&lt;/h2&gt;
&lt;p&gt;By the way, yesterday I read the most amazing tweet:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Host on GitHub, like you would a normal repo (incl. pics dir etc.)&lt;br&gt;&lt;br&gt;GH doesn&#39;t render HTML by default… But you just need to change the root of your URL:&lt;br&gt;&lt;br&gt;“github” -&amp;gt; “raw DOT githack”&lt;br&gt;&lt;br&gt;(Also delete the “blob/” bit.)&lt;br&gt;&lt;br&gt;I host all my lectures and seminar slides this way.
&lt;/p&gt;
— Grant McDermott (&lt;span class=&#34;citation&#34;&gt;@grant_mcdermott&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/grant_mcdermott/status/1366597702339891202?ref_src=twsrc%5Etfw&#34;&gt;March 2, 2021&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I used this trick to host the dashboard on github!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R makes it too easy to write papers</title>
      <link>https://www.brodrigues.co/blog/2021-02-20-covid_paper/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-02-20-covid_paper/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/drake.png&#34; title = &#34;Read the blog post to understand this cryptic meme.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;I’m currently working on a preprint on the spread of COVID-19 in Luxembourg. My hypothesis is that
landlocked countries, especially ones like Luxembourg that have very close ties to their neighbours
have a very hard time controlling the pandemic, unlike island countries which can completely close
off their borders, impose very drastic quarantine measure to anyone who would still have to come
in and successfully wipe out the disease by imposing strict lockdowns and contract tracing measures.&lt;/p&gt;
&lt;p&gt;In actuality, this started more as a project in which I simply wanted to look at COVID-19 cases
for Luxembourg and its neighbouring regions. As I started digging and writing code, this
evolved into &lt;a href=&#34;https://github.com/b-rodrigues/covidGrandeRegion&#34;&gt;this package&lt;/a&gt; which makes it easy
to download open data on the daily COVID-19 cases from Luxembourg and its neighbours. I
also blogged about it &lt;a href=&#34;https://www.brodrigues.co/blog/2021-02-06-echarts_map/&#34;&gt;here&lt;/a&gt;.
Creating and animating the map that you see in that blog post, I thought about this hypothesis
I wanted to test. Maybe it won’t work (preliminary results are &lt;em&gt;encouraging&lt;/em&gt; however), but I also
took this opportunity to write a preprint using only R, Rmarkdown and packages that make
writing something like that easy. This blog post is a shallow review of these tools.&lt;/p&gt;
&lt;p&gt;By the way, you can take a look at the repo with the preprint &lt;a href=&#34;https://github.com/b-rodrigues/covid_pred/tree/master&#34;&gt;here&lt;/a&gt;,
and I’ll be writing about it soon as well.&lt;/p&gt;
&lt;div id=&#34;packages-as-by-products-of-papers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages as by-products of papers&lt;/h2&gt;
&lt;p&gt;The first thing I did was download data from the various open data portals, make sense of it and
then plot it. At first, I did so in a very big a messy script file. As time went on, I felt more
and more disgusted with this script and wanted to make something cleaner out of it. This is how the
package I already mentioned above came to be. It took some time to prepare, but now it simplifies
the process of updating my plots and machine learning models much faster. It also makes the
paper more “interesting”; not everyone is interesting in the paper itself, but might be interested
in the data, or in the process of making the package itself. I think that there are many examples
of such packages as by-products of papers, especially papers that present and discuss new
methods are very often accompanied by a package to make it easy for readers of the paper to use
this new method.
Package development is made easy with &lt;code&gt;{usethis}&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;starting-a-draft-with-rticles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Starting a draft with {rticles}&lt;/h2&gt;
&lt;p&gt;The second thing I did was start a draft with &lt;code&gt;{rticles}&lt;/code&gt;. This package allows users to start a
Rmarkdown draft with a single command. Users can choose among many different drafts for many
different journals; I choose the arXiv draft, as I might publish the preprint there. To do so,
I used the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rmarkdown::draft(&amp;quot;paper.Rmd&amp;quot;, template = &amp;quot;arxiv&amp;quot;, package = &amp;quot;rticles&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now edit this &lt;code&gt;Rmd&lt;/code&gt; file and compile it to a nice looking pdf very easily. But I don’t do
so in the “traditional” way of knitting the &lt;code&gt;Rmd&lt;/code&gt; file from Rstudio (or rather, from Spacemacs,
my editor of choice). No, no, for this I use the magnificent &lt;code&gt;{targets}&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-a-clean-automated-and-reproducible-workflow-with-targets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setting up a clean, automated and reproducible workflow with {targets}&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;{targets}&lt;/code&gt; is the latest package by William Landau, who is also the author of &lt;code&gt;{drake}&lt;/code&gt;. I was
very impressed by &lt;code&gt;{drake}&lt;/code&gt; and even made a &lt;a href=&#34;https://www.youtube.com/watch?v=yNHwM3N8bAQ&#34;&gt;video about it&lt;/a&gt;
but now &lt;code&gt;{targets}&lt;/code&gt; will replace &lt;code&gt;{drake}&lt;/code&gt; as THE build automation tool for the R programming language.
I started using it for this project, and just like &lt;code&gt;{drake}&lt;/code&gt; it’s really an amazing package.
It allows you to declare your project as a series of steps, each one of them being a call to a function.
It’s very neat, and clean. The dependencies between each of the steps and objects that are created
at each step are tracked by &lt;code&gt;{targets}&lt;/code&gt; and should one of them get updated (for instance, because
you changed the code of the underlying function), every object that depends on it will also get
updated once you run the pipeline again.&lt;/p&gt;
&lt;p&gt;This can get complex very quickly, and here is the network of objects, functions and their
dependencies for the preprint I’m writing:&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/targets_network.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Imagine keeping track of all this in your head. Now I won’t go much into how to use &lt;code&gt;{targets}&lt;/code&gt;,
because the &lt;a href=&#34;https://books.ropensci.org/targets/&#34;&gt;user manual&lt;/a&gt; is very detailed. Also, you can
inspect the repository of my preprint I linked above to figure out the basics of &lt;code&gt;{targets}&lt;/code&gt;.
What’s really neat though, is that the &lt;code&gt;Rmd&lt;/code&gt; file of your paper is also a target that gets built
automatically. If you check out my repository, you will see that it’s the last target that is built.
And if you check the &lt;code&gt;Rmd&lt;/code&gt; file itself, you will see the only R code I use is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tar_load(something)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tar_load()&lt;/code&gt; is a &lt;code&gt;{targets}&lt;/code&gt; function that loads an object, in the example above this object
is called &lt;code&gt;something&lt;/code&gt; and puts it in the paper. For instance, if &lt;code&gt;something&lt;/code&gt; is a ggplot object,
then this plot will appear on that spot in the paper. It’s really great, because the paper
itself gets compiled very quickly once all the targets are built.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;machine-learning-and-everything-else&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Machine learning, and everything else&lt;/h2&gt;
&lt;p&gt;Last year I wrote a blog post about &lt;code&gt;{tidymodels}&lt;/code&gt;, which you can find &lt;a href=&#34;https://www.brodrigues.co/blog/2020-03-08-tidymodels/&#34;&gt;here&lt;/a&gt;.
Since then, the package evolved, and it’s in my opinion definitely one of the best machine learning
packages out there. Just like the other tools I discussed in this blog post, it abstracts away
many unimportant idiosyncrasies of many other packages and ways of doing things, and let’s you
focus on what matters; getting results and presenting them neatly.&lt;/p&gt;
&lt;p&gt;I think that this is what I really like about the R programming language, and the ecosystem of
packages built on top of it. Combining functional programming, build automation tools, markdown,
and all the helper packages like &lt;code&gt;{usethis}&lt;/code&gt; make it really easy to go from idea, to paper, or
interactive app using &lt;code&gt;{shiny}&lt;/code&gt; very quickly.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to draw a map of arbitrary contiguous regions, or visualizing the spread of COVID-19 in the Greater Region</title>
      <link>https://www.brodrigues.co/blog/2021-02-06-echarts_map/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2021-02-06-echarts_map/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://happy-newton-bf63ad.netlify.app/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/covidGrandeRegion.gif&#34; title = &#34;Click to go to visualisations&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I was able to blog during the year 2020 without mentioning the ongoing pandemic once. It’s not that I made
any conscious effort not to talk about it, but I did not really want to do something that had already
been done a 1000 times. This changed this year, when I wanted to look at the spread of
COVID-19, not only in the Grand-Duchy of Luxembourg, the country I live in, but also among our
neighbours. You see, the Grand-Duchy of Luxembourg is like an island, but instead of being surrounded
by water, it’s surrounded by Belgians, Germans and Frenchmen. Many of them commute every day to Luxembourg
to work, and even though they technically don’t live inside the country, many aspects of their
lives happen inside Luxembourguish borders. Their children might even come to school here, and sometimes
they live so close by the border, that they can catch Luxembourguish public transportation in their
towns. 200k commuters from Belgium, Germany and France work here every day. That’s half our
workforce! So that’s why I thought that it would make sense to look at the spread of the disease
at the level of the so-called &lt;em&gt;Greater Region&lt;/em&gt;. This &lt;em&gt;Greater Region&lt;/em&gt; is made up of the Grand-Duchy
of Luxembourg, the Provinces of Liège and Luxembourg in Belgium (hence why I keep writing the
&lt;em&gt;Grand-Duchy of&lt;/em&gt; Luxembourg to refer to the country, and the &lt;em&gt;Province of Luxembourg&lt;/em&gt; to refer
to the Belgian province of the same name), and two German &lt;em&gt;Länders&lt;/em&gt;, the Saarland and
the Rhineland-Palatinate. Confused? Welcome to Europe, where supranational institutions
literally have to have a page entitled &lt;a href=&#34;https://www.coe.int/en/web/about-us/do-not-get-confused&#34;&gt;Do not get confused&lt;/a&gt;
so that citizens don’t get lost (we still do).&lt;/p&gt;
&lt;p&gt;So the Greater Region is not a state, but facilitates collaboration between the regions comprising
it. To me, technically a citizen of the Greater Region, it feels like there was a want to &lt;strong&gt;peacefully&lt;/strong&gt; correct
for the randomness of history, where German-speaking regions ended up in both France and Belgium,
and where Belgium and Luxembourg, well, somehow became independent countries.&lt;/p&gt;
&lt;p&gt;Anyways, what I wanted to do was to first of all get the COVID-19 daily cases data for each of these
regions. I did that, and even created a package called &lt;code&gt;{covidGrandeRegion}&lt;/code&gt; hosted
&lt;a href=&#34;https://github.com/b-rodrigues/covidGrandeRegion&#34;&gt;here&lt;/a&gt; that makes it very easy to download the
latest data for the Greater Region. I will write another blog post about it, I have something
in mind that I wanted to try for some time, and this was the first step.
Then I thought that adding a function that would create a map could also be nice. And this is
where the technical aspect of this blog post starts.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problems-to-map-the-greater-region&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problems to map the Greater Region&lt;/h2&gt;
&lt;p&gt;So how do you draw a map for an arbitrary landmass like the Greater Region? I wanted to draw the
maps using &lt;code&gt;{echarts4r}&lt;/code&gt;, and there’s a very easy &lt;a href=&#34;https://echarts4r.john-coene.com/articles/make-geo-json.html&#34;&gt;guide you can read&lt;/a&gt;.
If you want to draw a map for one, or several, countries, this guide is all you need. But I wanted
a map with only parts of France, Belgium and Germany. The only complete country was Luxembourg.
So the first problem was how to get only parts of a country. The second problem, is that I had
daily covid cases for the lowest administrative levels for France (which are &lt;em&gt;Départements&lt;/em&gt;),
Belgium (the &lt;em&gt;Provinces&lt;/em&gt;) and Germany (&lt;em&gt;Land-&lt;/em&gt; and &lt;em&gt;Stadtkreise&lt;/em&gt;). But for the Grand-Duchy of Luxembourg,
there’s only data at the level of the country. So this would be another problem. How to draw a map
with unequal levels of precision?
One final problem: the names of the administrative divisions in my covid datasets are not the same
than the ones that get downloaded if you follow the guide I linked before. So I had to rename
them as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-solutions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The solutions&lt;/h2&gt;
&lt;p&gt;Let’s first start by following the guide, so loading the packages, and getting the maps I need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(echarts4r)
library(sp)
library(raster)
library(geojsonio)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;france_dep &amp;lt;- getData(&amp;quot;GADM&amp;quot;, country = &amp;quot;FRANCE&amp;quot;, level = 2)

ger_kreise &amp;lt;- getData(&amp;quot;GADM&amp;quot;, country = &amp;quot;GERMANY&amp;quot;, level = 2)

be_province &amp;lt;- getData(&amp;quot;GADM&amp;quot;, country = &amp;quot;BELGIUM&amp;quot;, level = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above lines of code load the required packages, and download the maps for France, Belgium
and Germany with the required administrative level I need. I’ll leave Luxembourg for last.&lt;/p&gt;
&lt;p&gt;Let’s take a look at what type of object we’re dealing with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(france_dep)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;SpatialPolygonsDataFrame&amp;quot;
## attr(,&amp;quot;package&amp;quot;)
## [1] &amp;quot;sp&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it seems to be something like a data frame, but probably more complex. Looking for some help
online, I saw that you can coerce it to a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.data.frame(be_province)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    GID_0  NAME_0   GID_1     NAME_1 NL_NAME_1     GID_2          NAME_2
## 1    BEL Belgium BEL.1_1  Bruxelles      &amp;lt;NA&amp;gt; BEL.1.1_1       Bruxelles
## 2    BEL Belgium BEL.2_1 Vlaanderen      &amp;lt;NA&amp;gt; BEL.2.1_1       Antwerpen
## 3    BEL Belgium BEL.2_1 Vlaanderen      &amp;lt;NA&amp;gt; BEL.2.2_1         Limburg
## 4    BEL Belgium BEL.2_1 Vlaanderen      &amp;lt;NA&amp;gt; BEL.2.3_1 Oost-Vlaanderen
## 5    BEL Belgium BEL.2_1 Vlaanderen      &amp;lt;NA&amp;gt; BEL.2.4_1  Vlaams Brabant
## 6    BEL Belgium BEL.2_1 Vlaanderen      &amp;lt;NA&amp;gt; BEL.2.5_1 West-Vlaanderen
## 7    BEL Belgium BEL.3_1   Wallonie      &amp;lt;NA&amp;gt; BEL.3.1_1  Brabant Wallon
## 8    BEL Belgium BEL.3_1   Wallonie      &amp;lt;NA&amp;gt; BEL.3.2_1         Hainaut
## 9    BEL Belgium BEL.3_1   Wallonie      &amp;lt;NA&amp;gt; BEL.3.3_1           Liège
## 10   BEL Belgium BEL.3_1   Wallonie      &amp;lt;NA&amp;gt; BEL.3.4_1      Luxembourg
## 11   BEL Belgium BEL.3_1   Wallonie      &amp;lt;NA&amp;gt; BEL.3.5_1           Namur
##                                                                                                             VARNAME_2
## 1  Brussel Hoofstadt|Brusselse Hoofdstedelijke Gewest|Brüssel|Bruxelas|Région de Bruxelles-Capitale|Brussels|Bruselas
## 2                                                                            Amberes|Antuérpia|Antwerp|Anvers|Anversa
## 3                                                                                                   Limbourg|Limburgo
## 4                   Flandres Oriental|Fiandra Orientale|Flandes Oriental|Flandre orientale|East Flanders|Ost Flandern
## 5                                                 Brabant Flamand|Brabante Flamenco|Brabante Flamengo|Flemish Brabant
## 6           Fiandra Occidentale|Flandes Occidental|Flandre occidentale|Flandres Ocidental|West Flandern|West Flanders
## 7                                                                                       Waals Brabant|Walloon Brabant
## 8                                                                                                 Henegouwen|Hennegau
## 9                                                                                            Luik|Liegi|Lieja|Lüttich
## 10                                                                                   Lussemburgo|Luxemburg|Luxemburgo
## 11                                                                                                              Namen
##    NL_NAME_2                                TYPE_2      ENGTYPE_2 CC_2 HASC_2
## 1       &amp;lt;NA&amp;gt; Hoofdstedelijk Gewest|Région Capitale Capital Region &amp;lt;NA&amp;gt;  BE.BU
## 2       &amp;lt;NA&amp;gt;                             Provincie       Province &amp;lt;NA&amp;gt;  BE.AN
## 3       &amp;lt;NA&amp;gt;                             Provincie       Province &amp;lt;NA&amp;gt;  BE.LI
## 4       &amp;lt;NA&amp;gt;                             Provincie       Province &amp;lt;NA&amp;gt;  BE.OV
## 5       &amp;lt;NA&amp;gt;                             Provincie       Province &amp;lt;NA&amp;gt;  BE.VB
## 6       &amp;lt;NA&amp;gt;                             Provincie       Province &amp;lt;NA&amp;gt;  BE.WV
## 7       &amp;lt;NA&amp;gt;                              Province      Provincie &amp;lt;NA&amp;gt;  BE.BW
## 8       &amp;lt;NA&amp;gt;                              Province      Provincie &amp;lt;NA&amp;gt;  BE.HT
## 9       &amp;lt;NA&amp;gt;                              Province      Provincie &amp;lt;NA&amp;gt;  BE.LG
## 10      &amp;lt;NA&amp;gt;                              Province      Provincie &amp;lt;NA&amp;gt;  BE.LX
## 11      &amp;lt;NA&amp;gt;                              Province      Provincie &amp;lt;NA&amp;gt;  BE.NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re not going to convert them to data frames however; but this is an interesting clue; these &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt;
objects share common methods with data frames. What this means is that we can use the usual,
base R way of manipulating these objects.&lt;/p&gt;
&lt;p&gt;So to get only the French &lt;em&gt;départements&lt;/em&gt; I need, I can slice them like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lorraine &amp;lt;- france_dep[`%in%`(france_dep$NAME_2, c(&amp;quot;Meurthe-et-Moselle&amp;quot;, &amp;quot;Meuse&amp;quot;, &amp;quot;Moselle&amp;quot;, &amp;quot;Vosges&amp;quot;)),]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Same for the German &lt;em&gt;kreise&lt;/em&gt;, here I select the &lt;em&gt;Länder&lt;/em&gt; which are a higher administrative division
than the Kreise, which makes it faster (so I don’t need to type all the 40+ Kreise):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ger_kreise &amp;lt;- ger_kreise[`%in%`(ger_kreise$NAME_1, c(&amp;quot;Rheinland-Pfalz&amp;quot;, &amp;quot;Saarland&amp;quot;)),]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For Germany, many Kreise had a name which was different than on my covid data, so I had to
rename them. So here again, the base R way of doing things works:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Eifelkreis Bitburg-Prüm&amp;quot;]  &amp;lt;- &amp;quot;Bitburg-Prüm&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;St. Wendel&amp;quot;]  &amp;lt;- &amp;quot;Sankt Wendel&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Altenkirchen (Westerwald)&amp;quot;]  &amp;lt;- &amp;quot;Altenkirchen&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Neustadt an der Weinstraße&amp;quot;]  &amp;lt;- &amp;quot;Neustadt a.d.Weinstraße&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Landau in der Pfalz&amp;quot;]  &amp;lt;- &amp;quot;Landau i.d.Pfalz&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Ludwigshafen am Rhein&amp;quot;]  &amp;lt;- &amp;quot;Ludwigshafen&amp;quot;
ger_kreise$NAME_2[ger_kreise$NAME_2 == &amp;quot;Frankenthal (Pfalz)&amp;quot;]  &amp;lt;- &amp;quot;Frankenthal&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, I do the same for Belgium, and rename their province of Luxembourg, which was simply called
“Luxembourg”, to “Province de Luxembourg”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;be_wallonia &amp;lt;- be_province[be_province$NAME_1 == &amp;quot;Wallonie&amp;quot;, ]
be_wallonia$NAME_2[be_wallonia$NAME_2 == &amp;quot;Luxembourg&amp;quot;]  &amp;lt;- &amp;quot;Province de Luxembourg&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I rename the province because the Grand-Duchy of Luxembourg is also only called “Luxembourg” in the
data, and this would cause issues when mapping.&lt;/p&gt;
&lt;p&gt;Now, comes Luxembourg. As I’ve written above, I only have data at the level of the country, so
I download the country map:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lu_map_0 &amp;lt;- getData(&amp;quot;GADM&amp;quot;, country = &amp;quot;LUXEMBOURG&amp;quot;, level = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s also see how it looks like as a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.data.frame(lu_map_0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   GID_0     NAME_0
## 1   LUX Luxembourg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unlike the previous &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt;s, there are much less columns and this will cause
an issue. Indeed, in order to have a single &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; object to draw my map,
I will need to combine them. This will be very easy, by simple using the &lt;code&gt;rbind()&lt;/code&gt; function.
Again, simply using base R functions. However, this only works if the data frames have the same
columns. Another issue, is that I will be using the names of the regions which are in the &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt;s’
column called &lt;code&gt;NAME_2&lt;/code&gt;, but for Luxembourg, the name of the region (in this case the whole country)
is in the column called &lt;code&gt;NAME_0&lt;/code&gt;. So I need to add this columns to the &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt;
object for Luxembourg:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lu_map_0$GID_1 &amp;lt;- NA
lu_map_0$NAME_1 &amp;lt;- NA
lu_map_0$NL_NAME_1 &amp;lt;- NA
lu_map_0$GID_2 &amp;lt;- NA
lu_map_0$NAME_2 &amp;lt;- &amp;quot;Luxembourg&amp;quot;
lu_map_0$VARNAME_2 &amp;lt;- NA
lu_map_0$NL_NAME_2 &amp;lt;- NA
lu_map_0$TYPE_2 &amp;lt;- NA
lu_map_0$ENGTYPE_2 &amp;lt;- NA
lu_map_0$CC_2 &amp;lt;- NA
lu_map_0$HASC_2 &amp;lt;- NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Aaaand… that’s it! Wasn’t that hard, but a bit convoluted nonetheless. Now I can bind all
the &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; objects in one and use that for mapping:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grande_region &amp;lt;- do.call(rbind, list(lorraine, ger_kreise, be_wallonia, lu_map_0))

as.data.frame(grande_region)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     GID_0     NAME_0    GID_1          NAME_1 NL_NAME_1       GID_2
## 76    FRA     France  FRA.6_1       Grand Est      &amp;lt;NA&amp;gt;   FRA.6.7_1
## 77    FRA     France  FRA.6_1       Grand Est      &amp;lt;NA&amp;gt;   FRA.6.8_1
## 78    FRA     France  FRA.6_1       Grand Est      &amp;lt;NA&amp;gt;   FRA.6.9_1
## 70    FRA     France  FRA.6_1       Grand Est      &amp;lt;NA&amp;gt;  FRA.6.10_1
## 99    DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.1_1
## 110   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.2_1
## 121   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.3_1
## 129   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.4_1
## 130   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.5_1
## 131   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.6_1
## 132   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.7_1
## 133   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.8_1
## 134   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt;  DEU.11.9_1
## 100   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.10_1
## 101   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.11_1
## 102   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.12_1
## 104   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.14_1
## 103   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.13_1
## 105   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.15_1
## 106   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.16_1
## 107   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.17_1
## 108   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.18_1
## 111   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.20_1
## 109   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.19_1
## 112   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.21_1
## 113   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.22_1
## 114   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.23_1
## 115   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.24_1
## 116   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.25_1
## 117   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.26_1
## 118   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.27_1
## 119   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.28_1
## 120   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.29_1
## 122   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.30_1
## 124   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.32_1
## 123   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.31_1
## 125   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.33_1
## 126   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.34_1
## 127   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.35_1
## 128   DEU    Germany DEU.11_1 Rheinland-Pfalz      &amp;lt;NA&amp;gt; DEU.11.36_1
## 135   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.1_1
## 136   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.2_1
## 137   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.3_1
## 138   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.4_1
## 139   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.5_1
## 140   DEU    Germany DEU.12_1        Saarland      &amp;lt;NA&amp;gt;  DEU.12.6_1
## 7     BEL    Belgium  BEL.3_1        Wallonie      &amp;lt;NA&amp;gt;   BEL.3.1_1
## 8     BEL    Belgium  BEL.3_1        Wallonie      &amp;lt;NA&amp;gt;   BEL.3.2_1
## 9     BEL    Belgium  BEL.3_1        Wallonie      &amp;lt;NA&amp;gt;   BEL.3.3_1
## 10    BEL    Belgium  BEL.3_1        Wallonie      &amp;lt;NA&amp;gt;   BEL.3.4_1
## 11    BEL    Belgium  BEL.3_1        Wallonie      &amp;lt;NA&amp;gt;   BEL.3.5_1
## 1     LUX Luxembourg     &amp;lt;NA&amp;gt;            &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt;        &amp;lt;NA&amp;gt;
##                                NAME_2                        VARNAME_2
## 76                 Meurthe-et-Moselle                             &amp;lt;NA&amp;gt;
## 77                              Meuse                             &amp;lt;NA&amp;gt;
## 78                            Moselle                       Lothringen
## 70                             Vosges                             &amp;lt;NA&amp;gt;
## 99                          Ahrweiler                             &amp;lt;NA&amp;gt;
## 110                      Altenkirchen                             &amp;lt;NA&amp;gt;
## 121                       Alzey-Worms                             &amp;lt;NA&amp;gt;
## 129                      Bad Dürkheim                             &amp;lt;NA&amp;gt;
## 130                     Bad Kreuznach                             &amp;lt;NA&amp;gt;
## 131               Bernkastel-Wittlich                             &amp;lt;NA&amp;gt;
## 132                        Birkenfeld                             &amp;lt;NA&amp;gt;
## 133                       Cochem-Zell                             &amp;lt;NA&amp;gt;
## 134                  Donnersbergkreis                             &amp;lt;NA&amp;gt;
## 100                      Bitburg-Prüm                             &amp;lt;NA&amp;gt;
## 101                       Frankenthal                             &amp;lt;NA&amp;gt;
## 102                       Germersheim                             &amp;lt;NA&amp;gt;
## 104                    Kaiserslautern                             &amp;lt;NA&amp;gt;
## 103 Kaiserslautern (Kreisfreie Stadt)                             &amp;lt;NA&amp;gt;
## 105                           Koblenz                             &amp;lt;NA&amp;gt;
## 106                             Kusel                             &amp;lt;NA&amp;gt;
## 107                  Landau i.d.Pfalz                             &amp;lt;NA&amp;gt;
## 108                      Ludwigshafen                             &amp;lt;NA&amp;gt;
## 111                             Mainz                             &amp;lt;NA&amp;gt;
## 109                      Mainz-Bingen                             &amp;lt;NA&amp;gt;
## 112                     Mayen-Koblenz                             &amp;lt;NA&amp;gt;
## 113           Neustadt a.d.Weinstraße                             &amp;lt;NA&amp;gt;
## 114                           Neuwied                             &amp;lt;NA&amp;gt;
## 115                         Pirmasens                             &amp;lt;NA&amp;gt;
## 116              Rhein-Hunsrück-Kreis                             &amp;lt;NA&amp;gt;
## 117                  Rhein-Lahn-Kreis                             &amp;lt;NA&amp;gt;
## 118                 Rhein-Pfalz-Kreis                             &amp;lt;NA&amp;gt;
## 119                            Speyer                             &amp;lt;NA&amp;gt;
## 120               Südliche Weinstraße                             &amp;lt;NA&amp;gt;
## 122                      Südwestpfalz                             &amp;lt;NA&amp;gt;
## 124                             Trier                             &amp;lt;NA&amp;gt;
## 123                    Trier-Saarburg                             &amp;lt;NA&amp;gt;
## 125                       Vulkaneifel                             &amp;lt;NA&amp;gt;
## 126                   Westerwaldkreis                             &amp;lt;NA&amp;gt;
## 127                             Worms                             &amp;lt;NA&amp;gt;
## 128                       Zweibrücken                             &amp;lt;NA&amp;gt;
## 135                     Merzig-Wadern                             &amp;lt;NA&amp;gt;
## 136                       Neunkirchen                             &amp;lt;NA&amp;gt;
## 137       Regionalverband Saarbrücken                             &amp;lt;NA&amp;gt;
## 138                         Saarlouis                             &amp;lt;NA&amp;gt;
## 139                   Saarpfalz-Kreis                             &amp;lt;NA&amp;gt;
## 140                      Sankt Wendel                             &amp;lt;NA&amp;gt;
## 7                      Brabant Wallon    Waals Brabant|Walloon Brabant
## 8                             Hainaut              Henegouwen|Hennegau
## 9                               Liège         Luik|Liegi|Lieja|Lüttich
## 10             Province de Luxembourg Lussemburgo|Luxemburg|Luxemburgo
## 11                              Namur                            Namen
## 1                          Luxembourg                             &amp;lt;NA&amp;gt;
##     NL_NAME_2           TYPE_2  ENGTYPE_2  CC_2   HASC_2
## 76       &amp;lt;NA&amp;gt;      Département Department    54    FR.MM
## 77       &amp;lt;NA&amp;gt;      Département Department    55    FR.MS
## 78       &amp;lt;NA&amp;gt;      Département Department    57    FR.MO
## 70       &amp;lt;NA&amp;gt;      Département Department    88    FR.VG
## 99       &amp;lt;NA&amp;gt;        Landkreis   District 07131 DE.RP.AR
## 110      &amp;lt;NA&amp;gt;        Landkreis   District 07132 DE.RP.AT
## 121      &amp;lt;NA&amp;gt;        Landkreis   District 07331 DE.RP.AW
## 129      &amp;lt;NA&amp;gt;        Landkreis   District 07332 DE.RP.BD
## 130      &amp;lt;NA&amp;gt;        Landkreis   District 07133 DE.RP.BK
## 131      &amp;lt;NA&amp;gt;        Landkreis   District 07231 DE.RP.BW
## 132      &amp;lt;NA&amp;gt;        Landkreis   District 07134 DE.RP.BR
## 133      &amp;lt;NA&amp;gt;        Landkreis   District 07135 DE.RP.CZ
## 134      &amp;lt;NA&amp;gt;        Landkreis   District 07333 DE.RP.DN
## 100      &amp;lt;NA&amp;gt;        Landkreis   District 07232 DE.RP.EB
## 101      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07311 DE.RP.FA
## 102      &amp;lt;NA&amp;gt;        Landkreis   District 07334 DE.RP.GR
## 104      &amp;lt;NA&amp;gt;        Landkreis   District 07335 DE.RP.KL
## 103      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07312 DE.RP.KL
## 105      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07111 DE.RP.KO
## 106      &amp;lt;NA&amp;gt;        Landkreis   District 07336 DE.RP.KU
## 107      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07313 DE.RP.LP
## 108      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07314 DE.RP.LR
## 111      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07315 DE.RP.MI
## 109      &amp;lt;NA&amp;gt;        Landkreis   District 07339 DE.RP.MB
## 112      &amp;lt;NA&amp;gt;        Landkreis   District 07137 DE.RP.MK
## 113      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07316 DE.RP.NW
## 114      &amp;lt;NA&amp;gt;        Landkreis   District 07138 DE.RP.NU
## 115      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07317 DE.RP.PR
## 116      &amp;lt;NA&amp;gt;        Landkreis   District 07140 DE.RP.RH
## 117      &amp;lt;NA&amp;gt;        Landkreis   District 07141 DE.RP.RN
## 118      &amp;lt;NA&amp;gt;        Landkreis   District 07338 DE.RP.RZ
## 119      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07318 DE.RP.SE
## 120      &amp;lt;NA&amp;gt;        Landkreis   District 07337 DE.RP.SW
## 122      &amp;lt;NA&amp;gt;        Landkreis   District 07340 DE.RP.SD
## 124      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07211 DE.RP.TI
## 123      &amp;lt;NA&amp;gt;        Landkreis   District 07235 DE.RP.TS
## 125      &amp;lt;NA&amp;gt;        Landkreis   District 07233 DE.RP.VL
## 126      &amp;lt;NA&amp;gt;        Landkreis   District 07143 DE.RP.WS
## 127      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07319 DE.RP.WR
## 128      &amp;lt;NA&amp;gt; Kreisfreie Stadt   District 07320 DE.RP.ZE
## 135      &amp;lt;NA&amp;gt;        Landkreis   District 10042 DE.SL.MW
## 136      &amp;lt;NA&amp;gt;        Landkreis   District 10043 DE.SL.NU
## 137      &amp;lt;NA&amp;gt;        Landkreis   District 10041 DE.SL.SB
## 138      &amp;lt;NA&amp;gt;        Landkreis   District 10044 DE.SL.SA
## 139      &amp;lt;NA&amp;gt;        Landkreis   District 10045 DE.SL.SP
## 140      &amp;lt;NA&amp;gt;        Landkreis   District 10046 DE.SL.SW
## 7        &amp;lt;NA&amp;gt;         Province  Provincie  &amp;lt;NA&amp;gt;    BE.BW
## 8        &amp;lt;NA&amp;gt;         Province  Provincie  &amp;lt;NA&amp;gt;    BE.HT
## 9        &amp;lt;NA&amp;gt;         Province  Provincie  &amp;lt;NA&amp;gt;    BE.LG
## 10       &amp;lt;NA&amp;gt;         Province  Provincie  &amp;lt;NA&amp;gt;    BE.LX
## 11       &amp;lt;NA&amp;gt;         Province  Provincie  &amp;lt;NA&amp;gt;    BE.NA
## 1        &amp;lt;NA&amp;gt;             &amp;lt;NA&amp;gt;       &amp;lt;NA&amp;gt;  &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now I can continue following the tutorial from the &lt;code&gt;{echarts4r}&lt;/code&gt; website, by converting this
&lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; object for the Greater Region into a geojson file which can now be
used to draw maps! You can take a look at the final result &lt;a href=&#34;https://happy-newton-bf63ad.netlify.app/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I don’t post the code to draw the map here, because it would require some more tinkering by
joining the COVID data. But you can find my raw script &lt;a href=&#34;https://github.com/b-rodrigues/covidGrandeRegion/blob/master/data-raw/maps.R&#34;&gt;here&lt;/a&gt;
(lines 51 to 61) or you could also take a look at the &lt;code&gt;draw_map()&lt;/code&gt; function from the package
I made, which you can find &lt;a href=&#34;https://github.com/b-rodrigues/covidGrandeRegion/blob/master/R/draw_map.R&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I really like the end result, &lt;code&gt;{echarts4r}&lt;/code&gt; is really a fantastic package!
Stay tuned part 2 of the project, which will deal with machine learning.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A year in review</title>
      <link>https://www.brodrigues.co/blog/2020-12-30-year_review/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-12-30-year_review/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/2020_review.png&#34; title = &#34;It wasn&#39;t the worst year ever, but it was quite crap.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://www.sciencemag.org/news/2018/11/why-536-was-worst-year-be-alive&#34;&gt;&lt;/script&gt;
&lt;p&gt;This blog post just contains the links I mention in my video that you can watch &lt;a href=&#34;https://youtu.be/Z5xNALiILzg&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I mention the following books, packages, and people in my video:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://echarts4r.john-coene.com/index.html&#34;&gt;echarts4r&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wlandau.github.io/targets/&#34;&gt;targets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/easystats&#34;&gt;easystats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hhsievertsen.github.io/applied_econ_with_r/#Welcome&#34;&gt;Applied Economics with R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/coolbutuseless?tab=repositories&#34;&gt;coolbutuseless&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCKxHtRdtFEPihEjTtjG8Y8w/featured&#34;&gt;Data Science ZJ&lt;/a&gt; and &lt;a href=&#34;https://diskframe.com/&#34;&gt;disk.frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4WVelCswXo4&amp;amp;list=PLDcUM9US4XdNM4Edgs7weiyIguLSToZRI&#34;&gt;Statistical Rethinking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://thinkr-open.github.io/golem/&#34;&gt;Golem&lt;/a&gt; and &lt;a href=&#34;https://engineering-shiny.org/&#34;&gt;Engineering production-grade shiny apps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://moderndive.com/&#34;&gt;ModernDive&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many others created and shared amazing content during the year, so sorry I could not mention
everyone!&lt;/p&gt;
&lt;p&gt;Happy new year to all and thank you for the ongoing support!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>(Half) Lies, (half) truths and (half) statistics</title>
      <link>https://www.brodrigues.co/blog/2020-12-12-ethics_statistics/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-12-12-ethics_statistics/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/d3/d3.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/d3-lasso/d3-lasso.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/ggiraphjs/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/ggiraphjs/ggiraphjs.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/girafe-binding/girafe.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/simpson.gif&#34; title = &#34;Sometimes, simple does not mean trivial, but many confuse the two.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;Note: if you’re reading this and images are not showing, visit the original post on my blog. The
blog post contains interactive plots which help in understanding the point I’m making.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’ve recently come across this graph (on Twitter) from the Economist:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/economist_safe_vaccines.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can read the article &lt;a href=&#34;https://archive.is/EcdNZ&#34;&gt;here&lt;/a&gt; (archived for posterity). There are many
things wrong with this chart.
First of all, the economist is fitting a linear regression to some data points, and does not provide
anything else to the reader, namely the regression coefficients, their standard errors, and the R².
I know already that some readers will disagree, thinking something along the lines of
“But Bruno, come on, this is only to show that’s there a negative correlation between GDP per
capita and trust in vaccines! The readers don’t need to be bothered with these complex concepts.
This is just an illustration, and it’s good enough.”&lt;/p&gt;
&lt;p&gt;WRONG.&lt;/p&gt;
&lt;p&gt;Look, I’m all for good enough. That’s very likely going to be my epitaph. But sometimes, you can’t
simplify things so much that they’re not only misleading, but lies. In this case here, the
relationship between GDP per capita and trust in vaccines, if there is any, is probably highly nonlinear,
and very difficult to pinpoint with any degree of accuracy.
But before going further, let’s get the data and replicate the graph. I’ll be adding the equation
of the regression line as well as the R² to the plot. I won’t comment my code, since the point of this blog
post is not to teach you how to do it, but of course, you’re very welcome to reproduce the analysis.&lt;/p&gt;
&lt;p&gt;You can download the data &lt;a href=&#34;https://wellcome.org/reports/wellcome-global-monitor/2018/appendix-country-level-data&#34;&gt;here&lt;/a&gt;,
under “Full dataset for this chart”. You can also grab a csv version &lt;a href=&#34;https://gist.githubusercontent.com/b-rodrigues/388f6309a462c9ccbdf00f32ac9055cb/raw/92962f08f9e23b9a8586045291795f4ab21ad053/wgm2018.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click to see the code
&lt;/summary&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ggiraph)

dataset &amp;lt;- data.table::fread(&amp;quot;https://gist.githubusercontent.com/b-rodrigues/388f6309a462c9ccbdf00f32ac9055cb/raw/92962f08f9e23b9a8586045291795f4ab21ad053/wgm2018.csv&amp;quot;)

dataset &amp;lt;- dataset %&amp;gt;%
  filter(grepl(&amp;quot;(GDP per capita)|(Q25)&amp;quot;, question_statistic)) %&amp;gt;%
  mutate(response_type = ifelse(response_type == &amp;quot;&amp;quot;, &amp;quot;GDP per capita&amp;quot;, response_type)) %&amp;gt;%
  filter(grepl(&amp;quot;(National Total)|(GDP)&amp;quot;, response_type)) %&amp;gt;%
  mutate(response_type = str_remove(response_type, &amp;quot;National Total: &amp;quot;)) %&amp;gt;%
  select(country_name, response = response_type, value = result_percent) %&amp;gt;%
  mutate(gdp_per_capita = ifelse(grepl(&amp;quot;GDP&amp;quot;, response), value, NA)) %&amp;gt;% 
  fill(gdp_per_capita, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%
  filter(!grepl(&amp;quot;GDP&amp;quot;, response))  %&amp;gt;%
  mutate(gdp_per_capita = as.numeric(gdp_per_capita),
         value = as.numeric(value),
         l_gdp = log(gdp_per_capita))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_data &amp;lt;- dataset %&amp;gt;%
  mutate(agree = ifelse(grepl(&amp;quot; agree$&amp;quot;, response), &amp;quot;safe&amp;quot;, &amp;quot;not_safe&amp;quot;)) %&amp;gt;%  
  group_by(country_name, l_gdp, agree) %&amp;gt;% 
  summarise(value = sum(value)) %&amp;gt;%
  filter(agree == &amp;quot;safe&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` regrouping output by &amp;#39;country_name&amp;#39;, &amp;#39;l_gdp&amp;#39; (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lin_mod &amp;lt;- lm(value ~ l_gdp, data = plot_data)

lin_mod_coefs &amp;lt;- coefficients(lin_mod)
lin_mod_se &amp;lt;- sqrt(diag(vcov(lin_mod)))

regression_line_result &amp;lt;- paste0(&amp;quot;value = &amp;quot;,
       round(lin_mod_coefs[1], 2),
       &amp;quot;[&amp;quot;,
       round(lin_mod_se[1], 2),
       &amp;quot;]&amp;quot;,
       round(lin_mod_coefs[2], 2),
       &amp;quot;[&amp;quot;,
       round(lin_mod_se[2], 2),
       &amp;quot;]&amp;quot;,
       &amp;quot;*l_gdp&amp;quot;,
       &amp;quot;,\n R2 = &amp;quot;,
       round(summary(lin_mod)$r.squared, 2))

my_plot &amp;lt;- plot_data %&amp;gt;%
  ggplot(aes(y = value, x = l_gdp)) +
  geom_point_interactive(aes(tooltip = country_name), colour = &amp;quot;orange&amp;quot;) +
  #geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;, se = FALSE) +
  #ggrepel::geom_label_repel(aes(label = country_name)) +
  geom_text(y = 35, x = 8,
            label = regression_line_result,
            colour = &amp;quot;white&amp;quot;,
            size = 3) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;If you look at the code above, you’ll see that I’m doing a bunch of stuff to reproduce the graph.
Let’s take a look at it (you can mouse over the points to see the country names over the labels):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;girafe(ggobj = my_plot, width_svg = 8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;girafe html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;?xml version=\&#34;1.0\&#34; encoding=\&#34;UTF-8\&#34;?&gt;\n&lt;svg xmlns=\&#34;http://www.w3.org/2000/svg\&#34; xmlns:xlink=\&#34;http://www.w3.org/1999/xlink\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621\&#34; viewBox=\&#34;0 0 576.00 360.00\&#34;&gt;\n  &lt;g&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_1\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_1\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_1)\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.75\&#34; stroke=\&#34;#FFFFFF\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_2\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_2\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_2)\&#34; fill=\&#34;#272B30\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#000000\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3\&#34;&gt;\n        &lt;rect x=\&#34;40.25\&#34; y=\&#34;5.48\&#34; width=\&#34;530.27\&#34; height=\&#34;322.82\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;polyline points=\&#34;40.25,309.31 570.52,309.31\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_3\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,222.99 570.52,222.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_4\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,136.68 570.52,136.68\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_5\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,50.36 570.52,50.36\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_6\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;54.78,328.30 54.78,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_7\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;152.14,328.30 152.14,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_8\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;249.50,328.30 249.50,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_9\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;346.86,328.30 346.86,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_10\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;444.22,328.30 444.22,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_11\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;541.58,328.30 541.58,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_12\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,266.15 570.52,266.15\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_13\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,179.84 570.52,179.84\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_14\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,93.52 570.52,93.52\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_15\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,7.21 570.52,7.21\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_16\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;103.46,328.30 103.46,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_17\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;200.82,328.30 200.82,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_18\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;298.18,328.30 298.18,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_19\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;395.54,328.30 395.54,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_20\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;492.90,328.30 492.90,5.48\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_21\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;circle cx=\&#34;160.60\&#34; cy=\&#34;33.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_22\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Afghanistan\&#34;/&gt;\n    &lt;circle cx=\&#34;343.78\&#34; cy=\&#34;166.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_23\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Albania\&#34;/&gt;\n    &lt;circle cx=\&#34;359.81\&#34; cy=\&#34;166.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_24\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Algeria\&#34;/&gt;\n    &lt;circle cx=\&#34;389.89\&#34; cy=\&#34;58.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_25\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Argentina\&#34;/&gt;\n    &lt;circle cx=\&#34;315.17\&#34; cy=\&#34;257.52\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_26\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Armenia\&#34;/&gt;\n    &lt;circle cx=\&#34;472.31\&#34; cy=\&#34;80.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_27\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Australia\&#34;/&gt;\n    &lt;circle cx=\&#34;479.91\&#34; cy=\&#34;201.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_28\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Austria\&#34;/&gt;\n    &lt;circle cx=\&#34;372.57\&#34; cy=\&#34;166.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_29\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Azerbaijan\&#34;/&gt;\n    &lt;circle cx=\&#34;226.20\&#34; cy=\&#34;20.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_30\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bangladesh\&#34;/&gt;\n    &lt;circle cx=\&#34;380.31\&#34; cy=\&#34;283.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_31\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Belarus\&#34;/&gt;\n    &lt;circle cx=\&#34;471.05\&#34; cy=\&#34;171.20\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_32\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Belgium\&#34;/&gt;\n    &lt;circle cx=\&#34;174.37\&#34; cy=\&#34;84.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_33\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Benin\&#34;/&gt;\n    &lt;circle cx=\&#34;291.42\&#34; cy=\&#34;115.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_34\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bolivia\&#34;/&gt;\n    &lt;circle cx=\&#34;345.01\&#34; cy=\&#34;136.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_35\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bosnia Herzegovina\&#34;/&gt;\n    &lt;circle cx=\&#34;370.25\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_36\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Botswana\&#34;/&gt;\n    &lt;circle cx=\&#34;361.22\&#34; cy=\&#34;93.52\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_37\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Brazil\&#34;/&gt;\n    &lt;circle cx=\&#34;390.65\&#34; cy=\&#34;266.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_38\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bulgaria\&#34;/&gt;\n    &lt;circle cx=\&#34;155.01\&#34; cy=\&#34;145.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_39\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Burkina Faso\&#34;/&gt;\n    &lt;circle cx=\&#34;64.36\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_40\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Burundi\&#34;/&gt;\n    &lt;circle cx=\&#34;229.67\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_41\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cambodia\&#34;/&gt;\n    &lt;circle cx=\&#34;222.24\&#34; cy=\&#34;106.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_42\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cameroon\&#34;/&gt;\n    &lt;circle cx=\&#34;468.72\&#34; cy=\&#34;110.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_43\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Canada\&#34;/&gt;\n    &lt;circle cx=\&#34;159.06\&#34; cy=\&#34;89.20\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_44\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Chad\&#34;/&gt;\n    &lt;circle cx=\&#34;406.44\&#34; cy=\&#34;119.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_45\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Chile\&#34;/&gt;\n    &lt;circle cx=\&#34;369.21\&#34; cy=\&#34;123.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_46\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;China\&#34;/&gt;\n    &lt;circle cx=\&#34;354.65\&#34; cy=\&#34;84.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_47\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Colombia\&#34;/&gt;\n    &lt;circle cx=\&#34;192.80\&#34; cy=\&#34;54.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_48\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Comoros\&#34;/&gt;\n    &lt;circle cx=\&#34;259.43\&#34; cy=\&#34;115.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_49\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Congo, Rep.\&#34;/&gt;\n    &lt;circle cx=\&#34;370.74\&#34; cy=\&#34;67.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_50\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Costa Rica\&#34;/&gt;\n    &lt;circle cx=\&#34;412.76\&#34; cy=\&#34;192.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_51\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Croatia\&#34;/&gt;\n    &lt;circle cx=\&#34;439.24\&#34; cy=\&#34;171.20\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_52\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cyprus\&#34;/&gt;\n    &lt;circle cx=\&#34;444.25\&#34; cy=\&#34;162.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_53\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Czech Republic\&#34;/&gt;\n    &lt;circle cx=\&#34;477.97\&#34; cy=\&#34;140.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_54\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Denmark\&#34;/&gt;\n    &lt;circle cx=\&#34;364.60\&#34; cy=\&#34;54.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_55\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Dominican Republic\&#34;/&gt;\n    &lt;circle cx=\&#34;333.00\&#34; cy=\&#34;67.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_56\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ecuador\&#34;/&gt;\n    &lt;circle cx=\&#34;332.97\&#34; cy=\&#34;20.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_57\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Egypt\&#34;/&gt;\n    &lt;circle cx=\&#34;297.01\&#34; cy=\&#34;102.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_58\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;El Salvador\&#34;/&gt;\n    &lt;circle cx=\&#34;431.12\&#34; cy=\&#34;218.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_59\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Estonia\&#34;/&gt;\n    &lt;circle cx=\&#34;431.12\&#34; cy=\&#34;110.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_60\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Eswatini\&#34;/&gt;\n    &lt;circle cx=\&#34;156.93\&#34; cy=\&#34;24.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_61\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ethiopia\&#34;/&gt;\n    &lt;circle cx=\&#34;464.81\&#34; cy=\&#34;123.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_62\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Finland\&#34;/&gt;\n    &lt;circle cx=\&#34;460.33\&#34; cy=\&#34;235.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_63\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;France\&#34;/&gt;\n    &lt;circle cx=\&#34;376.29\&#34; cy=\&#34;166.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_64\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Gabon\&#34;/&gt;\n    &lt;circle cx=\&#34;325.09\&#34; cy=\&#34;136.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_65\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Georgia\&#34;/&gt;\n    &lt;circle cx=\&#34;476.59\&#34; cy=\&#34;149.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_66\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Germany\&#34;/&gt;\n    &lt;circle cx=\&#34;240.75\&#34; cy=\&#34;58.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_67\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ghana\&#34;/&gt;\n    &lt;circle cx=\&#34;417.51\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_68\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Greece\&#34;/&gt;\n    &lt;circle cx=\&#34;298.75\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_69\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Guatemala\&#34;/&gt;\n    &lt;circle cx=\&#34;173.10\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_70\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Guinea\&#34;/&gt;\n    &lt;circle cx=\&#34;152.51\&#34; cy=\&#34;132.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_71\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Haiti\&#34;/&gt;\n    &lt;circle cx=\&#34;250.91\&#34; cy=\&#34;54.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_72\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Honduras\&#34;/&gt;\n    &lt;circle cx=\&#34;419.28\&#34; cy=\&#34;106.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_73\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Hungary\&#34;/&gt;\n    &lt;circle cx=\&#34;481.31\&#34; cy=\&#34;175.52\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_74\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iceland\&#34;/&gt;\n    &lt;circle cx=\&#34;284.75\&#34; cy=\&#34;28.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_75\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;India\&#34;/&gt;\n    &lt;circle cx=\&#34;338.68\&#34; cy=\&#34;80.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_76\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Indonesia\&#34;/&gt;\n    &lt;circle cx=\&#34;390.15\&#34; cy=\&#34;140.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_77\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iran\&#34;/&gt;\n    &lt;circle cx=\&#34;369.74\&#34; cy=\&#34;50.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_78\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iraq\&#34;/&gt;\n    &lt;circle cx=\&#34;515.67\&#34; cy=\&#34;119.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_79\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ireland\&#34;/&gt;\n    &lt;circle cx=\&#34;449.30\&#34; cy=\&#34;115.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_80\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Israel\&#34;/&gt;\n    &lt;circle cx=\&#34;452.22\&#34; cy=\&#34;110.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_81\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Italy\&#34;/&gt;\n    &lt;circle cx=\&#34;227.89\&#34; cy=\&#34;106.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_82\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ivory Coast\&#34;/&gt;\n    &lt;circle cx=\&#34;461.30\&#34; cy=\&#34;292.04\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_83\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Japan\&#34;/&gt;\n    &lt;circle cx=\&#34;310.05\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_84\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Jordan\&#34;/&gt;\n    &lt;circle cx=\&#34;413.30\&#34; cy=\&#34;240.26\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_85\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kazakhstan\&#34;/&gt;\n    &lt;circle cx=\&#34;210.29\&#34; cy=\&#34;54.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_86\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kenya\&#34;/&gt;\n    &lt;circle cx=\&#34;210.29\&#34; cy=\&#34;132.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_87\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kosovo\&#34;/&gt;\n    &lt;circle cx=\&#34;510.78\&#34; cy=\&#34;67.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_88\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kuwait\&#34;/&gt;\n    &lt;circle cx=\&#34;222.53\&#34; cy=\&#34;145.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_89\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kyrgyzstan\&#34;/&gt;\n    &lt;circle cx=\&#34;284.26\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_90\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Laos\&#34;/&gt;\n    &lt;circle cx=\&#34;419.59\&#34; cy=\&#34;244.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_91\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Latvia\&#34;/&gt;\n    &lt;circle cx=\&#34;354.71\&#34; cy=\&#34;76.26\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_92\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Lebanon\&#34;/&gt;\n    &lt;circle cx=\&#34;118.71\&#34; cy=\&#34;24.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_93\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Liberia\&#34;/&gt;\n    &lt;circle cx=\&#34;384.33\&#34; cy=\&#34;119.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_94\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Libya\&#34;/&gt;\n    &lt;circle cx=\&#34;434.89\&#34; cy=\&#34;214.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_95\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Lithuania\&#34;/&gt;\n    &lt;circle cx=\&#34;546.42\&#34; cy=\&#34;132.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_96\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Luxembourg\&#34;/&gt;\n    &lt;circle cx=\&#34;360.00\&#34; cy=\&#34;205.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_97\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Macedonia\&#34;/&gt;\n    &lt;circle cx=\&#34;137.46\&#34; cy=\&#34;71.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_98\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Madagascar\&#34;/&gt;\n    &lt;circle cx=\&#34;112.41\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_99\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malawi\&#34;/&gt;\n    &lt;circle cx=\&#34;423.81\&#34; cy=\&#34;46.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_100\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malaysia\&#34;/&gt;\n    &lt;circle cx=\&#34;171.84\&#34; cy=\&#34;153.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_101\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mali\&#34;/&gt;\n    &lt;circle cx=\&#34;456.11\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_102\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malta\&#34;/&gt;\n    &lt;circle cx=\&#34;228.22\&#34; cy=\&#34;119.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_103\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mauritania\&#34;/&gt;\n    &lt;circle cx=\&#34;396.78\&#34; cy=\&#34;166.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_104\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mauritius\&#34;/&gt;\n    &lt;circle cx=\&#34;377.35\&#34; cy=\&#34;54.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_105\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mexico\&#34;/&gt;\n    &lt;circle cx=\&#34;263.89\&#34; cy=\&#34;248.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_106\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Moldova\&#34;/&gt;\n    &lt;circle cx=\&#34;343.59\&#34; cy=\&#34;119.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_107\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mongolia\&#34;/&gt;\n    &lt;circle cx=\&#34;382.94\&#34; cy=\&#34;244.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_108\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Montenegro\&#34;/&gt;\n    &lt;circle cx=\&#34;299.55\&#34; cy=\&#34;93.52\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_109\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Morocco\&#34;/&gt;\n    &lt;circle cx=\&#34;116.02\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_110\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mozambique\&#34;/&gt;\n    &lt;circle cx=\&#34;271.50\&#34; cy=\&#34;46.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_111\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Myanmar\&#34;/&gt;\n    &lt;circle cx=\&#34;322.93\&#34; cy=\&#34;80.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_112\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Namibia\&#34;/&gt;\n    &lt;circle cx=\&#34;191.06\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_113\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nepal\&#34;/&gt;\n    &lt;circle cx=\&#34;480.11\&#34; cy=\&#34;149.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_114\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Netherlands\&#34;/&gt;\n    &lt;circle cx=\&#34;456.29\&#34; cy=\&#34;128.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_115\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;New Zealand\&#34;/&gt;\n    &lt;circle cx=\&#34;266.33\&#34; cy=\&#34;41.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_116\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nicaragua\&#34;/&gt;\n    &lt;circle cx=\&#34;96.08\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_117\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Niger\&#34;/&gt;\n    &lt;circle cx=\&#34;266.87\&#34; cy=\&#34;46.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_118\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nigeria\&#34;/&gt;\n    &lt;circle cx=\&#34;266.87\&#34; cy=\&#34;58.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_119\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Northern Cyprus\&#34;/&gt;\n    &lt;circle cx=\&#34;495.37\&#34; cy=\&#34;80.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_120\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Norway\&#34;/&gt;\n    &lt;circle cx=\&#34;260.94\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_121\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Pakistan\&#34;/&gt;\n    &lt;circle cx=\&#34;248.92\&#34; cy=\&#34;46.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_122\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Palestine\&#34;/&gt;\n    &lt;circle cx=\&#34;405.78\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_123\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Panama\&#34;/&gt;\n    &lt;circle cx=\&#34;344.81\&#34; cy=\&#34;102.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_124\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Paraguay\&#34;/&gt;\n    &lt;circle cx=\&#34;347.40\&#34; cy=\&#34;136.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_125\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Peru\&#34;/&gt;\n    &lt;circle cx=\&#34;301.02\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_126\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Philippines\&#34;/&gt;\n    &lt;circle cx=\&#34;422.73\&#34; cy=\&#34;102.15\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_127\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Poland\&#34;/&gt;\n    &lt;circle cx=\&#34;430.90\&#34; cy=\&#34;89.20\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_128\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Portugal\&#34;/&gt;\n    &lt;circle cx=\&#34;414.12\&#34; cy=\&#34;158.26\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_129\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Romania\&#34;/&gt;\n    &lt;circle cx=\&#34;409.92\&#34; cy=\&#34;248.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_130\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Russia\&#34;/&gt;\n    &lt;circle cx=\&#34;163.85\&#34; cy=\&#34;33.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_131\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Rwanda\&#34;/&gt;\n    &lt;circle cx=\&#34;482.45\&#34; cy=\&#34;71.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_132\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Saudi Arabia\&#34;/&gt;\n    &lt;circle cx=\&#34;215.05\&#34; cy=\&#34;123.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_133\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Senegal\&#34;/&gt;\n    &lt;circle cx=\&#34;360.88\&#34; cy=\&#34;153.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_134\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Serbia\&#34;/&gt;\n    &lt;circle cx=\&#34;135.70\&#34; cy=\&#34;37.42\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_135\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sierra Leone\&#34;/&gt;\n    &lt;circle cx=\&#34;536.72\&#34; cy=\&#34;110.78\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_136\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Singapore\&#34;/&gt;\n    &lt;circle cx=\&#34;430.73\&#34; cy=\&#34;123.73\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_137\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Slovakia\&#34;/&gt;\n    &lt;circle cx=\&#34;440.26\&#34; cy=\&#34;136.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_138\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Slovenia\&#34;/&gt;\n    &lt;circle cx=\&#34;347.86\&#34; cy=\&#34;84.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_139\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;South Africa\&#34;/&gt;\n    &lt;circle cx=\&#34;449.49\&#34; cy=\&#34;227.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_140\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;South Korea\&#34;/&gt;\n    &lt;circle cx=\&#34;448.63\&#34; cy=\&#34;97.84\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_141\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Spain\&#34;/&gt;\n    &lt;circle cx=\&#34;342.96\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_142\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sri Lanka\&#34;/&gt;\n    &lt;circle cx=\&#34;475.76\&#34; cy=\&#34;140.99\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_143\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sweden\&#34;/&gt;\n    &lt;circle cx=\&#34;500.47\&#34; cy=\&#34;210.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_144\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Switzerland\&#34;/&gt;\n    &lt;circle cx=\&#34;207.57\&#34; cy=\&#34;46.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_145\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tajikistan\&#34;/&gt;\n    &lt;circle cx=\&#34;199.67\&#34; cy=\&#34;24.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_146\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tanzania\&#34;/&gt;\n    &lt;circle cx=\&#34;375.19\&#34; cy=\&#34;37.42\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_147\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Thailand\&#34;/&gt;\n    &lt;circle cx=\&#34;145.88\&#34; cy=\&#34;63.31\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_148\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;The Gambia\&#34;/&gt;\n    &lt;circle cx=\&#34;143.82\&#34; cy=\&#34;218.68\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_149\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Togo\&#34;/&gt;\n    &lt;circle cx=\&#34;335.68\&#34; cy=\&#34;106.47\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_150\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tunisia\&#34;/&gt;\n    &lt;circle cx=\&#34;413.61\&#34; cy=\&#34;84.89\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_151\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Turkey\&#34;/&gt;\n    &lt;circle cx=\&#34;375.85\&#34; cy=\&#34;67.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_152\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Turkmenistan\&#34;/&gt;\n    &lt;circle cx=\&#34;513.36\&#34; cy=\&#34;80.57\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_153\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;UAE\&#34;/&gt;\n    &lt;circle cx=\&#34;155.12\&#34; cy=\&#34;67.63\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_154\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uganda\&#34;/&gt;\n    &lt;circle cx=\&#34;461.28\&#34; cy=\&#34;115.10\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_155\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;UK\&#34;/&gt;\n    &lt;circle cx=\&#34;304.73\&#34; cy=\&#34;313.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_156\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ukraine\&#34;/&gt;\n    &lt;circle cx=\&#34;397.88\&#34; cy=\&#34;128.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_157\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uruguay\&#34;/&gt;\n    &lt;circle cx=\&#34;492.34\&#34; cy=\&#34;128.05\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_158\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;USA\&#34;/&gt;\n    &lt;circle cx=\&#34;282.04\&#34; cy=\&#34;37.42\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_159\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uzbekistan\&#34;/&gt;\n    &lt;circle cx=\&#34;373.92\&#34; cy=\&#34;37.42\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_160\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Venezuela\&#34;/&gt;\n    &lt;circle cx=\&#34;280.76\&#34; cy=\&#34;132.36\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_161\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Vietnam\&#34;/&gt;\n    &lt;circle cx=\&#34;187.54\&#34; cy=\&#34;76.26\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_162\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Yemen\&#34;/&gt;\n    &lt;circle cx=\&#34;230.03\&#34; cy=\&#34;93.52\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_163\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Zambia\&#34;/&gt;\n    &lt;circle cx=\&#34;180.87\&#34; cy=\&#34;71.94\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_164\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;#FFA500\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#FFA500\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Zimbabwe\&#34;/&gt;\n    &lt;polyline points=\&#34;64.36,53.13 70.46,54.47 76.56,55.80 82.66,57.14 88.77,58.48 94.87,59.82 100.97,61.16 107.07,62.50 113.17,63.84 119.28,65.18 125.38,66.52 131.48,67.86 137.58,69.20 143.68,70.54 149.79,71.88 155.89,73.22 161.99,74.56 168.09,75.90 174.19,77.24 180.30,78.58 186.40,79.92 192.50,81.26 198.60,82.60 204.70,83.93 210.81,85.27 216.91,86.61 223.01,87.95 229.11,89.29 235.21,90.63 241.32,91.97 247.42,93.31 253.52,94.65 259.62,95.99 265.72,97.33 271.83,98.67 277.93,100.01 284.03,101.35 290.13,102.69 296.23,104.03 302.34,105.37 308.44,106.71 314.54,108.05 320.64,109.39 326.74,110.73 332.85,112.07 338.95,113.40 345.05,114.74 351.15,116.08 357.25,117.42 363.36,118.76 369.46,120.10 375.56,121.44 381.66,122.78 387.76,124.12 393.87,125.46 399.97,126.80 406.07,128.14 412.17,129.48 418.27,130.82 424.38,132.16 430.48,133.50 436.58,134.84 442.68,136.18 448.79,137.52 454.89,138.86 460.99,140.20 467.09,141.53 473.19,142.87 479.30,144.21 485.40,145.55 491.50,146.89 497.60,148.23 503.70,149.57 509.81,150.91 515.91,152.25 522.01,153.59 528.11,154.93 534.21,156.27 540.32,157.61 546.42,158.95\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_165\&#34; clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;2.13396\&#34; stroke=\&#34;#3366FF\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_166\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_167\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_168\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_169\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_170\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_171\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_172\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_173\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_174\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_175\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_176\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_177\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_178\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_179\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_180\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_181\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_182\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_183\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_184\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_185\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_186\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_187\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_188\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_189\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_190\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_191\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_192\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_193\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_194\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_195\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_196\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_197\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_198\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_199\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_200\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_201\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_202\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_203\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_204\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_205\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_206\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_207\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_208\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_209\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_210\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_211\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_212\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_213\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_214\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_215\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_216\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_217\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_218\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_219\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_220\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_221\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_222\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_223\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_224\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_225\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_226\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_227\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_228\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_229\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_230\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_231\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_232\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_233\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_234\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_235\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_236\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_237\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_238\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_239\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_240\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_241\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_242\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_243\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_244\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_245\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_246\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_247\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_248\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_249\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_250\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_251\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_252\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_253\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_254\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_255\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_256\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_257\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_258\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_259\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_260\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_261\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_262\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_263\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_264\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_265\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_266\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_267\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_268\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_269\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_270\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_271\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_272\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_273\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_274\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_275\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_276\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_277\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_278\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_279\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_280\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_281\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_282\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_283\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_284\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_285\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_286\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_287\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_288\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_289\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_290\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_291\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_292\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_293\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_294\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_295\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_296\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_297\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_298\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_299\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_300\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_301\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_302\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_303\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_304\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_305\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_306\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_307\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_308\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_309\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_310\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_311\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_312\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_313\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_314\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_315\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_316\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_317\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_318\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_319\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_320\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_321\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_322\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_323\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_324\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_325\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_326\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_327\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_328\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_329\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_330\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_331\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_332\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_333\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_334\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_335\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_336\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_337\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_338\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_339\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_340\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_341\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_342\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_343\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_344\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_345\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_346\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_347\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_348\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_349\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_350\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_351\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_352\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_353\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_354\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_355\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_356\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_357\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_358\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_359\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_360\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_361\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_362\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_363\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_364\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_365\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_366\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_367\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_368\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_369\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_370\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_371\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_372\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_373\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_374\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_375\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_376\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_377\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_378\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_379\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_380\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_381\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_382\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_383\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_384\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_385\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_386\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_387\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_388\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_389\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_390\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_391\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_392\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_393\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_394\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_395\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_396\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_397\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_398\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_399\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_400\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_401\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_402\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_403\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_404\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_405\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_406\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_407\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_408\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_409\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_410\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_411\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_412\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_413\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_414\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_415\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_416\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_417\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_418\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_419\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_420\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_421\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_422\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_423\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_424\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_425\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_426\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_427\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_428\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_429\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_430\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_431\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_432\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_433\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_434\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_435\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_436\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_437\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_438\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_439\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_440\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_441\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_442\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_443\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_444\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_445\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_446\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_447\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_448\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_449\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_450\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_451\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;119.01\&#34; y=\&#34;284.69\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_452\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value = 122.04[9.3]-4.95[0.98]*l_gdp,&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_3)\&#34;&gt;\n      &lt;text x=\&#34;177.99\&#34; y=\&#34;296.99\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_453\&#34; font-size=\&#34;6.40pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt; R2 = 0.15&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;269.36\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_454\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;40&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;183.04\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_455\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;60&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;96.73\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_456\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;80&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;18.53\&#34; y=\&#34;10.41\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_457\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;100&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;100.66\&#34; y=\&#34;339.64\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_458\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;7&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;198.02\&#34; y=\&#34;339.64\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_459\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;8&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;295.38\&#34; y=\&#34;339.64\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_460\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;9&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;389.94\&#34; y=\&#34;339.64\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_461\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;10&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;487.30\&#34; y=\&#34;339.64\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_462\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;11&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;290.64\&#34; y=\&#34;352.23\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_463\&#34; font-size=\&#34;8.25pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;l_gdp&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_cl_4)\&#34;&gt;\n      &lt;text transform=\&#34;translate(13.50,181.91) rotate(-90)\&#34; id=\&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621_el_464\&#34; font-size=\&#34;8.25pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value&lt;\/text&gt;\n    &lt;\/g&gt;\n  &lt;\/g&gt;\n&lt;\/svg&gt;\n&#34;,&#34;js&#34;:null,&#34;uid&#34;:&#34;svg_453fcb5d-815e-47b7-98f5-9b9c70ef5621&#34;,&#34;ratio&#34;:1.6,&#34;settings&#34;:{&#34;tooltip&#34;:{&#34;css&#34;:&#34; .tooltip_SVGID_ { padding:5px;background:black;color:white;border-radius:2px 2px 2px 2px ; position:absolute;pointer-events:none;z-index:999;}\n&#34;,&#34;offx&#34;:10,&#34;offy&#34;:0,&#34;use_cursor_pos&#34;:true,&#34;opacity&#34;:0.9,&#34;usefill&#34;:false,&#34;usestroke&#34;:false,&#34;delay&#34;:{&#34;over&#34;:200,&#34;out&#34;:500}},&#34;hover&#34;:{&#34;css&#34;:&#34; .hover_SVGID_ { fill:orange;stroke:gray; }\n&#34;},&#34;hoverkey&#34;:{&#34;css&#34;:&#34; .hover_key_SVGID_ { stroke:red; }\n&#34;},&#34;hovertheme&#34;:{&#34;css&#34;:&#34; .hover_theme_SVGID_ { fill:green; }\n&#34;},&#34;zoom&#34;:{&#34;min&#34;:1,&#34;max&#34;:1},&#34;capture&#34;:{&#34;css&#34;:&#34; .selected_SVGID_ { fill:red;stroke:gray; }\n&#34;,&#34;type&#34;:&#34;multiple&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;capturekey&#34;:{&#34;css&#34;:&#34; .selected_key_SVGID_ { stroke:gray; }\n&#34;,&#34;type&#34;:&#34;single&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;capturetheme&#34;:{&#34;css&#34;:&#34; .selected_theme_SVGID_ { stroke:gray; }\n&#34;,&#34;type&#34;:&#34;single&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;toolbar&#34;:{&#34;position&#34;:&#34;topright&#34;,&#34;saveaspng&#34;:true},&#34;sizing&#34;:{&#34;rescale&#34;:true,&#34;width&#34;:1}}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;So what’s actually going on? &lt;code&gt;value&lt;/code&gt; is the percentage of people, in a country, that believe vaccines
are safe. &lt;code&gt;l_gdp&lt;/code&gt; is the logarithm of GDP per capita in that same country. Looking at this,
many people will conclude that the richer the country, the less people trust vaccines. This is
the story the Economist is telling its readers. This is a simple explanation, and it’s backed by
numbers and stats, so it must be correct. Right?&lt;/p&gt;
&lt;p&gt;WRONG.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the regression equation (standard errors in square brackets):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{value} = 122.04[9.3] - 4.95[0.98] * \text{l_gdp}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both coefficients are significant at the usual 5% level (the intercept is interesting though, as
it implies a value greater than 100 for very low levels of log of GDP). This gives comfort to the
person believing the basic story.&lt;/p&gt;
&lt;p&gt;But take a look at the R². It’s 0.15. That means that the linear regression will be able to predict
up to 15% of the variance in the dependent variable using the log of GDP per capita as a predictor.
That already should sound all sorts of alarms in your head (if that scatter plot that looks almost
like random noise didn’t already). However, I’m not done yet.&lt;/p&gt;
&lt;p&gt;What if you wanted to do something a little bit more elaborate? For
instance, let’s say that you’d like to see if infant mortality plays a role? After all, you could
argue that in very poor countries, where people seem to trust vaccines very much, infant mortality
is very high. Vaccinating your kid seems like a no-brainer when the alternative is almost
certain death from any of the many diseases afflicting children (don’t get me wrong here, vaccinating
children against deadly diseases is a no-brainer anywhere on the planet).
Maybe people in wealthier countries don’t ascribe low infant mortality to vaccines, but to other
things such as access to clean water, good infrastructure etc, and thus tend to downplay the role of
vaccines. Who knows. But let’s dig deeper and get some more data.&lt;/p&gt;
&lt;p&gt;For this I’m using another data set that gives the infant mortality rate in 2018 for most of the
countries from the original analysis. I got that data from the Worldbank, and you can easily
download the csv from &lt;a href=&#34;https://gist.github.com/b-rodrigues/33f64ce6910e6ec4df9d586eacf335c2&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below, I’m downloading the data and joining that to my original dataset. Then I’m computing a rank
based on the median infant mortality rate. Countries that have an infant mortality rate below
the median are classified as “low infant mortality rate” countries and countries that have an
infant mortality rate above the median infant mortality rate are classified as
“high infant mortality rate” countries. I then redo the same plot as before, but I’m computing
one regression line per group of countries.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click to see the code
&lt;/summary&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;infant_mortality_rate &amp;lt;- data.table::fread(&amp;quot;https://gist.githubusercontent.com/b-rodrigues/33f64ce6910e6ec4df9d586eacf335c2/raw/01df8977edd3924a3687f783e7e5a134d5f3fd87/infant_mortality_rate_2018.csv&amp;quot;) %&amp;gt;%
  janitor::clean_names() %&amp;gt;%
  select(country_name, imr = x2018_yr2018)

plot_data_simpson &amp;lt;- plot_data %&amp;gt;%
  ungroup() %&amp;gt;%  
  left_join(infant_mortality_rate) %&amp;gt;%
  mutate(imr = as.numeric(imr)) %&amp;gt;%  
  filter(!is.na(imr)) %&amp;gt;%  
  mutate(rank = ntile(imr, n = 2))  %&amp;gt;%
  mutate(rank = ifelse(rank == 2,
                       &amp;quot;High infant mortality rate&amp;quot;,
                       &amp;quot;Low infant mortality rate&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;country_name&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_plot &amp;lt;- plot_data_simpson %&amp;gt;%
  ggplot(aes(y = value, x = l_gdp)) +
  geom_point_interactive(aes(tooltip = country_name, colour = rank)) +
  geom_smooth(aes(group = rank), method = &amp;quot;lm&amp;quot;) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;girafe(ggobj = my_plot, width_svg = 8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:672px;height:480px;&#34; class=&#34;girafe html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;?xml version=\&#34;1.0\&#34; encoding=\&#34;UTF-8\&#34;?&gt;\n&lt;svg xmlns=\&#34;http://www.w3.org/2000/svg\&#34; xmlns:xlink=\&#34;http://www.w3.org/1999/xlink\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b\&#34; viewBox=\&#34;0 0 576.00 360.00\&#34;&gt;\n  &lt;g&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_1\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_1\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_1)\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.75\&#34; stroke=\&#34;#FFFFFF\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_2\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_2\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_2)\&#34; fill=\&#34;#272B30\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#000000\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3\&#34;&gt;\n        &lt;rect x=\&#34;40.25\&#34; y=\&#34;5.48\&#34; width=\&#34;530.27\&#34; height=\&#34;283.62\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;polyline points=\&#34;40.25,272.42 570.52,272.42\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_3\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,196.58 570.52,196.58\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_4\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,120.75 570.52,120.75\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_5\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,44.91 570.52,44.91\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_6\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;54.78,289.10 54.78,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_7\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;152.14,289.10 152.14,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_8\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;249.50,289.10 249.50,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_9\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;346.86,289.10 346.86,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_10\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;444.22,289.10 444.22,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_11\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;541.58,289.10 541.58,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_12\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;0.533489\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,234.50 570.52,234.50\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_13\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,158.66 570.52,158.66\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_14\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,82.83 570.52,82.83\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_15\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;40.25,7.00 570.52,7.00\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_16\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;103.46,289.10 103.46,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_17\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;200.82,289.10 200.82,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_18\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;298.18,289.10 298.18,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_19\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;395.54,289.10 395.54,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_20\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polyline points=\&#34;492.90,289.10 492.90,5.48\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_21\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;1.06698\&#34; stroke=\&#34;#425D65\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;circle cx=\&#34;160.60\&#34; cy=\&#34;29.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_22\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Afghanistan\&#34;/&gt;\n    &lt;circle cx=\&#34;343.78\&#34; cy=\&#34;147.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_23\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Albania\&#34;/&gt;\n    &lt;circle cx=\&#34;359.81\&#34; cy=\&#34;147.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_24\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Algeria\&#34;/&gt;\n    &lt;circle cx=\&#34;389.89\&#34; cy=\&#34;52.50\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_25\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Argentina\&#34;/&gt;\n    &lt;circle cx=\&#34;315.17\&#34; cy=\&#34;226.91\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_26\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Armenia\&#34;/&gt;\n    &lt;circle cx=\&#34;472.31\&#34; cy=\&#34;71.46\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_27\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Australia\&#34;/&gt;\n    &lt;circle cx=\&#34;479.91\&#34; cy=\&#34;177.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_28\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Austria\&#34;/&gt;\n    &lt;circle cx=\&#34;372.57\&#34; cy=\&#34;147.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_29\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Azerbaijan\&#34;/&gt;\n    &lt;circle cx=\&#34;226.20\&#34; cy=\&#34;18.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_30\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bangladesh\&#34;/&gt;\n    &lt;circle cx=\&#34;380.31\&#34; cy=\&#34;249.66\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_31\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Belarus\&#34;/&gt;\n    &lt;circle cx=\&#34;471.05\&#34; cy=\&#34;151.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_32\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Belgium\&#34;/&gt;\n    &lt;circle cx=\&#34;174.37\&#34; cy=\&#34;75.25\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_33\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Benin\&#34;/&gt;\n    &lt;circle cx=\&#34;291.42\&#34; cy=\&#34;101.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_34\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bolivia\&#34;/&gt;\n    &lt;circle cx=\&#34;345.01\&#34; cy=\&#34;120.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_35\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bosnia Herzegovina\&#34;/&gt;\n    &lt;circle cx=\&#34;370.25\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_36\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Botswana\&#34;/&gt;\n    &lt;circle cx=\&#34;361.22\&#34; cy=\&#34;82.83\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_37\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Brazil\&#34;/&gt;\n    &lt;circle cx=\&#34;390.65\&#34; cy=\&#34;234.50\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_38\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Bulgaria\&#34;/&gt;\n    &lt;circle cx=\&#34;155.01\&#34; cy=\&#34;128.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_39\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Burkina Faso\&#34;/&gt;\n    &lt;circle cx=\&#34;64.36\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_40\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Burundi\&#34;/&gt;\n    &lt;circle cx=\&#34;229.67\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_41\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cambodia\&#34;/&gt;\n    &lt;circle cx=\&#34;222.24\&#34; cy=\&#34;94.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_42\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cameroon\&#34;/&gt;\n    &lt;circle cx=\&#34;468.72\&#34; cy=\&#34;98.00\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_43\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Canada\&#34;/&gt;\n    &lt;circle cx=\&#34;159.06\&#34; cy=\&#34;79.04\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_44\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Chad\&#34;/&gt;\n    &lt;circle cx=\&#34;406.44\&#34; cy=\&#34;105.58\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_45\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Chile\&#34;/&gt;\n    &lt;circle cx=\&#34;369.21\&#34; cy=\&#34;109.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_46\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;China\&#34;/&gt;\n    &lt;circle cx=\&#34;354.65\&#34; cy=\&#34;75.25\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_47\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Colombia\&#34;/&gt;\n    &lt;circle cx=\&#34;192.80\&#34; cy=\&#34;48.70\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_48\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Comoros\&#34;/&gt;\n    &lt;circle cx=\&#34;259.43\&#34; cy=\&#34;101.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_49\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Congo, Rep.\&#34;/&gt;\n    &lt;circle cx=\&#34;370.74\&#34; cy=\&#34;60.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_50\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Costa Rica\&#34;/&gt;\n    &lt;circle cx=\&#34;412.76\&#34; cy=\&#34;170.04\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_51\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Croatia\&#34;/&gt;\n    &lt;circle cx=\&#34;439.24\&#34; cy=\&#34;151.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_52\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Cyprus\&#34;/&gt;\n    &lt;circle cx=\&#34;444.25\&#34; cy=\&#34;143.50\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_53\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Czech Republic\&#34;/&gt;\n    &lt;circle cx=\&#34;477.97\&#34; cy=\&#34;124.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_54\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Denmark\&#34;/&gt;\n    &lt;circle cx=\&#34;364.60\&#34; cy=\&#34;48.70\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_55\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Dominican Republic\&#34;/&gt;\n    &lt;circle cx=\&#34;333.00\&#34; cy=\&#34;60.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_56\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ecuador\&#34;/&gt;\n    &lt;circle cx=\&#34;332.97\&#34; cy=\&#34;18.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_57\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Egypt\&#34;/&gt;\n    &lt;circle cx=\&#34;297.01\&#34; cy=\&#34;90.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_58\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;El Salvador\&#34;/&gt;\n    &lt;circle cx=\&#34;431.12\&#34; cy=\&#34;192.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_59\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Estonia\&#34;/&gt;\n    &lt;circle cx=\&#34;431.12\&#34; cy=\&#34;98.00\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_60\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Eswatini\&#34;/&gt;\n    &lt;circle cx=\&#34;156.93\&#34; cy=\&#34;22.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_61\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ethiopia\&#34;/&gt;\n    &lt;circle cx=\&#34;464.81\&#34; cy=\&#34;109.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_62\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Finland\&#34;/&gt;\n    &lt;circle cx=\&#34;460.33\&#34; cy=\&#34;207.96\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_63\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;France\&#34;/&gt;\n    &lt;circle cx=\&#34;376.29\&#34; cy=\&#34;147.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_64\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Gabon\&#34;/&gt;\n    &lt;circle cx=\&#34;325.09\&#34; cy=\&#34;120.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_65\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Georgia\&#34;/&gt;\n    &lt;circle cx=\&#34;476.59\&#34; cy=\&#34;132.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_66\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Germany\&#34;/&gt;\n    &lt;circle cx=\&#34;240.75\&#34; cy=\&#34;52.50\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_67\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ghana\&#34;/&gt;\n    &lt;circle cx=\&#34;417.51\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_68\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Greece\&#34;/&gt;\n    &lt;circle cx=\&#34;298.75\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_69\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Guatemala\&#34;/&gt;\n    &lt;circle cx=\&#34;173.10\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_70\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Guinea\&#34;/&gt;\n    &lt;circle cx=\&#34;152.51\&#34; cy=\&#34;116.96\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_71\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Haiti\&#34;/&gt;\n    &lt;circle cx=\&#34;250.91\&#34; cy=\&#34;48.70\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_72\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Honduras\&#34;/&gt;\n    &lt;circle cx=\&#34;419.28\&#34; cy=\&#34;94.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_73\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Hungary\&#34;/&gt;\n    &lt;circle cx=\&#34;481.31\&#34; cy=\&#34;154.87\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_74\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iceland\&#34;/&gt;\n    &lt;circle cx=\&#34;284.75\&#34; cy=\&#34;25.95\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_75\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;India\&#34;/&gt;\n    &lt;circle cx=\&#34;338.68\&#34; cy=\&#34;71.46\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_76\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Indonesia\&#34;/&gt;\n    &lt;circle cx=\&#34;390.15\&#34; cy=\&#34;124.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_77\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iran\&#34;/&gt;\n    &lt;circle cx=\&#34;369.74\&#34; cy=\&#34;44.91\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_78\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Iraq\&#34;/&gt;\n    &lt;circle cx=\&#34;515.67\&#34; cy=\&#34;105.58\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_79\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ireland\&#34;/&gt;\n    &lt;circle cx=\&#34;449.30\&#34; cy=\&#34;101.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_80\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Israel\&#34;/&gt;\n    &lt;circle cx=\&#34;452.22\&#34; cy=\&#34;98.00\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_81\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Italy\&#34;/&gt;\n    &lt;circle cx=\&#34;227.89\&#34; cy=\&#34;94.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_82\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ivory Coast\&#34;/&gt;\n    &lt;circle cx=\&#34;461.30\&#34; cy=\&#34;257.25\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_83\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Japan\&#34;/&gt;\n    &lt;circle cx=\&#34;310.05\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_84\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Jordan\&#34;/&gt;\n    &lt;circle cx=\&#34;413.30\&#34; cy=\&#34;211.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_85\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kazakhstan\&#34;/&gt;\n    &lt;circle cx=\&#34;210.29\&#34; cy=\&#34;48.70\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_86\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kenya\&#34;/&gt;\n    &lt;circle cx=\&#34;510.78\&#34; cy=\&#34;60.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_87\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kuwait\&#34;/&gt;\n    &lt;circle cx=\&#34;222.53\&#34; cy=\&#34;128.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_88\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Kyrgyzstan\&#34;/&gt;\n    &lt;circle cx=\&#34;284.26\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_89\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Laos\&#34;/&gt;\n    &lt;circle cx=\&#34;419.59\&#34; cy=\&#34;215.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_90\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Latvia\&#34;/&gt;\n    &lt;circle cx=\&#34;354.71\&#34; cy=\&#34;67.66\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_91\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Lebanon\&#34;/&gt;\n    &lt;circle cx=\&#34;118.71\&#34; cy=\&#34;22.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_92\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Liberia\&#34;/&gt;\n    &lt;circle cx=\&#34;384.33\&#34; cy=\&#34;105.58\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_93\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Libya\&#34;/&gt;\n    &lt;circle cx=\&#34;434.89\&#34; cy=\&#34;189.00\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_94\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Lithuania\&#34;/&gt;\n    &lt;circle cx=\&#34;546.42\&#34; cy=\&#34;116.96\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_95\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Luxembourg\&#34;/&gt;\n    &lt;circle cx=\&#34;360.00\&#34; cy=\&#34;181.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_96\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Macedonia\&#34;/&gt;\n    &lt;circle cx=\&#34;137.46\&#34; cy=\&#34;63.87\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_97\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Madagascar\&#34;/&gt;\n    &lt;circle cx=\&#34;112.41\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_98\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malawi\&#34;/&gt;\n    &lt;circle cx=\&#34;423.81\&#34; cy=\&#34;41.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_99\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malaysia\&#34;/&gt;\n    &lt;circle cx=\&#34;171.84\&#34; cy=\&#34;135.91\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_100\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mali\&#34;/&gt;\n    &lt;circle cx=\&#34;456.11\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_101\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Malta\&#34;/&gt;\n    &lt;circle cx=\&#34;228.22\&#34; cy=\&#34;105.58\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_102\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mauritania\&#34;/&gt;\n    &lt;circle cx=\&#34;396.78\&#34; cy=\&#34;147.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_103\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mauritius\&#34;/&gt;\n    &lt;circle cx=\&#34;377.35\&#34; cy=\&#34;48.70\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_104\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mexico\&#34;/&gt;\n    &lt;circle cx=\&#34;263.89\&#34; cy=\&#34;219.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_105\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Moldova\&#34;/&gt;\n    &lt;circle cx=\&#34;343.59\&#34; cy=\&#34;105.58\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_106\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mongolia\&#34;/&gt;\n    &lt;circle cx=\&#34;382.94\&#34; cy=\&#34;215.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_107\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Montenegro\&#34;/&gt;\n    &lt;circle cx=\&#34;299.55\&#34; cy=\&#34;82.83\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_108\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Morocco\&#34;/&gt;\n    &lt;circle cx=\&#34;116.02\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_109\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Mozambique\&#34;/&gt;\n    &lt;circle cx=\&#34;271.50\&#34; cy=\&#34;41.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_110\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Myanmar\&#34;/&gt;\n    &lt;circle cx=\&#34;322.93\&#34; cy=\&#34;71.46\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_111\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Namibia\&#34;/&gt;\n    &lt;circle cx=\&#34;191.06\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_112\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nepal\&#34;/&gt;\n    &lt;circle cx=\&#34;480.11\&#34; cy=\&#34;132.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_113\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Netherlands\&#34;/&gt;\n    &lt;circle cx=\&#34;456.29\&#34; cy=\&#34;113.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_114\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;New Zealand\&#34;/&gt;\n    &lt;circle cx=\&#34;266.33\&#34; cy=\&#34;37.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_115\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nicaragua\&#34;/&gt;\n    &lt;circle cx=\&#34;96.08\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_116\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Niger\&#34;/&gt;\n    &lt;circle cx=\&#34;266.87\&#34; cy=\&#34;41.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_117\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Nigeria\&#34;/&gt;\n    &lt;circle cx=\&#34;495.37\&#34; cy=\&#34;71.46\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_118\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Norway\&#34;/&gt;\n    &lt;circle cx=\&#34;260.94\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_119\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Pakistan\&#34;/&gt;\n    &lt;circle cx=\&#34;248.92\&#34; cy=\&#34;41.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_120\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Palestine\&#34;/&gt;\n    &lt;circle cx=\&#34;405.78\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_121\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Panama\&#34;/&gt;\n    &lt;circle cx=\&#34;344.81\&#34; cy=\&#34;90.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_122\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Paraguay\&#34;/&gt;\n    &lt;circle cx=\&#34;347.40\&#34; cy=\&#34;120.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_123\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Peru\&#34;/&gt;\n    &lt;circle cx=\&#34;301.02\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_124\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Philippines\&#34;/&gt;\n    &lt;circle cx=\&#34;422.73\&#34; cy=\&#34;90.41\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_125\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Poland\&#34;/&gt;\n    &lt;circle cx=\&#34;430.90\&#34; cy=\&#34;79.04\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_126\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Portugal\&#34;/&gt;\n    &lt;circle cx=\&#34;414.12\&#34; cy=\&#34;139.71\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_127\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Romania\&#34;/&gt;\n    &lt;circle cx=\&#34;409.92\&#34; cy=\&#34;219.33\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_128\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Russia\&#34;/&gt;\n    &lt;circle cx=\&#34;163.85\&#34; cy=\&#34;29.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_129\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Rwanda\&#34;/&gt;\n    &lt;circle cx=\&#34;482.45\&#34; cy=\&#34;63.87\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_130\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Saudi Arabia\&#34;/&gt;\n    &lt;circle cx=\&#34;215.05\&#34; cy=\&#34;109.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_131\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Senegal\&#34;/&gt;\n    &lt;circle cx=\&#34;360.88\&#34; cy=\&#34;135.91\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_132\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Serbia\&#34;/&gt;\n    &lt;circle cx=\&#34;135.70\&#34; cy=\&#34;33.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_133\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sierra Leone\&#34;/&gt;\n    &lt;circle cx=\&#34;536.72\&#34; cy=\&#34;98.00\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_134\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Singapore\&#34;/&gt;\n    &lt;circle cx=\&#34;430.73\&#34; cy=\&#34;109.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_135\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Slovakia\&#34;/&gt;\n    &lt;circle cx=\&#34;440.26\&#34; cy=\&#34;120.75\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_136\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Slovenia\&#34;/&gt;\n    &lt;circle cx=\&#34;347.86\&#34; cy=\&#34;75.25\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_137\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;South Africa\&#34;/&gt;\n    &lt;circle cx=\&#34;449.49\&#34; cy=\&#34;200.37\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_138\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;South Korea\&#34;/&gt;\n    &lt;circle cx=\&#34;448.63\&#34; cy=\&#34;86.62\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_139\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Spain\&#34;/&gt;\n    &lt;circle cx=\&#34;342.96\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_140\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sri Lanka\&#34;/&gt;\n    &lt;circle cx=\&#34;475.76\&#34; cy=\&#34;124.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_141\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Sweden\&#34;/&gt;\n    &lt;circle cx=\&#34;500.47\&#34; cy=\&#34;185.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_142\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Switzerland\&#34;/&gt;\n    &lt;circle cx=\&#34;207.57\&#34; cy=\&#34;41.12\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_143\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tajikistan\&#34;/&gt;\n    &lt;circle cx=\&#34;199.67\&#34; cy=\&#34;22.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_144\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tanzania\&#34;/&gt;\n    &lt;circle cx=\&#34;375.19\&#34; cy=\&#34;33.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_145\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Thailand\&#34;/&gt;\n    &lt;circle cx=\&#34;145.88\&#34; cy=\&#34;56.29\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_146\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;The Gambia\&#34;/&gt;\n    &lt;circle cx=\&#34;143.82\&#34; cy=\&#34;192.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_147\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Togo\&#34;/&gt;\n    &lt;circle cx=\&#34;335.68\&#34; cy=\&#34;94.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_148\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Tunisia\&#34;/&gt;\n    &lt;circle cx=\&#34;413.61\&#34; cy=\&#34;75.25\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_149\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Turkey\&#34;/&gt;\n    &lt;circle cx=\&#34;375.85\&#34; cy=\&#34;60.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_150\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Turkmenistan\&#34;/&gt;\n    &lt;circle cx=\&#34;513.36\&#34; cy=\&#34;71.46\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_151\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;UAE\&#34;/&gt;\n    &lt;circle cx=\&#34;155.12\&#34; cy=\&#34;60.08\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_152\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uganda\&#34;/&gt;\n    &lt;circle cx=\&#34;461.28\&#34; cy=\&#34;101.79\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_153\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;UK\&#34;/&gt;\n    &lt;circle cx=\&#34;304.73\&#34; cy=\&#34;276.21\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_154\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Ukraine\&#34;/&gt;\n    &lt;circle cx=\&#34;397.88\&#34; cy=\&#34;113.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_155\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uruguay\&#34;/&gt;\n    &lt;circle cx=\&#34;492.34\&#34; cy=\&#34;113.16\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_156\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;USA\&#34;/&gt;\n    &lt;circle cx=\&#34;282.04\&#34; cy=\&#34;33.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_157\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Uzbekistan\&#34;/&gt;\n    &lt;circle cx=\&#34;373.92\&#34; cy=\&#34;33.54\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_158\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Venezuela\&#34;/&gt;\n    &lt;circle cx=\&#34;280.76\&#34; cy=\&#34;116.96\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_159\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Vietnam\&#34;/&gt;\n    &lt;circle cx=\&#34;187.54\&#34; cy=\&#34;67.66\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_160\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Yemen\&#34;/&gt;\n    &lt;circle cx=\&#34;230.03\&#34; cy=\&#34;82.83\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_161\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Zambia\&#34;/&gt;\n    &lt;circle cx=\&#34;180.87\&#34; cy=\&#34;63.87\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_162\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34; title=\&#34;Zimbabwe\&#34;/&gt;\n    &lt;polygon points=\&#34;64.36,33.18 69.00,34.07 73.64,34.96 78.28,35.85 82.93,36.73 87.57,37.61 92.21,38.49 96.85,39.37 101.50,40.24 106.14,41.11 110.78,41.98 115.42,42.84 120.07,43.69 124.71,44.54 129.35,45.39 133.99,46.23 138.64,47.06 143.28,47.89 147.92,48.71 152.56,49.52 157.21,50.32 161.85,51.11 166.49,51.90 171.13,52.67 175.78,53.43 180.42,54.18 185.06,54.91 189.70,55.63 194.35,56.34 198.99,57.02 203.63,57.69 208.27,58.34 212.92,58.96 217.56,59.57 222.20,60.15 226.84,60.70 231.49,61.23 236.13,61.74 240.77,62.21 245.41,62.66 250.06,63.08 254.70,63.47 259.34,63.84 263.99,64.17 268.63,64.48 273.27,64.77 277.91,65.03 282.56,65.26 287.20,65.47 291.84,65.67 296.48,65.84 301.13,65.99 305.77,66.12 310.41,66.24 315.05,66.34 319.70,66.43 324.34,66.51 328.98,66.57 333.62,66.62 338.27,66.66 342.91,66.69 347.55,66.72 352.19,66.73 356.84,66.74 361.48,66.74 366.12,66.74 370.76,66.72 375.41,66.71 380.05,66.69 384.69,66.66 389.33,66.63 393.98,66.59 398.62,66.55 403.26,66.51 407.90,66.46 412.55,66.41 417.19,66.36 421.83,66.31 426.47,66.25 431.12,66.19 431.12,112.29 426.47,111.39 421.83,110.50 417.19,109.62 412.55,108.73 407.90,107.85 403.26,106.97 398.62,106.10 393.98,105.23 389.33,104.36 384.69,103.49 380.05,102.64 375.41,101.78 370.76,100.93 366.12,100.09 361.48,99.25 356.84,98.42 352.19,97.59 347.55,96.78 342.91,95.97 338.27,95.17 333.62,94.38 328.98,93.60 324.34,92.83 319.70,92.07 315.05,91.33 310.41,90.60 305.77,89.88 301.13,89.19 296.48,88.51 291.84,87.84 287.20,87.20 282.56,86.58 277.91,85.99 273.27,85.41 268.63,84.86 263.99,84.34 259.34,83.85 254.70,83.38 250.06,82.94 245.41,82.53 240.77,82.14 236.13,81.79 231.49,81.46 226.84,81.16 222.20,80.88 217.56,80.63 212.92,80.40 208.27,80.19 203.63,80.01 198.99,79.84 194.35,79.70 189.70,79.57 185.06,79.46 180.42,79.36 175.78,79.27 171.13,79.20 166.49,79.14 161.85,79.09 157.21,79.05 152.56,79.02 147.92,79.00 143.28,78.99 138.64,78.98 133.99,78.99 129.35,78.99 124.71,79.01 120.07,79.03 115.42,79.05 110.78,79.08 106.14,79.11 101.50,79.15 96.85,79.19 92.21,79.23 87.57,79.28 82.93,79.33 78.28,79.38 73.64,79.44 69.00,79.49 64.36,79.55\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_163\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#999999\&#34; fill-opacity=\&#34;0.4\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;64.36,33.18 69.00,34.07 73.64,34.96 78.28,35.85 82.93,36.73 87.57,37.61 92.21,38.49 96.85,39.37 101.50,40.24 106.14,41.11 110.78,41.98 115.42,42.84 120.07,43.69 124.71,44.54 129.35,45.39 133.99,46.23 138.64,47.06 143.28,47.89 147.92,48.71 152.56,49.52 157.21,50.32 161.85,51.11 166.49,51.90 171.13,52.67 175.78,53.43 180.42,54.18 185.06,54.91 189.70,55.63 194.35,56.34 198.99,57.02 203.63,57.69 208.27,58.34 212.92,58.96 217.56,59.57 222.20,60.15 226.84,60.70 231.49,61.23 236.13,61.74 240.77,62.21 245.41,62.66 250.06,63.08 254.70,63.47 259.34,63.84 263.99,64.17 268.63,64.48 273.27,64.77 277.91,65.03 282.56,65.26 287.20,65.47 291.84,65.67 296.48,65.84 301.13,65.99 305.77,66.12 310.41,66.24 315.05,66.34 319.70,66.43 324.34,66.51 328.98,66.57 333.62,66.62 338.27,66.66 342.91,66.69 347.55,66.72 352.19,66.73 356.84,66.74 361.48,66.74 366.12,66.74 370.76,66.72 375.41,66.71 380.05,66.69 384.69,66.66 389.33,66.63 393.98,66.59 398.62,66.55 403.26,66.51 407.90,66.46 412.55,66.41 417.19,66.36 421.83,66.31 426.47,66.25 431.12,66.19\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_164\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;431.12,112.29 426.47,111.39 421.83,110.50 417.19,109.62 412.55,108.73 407.90,107.85 403.26,106.97 398.62,106.10 393.98,105.23 389.33,104.36 384.69,103.49 380.05,102.64 375.41,101.78 370.76,100.93 366.12,100.09 361.48,99.25 356.84,98.42 352.19,97.59 347.55,96.78 342.91,95.97 338.27,95.17 333.62,94.38 328.98,93.60 324.34,92.83 319.70,92.07 315.05,91.33 310.41,90.60 305.77,89.88 301.13,89.19 296.48,88.51 291.84,87.84 287.20,87.20 282.56,86.58 277.91,85.99 273.27,85.41 268.63,84.86 263.99,84.34 259.34,83.85 254.70,83.38 250.06,82.94 245.41,82.53 240.77,82.14 236.13,81.79 231.49,81.46 226.84,81.16 222.20,80.88 217.56,80.63 212.92,80.40 208.27,80.19 203.63,80.01 198.99,79.84 194.35,79.70 189.70,79.57 185.06,79.46 180.42,79.36 175.78,79.27 171.13,79.20 166.49,79.14 161.85,79.09 157.21,79.05 152.56,79.02 147.92,79.00 143.28,78.99 138.64,78.98 133.99,78.99 129.35,78.99 124.71,79.01 120.07,79.03 115.42,79.05 110.78,79.08 106.14,79.11 101.50,79.15 96.85,79.19 92.21,79.23 87.57,79.28 82.93,79.33 78.28,79.38 73.64,79.44 69.00,79.49 64.36,79.55\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_165\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;64.36,56.37 69.00,56.78 73.64,57.20 78.28,57.61 82.93,58.03 87.57,58.45 92.21,58.86 96.85,59.28 101.50,59.69 106.14,60.11 110.78,60.53 115.42,60.94 120.07,61.36 124.71,61.77 129.35,62.19 133.99,62.61 138.64,63.02 143.28,63.44 147.92,63.86 152.56,64.27 157.21,64.69 161.85,65.10 166.49,65.52 171.13,65.94 175.78,66.35 180.42,66.77 185.06,67.18 189.70,67.60 194.35,68.02 198.99,68.43 203.63,68.85 208.27,69.26 212.92,69.68 217.56,70.10 222.20,70.51 226.84,70.93 231.49,71.35 236.13,71.76 240.77,72.18 245.41,72.59 250.06,73.01 254.70,73.43 259.34,73.84 263.99,74.26 268.63,74.67 273.27,75.09 277.91,75.51 282.56,75.92 287.20,76.34 291.84,76.75 296.48,77.17 301.13,77.59 305.77,78.00 310.41,78.42 315.05,78.84 319.70,79.25 324.34,79.67 328.98,80.08 333.62,80.50 338.27,80.92 342.91,81.33 347.55,81.75 352.19,82.16 356.84,82.58 361.48,83.00 366.12,83.41 370.76,83.83 375.41,84.24 380.05,84.66 384.69,85.08 389.33,85.49 393.98,85.91 398.62,86.33 403.26,86.74 407.90,87.16 412.55,87.57 417.19,87.99 421.83,88.41 426.47,88.82 431.12,89.24\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_166\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;2.13396\&#34; stroke=\&#34;#3366FF\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;polygon points=\&#34;297.01,103.17 300.16,103.61 303.32,104.04 306.48,104.47 309.64,104.89 312.79,105.31 315.95,105.73 319.11,106.14 322.26,106.55 325.42,106.95 328.58,107.35 331.74,107.74 334.89,108.12 338.05,108.50 341.21,108.87 344.36,109.24 347.52,109.59 350.68,109.94 353.84,110.27 356.99,110.60 360.15,110.91 363.31,111.21 366.46,111.50 369.62,111.77 372.78,112.02 375.93,112.26 379.09,112.48 382.25,112.68 385.41,112.85 388.56,113.01 391.72,113.13 394.88,113.23 398.03,113.30 401.19,113.33 404.35,113.33 407.51,113.30 410.66,113.23 413.82,113.12 416.98,112.97 420.13,112.78 423.29,112.55 426.45,112.28 429.61,111.97 432.76,111.62 435.92,111.22 439.08,110.80 442.23,110.33 445.39,109.83 448.55,109.29 451.70,108.73 454.86,108.14 458.02,107.51 461.18,106.87 464.33,106.20 467.49,105.50 470.65,104.79 473.80,104.06 476.96,103.31 480.12,102.55 483.28,101.77 486.43,100.98 489.59,100.17 492.75,99.36 495.90,98.53 499.06,97.69 502.22,96.85 505.38,96.00 508.53,95.13 511.69,94.27 514.85,93.39 518.00,92.51 521.16,91.62 524.32,90.73 527.48,89.84 530.63,88.94 533.79,88.03 536.95,87.12 540.10,86.21 543.26,85.29 546.42,84.37 546.42,148.93 543.26,148.50 540.10,148.07 536.95,147.64 533.79,147.22 530.63,146.80 527.48,146.39 524.32,145.98 521.16,145.57 518.00,145.17 514.85,144.78 511.69,144.39 508.53,144.01 505.38,143.64 502.22,143.27 499.06,142.92 495.90,142.57 492.75,142.23 489.59,141.90 486.43,141.58 483.28,141.28 480.12,140.99 476.96,140.71 473.80,140.45 470.65,140.20 467.49,139.98 464.33,139.77 461.18,139.59 458.02,139.43 454.86,139.30 451.70,139.19 448.55,139.11 445.39,139.07 442.23,139.05 439.08,139.07 435.92,139.13 432.76,139.23 429.61,139.36 426.45,139.54 423.29,139.76 420.13,140.01 416.98,140.31 413.82,140.65 410.66,141.03 407.51,141.44 404.35,141.90 401.19,142.39 398.03,142.91 394.88,143.46 391.72,144.05 388.56,144.66 385.41,145.30 382.25,145.96 379.09,146.65 375.93,147.35 372.78,148.08 369.62,148.82 366.46,149.58 363.31,150.36 360.15,151.14 356.99,151.94 353.84,152.76 350.68,153.58 347.52,154.41 344.36,155.25 341.21,156.10 338.05,156.96 334.89,157.83 331.74,158.70 328.58,159.58 325.42,160.46 322.26,161.35 319.11,162.25 315.95,163.15 312.79,164.05 309.64,164.96 306.48,165.87 303.32,166.79 300.16,167.71 297.01,168.63\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_167\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;#999999\&#34; fill-opacity=\&#34;0.4\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;297.01,103.17 300.16,103.61 303.32,104.04 306.48,104.47 309.64,104.89 312.79,105.31 315.95,105.73 319.11,106.14 322.26,106.55 325.42,106.95 328.58,107.35 331.74,107.74 334.89,108.12 338.05,108.50 341.21,108.87 344.36,109.24 347.52,109.59 350.68,109.94 353.84,110.27 356.99,110.60 360.15,110.91 363.31,111.21 366.46,111.50 369.62,111.77 372.78,112.02 375.93,112.26 379.09,112.48 382.25,112.68 385.41,112.85 388.56,113.01 391.72,113.13 394.88,113.23 398.03,113.30 401.19,113.33 404.35,113.33 407.51,113.30 410.66,113.23 413.82,113.12 416.98,112.97 420.13,112.78 423.29,112.55 426.45,112.28 429.61,111.97 432.76,111.62 435.92,111.22 439.08,110.80 442.23,110.33 445.39,109.83 448.55,109.29 451.70,108.73 454.86,108.14 458.02,107.51 461.18,106.87 464.33,106.20 467.49,105.50 470.65,104.79 473.80,104.06 476.96,103.31 480.12,102.55 483.28,101.77 486.43,100.98 489.59,100.17 492.75,99.36 495.90,98.53 499.06,97.69 502.22,96.85 505.38,96.00 508.53,95.13 511.69,94.27 514.85,93.39 518.00,92.51 521.16,91.62 524.32,90.73 527.48,89.84 530.63,88.94 533.79,88.03 536.95,87.12 540.10,86.21 543.26,85.29 546.42,84.37\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_168\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;546.42,148.93 543.26,148.50 540.10,148.07 536.95,147.64 533.79,147.22 530.63,146.80 527.48,146.39 524.32,145.98 521.16,145.57 518.00,145.17 514.85,144.78 511.69,144.39 508.53,144.01 505.38,143.64 502.22,143.27 499.06,142.92 495.90,142.57 492.75,142.23 489.59,141.90 486.43,141.58 483.28,141.28 480.12,140.99 476.96,140.71 473.80,140.45 470.65,140.20 467.49,139.98 464.33,139.77 461.18,139.59 458.02,139.43 454.86,139.30 451.70,139.19 448.55,139.11 445.39,139.07 442.23,139.05 439.08,139.07 435.92,139.13 432.76,139.23 429.61,139.36 426.45,139.54 423.29,139.76 420.13,140.01 416.98,140.31 413.82,140.65 410.66,141.03 407.51,141.44 404.35,141.90 401.19,142.39 398.03,142.91 394.88,143.46 391.72,144.05 388.56,144.66 385.41,145.30 382.25,145.96 379.09,146.65 375.93,147.35 372.78,148.08 369.62,148.82 366.46,149.58 363.31,150.36 360.15,151.14 356.99,151.94 353.84,152.76 350.68,153.58 347.52,154.41 344.36,155.25 341.21,156.10 338.05,156.96 334.89,157.83 331.74,158.70 328.58,159.58 325.42,160.46 322.26,161.35 319.11,162.25 315.95,163.15 312.79,164.05 309.64,164.96 306.48,165.87 303.32,166.79 300.16,167.71 297.01,168.63\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_169\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke=\&#34;none\&#34;/&gt;\n    &lt;polyline points=\&#34;297.01,135.90 300.16,135.66 303.32,135.41 306.48,135.17 309.64,134.93 312.79,134.68 315.95,134.44 319.11,134.19 322.26,133.95 325.42,133.71 328.58,133.46 331.74,133.22 334.89,132.98 338.05,132.73 341.21,132.49 344.36,132.25 347.52,132.00 350.68,131.76 353.84,131.51 356.99,131.27 360.15,131.03 363.31,130.78 366.46,130.54 369.62,130.30 372.78,130.05 375.93,129.81 379.09,129.56 382.25,129.32 385.41,129.08 388.56,128.83 391.72,128.59 394.88,128.35 398.03,128.10 401.19,127.86 404.35,127.62 407.51,127.37 410.66,127.13 413.82,126.88 416.98,126.64 420.13,126.40 423.29,126.15 426.45,125.91 429.61,125.67 432.76,125.42 435.92,125.18 439.08,124.93 442.23,124.69 445.39,124.45 448.55,124.20 451.70,123.96 454.86,123.72 458.02,123.47 461.18,123.23 464.33,122.99 467.49,122.74 470.65,122.50 473.80,122.25 476.96,122.01 480.12,121.77 483.28,121.52 486.43,121.28 489.59,121.04 492.75,120.79 495.90,120.55 499.06,120.30 502.22,120.06 505.38,119.82 508.53,119.57 511.69,119.33 514.85,119.09 518.00,118.84 521.16,118.60 524.32,118.36 527.48,118.11 530.63,117.87 533.79,117.62 536.95,117.38 540.10,117.14 543.26,116.89 546.42,116.65\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_170\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_3)\&#34; fill=\&#34;none\&#34; stroke-width=\&#34;2.13396\&#34; stroke=\&#34;#3366FF\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;butt\&#34;/&gt;\n    &lt;defs&gt;\n      &lt;clipPath id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4\&#34;&gt;\n        &lt;rect x=\&#34;0.00\&#34; y=\&#34;0.00\&#34; width=\&#34;576.00\&#34; height=\&#34;360.00\&#34;/&gt;\n      &lt;\/clipPath&gt;\n    &lt;\/defs&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;237.71\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_171\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;40&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;161.87\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_172\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;60&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;24.13\&#34; y=\&#34;86.04\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_173\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;80&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;18.53\&#34; y=\&#34;10.20\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_174\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;100&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;100.66\&#34; y=\&#34;300.45\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_175\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;7&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;198.02\&#34; y=\&#34;300.45\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_176\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;8&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;295.38\&#34; y=\&#34;300.45\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_177\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;9&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;389.94\&#34; y=\&#34;300.45\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_178\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;10&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;487.30\&#34; y=\&#34;300.45\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_179\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;11&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;290.64\&#34; y=\&#34;313.03\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_180\&#34; font-size=\&#34;8.25pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;l_gdp&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text transform=\&#34;translate(13.50,162.31) rotate(-90)\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_181\&#34; font-size=\&#34;8.25pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;value&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;154.22\&#34; y=\&#34;344.41\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_182\&#34; font-size=\&#34;8.25pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;rank&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;circle cx=\&#34;192.94\&#34; cy=\&#34;340.40\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_183\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34; fill=\&#34;#F8766D\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#F8766D\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;circle cx=\&#34;333.18\&#34; cy=\&#34;340.40\&#34; r=\&#34;1.47pt\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_184\&#34; clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34; fill=\&#34;#00BFC4\&#34; fill-opacity=\&#34;1\&#34; stroke-width=\&#34;0.708661\&#34; stroke=\&#34;#00BFC4\&#34; stroke-opacity=\&#34;1\&#34; stroke-linejoin=\&#34;round\&#34; stroke-linecap=\&#34;round\&#34;/&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;207.06\&#34; y=\&#34;343.61\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_185\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;High infant mortality rate&lt;\/text&gt;\n    &lt;\/g&gt;\n    &lt;g clip-path=\&#34;url(#svg_790a8806-4836-491a-8eea-2a594d6a280b_cl_4)\&#34;&gt;\n      &lt;text x=\&#34;347.30\&#34; y=\&#34;343.61\&#34; id=\&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b_el_186\&#34; font-size=\&#34;6.60pt\&#34; fill=\&#34;#FFFFFF\&#34; fill-opacity=\&#34;1\&#34; font-family=\&#34;DejaVu Sans\&#34;&gt;Low infant mortality rate&lt;\/text&gt;\n    &lt;\/g&gt;\n  &lt;\/g&gt;\n&lt;\/svg&gt;\n&#34;,&#34;js&#34;:null,&#34;uid&#34;:&#34;svg_790a8806-4836-491a-8eea-2a594d6a280b&#34;,&#34;ratio&#34;:1.6,&#34;settings&#34;:{&#34;tooltip&#34;:{&#34;css&#34;:&#34; .tooltip_SVGID_ { padding:5px;background:black;color:white;border-radius:2px 2px 2px 2px ; position:absolute;pointer-events:none;z-index:999;}\n&#34;,&#34;offx&#34;:10,&#34;offy&#34;:0,&#34;use_cursor_pos&#34;:true,&#34;opacity&#34;:0.9,&#34;usefill&#34;:false,&#34;usestroke&#34;:false,&#34;delay&#34;:{&#34;over&#34;:200,&#34;out&#34;:500}},&#34;hover&#34;:{&#34;css&#34;:&#34; .hover_SVGID_ { fill:orange;stroke:gray; }\n&#34;},&#34;hoverkey&#34;:{&#34;css&#34;:&#34; .hover_key_SVGID_ { stroke:red; }\n&#34;},&#34;hovertheme&#34;:{&#34;css&#34;:&#34; .hover_theme_SVGID_ { fill:green; }\n&#34;},&#34;zoom&#34;:{&#34;min&#34;:1,&#34;max&#34;:1},&#34;capture&#34;:{&#34;css&#34;:&#34; .selected_SVGID_ { fill:red;stroke:gray; }\n&#34;,&#34;type&#34;:&#34;multiple&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;capturekey&#34;:{&#34;css&#34;:&#34; .selected_key_SVGID_ { stroke:gray; }\n&#34;,&#34;type&#34;:&#34;single&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;capturetheme&#34;:{&#34;css&#34;:&#34; .selected_theme_SVGID_ { stroke:gray; }\n&#34;,&#34;type&#34;:&#34;single&#34;,&#34;only_shiny&#34;:true,&#34;selected&#34;:[]},&#34;toolbar&#34;:{&#34;position&#34;:&#34;topright&#34;,&#34;saveaspng&#34;:true},&#34;sizing&#34;:{&#34;rescale&#34;:true,&#34;width&#34;:1}}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;All of a sudden, the relationship turns positive for high income countries. This is the famous
Simpson’s paradox in action. If you don’t know about Simpson’s paradox, you can read about it &lt;a href=&#34;https://en.wikipedia.org/wiki/Simpson%27s_paradox&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now what? Should we stop here? No.&lt;/p&gt;
&lt;p&gt;Let’s not even consider Simpson’s paradox. Even though the authors never claim to have found any
causal mechanism (and the Economist made no such claim, even though they tried hard to find some after
the fact explanation to justify their findings), authors of such studies do very often imply that
their simple analysis has at the very least some predictive power. We already know that this is bullocks, because
the R² is so low. But let’s try something fun; let’s split the dataset into a training set and a testing
set, and let’s see if we can accurately predict the points from the test set. Also, I won’t do
this once, because, who knows, maybe that one regression we did had some very hard to predict points
in the test set, so I’ll do it 100 times, always with new randomly generated training and testing sets.
The way I’m evaluating the accuracy of the regression is visually: I’ll be doing a plot like before,
where I’m showing the points from the training set, the points from the test set, as well as the
predictions. I’ll also be showing the distance between the prediction and the points from the test set.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click to see the code to run the 100 regressions.
&lt;/summary&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_regression &amp;lt;- function(dataset){

  training_index &amp;lt;- sample(1:nrow(dataset), 120)

  training_set &amp;lt;- dataset[training_index, ]

  testing_set &amp;lt;- dataset[-training_index, ]

  fitted_model &amp;lt;- lm(value ~ l_gdp, data = training_set)

  predicted_points &amp;lt;- predict.lm(fitted_model, newdata = testing_set)

  predicted_points &amp;lt;- cbind(testing_set, &amp;quot;prediction&amp;quot; = predicted_points)

  rbind(training_set, predicted_points)
}

results &amp;lt;- tribble(~id,
                   seq(1, 100)) %&amp;gt;%
  mutate(dataset = list(filter(plot_data, country_name != &amp;quot;Taiwan&amp;quot;))) %&amp;gt;%  
  unnest(cols = c(id)) %&amp;gt;%
  mutate(regression = map(dataset, run_regression))&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Now that I ran the 100 regressions, let’s create some visualisations:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click to see the code to create the plots.
&lt;/summary&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- results %&amp;gt;%
  mutate(regression = map(regression,
                          ~mutate(., type_set = ifelse(is.na(prediction),
                                                    &amp;quot;training_set&amp;quot;,
                                                    &amp;quot;testing_set&amp;quot;))))


make_plots &amp;lt;- function(dataset){
ggplot() +
  geom_point(data = dataset,
             aes(y = value, x = l_gdp, shape = type_set), size = 5) +
  geom_smooth(data = dataset,
              aes(y = value, x = l_gdp),
              method = &amp;quot;lm&amp;quot;) +
  geom_point(data = {dataset %&amp;gt;%
                      filter(!is.na(prediction)) %&amp;gt;%
                       pivot_longer(c(value, prediction), names_to = &amp;quot;values&amp;quot;) %&amp;gt;%
                       mutate(values = ifelse(values == &amp;quot;value&amp;quot;,
                                              &amp;quot;Actual value&amp;quot;,
                                              &amp;quot;Prediction&amp;quot;))},
             aes(y = value, x = l_gdp, colour = values, group = country_name)) +
  geom_path(data = {dataset %&amp;gt;%
                      filter(!is.na(prediction)) %&amp;gt;%
                      pivot_longer(c(value, prediction), names_to = &amp;quot;values&amp;quot;) %&amp;gt;%
                      mutate(values = ifelse(values == &amp;quot;value&amp;quot;,
                                             &amp;quot;Actual value&amp;quot;,
                                             &amp;quot;Prediction&amp;quot;))},
               aes(y = value, x = l_gdp, colour = values, group = country_name),
               arrow = arrow(length = unit(0.03, &amp;quot;npc&amp;quot;))) +
  brotools::theme_blog()
} 

results &amp;lt;- results %&amp;gt;%
  mutate(plots = map(regression, make_plots))&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Finally, let’s take a look at some of them:&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;
Click to see some plots.
&lt;/summary&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results$plots[1:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-12-12-ethics_statistics_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-12-12-ethics_statistics_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[3]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://www.brodrigues.co/blog/2020-12-12-ethics_statistics_files/figure-html/unnamed-chunk-9-3.png&#34; width=&#34;672&#34; /&gt;
&lt;/details&gt;
&lt;p&gt;The red dots are the actual values in the test set (the triangles are the points in the training set).
The blue dots are the predictions. See what happens? They all get very close to the regression line.
This is of course completely normal; after all, the line is what the model is predicting, so
how else could it be? I don’t know if this is exactly what is named “regression towards the mean”,
but it does look very much like it. But in general, we speak of regression towards the mean when there’s time
involved in whatever you’re studying (for example students that score very well on a first test
tend to score worse, on average, on a second test, and vice-versa).
But what matters here, is that a regression line cannot even be useful to make any type of prediction.&lt;/p&gt;
&lt;p&gt;So where does that leave us? Should we avoid using simple methods like linear regression and only
use very complex methods? Should we stop communicating numbers and stats and graphs to the general
public? Certainly not. But using the excuse that the general public does not understand complex
methods to justify using faulty stats is also not an option.
In an article that mentions trust in vaccines, it also seems crucial to give more context; trust in
vaccines may be higher on average in poorer countries (and that’s an assumption, the article of
the Economist does not allow to conclude that), but distrust is also more
&lt;a href=&#34;https://www.nytimes.com/2013/02/09/world/africa/in-nigeria-polio-vaccine-workers-are-killed-by-gunmen.html&#34;&gt;extreme&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I don’t think I’ve ever seen the general public distrust science and stats so much than during this
pandemic. Many scientists made many predictions that of course never materialized, because
scientists should not give out single point forecasts. Unfortunately, that’s what they do because
that’s how they get people’s attention, and unfortunately, many also confuse science with stats. I
think Millenials are very guilty of this. We all were thought critical thinking in school, and now
all arguments devolve very quickly to “I have data and models to back my opinions up so my opinions
are actually facts, and your data and models are wrong and you’re a terrible human being by the
way”. The problem is that having data and models is not a sufficient condition for being right.&lt;/p&gt;
&lt;p&gt;As statisticians, we have a responsibility to use the right methods, and make more and better
efforts to communicate our results to the general public, even if the methods used are complex.
Sometimes there’s simply no simplifying further. Anything else is just charlatanism.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Poorman&#39;s automated translation with R and Google Sheets using {googlesheets4}</title>
      <link>https://www.brodrigues.co/blog/2020-12-05-poorman_translate/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-12-05-poorman_translate/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2kArCRjT29w&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/omelette_du_fromage.gif&#34; title = &#34;A classic.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A little trick I thought about this week; using Google Sheets, which includes a “googletranslate()”
function to translate a survey that we’re preparing at work, from French to English, and using
R of course. You’ll need a Google account for this. Also, keep in mind that you’ll be sending
the text you want to translate to Google, so don’t go sending out anything sensitive.&lt;/p&gt;
&lt;p&gt;First, let’s load the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(googlesheets4)
library(dplyr)
library(tibble)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an example, I’ll be defining a tibble with one column, and two rows. Each cell contains a
sentence in French from the best show in the entire French speaking world, Kaamelott:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_french_tibble &amp;lt;- tribble(~french,
                  &amp;quot;J&amp;#39;apprécie les fruits au sirop&amp;quot;,
                  &amp;quot;C&amp;#39;est pas faux&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To this tibble, I’m now adding two more columns, that contain the following string: “=googletranslate(A:A,”fr“,”en“)”.
This is exactly what you would write in the formula bar in Sheets. Then, we need to convert that to
an actual Google Sheets formula using &lt;code&gt;gs4_formula()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
my_french_tibble &amp;lt;- my_french_tibble %&amp;gt;%
  mutate(english = &amp;#39;=googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;en&amp;quot;)&amp;#39;) %&amp;gt;%
  mutate(portuguese = &amp;#39;=googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;pt&amp;quot;)&amp;#39;) %&amp;gt;%
  mutate(english = gs4_formula(english),
         portuguese = gs4_formula(portuguese))
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   french     english                           portuguese                       
##   &amp;lt;chr&amp;gt;      &amp;lt;fmla&amp;gt;                            &amp;lt;fmla&amp;gt;                           
## 1 J&amp;#39;appréci… =googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;en&amp;quot;) =googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;pt&amp;quot;)
## 2 C&amp;#39;est pas… =googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;en&amp;quot;) =googletranslate(A:A, &amp;quot;fr&amp;quot;, &amp;quot;pt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re ready to send this to Google Sheets. As soon as the sheet gets uploaded, the formulas will be
evaluated, yielding translations in both English and Portuguese.&lt;/p&gt;
&lt;p&gt;To upload the tibble to sheets, run the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;french_sheet &amp;lt;- gs4_create(&amp;quot;repliques_kaamelott&amp;quot;,
                           sheets = list(perceval = my_french_tibble))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll be asked if you want to cache your credentials so that you don’t need to re-authenticate
between R sessions:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gs4_oauth.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Your browser will the open a tab asking you to login to Google:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gs4_login.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At this point, you might get a notification on your phone, alerting you that there was a login to your account:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gs4_android_notification.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you go on your Google Sheets account, this is what you’ll see:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gs4_repliques_kaamelott.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And if you open the sheet:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/gs4_repliques_kaamelott_result.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Pretty nice, no? You can of course download the workbook, or better yet, never leave your R session at all
and simply get back the workbook using either the &lt;code&gt;{googledrive}&lt;/code&gt; package, which simply needs the name
of the workbook (&lt;code&gt;{googledrive}&lt;/code&gt; also needs authentication):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
translations &amp;lt;- googledrive::drive_get(&amp;quot;repliques_kaamelott&amp;quot;) %&amp;gt;%
  read_sheet
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll get a new data frame with the translation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Reading from &amp;quot;repliques_kaamelott&amp;quot;
Range &amp;quot;perceval&amp;quot;
# A tibble: 2 x 3
  french                    english                     portuguese              
  &amp;lt;chr&amp;gt;                     &amp;lt;chr&amp;gt;                       &amp;lt;chr&amp;gt;                   
1 J&amp;#39;apprécie les fruits au… I appreciate the fruits in… I apreciar os frutos em…
2 C&amp;#39;est pas faux            It is not false             Não é falsa             &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or you can use the link to the sheet (which does not require to re-authenticate at this point):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;translations &amp;lt;- read_sheet(&amp;quot;the_link_goes_here&amp;quot;, &amp;quot;perceval&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could of course encapsulate all these steps into a function and have any text translated
very easily! Just be careful not to send out any confidential information out…&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graphical User Interfaces were a mistake but you can still make things right</title>
      <link>https://www.brodrigues.co/blog/2020-11-21-guis_mistake/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-11-21-guis_mistake/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/cHw4GER-MiE?t=2&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/just_kill_me.png&#34; title = &#34;Welcome to Hell.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Some weeks ago I tweeted this:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
GUIs were a mistake
&lt;/p&gt;
— Bruno Rodrigues (&lt;span class=&#34;citation&#34;&gt;@brodriguesco&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1314505586172624898?ref_src=twsrc%5Etfw&#34;&gt;October 9, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;you might think that I tweeted this as an unfunny joke, but it’s not. GUIs were one of the worst
things to happen for statisticians. Clickable interfaces for data analysis is probably one of the
greatest source of mistakes and errors in data processing, very likely costing many millions to
companies worldwide and is a source of constant embarassment when mistakes happen which cost the
reputation, and money, of institutions or people.&lt;/p&gt;
&lt;p&gt;Remember the infamous Excel mistake by Reinhard and Rogoff? If you don’t know what I’m
talking about, you can get up to speed by reading &lt;a href=&#34;https://theconversation.com/the-reinhart-rogoff-error-or-how-not-to-excel-at-economics-13646&#34;&gt;this&lt;/a&gt;.
I think the most interesting sentence is this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The most serious was that, in their Excel spreadsheet, Reinhart and Rogoff had not selected the entire row when averaging growth figures: they omitted data from Australia, Austria, Belgium, Canada and Denmark.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a typical mistake that happens when a mouse is used to select data in a GUI, instead of
typing whatever you need in a scripting language. Many other mistakes like that happen, and they
remain hidden, potentially for years, or go unreported.&lt;/p&gt;
&lt;p&gt;Recently there was another Excel-related problem in England where positive Covid tests got lost. For some
obscure reason, the raw data, which was encoded in a CSV file, got converted into an Excel
spreadsheet, most likely for further analysis. The problem is that the format that was used was the
now obsolete XLS format, instead of the latest XLSX format, which can handle millions of rows.
Because the data was converted in the XLS format, up to 15841 cases were lost. You can get all the
details from this BBC &lt;a href=&#34;https://www.bbc.com/news/technology-54423988&#34;&gt;article&lt;/a&gt;. Again, not entirely
Excel’s fault, as it was misused. The problem is that when all you have is a hammer, everything
looks like a nail, and Excel is that data analytics hammer. So to the uncultured, everything
looks like an Excel problem.&lt;/p&gt;
&lt;p&gt;Now don’t misunderstand me; I’m not blaming Excel specifically, or any other specific GUI
application for this. In many cases, the problem lies between the keyboard and the chair. But GUI
applications have a part of responsibility, as they allow users to implement GUI-based workflows. I
think that complex GUI based workflows were an unintended consequence of developing GUIs. Who could
have expected, 40 years ago, that office jobs would evolve so much and that they would require such
complex workflows to generate an output? Consider the life-cycle of a shared Excel file in your
typical run-of-the-mill financial advisory firm. In many cases, it starts with an already existing
file that was made for another client and that is now used as a starting point. The first thing to
do, is to assign a poor junior to update the file and adapt it for the current assignment. He or
she will spend hours trying to reverse engineer this Excel file and then update it. This file
will at some point go to more senior members that will continue working on it, until it gets send
off for review to a manager. This manager, already overworked and with little time between meetings
to review the file correctly, just gives it a cursory glance and might find some mistakes here and
there. As a review method, colours and comments will be used.
The file goes back for a round of updates and reviews. As time goes by, and as the file gets
more and more complex, it starts to become impossible to manage and review properly. It eventually
gets used to give advice to a client, which might be totally wrong, because just as in the case of Reinhard and
Rogoff, someone, at some point, somewhere, did not select the right cells for the right formula.
Good luck ever finding this mistake, and who did it. During my consulting years, I have been
involved with very, very, big clients that were completely overwhelmed because all their
workflows were GUI based. They had been working like that for years, and kept recruiting highly
educated people en masse just to manage Excel and Word files. They were looking for a magic,
AI-based solution, because in their minds, if AIs could drive fricking cars, they should
also be able to edit and send Excel files around for review. Well, we’re not quite there yet,
so we told them, after our review of their processes and data sources (which in many
cases were Excel AND Word files), that what they needed was for their
company to go through an in-depth optimisation process “journey”. They weren’t interested
so they kept hiring very intelligent people to be office drones. I don’t think
that business model can remain sustainable.&lt;/p&gt;
&lt;p&gt;Now how much are situations like that the fault of Excel and how much personal responsibility do the
people involved have? I don’t know, but my point is that if, by magic, GUIs were
made to disappear, problems like that would also not exist. The reason is that if
you’re forced to write code to reach the results you want, you avoid a lot of these pitfalls
I just described. Working with scripts and the command line forces a discipline unto
you; you cannot be lazy and click around.
For example, reverse engineering a source code file is much easier that a finished
Excel spreadsheet. Even poorly written and undocumented code is always much better
than an Excel spreadsheet. If you throw a version control system in the mix, you have
the whole history of the file and the ability to know exactly what happened and when.
Add unit tests on the pile, and you start to get something that is very robust,
transparent, and much easier to audit.&lt;/p&gt;
&lt;p&gt;“But Bruno, not everyone is a programmer!” I hear you scream at your monitor.&lt;/p&gt;
&lt;p&gt;My point, again, is that if GUIs did not exist, people would have enough knowledge of these
tools to be able to work. What other choice would they have?&lt;/p&gt;
&lt;p&gt;Of course, GUIs have been invented, and they’re going nowhere. So what can you do?&lt;/p&gt;
&lt;p&gt;When it comes to statistics and data analysis/processing, you can at least not be part of the
problem and avoid using Excel altogether. If we go back to our previous scenario from the financial
advisory firm, the first step, which consisted in reverse engineering an Excel file, can be done
using &lt;code&gt;{tidyxl}&lt;/code&gt;. Let’s take a quick look; the spreadsheet I used as the header image for this blog
post comes from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Enron_Corpus&#34;&gt;Enron corpus&lt;/a&gt; , which is mostly
know for being a database of over 600000 emails from the US company Enron. But it also contains
spreadsheets, which are delightful. You can download the one from the picture
&lt;a href=&#34;https://github.com/rbind/b-rodrigues.github.com/raw/master/dutch_quigley__9378__modeldutch.xlsx&#34;&gt;here&lt;/a&gt;
(8mb xlsx warning). Opening it in your usual spreadsheet application will probably cause your heart
rate to increase to dangerous levels, so avoid that. Instead, let’s take a look at what &lt;code&gt;{tidyxl}&lt;/code&gt;
does with it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyxl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyxl&amp;#39; was built under R version 4.0.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: replacing previous import &amp;#39;vctrs::data_frame&amp;#39; by &amp;#39;tibble::data_frame&amp;#39;
## when loading &amp;#39;dplyr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 3.3.2     ✔ purrr   0.3.4
## ✔ tibble  3.0.1     ✔ dplyr   1.0.0
## ✔ tidyr   1.1.2     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;tidyr&amp;#39; was built under R version 4.0.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dutch_quigley_9378 &amp;lt;- xlsx_cells(&amp;quot;~/six_to/spreadsheets/dutch_quigley__9378__modeldutch.xlsx&amp;quot;)


head(dutch_quigley_9378)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 21
##   sheet address   row   col is_blank data_type error logical numeric
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;lgl&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Swap… A1          1     1 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 2 Swap… D2          2     4 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 3 Swap… E2          2     5 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 4 Swap… F2          2     6 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 5 Swap… G2          2     7 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 6 Swap… D3          3     4 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## # … with 12 more variables: date &amp;lt;dttm&amp;gt;, character &amp;lt;chr&amp;gt;,
## #   character_formatted &amp;lt;list&amp;gt;, formula &amp;lt;chr&amp;gt;, is_array &amp;lt;lgl&amp;gt;,
## #   formula_ref &amp;lt;chr&amp;gt;, formula_group &amp;lt;int&amp;gt;, comment &amp;lt;chr&amp;gt;, height &amp;lt;dbl&amp;gt;,
## #   width &amp;lt;dbl&amp;gt;, style_format &amp;lt;chr&amp;gt;, local_format_id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That whole Excel workbook is inside a neat data frame. Imagine that you want
to quickly know where all the formulas are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dutch_quigley_9378 %&amp;gt;%
  filter(!is.na(formula)) %&amp;gt;%
  count(sheet, address)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18,776 x 3
##    sheet address     n
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt;
##  1 Front B22         1
##  2 Front C13         1
##  3 Front C2          1
##  4 Front C22         1
##  5 Front C25         1
##  6 Front C26         1
##  7 Front C27         1
##  8 Front C28         1
##  9 Front C30         1
## 10 Front C31         1
## # … with 18,766 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the code above, you can quickly find, for each sheet, where the formulas
are. This workbook contains 18776 formulas. If Hell is a real place, it’s probably
an office building full of cubicles where you’ll sit for eternity looking
at these spreadsheets and trying to make sense of them.&lt;/p&gt;
&lt;p&gt;Now imagine that you’d like to know what these formulas are, let’s say, for the
&lt;code&gt;Swap&lt;/code&gt; sheet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dutch_quigley_9378 %&amp;gt;%
  filter(sheet == &amp;quot;Swap&amp;quot;, !is.na(formula)) %&amp;gt;%
  select(address, formula)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6,773 x 2
##    address formula           
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;             
##  1 F1      DAY(EOMONTH(G1,0))
##  2 G1      A11               
##  3 E2      BE9               
##  4 A3      BQ5               
##  5 E3      BF9               
##  6 F3      SUM(G3:K3)        
##  7 H3      $F$1*H2           
##  8 I3      $F$1*I2           
##  9 J3      $F$1*J2           
## 10 K3      $F$1*K2           
## # … with 6,763 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Brilliant! Maybe you’re interested to find all the &lt;code&gt;&#34;SUM&#34;&lt;/code&gt; formulas? Easy!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dutch_quigley_9378 %&amp;gt;%
  filter(sheet == &amp;quot;Swap&amp;quot;, !is.na(formula)) %&amp;gt;%
  filter(grepl(&amp;quot;SUM&amp;quot;, formula)) %&amp;gt;%
  select(address, formula)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 31 x 2
##    address formula        
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          
##  1 F3      SUM(G3:K3)     
##  2 E4      SUM(D11:D309)  
##  3 F5      SUM(G5:K5)     
##  4 E6      SUM(F6:H6)     
##  5 BF8     SUM(BF11:BF242)
##  6 B9      SUM(B47:B294)  
##  7 AB9     SUM(AB11:AB253)
##  8 AC9     SUM(AC11:AC253)
##  9 AD9     SUM(AD11:AD253)
## 10 AE9     SUM(AE11:AE253)
## # … with 21 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You get the idea. There are many more things that you can extract such as
the formatting, the contents of the cells, the comments (and where to find them)
and much, much more. This will make making sense of a complex Excel file a breeze.&lt;/p&gt;
&lt;p&gt;The other thing that you can also do, once you’re done understanding this
monster Excel file, is not to perform the analysis inside Excel. Don’t fall into the temptation of
continuing this bad habit. As one on the data experts in your team/company, you have a
responsibility to bring the light to your colleagues. Be their Prometheus and decouple the data
from the code. Let the data be in Excel, but write all the required code to create whatever is
expected from you inside R. You can then export your finalized results back to Excel if needed. If
management tells you to do it in Excel, tell them that you’re the professional statistician/data
scientist, and that they shouldn’t tell you how to do your job. Granted, this is not always
possible, but you should plead your case as much as possible. In general, a good manager will be
all ears if you explain that not using GUIs like Excel makes it easier to spot and correct
mistakes, with the added benefit of being much easily audited and with huge time savings in the
long run. This is of course easier for completely new projects, and if you have an open-minded
manager. If you’re the manager, then you should ask your IT department to uninstall Excel
from your team member’s computers.&lt;/p&gt;
&lt;p&gt;Be brave, and ditch the GUI.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.
You can also watch my videos on &lt;a href=&#34;https://www.youtube.com/c/BrunoRodrigues1988/&#34;&gt;youtube&lt;/a&gt;.
So much content for you to consoom!&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s time to retire the &#34;data scientist&#34; label</title>
      <link>https://www.brodrigues.co/blog/2020-11-05-retire_data_science/</link>
      <pubDate>Thu, 05 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-11-05-retire_data_science/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/venn.png&#34; title = &#34;The correct data scientist venn diagram&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The “Data Scientist” label served its purpose; it allowed us to signal a transition happening in
our profession from using only applied mathematical statistical methods to something else, which
now also involves the use of a subset of software engineering practices. This transition was
mentioned back in 2010 by Deborah Nolan
(&lt;a href=&#34;https://www.stat.berkeley.edu/~statcur/Preprints/ComputingCurric3.pdf&#34; class=&#34;uri&#34;&gt;https://www.stat.berkeley.edu/~statcur/Preprints/ComputingCurric3.pdf&lt;/a&gt;), and this transition might
now be complete. Version control systems, document generation from annotated source code (or even
full reports generation &lt;em&gt;à la&lt;/em&gt; rmarkdown), containers and build automation tools have now entered
the toolbox of the run-of-the-mill statistician. Maybe not all of these tools, of course, it
largely depends on what it is exactly you do, but certainly some of these. Same goes for software
engineering practices. I have had the opportunity to work with some old-school statisticians (and
still do), and the difference is clear; just like old school users of WYSIWYG editors like Word
don’t use its “newest” features such as “Track changes” (and thus keep writing their text in
different colors to signal which paragraphs are new), or the concept of versions of a document
synced on Sharepoint (and thus keep multiple versions of the same document with different names)
old school statisticians have not included the tools I mentioned before in their toolbox.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.phdcomics.com/comics/archive/phd101212s.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Now don’t get me wrong here; that is absolutely ok. We need and respect old school statisticians
because they’ve been in the business of getting insights from data for longer than I’ve been alive.
This blog post is not a jab at them because they don’t know how to use git (if you interpret it
like that, that’s on you). Old school statisticians now have very senior positions and for many of
them, their job does not involve getting their hands dirty on data anymore; most of them are now
more like managers or mentors, and share their deep knowledge with their more junior team members.
(Obviously there’s exceptions, when I say &lt;em&gt;all&lt;/em&gt; old school statisticians do this or that, I don’t
mean &lt;em&gt;all&lt;/em&gt; of them, but most of them. Of course, I don’t have any evidence to back that up).&lt;/p&gt;
&lt;p&gt;What this blog post is about is the label “Data Scientist” that gets used by these more junior team
members and by companies that want to hire talented and motivated young people. This label,
and the purported difference between a “Data Scientist” and “statistician” does not make any sense
in 2020 anymore. (I know I’m beating a dead horse here, but this is my blog. I’ll blog about dead
horses as much as I want thank you very much.)&lt;/p&gt;
&lt;p&gt;Firstly, this label has always been confusing. “Data Scientist”… what does it even mean? The fact
it took so long to find a definition, and that almost everyone working in the profession has a
different one speaks volumes. Also, don’t all scientists use data? Data from experiments, from
observational studies, from surveys, from the literature?&lt;/p&gt;
&lt;p&gt;Secondly, I don’t believe that you can get a degree in statistics today without any exposition
whatsoever to at least some of the tools I mentioned before. I really doubt that there’s people out
there getting Master’s degrees in statistics without having &lt;em&gt;ever&lt;/em&gt; touched these tools, or the unix
command line. The degrees they’re going for might not focus a lot on these tools, true, but they
certainly touch upon them. And of course, once they join a team at their first job, they’ll get
more exposed to these tools and incorporate them in their day to day work. So, they’re not
statisticians anymore? Their degree magically transformed into a data science degree?&lt;/p&gt;
&lt;p&gt;But what about data science degrees? Are the students graduating with these degrees statisticians?
I’d argue that yes, they are indeed statisticians; it’s just that they took a statistics degree
that might have focused more than usual on these “new” practices/tools, and changed its name to
“Data Science degree” for marketing purposes.&lt;/p&gt;
&lt;p&gt;Anyways, the label “Data Scientist” is now completely defunct; as I mentioned in the very
beginning, it served us well to signal that a transition was happening in the profession. I believe
that this transition is now complete, or should be nearing its final stages. Also, this transition
was not only about the tools used, but also about the deliverables. Statisticians now don’t only
deliver tables, graphs and studies but more and more of them deliver &lt;em&gt;products&lt;/em&gt;. This product can
be a package implementing a bleeding edge statistical method for the profession as a whole, or it
can be part of a piece of software that needs it to run (like your smartphone keyboard using a
statistical model for word predictions). See
&lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/10691898.2020.1845109?scroll=top&amp;amp;needAccess=true&amp;amp;&#34;&gt;this paper&lt;/a&gt; for
an interesting exposition about how curricula and deliverables have evolved in the past two
decades.&lt;/p&gt;
&lt;p&gt;Currently, this label gets used by people that try to get insights from data. But we already have a
word for them; statisticians. It’s just that the tools of the statistician have evolved over the
past decade or so. Actually, I would perhaps even make another distinction; we should reserve the
label of “statistician” to people that do statistics without ever touching any data. The other
statisticians, the ones that get dirty wrestling in the mud with the data (they’re the &lt;em&gt;pigs that
like it&lt;/em&gt; from that famous quote) should be called “data janitors”. I’m not even joking; not only
does that term already exist and gets used, I think it suits what we do perfectly. What do janitors
do? They clean stuff and put things in order. We clean data and put it in order; meaning creating
summary tables, visualizations, interactive applications, and models. Oh, and we do so (preferably)
in a reproducible way.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building apps with {shinipsum} and {golem}</title>
      <link>https://www.brodrigues.co/blog/2020-09-27-golemdemo/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-09-27-golemdemo/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=B35E8QleVhg&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/golem.png&#34; title = &#34;Only 90&#39;s kids will get it&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2020-09-20-shiny_raspberry/&#34;&gt;In my previous blog post&lt;/a&gt; I showed you
how I set up my own Shiny server using a Raspberry Pi 4B. If you visited the following
&lt;a href=&#34;https://www.brodrigues.co/blog/2020-09-20-shiny_raspberry/&#34;&gt;link&lt;/a&gt; you’ll be connecting to my
Raspberry Pi and can play around with a Shiny app that I called &lt;code&gt;golemDemo&lt;/code&gt;.
It’s been quite a few months that I wanted to discuss this app:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;A little prototype app I&amp;#39;m working on to learn more about &lt;a href=&#34;https://twitter.com/thinkR_fr?ref_src=twsrc%5Etfw&#34;&gt;@thinkR_fr&lt;/a&gt; &amp;#39;s {golem} and interaction between modules, YouTube video coming later this week &lt;a href=&#34;https://t.co/DRfM2KqqQf&#34;&gt;pic.twitter.com/DRfM2KqqQf&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bruno Rodrigues (@brodriguesco@fosstodon.org) (@brodriguesco) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1277671383573704706?ref_src=twsrc%5Etfw&#34;&gt;June 29, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;So the tweet mentions that a video was coming in the following week and you’ll notice that the tweet
was made on… June 29th, and still no video. As I said in my previous blog post, I’ve been busy.
Anyways, here’s already a blog post, and I might still do a video where I’ll go into greater detail.
I think that videos are quite nice to walk an audience through an app, but it works best with an
accompanying blog post where I can comment some more complicated snippets of code.&lt;/p&gt;
&lt;div id=&#34;why-golem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why &lt;code&gt;{golem}&lt;/code&gt;?&lt;/h1&gt;
&lt;p&gt;Why should you consider the &lt;code&gt;{golem}&lt;/code&gt; package to develop your Shiny apps? For me, there are two
main reasons. First of all, I’m already familiar with package development in R, having made some
little packages that I have on my Github account, and one out on CRAN (with the complete texts of
Luxembourguish author &lt;a href=&#34;https://cran.r-project.org/web/packages/michelRodange/index.html&#34;&gt;Michel Rodange&lt;/a&gt;)
so using &lt;code&gt;{golem}&lt;/code&gt; came at no additional costs. This is because a Shiny app built with &lt;code&gt;{golem}&lt;/code&gt; is
actually an R package! This has many advantages; all the steps of documenting, testing and sharing
the app are greatly simplified.
Another reason to use &lt;code&gt;{golem}&lt;/code&gt; is that it forces on you a certain way of working. Now this
might seem like a pretty bad thing, but I find that it is quite helpful. When you start working
on a Shiny app, you might get very quickly overwhelmed with both thinking about your server logic
and your UI. You might spend much time tinkering with getting the server functions working, while
still not having no UI to speak of, or you might work on one part of the server and then go to the UI,
then back on the server… You’ll spend hours working on the app without a clear approach, and
probably waste much time because of this back and forth.
The first recommended step when building a shiny app (with or without &lt;code&gt;{golem}&lt;/code&gt;) is a “UI first” approach.
For this, we’re going to use &lt;code&gt;{shinipsum}&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lorem-ipsum-dolor-server-amet-its-latin-for-dont-bother-with-the-server-logic-until-its-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Lorem ipsum dolor server amet (it’s Latin for “don’t bother with the server logic until it’s time”)&lt;/h1&gt;
&lt;p&gt;The developers of &lt;code&gt;{golem}&lt;/code&gt;, French company &lt;a href=&#34;https://thinkr.fr/&#34;&gt;ThinkR&lt;/a&gt;
suggest an “UI” first approach. The idea is to focus on the UI, and to do so using their other package called
&lt;code&gt;{shinipsum}&lt;/code&gt; to randomly generate elements on the server side which you can then later replace
with your actual server logic. For instance, imagine that somewhere on your app, you want to show
a bar plot using the &lt;code&gt;{ggplot2}&lt;/code&gt; package. Using &lt;code&gt;{shinipsum}&lt;/code&gt;, you can generate a random bar plot
with the following line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shinipsum::random_ggplot(&amp;quot;bar&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-09-27-golemDemo_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and that’s it! Now simply ignore this bit on the server, and continue focusing on the UI. You need
to show a random table? No problem:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shinipsum::random_table(ncol = 7, nrow = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    conc rate   state conc.1 rate.1 state.1 conc.2
## 1  0.02   76 treated   0.02     76 treated   0.02
## 2  0.02   47 treated   0.02     47 treated   0.02
## 3  0.06   97 treated   0.06     97 treated   0.06
## 4  0.06  107 treated   0.06    107 treated   0.06
## 5  0.11  123 treated   0.11    123 treated   0.11
## 6  0.11  139 treated   0.11    139 treated   0.11
## 7  0.22  159 treated   0.22    159 treated   0.22
## 8  0.22  152 treated   0.22    152 treated   0.22
## 9  0.56  191 treated   0.56    191 treated   0.56
## 10 0.56  201 treated   0.56    201 treated   0.56&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your app might now look something like this (actually, it won’t because the little demo below
is not a &lt;code&gt;{golem}&lt;/code&gt; app, but it illustrates &lt;code&gt;{shinipsum}&lt;/code&gt; well):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(reactable)
library(shinipsum)
library(ggiraph)

ui &amp;lt;- pageWithSidebar(
  
  headerPanel(&amp;quot;This is a shinipsum demo&amp;quot;),
  
  sidebarPanel(
    sliderInput(&amp;quot;rows&amp;quot;,
                &amp;quot;Number of rows:&amp;quot;,
                min = 1,
                max = 50,
                value = 5)
  ),
  
  mainPanel(
    reactableOutput(&amp;quot;table&amp;quot;),
    girafeOutput(&amp;quot;graph&amp;quot;)
  )
)


server &amp;lt;- function(input, output) {

  output$table &amp;lt;- renderReactable({
    reactable(random_table(ncol = 10, nrow = input$rows))
  })

  output$graph &amp;lt;- renderGirafe({
    girafe(ggobj = random_ggplot(&amp;quot;bar&amp;quot;))
  })
}

shinyApp(ui = ui, server = server)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have the required packages, running this on a fresh R session should start a little app.&lt;/p&gt;
&lt;p&gt;You see that the server is only a call to &lt;code&gt;shinipsum::random_table&lt;/code&gt;, and &lt;code&gt;shinipsum::random_ggplot&lt;/code&gt;.
Because I want a &lt;code&gt;reactable&lt;/code&gt; and an interactive plot using the &lt;code&gt;{ggiraph}&lt;/code&gt; package, I have already
written the minimum amount of code on the server side to get things working. Now I can focus on my
UI and then, when I’m done, I can start replacing the random objects from &lt;code&gt;{shinipsum}&lt;/code&gt; with
the actual code.&lt;/p&gt;
&lt;p&gt;Now proceeding in this way is not a requirement of &lt;code&gt;{golem}&lt;/code&gt;, but it helps to structure your thoughts
and your app, and you can use this approach for any type of app. The example above, after all, is
not a &lt;code&gt;{golem}&lt;/code&gt; app.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-modular-with-golem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Get modular with &lt;code&gt;{golem}&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;This is now where we get to some more interesting, and &lt;code&gt;{golem}&lt;/code&gt; specific things. If you’ve been
using R and Shiny for the past years, you’ve probably have heard a lot about functional programming.
Functional programming is a programming paradigm that encourages, and in some languages
forces, the use of functions. The idea is that everything you do should be a call to a function,
and functions should be chained together to achieve whatever it is you want to do; cleaning data,
visualizing data, modeling data… R has many functional tools out of the box, which can be complemented
using the &lt;code&gt;{purrr}&lt;/code&gt; package.
What does all of this have to do with Shiny and &lt;code&gt;{golem}&lt;/code&gt;? Well, &lt;code&gt;{golem}&lt;/code&gt; forces you to write
modules to build your apps, and modules are very similar to functions (they’re actually functions).
They’re bits of code that can be decoupled from your app, used in any other app, they can be linked together,
they can be easily documented and tested… If you are familiar with R’s functional programming
approach, modules should not be totally new to you. But if you’ve been using Shiny without module,
they’ll require some getting used to.&lt;/p&gt;
&lt;p&gt;To illustrate how a simple app can be written using modules, I have built &lt;code&gt;golemDemo&lt;/code&gt;, which, as implied
by its name, is a demonstration of a &lt;code&gt;{golem}&lt;/code&gt; app which I hope is simple enough for anyone to
start using. The app is quite simple and does only three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it allows you to choose between two datasets;&lt;/li&gt;
&lt;li&gt;it shows a table of the selected dataset;&lt;/li&gt;
&lt;li&gt;it shows a map of Luxembourg with the data points;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these things is a module, which means that if I were to create another app with a map of
Luxembourg, I could simply reuse it. But remember, the app is actually an R package. Here is
the root of the app on my computer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;ls&amp;quot;, args = &amp;quot;-lFR ~/Documents/golemDemo&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;/home/cbrunos/Documents/golemDemo:&amp;quot;                                    
##  [2] &amp;quot;total 56&amp;quot;                                                              
##  [3] &amp;quot;-rw-r--r-- 1 cbrunos users  302 Sep 19 11:28 app.R&amp;quot;                    
##  [4] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Jun 29 17:49 data-raw/&amp;quot;                
##  [5] &amp;quot;-rw-r--r-- 1 cbrunos users  729 Sep 19 21:27 DESCRIPTION&amp;quot;              
##  [6] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Sep 11 23:39 dev/&amp;quot;                     
##  [7] &amp;quot;-rw-r--r-- 1 cbrunos users 2723 Sep 12 15:04 Dockerfile&amp;quot;               
##  [8] &amp;quot;drwxr-xr-x 3 cbrunos users 4096 Jun 28 11:33 inst/&amp;quot;                    
##  [9] &amp;quot;-rw-r--r-- 1 cbrunos users  483 Apr  8 21:38 LICENSE.md&amp;quot;               
## [10] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Sep 19 21:27 man/&amp;quot;                     
## [11] &amp;quot;-rw-r--r-- 1 cbrunos users 1420 Sep 19 21:27 NAMESPACE&amp;quot;                
## [12] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Sep 19 21:27 R/&amp;quot;                       
## [13] &amp;quot;-rw-r--r-- 1 cbrunos users 1056 Jun 28 11:38 README.Rmd&amp;quot;               
## [14] &amp;quot;drwxr-xr-x 3 cbrunos users 4096 Sep 11 17:12 rsconnect/&amp;quot;               
## [15] &amp;quot;drwxr-xr-x 3 cbrunos users 4096 Jun 28 11:48 tests/&amp;quot;                   
## [16] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Jun 28 11:48 vignettes/&amp;quot;               
## [17] &amp;quot;&amp;quot;                                                                      
## [18] &amp;quot;/home/cbrunos/Documents/golemDemo/data-raw:&amp;quot;                           
## [19] &amp;quot;total 1168&amp;quot;                                                            
## [20] &amp;quot;-rw-r--r-- 1 cbrunos users 1176106 Jun 11 09:52 communes_df.csv&amp;quot;       
## [21] &amp;quot;-rw-r--r-- 1 cbrunos users      99 Jun 28 11:48 my_dataset.R&amp;quot;          
## [22] &amp;quot;-rw-r--r-- 1 cbrunos users    1998 Jun 28 17:00 radars.csv&amp;quot;            
## [23] &amp;quot;-rw-r--r-- 1 cbrunos users    6390 Jun 28 12:31 rettungspunkte.csv&amp;quot;    
## [24] &amp;quot;&amp;quot;                                                                      
## [25] &amp;quot;/home/cbrunos/Documents/golemDemo/dev:&amp;quot;                                
## [26] &amp;quot;total 16&amp;quot;                                                              
## [27] &amp;quot;-rw-r--r-- 1 cbrunos users 1935 Jun 28 11:33 01_start.R&amp;quot;               
## [28] &amp;quot;-rw-r--r-- 1 cbrunos users 2011 Sep 11 23:39 02_dev.R&amp;quot;                 
## [29] &amp;quot;-rw-r--r-- 1 cbrunos users 1012 Jun 28 11:33 03_deploy.R&amp;quot;              
## [30] &amp;quot;-rw-r--r-- 1 cbrunos users  318 Jun 28 11:33 run_dev.R&amp;quot;                
## [31] &amp;quot;&amp;quot;                                                                      
## [32] &amp;quot;/home/cbrunos/Documents/golemDemo/inst:&amp;quot;                               
## [33] &amp;quot;total 8&amp;quot;                                                               
## [34] &amp;quot;drwxr-xr-x 3 cbrunos users 4096 Jun 28 11:33 app/&amp;quot;                     
## [35] &amp;quot;-rw-r--r-- 1 cbrunos users  140 Jun 28 11:38 golem-config.yml&amp;quot;         
## [36] &amp;quot;&amp;quot;                                                                      
## [37] &amp;quot;/home/cbrunos/Documents/golemDemo/inst/app:&amp;quot;                           
## [38] &amp;quot;total 4&amp;quot;                                                               
## [39] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Jun 28 11:48 www/&amp;quot;                     
## [40] &amp;quot;&amp;quot;                                                                      
## [41] &amp;quot;/home/cbrunos/Documents/golemDemo/inst/app/www:&amp;quot;                       
## [42] &amp;quot;total 12&amp;quot;                                                              
## [43] &amp;quot;-rw-r--r-- 1 cbrunos users    0 Jun 28 11:48 custom.css&amp;quot;               
## [44] &amp;quot;-rw-r--r-- 1 cbrunos users 3774 Jun 28 11:33 favicon.ico&amp;quot;              
## [45] &amp;quot;-rw-r--r-- 1 cbrunos users  100 Jun 28 11:48 handlers.js&amp;quot;              
## [46] &amp;quot;-rw-r--r-- 1 cbrunos users   40 Jun 28 11:48 script.js&amp;quot;                
## [47] &amp;quot;&amp;quot;                                                                      
## [48] &amp;quot;/home/cbrunos/Documents/golemDemo/man:&amp;quot;                                
## [49] &amp;quot;total 8&amp;quot;                                                               
## [50] &amp;quot;-rw-r--r-- 1 cbrunos users 261 Sep 19 21:27 pipe.Rd&amp;quot;                   
## [51] &amp;quot;-rw-r--r-- 1 cbrunos users 291 Jun 28 11:33 run_app.Rd&amp;quot;                
## [52] &amp;quot;&amp;quot;                                                                      
## [53] &amp;quot;/home/cbrunos/Documents/golemDemo/R:&amp;quot;                                  
## [54] &amp;quot;total 48&amp;quot;                                                              
## [55] &amp;quot;-rw-r--r-- 1 cbrunos users  783 Jun 28 11:33 app_config.R&amp;quot;             
## [56] &amp;quot;-rw-r--r-- 1 cbrunos users  654 Jun 29 18:34 app_server.R&amp;quot;             
## [57] &amp;quot;-rw-r--r-- 1 cbrunos users 1790 Sep 12 15:00 app_ui.R&amp;quot;                 
## [58] &amp;quot;-rw-r--r-- 1 cbrunos users    0 Jun 28 11:48 fct_helpers.R&amp;quot;            
## [59] &amp;quot;-rw-rw-r-- 1 cbrunos users  997 Jun 28 11:38 golem_utils_server.R&amp;quot;     
## [60] &amp;quot;-rw-rw-r-- 1 cbrunos users 5849 Jun 28 11:38 golem_utils_ui.R&amp;quot;         
## [61] &amp;quot;-rw-r--r-- 1 cbrunos users  549 Jun 28 11:48 mod_filter_data.R&amp;quot;        
## [62] &amp;quot;-rw-r--r-- 1 cbrunos users 3118 Sep 19 11:16 mod_load_data.R&amp;quot;          
## [63] &amp;quot;-rw-r--r-- 1 cbrunos users 2088 Jun 29 18:30 mod_map_data.R&amp;quot;           
## [64] &amp;quot;-rw-r--r-- 1 cbrunos users  910 Jun 29 18:17 mod_table_data.R&amp;quot;         
## [65] &amp;quot;-rw-r--r-- 1 cbrunos users  337 Jun 28 11:33 run_app.R&amp;quot;                
## [66] &amp;quot;-rw-r--r-- 1 cbrunos users    0 Jun 28 11:48 utils_helpers.R&amp;quot;          
## [67] &amp;quot;-rw-r--r-- 1 cbrunos users  207 Sep 19 21:27 utils-pipe.R&amp;quot;             
## [68] &amp;quot;&amp;quot;                                                                      
## [69] &amp;quot;/home/cbrunos/Documents/golemDemo/rsconnect:&amp;quot;                          
## [70] &amp;quot;total 4&amp;quot;                                                               
## [71] &amp;quot;drwxr-xr-x 3 cbrunos users 4096 Sep 11 17:12 shinyapps.io/&amp;quot;            
## [72] &amp;quot;&amp;quot;                                                                      
## [73] &amp;quot;/home/cbrunos/Documents/golemDemo/rsconnect/shinyapps.io:&amp;quot;             
## [74] &amp;quot;total 4&amp;quot;                                                               
## [75] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Sep 11 17:12 brodriguesco/&amp;quot;            
## [76] &amp;quot;&amp;quot;                                                                      
## [77] &amp;quot;/home/cbrunos/Documents/golemDemo/rsconnect/shinyapps.io/brodriguesco:&amp;quot;
## [78] &amp;quot;total 4&amp;quot;                                                               
## [79] &amp;quot;-rw-r--r-- 1 cbrunos users 219 Sep 19 21:30 golemdemo.dcf&amp;quot;             
## [80] &amp;quot;&amp;quot;                                                                      
## [81] &amp;quot;/home/cbrunos/Documents/golemDemo/tests:&amp;quot;                              
## [82] &amp;quot;total 8&amp;quot;                                                               
## [83] &amp;quot;drwxr-xr-x 2 cbrunos users 4096 Jun 28 11:48 testthat/&amp;quot;                
## [84] &amp;quot;-rw-r--r-- 1 cbrunos users   62 Jun 28 11:48 testthat.R&amp;quot;               
## [85] &amp;quot;&amp;quot;                                                                      
## [86] &amp;quot;/home/cbrunos/Documents/golemDemo/tests/testthat:&amp;quot;                     
## [87] &amp;quot;total 4&amp;quot;                                                               
## [88] &amp;quot;-rw-r--r-- 1 cbrunos users 64 Jun 28 11:48 test-app.R&amp;quot;                 
## [89] &amp;quot;&amp;quot;                                                                      
## [90] &amp;quot;/home/cbrunos/Documents/golemDemo/vignettes:&amp;quot;                          
## [91] &amp;quot;total 4&amp;quot;                                                               
## [92] &amp;quot;-rw-r--r-- 1 cbrunos users 298 Jun 28 11:48 golemDemo.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first 16 lines show the root of the folder, and then we see what’s inside each subfolder,
starting with &lt;code&gt;data-raw/&lt;/code&gt;, then &lt;code&gt;dev/&lt;/code&gt; etc (this is done via a call to the &lt;code&gt;ls -lFR&lt;/code&gt; Linux command,
invoked here with R’s &lt;code&gt;system2()&lt;/code&gt; function).&lt;/p&gt;
&lt;p&gt;If you’ve already developed a package in the past, you’ll recognize the structure. What’s important
here is the &lt;code&gt;dev/&lt;/code&gt; folder, which is &lt;code&gt;{golem}&lt;/code&gt; specific. This folder contains for files,
&lt;code&gt;01_start.R&lt;/code&gt;, &lt;code&gt;02_dev.R&lt;/code&gt;, &lt;code&gt;03_deploy.R&lt;/code&gt; and &lt;code&gt;run_dev.R&lt;/code&gt;. These files are the ones that will help
you develop your shiny app and you should follow the instructions contained in each of them. Let’s
take a look at &lt;code&gt;01_start.R&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;cat&amp;quot;, args = &amp;quot;~/Documents/golemDemo/dev/01_start.R&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;# Building a Prod-Ready, Robust Shiny Application.&amp;quot;                                     
##  [2] &amp;quot;# &amp;quot;                                                                                     
##  [3] &amp;quot;# README: each step of the dev files is optional, and you don&amp;#39;t have to &amp;quot;               
##  [4] &amp;quot;# fill every dev scripts before getting started. &amp;quot;                                      
##  [5] &amp;quot;# 01_start.R should be filled at start. &amp;quot;                                               
##  [6] &amp;quot;# 02_dev.R should be used to keep track of your development during the project.&amp;quot;        
##  [7] &amp;quot;# 03_deploy.R should be used once you need to deploy your app.&amp;quot;                         
##  [8] &amp;quot;# &amp;quot;                                                                                     
##  [9] &amp;quot;# &amp;quot;                                                                                     
## [10] &amp;quot;########################################&amp;quot;                                               
## [11] &amp;quot;#### CURRENT FILE: ON START SCRIPT #####&amp;quot;                                               
## [12] &amp;quot;########################################&amp;quot;                                               
## [13] &amp;quot;&amp;quot;                                                                                       
## [14] &amp;quot;## Fill the DESCRIPTION ----&amp;quot;                                                           
## [15] &amp;quot;## Add meta data about your application&amp;quot;                                                
## [16] &amp;quot;golem::fill_desc(&amp;quot;                                                                      
## [17] &amp;quot;  pkg_name = \&amp;quot;golemDemo\&amp;quot;, # The Name of the package containing the App &amp;quot;              
## [18] &amp;quot;  pkg_title = \&amp;quot;PKG_TITLE\&amp;quot;, # The Title of the package containing the App &amp;quot;            
## [19] &amp;quot;  pkg_description = \&amp;quot;PKG_DESC.\&amp;quot;, # The Description of the package containing the App &amp;quot;
## [20] &amp;quot;  author_first_name = \&amp;quot;AUTHOR_FIRST\&amp;quot;, # Your First Name&amp;quot;                              
## [21] &amp;quot;  author_last_name = \&amp;quot;AUTHOR_LAST\&amp;quot;, # Your Last Name&amp;quot;                                 
## [22] &amp;quot;  author_email = \&amp;quot;AUTHOR@MAIL.COM\&amp;quot;, # Your Email&amp;quot;                                     
## [23] &amp;quot;  repo_url = NULL # The URL of the GitHub Repo (optional) &amp;quot;                             
## [24] &amp;quot;)     &amp;quot;                                                                                 
## [25] &amp;quot;&amp;quot;                                                                                       
## [26] &amp;quot;## Set {golem} options ----&amp;quot;                                                            
## [27] &amp;quot;golem::set_golem_options()&amp;quot;                                                             
## [28] &amp;quot;&amp;quot;                                                                                       
## [29] &amp;quot;## Create Common Files ----&amp;quot;                                                            
## [30] &amp;quot;## See ?usethis for more information&amp;quot;                                                   
## [31] &amp;quot;usethis::use_mit_license( name = \&amp;quot;Golem User\&amp;quot; )  # You can set another license here&amp;quot;  
## [32] &amp;quot;usethis::use_readme_rmd( open = FALSE )&amp;quot;                                                
## [33] &amp;quot;usethis::use_code_of_conduct()&amp;quot;                                                         
## [34] &amp;quot;usethis::use_lifecycle_badge( \&amp;quot;Experimental\&amp;quot; )&amp;quot;                                       
## [35] &amp;quot;usethis::use_news_md( open = FALSE )&amp;quot;                                                   
## [36] &amp;quot;&amp;quot;                                                                                       
## [37] &amp;quot;## Use git ----&amp;quot;                                                                        
## [38] &amp;quot;usethis::use_git()&amp;quot;                                                                     
## [39] &amp;quot;&amp;quot;                                                                                       
## [40] &amp;quot;## Init Testing Infrastructure ----&amp;quot;                                                    
## [41] &amp;quot;## Create a template for tests&amp;quot;                                                         
## [42] &amp;quot;golem::use_recommended_tests()&amp;quot;                                                         
## [43] &amp;quot;&amp;quot;                                                                                       
## [44] &amp;quot;## Use Recommended Packages ----&amp;quot;                                                       
## [45] &amp;quot;golem::use_recommended_deps()&amp;quot;                                                          
## [46] &amp;quot;&amp;quot;                                                                                       
## [47] &amp;quot;## Favicon ----&amp;quot;                                                                        
## [48] &amp;quot;# If you want to change the favicon (default is golem&amp;#39;s one)&amp;quot;                           
## [49] &amp;quot;golem::remove_favicon()&amp;quot;                                                                
## [50] &amp;quot;golem::use_favicon() # path = \&amp;quot;path/to/ico\&amp;quot;. Can be an online file. &amp;quot;                 
## [51] &amp;quot;&amp;quot;                                                                                       
## [52] &amp;quot;## Add helper functions ----&amp;quot;                                                           
## [53] &amp;quot;golem::use_utils_ui()&amp;quot;                                                                  
## [54] &amp;quot;golem::use_utils_server()&amp;quot;                                                              
## [55] &amp;quot;&amp;quot;                                                                                       
## [56] &amp;quot;# You&amp;#39;re now set! ----&amp;quot;                                                                 
## [57] &amp;quot;&amp;quot;                                                                                       
## [58] &amp;quot;# go to dev/02_dev.R&amp;quot;                                                                   
## [59] &amp;quot;rstudioapi::navigateToFile( \&amp;quot;dev/02_dev.R\&amp;quot; )&amp;quot;                                         
## [60] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This script is a series of calls to &lt;code&gt;{usethis}&lt;/code&gt; functions; you can remove whatever you don’t need
and adapt the others that you need. As you can see, I did not change much here. Execute it line by
line when you’re done editing it. Once you’re done, you can go to &lt;code&gt;02_dev.R&lt;/code&gt; and this is probably
the script that you’ll change the most:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;cat&amp;quot;, args = &amp;quot;~/Documents/golemDemo/dev/02_dev.R&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;# Building a Prod-Ready, Robust Shiny Application.&amp;quot;                             
##  [2] &amp;quot;# &amp;quot;                                                                             
##  [3] &amp;quot;# README: each step of the dev files is optional, and you don&amp;#39;t have to &amp;quot;       
##  [4] &amp;quot;# fill every dev scripts before getting started. &amp;quot;                              
##  [5] &amp;quot;# 01_start.R should be filled at start. &amp;quot;                                       
##  [6] &amp;quot;# 02_dev.R should be used to keep track of your development during the project.&amp;quot;
##  [7] &amp;quot;# 03_deploy.R should be used once you need to deploy your app.&amp;quot;                 
##  [8] &amp;quot;# &amp;quot;                                                                             
##  [9] &amp;quot;# &amp;quot;                                                                             
## [10] &amp;quot;###################################&amp;quot;                                            
## [11] &amp;quot;#### CURRENT FILE: DEV SCRIPT #####&amp;quot;                                            
## [12] &amp;quot;###################################&amp;quot;                                            
## [13] &amp;quot;&amp;quot;                                                                               
## [14] &amp;quot;# Engineering&amp;quot;                                                                  
## [15] &amp;quot;&amp;quot;                                                                               
## [16] &amp;quot;## Dependencies ----&amp;quot;                                                           
## [17] &amp;quot;## Add one line by package you want to add as dependency&amp;quot;                       
## [18] &amp;quot;usethis::use_package( \&amp;quot;shiny\&amp;quot; )&amp;quot;                                              
## [19] &amp;quot;usethis::use_package( \&amp;quot;shinydashboard\&amp;quot; )&amp;quot;                                     
## [20] &amp;quot;usethis::use_package(\&amp;quot;data.table\&amp;quot;) &amp;quot;                                          
## [21] &amp;quot;usethis::use_package(\&amp;quot;DT\&amp;quot;)&amp;quot;                                                   
## [22] &amp;quot;usethis::use_package(\&amp;quot;dplyr\&amp;quot;)&amp;quot;                                                
## [23] &amp;quot;usethis::use_package(\&amp;quot;rlang\&amp;quot;)&amp;quot;                                                
## [24] &amp;quot;usethis::use_package(\&amp;quot;ggiraph\&amp;quot;)&amp;quot;                                              
## [25] &amp;quot;usethis::use_package(\&amp;quot;ggplot2\&amp;quot;)&amp;quot;                                              
## [26] &amp;quot;usethis::use_package(\&amp;quot;htmlwidgets\&amp;quot;)&amp;quot;                                          
## [27] &amp;quot;usethis::use_package(\&amp;quot;dplyr\&amp;quot;)&amp;quot;                                                
## [28] &amp;quot;usethis::use_package(\&amp;quot;colorspace\&amp;quot;)&amp;quot;                                           
## [29] &amp;quot;usethis::use_package(\&amp;quot;shinycssloaders\&amp;quot;)&amp;quot;                                      
## [30] &amp;quot;usethis::use_package(\&amp;quot;lubridate\&amp;quot;)&amp;quot;                                            
## [31] &amp;quot;&amp;quot;                                                                               
## [32] &amp;quot;## Add modules ----&amp;quot;                                                            
## [33] &amp;quot;## Create a module infrastructure in R/&amp;quot;                                        
## [34] &amp;quot;golem::add_module( name = \&amp;quot;name_of_module1\&amp;quot; ) # Name of the module&amp;quot;           
## [35] &amp;quot;golem::add_module( name = \&amp;quot;name_of_module2\&amp;quot; ) # Name of the module&amp;quot;           
## [36] &amp;quot;&amp;quot;                                                                               
## [37] &amp;quot;## Add helper functions ----&amp;quot;                                                   
## [38] &amp;quot;## Creates ftc_* and utils_*&amp;quot;                                                   
## [39] &amp;quot;golem::add_fct( \&amp;quot;helpers\&amp;quot; ) &amp;quot;                                                 
## [40] &amp;quot;golem::add_utils( \&amp;quot;helpers\&amp;quot; )&amp;quot;                                                
## [41] &amp;quot;&amp;quot;                                                                               
## [42] &amp;quot;## External resources&amp;quot;                                                          
## [43] &amp;quot;## Creates .js and .css files at inst/app/www&amp;quot;                                  
## [44] &amp;quot;golem::add_js_file( \&amp;quot;script\&amp;quot; )&amp;quot;                                               
## [45] &amp;quot;golem::add_js_handler( \&amp;quot;handlers\&amp;quot; )&amp;quot;                                          
## [46] &amp;quot;golem::add_css_file( \&amp;quot;custom\&amp;quot; )&amp;quot;                                              
## [47] &amp;quot;&amp;quot;                                                                               
## [48] &amp;quot;## Add internal datasets ----&amp;quot;                                                  
## [49] &amp;quot;## If you have data in your package&amp;quot;                                            
## [50] &amp;quot;usethis::use_data_raw( name = \&amp;quot;my_dataset\&amp;quot;, open = FALSE ) &amp;quot;                  
## [51] &amp;quot;&amp;quot;                                                                               
## [52] &amp;quot;## Tests ----&amp;quot;                                                                  
## [53] &amp;quot;## Add one line by test you want to create&amp;quot;                                     
## [54] &amp;quot;usethis::use_test( \&amp;quot;app\&amp;quot; )&amp;quot;                                                   
## [55] &amp;quot;&amp;quot;                                                                               
## [56] &amp;quot;# Documentation&amp;quot;                                                                
## [57] &amp;quot;&amp;quot;                                                                               
## [58] &amp;quot;## Vignette ----&amp;quot;                                                               
## [59] &amp;quot;usethis::use_vignette(\&amp;quot;golemDemo\&amp;quot;)&amp;quot;                                           
## [60] &amp;quot;devtools::build_vignettes()&amp;quot;                                                    
## [61] &amp;quot;&amp;quot;                                                                               
## [62] &amp;quot;## Code coverage ----&amp;quot;                                                          
## [63] &amp;quot;## (You&amp;#39;ll need GitHub there)&amp;quot;                                                  
## [64] &amp;quot;usethis::use_github()&amp;quot;                                                          
## [65] &amp;quot;usethis::use_travis()&amp;quot;                                                          
## [66] &amp;quot;usethis::use_appveyor()&amp;quot;                                                        
## [67] &amp;quot;&amp;quot;                                                                               
## [68] &amp;quot;# You&amp;#39;re now set! ----&amp;quot;                                                         
## [69] &amp;quot;# go to dev/03_deploy.R&amp;quot;                                                        
## [70] &amp;quot;rstudioapi::navigateToFile(\&amp;quot;dev/03_deploy.R\&amp;quot;)&amp;quot;                                
## [71] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where you will list the dependencies of your package (lines 18 to 30) as well as the
modules (lines 34 to 35). I have mostly used this file for the dependencies, as I already
had the modules from another app, so I didn’t bother listing them here. But if I would have started
from scratch, I would changed the line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;golem::add_module( name = \&amp;quot;name_of_module1\&amp;quot; ) # Name of the module&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;golem::add_module( name = \&amp;quot;import_data\&amp;quot; ) # Name of the module&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and executing it would have generated the needed files to start creating the module at the right
spot. Let’s go see how such a module looks like (I’m skipping the third script for now, as it is
only useful once you want to deploy).&lt;/p&gt;
&lt;p&gt;You can find the modules in the &lt;code&gt;R/&lt;/code&gt; folder. Let’s take a look at the module that allows the user
to load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;cat&amp;quot;, args = &amp;quot;~/Documents/golemDemo/R/mod_load_data.R&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;#&amp;#39; load_data UI Function&amp;quot;                                                                                                    
##   [2] &amp;quot;#&amp;#39;&amp;quot;                                                                                                                          
##   [3] &amp;quot;#&amp;#39; @description A shiny Module.&amp;quot;                                                                                             
##   [4] &amp;quot;#&amp;#39;&amp;quot;                                                                                                                          
##   [5] &amp;quot;#&amp;#39; @param id,input,output,session Internal parameters for {shiny}.&amp;quot;                                                          
##   [6] &amp;quot;#&amp;#39;&amp;quot;                                                                                                                          
##   [7] &amp;quot;#&amp;#39; @noRd &amp;quot;                                                                                                                   
##   [8] &amp;quot;#&amp;#39;&amp;quot;                                                                                                                          
##   [9] &amp;quot;#&amp;#39; @importFrom shiny NS tagList &amp;quot;                                                                                            
##  [10] &amp;quot;#&amp;#39; @importFrom data.table fread&amp;quot;                                                                                             
##  [11] &amp;quot;#&amp;#39; @importFrom DT renderDataTable dataTableOutput&amp;quot;                                                                           
##  [12] &amp;quot;#&amp;#39; @importFrom dplyr filter&amp;quot;                                                                                                 
##  [13] &amp;quot;#&amp;#39; @importFrom rlang quo `!!` as_name&amp;quot;                                                                                       
##  [14] &amp;quot;mod_load_data_ui &amp;lt;- function(id){&amp;quot;                                                                                           
##  [15] &amp;quot;  ns &amp;lt;- NS(id)&amp;quot;                                                                                                              
##  [16] &amp;quot;  tagList(&amp;quot;                                                                                                                  
##  [17] &amp;quot;    box(title = \&amp;quot;Select dataset\&amp;quot;,&amp;quot;                                                                                         
##  [18] &amp;quot;        radioButtons(ns(\&amp;quot;select_dataset\&amp;quot;),&amp;quot;                                                                                
##  [19] &amp;quot;                    label = \&amp;quot;Select dataset\&amp;quot;,&amp;quot;                                                                             
##  [20] &amp;quot;                    choices = c(\&amp;quot;Rescue points\&amp;quot;, \&amp;quot;Radars\&amp;quot;),&amp;quot;                                                             
##  [21] &amp;quot;                    selected = c(\&amp;quot;Rescue points\&amp;quot;)),&amp;quot;                                                                       
##  [22] &amp;quot;        conditionalPanel(&amp;quot;                                                                                                   
##  [23] &amp;quot;          condition = paste0(&amp;#39;input[\\&amp;#39;&amp;#39;, ns(&amp;#39;select_dataset&amp;#39;), \&amp;quot;\\&amp;#39;] == \\&amp;#39;Rescue points\\&amp;#39;\&amp;quot;),&amp;quot;                           
##  [24] &amp;quot;          selectInput(ns(\&amp;quot;selector_place\&amp;quot;), \&amp;quot;Place\&amp;quot;,&amp;quot;                                                                    
##  [25] &amp;quot;                      choices = c(\&amp;quot;test\&amp;quot;),&amp;quot;                                                                                
##  [26] &amp;quot;                      #choices = c(unique(output$dataset$place)),&amp;quot;                                                           
##  [27] &amp;quot;                      selected = c(\&amp;quot;Luxembourg, Ville (G)\&amp;quot;),&amp;quot;                                                              
##  [28] &amp;quot;                      multiple = TRUE)),&amp;quot;                                                                                    
##  [29] &amp;quot;        conditionalPanel(&amp;quot;                                                                                                   
##  [30] &amp;quot;          condition = paste0(&amp;#39;input[\\&amp;#39;&amp;#39;, ns(&amp;#39;select_dataset&amp;#39;), \&amp;quot;\\&amp;#39;] == \\&amp;#39;Radars\\&amp;#39;\&amp;quot;),&amp;quot;                                  
##  [31] &amp;quot;          selectInput(ns(\&amp;quot;selector_radar\&amp;quot;), \&amp;quot;Radar\&amp;quot;,&amp;quot;                                                                    
##  [32] &amp;quot;                      choices = c(\&amp;quot;test\&amp;quot;),&amp;quot;                                                                                
##  [33] &amp;quot;                      #choices = c(\&amp;quot;huhu\&amp;quot;),&amp;quot;                                                                               
##  [34] &amp;quot;                      selected = c(\&amp;quot;National road\&amp;quot;),&amp;quot;                                                                      
##  [35] &amp;quot;                      multiple = TRUE)),&amp;quot;                                                                                    
##  [36] &amp;quot;        width = NULL),&amp;quot;                                                                                                      
##  [37] &amp;quot;  )&amp;quot;                                                                                                                         
##  [38] &amp;quot;}&amp;quot;                                                                                                                           
##  [39] &amp;quot;&amp;quot;                                                                                                                            
##  [40] &amp;quot;#&amp;#39; load_data Server Function&amp;quot;                                                                                                
##  [41] &amp;quot;#&amp;#39;&amp;quot;                                                                                                                          
##  [42] &amp;quot;#&amp;#39; @noRd &amp;quot;                                                                                                                   
##  [43] &amp;quot;mod_load_data_server &amp;lt;- function(input, output, session){&amp;quot;                                                                   
##  [44] &amp;quot;  ns &amp;lt;- session$ns&amp;quot;                                                                                                          
##  [45] &amp;quot; &amp;quot;                                                                                                                           
##  [46] &amp;quot;  &amp;quot;                                                                                                                          
##  [47] &amp;quot;  read_dataset &amp;lt;- reactive({&amp;quot;                                                                                                
##  [48] &amp;quot;    if(input$select_dataset == \&amp;quot;Rescue points\&amp;quot;) {&amp;quot;                                                                         
##  [49] &amp;quot;&amp;quot;                                                                                                                            
##  [50] &amp;quot;      dataset &amp;lt;- fread(\&amp;quot;data-raw/rettungspunkte.csv\&amp;quot;)&amp;quot;                                                                     
##  [51] &amp;quot;      variable &amp;lt;- quo(place)&amp;quot;                                                                                                
##  [52] &amp;quot;      filter_values &amp;lt;- unique(dataset[, place])&amp;quot;                                                                             
##  [53] &amp;quot;    } else {&amp;quot;                                                                                                                
##  [54] &amp;quot;      dataset &amp;lt;- fread(\&amp;quot;data-raw/radars.csv\&amp;quot;)&amp;quot;                                                                             
##  [55] &amp;quot;      variable &amp;lt;- quo(type_road)&amp;quot;                                                                                            
##  [56] &amp;quot;      filter_values &amp;lt;- unique(dataset[, type_road])&amp;quot;                                                                         
##  [57] &amp;quot;    }&amp;quot;                                                                                                                       
##  [58] &amp;quot;    cat(\&amp;quot;reading data\\n\&amp;quot;)&amp;quot;                                                                                                
##  [59] &amp;quot;    list(dataset = dataset,&amp;quot;                                                                                                 
##  [60] &amp;quot;         variable = variable,&amp;quot;                                                                                               
##  [61] &amp;quot;         filter_values = filter_values)&amp;quot;                                                                                     
##  [62] &amp;quot;  })&amp;quot;                                                                                                                        
##  [63] &amp;quot;&amp;quot;                                                                                                                            
##  [64] &amp;quot;&amp;quot;                                                                                                                            
##  [65] &amp;quot;  observe({&amp;quot;                                                                                                                 
##  [66] &amp;quot;    updateSelectInput(session, \&amp;quot;selector_place\&amp;quot;, label = \&amp;quot;Select place:\&amp;quot;, choices = read_dataset()$filter_values,&amp;quot;       
##  [67] &amp;quot;                      selected = \&amp;quot;Luxembourg, Ville (G)\&amp;quot;)&amp;quot;                                                                 
##  [68] &amp;quot;  })&amp;quot;                                                                                                                        
##  [69] &amp;quot;&amp;quot;                                                                                                                            
##  [70] &amp;quot;  observe({&amp;quot;                                                                                                                 
##  [71] &amp;quot;    updateSelectInput(session, \&amp;quot;selector_radar\&amp;quot;, label = \&amp;quot;Select type of road:\&amp;quot;, choices = read_dataset()$filter_values,&amp;quot;
##  [72] &amp;quot;                      selected = \&amp;quot;National road\&amp;quot;)&amp;quot;                                                                         
##  [73] &amp;quot;  })&amp;quot;                                                                                                                        
##  [74] &amp;quot;&amp;quot;                                                                                                                            
##  [75] &amp;quot;  result &amp;lt;- reactive({&amp;quot;                                                                                                      
##  [76] &amp;quot;    return_dataset &amp;lt;- read_dataset()$dataset&amp;quot;                                                                                
##  [77] &amp;quot;&amp;quot;                                                                                                                            
##  [78] &amp;quot;    if(\&amp;quot;place\&amp;quot; %in% colnames(return_dataset)){&amp;quot;                                                                            
##  [79] &amp;quot;      return_dataset &amp;lt;- return_dataset %&amp;gt;%&amp;quot;                                                                                  
##  [80] &amp;quot;        filter((!!read_dataset()$variable) %in% input$selector_place)&amp;quot;                                                       
##  [81] &amp;quot;&amp;quot;                                                                                                                            
##  [82] &amp;quot;      result &amp;lt;- list(&amp;quot;                                                                                                       
##  [83] &amp;quot;        return_dataset = return_dataset,&amp;quot;                                                                                    
##  [84] &amp;quot;        variable = quo(place)&amp;quot;                                                                                               
##  [85] &amp;quot;      )&amp;quot;                                                                                                                     
##  [86] &amp;quot;    } else {&amp;quot;                                                                                                                
##  [87] &amp;quot;      return_dataset &amp;lt;- return_dataset %&amp;gt;%&amp;quot;                                                                                  
##  [88] &amp;quot;        filter((!!read_dataset()$variable) %in% input$selector_radar)&amp;quot;                                                       
##  [89] &amp;quot;&amp;quot;                                                                                                                            
##  [90] &amp;quot;      result &amp;lt;- list(&amp;quot;                                                                                                       
##  [91] &amp;quot;        return_dataset = return_dataset,&amp;quot;                                                                                    
##  [92] &amp;quot;        variable = quo(type_road)&amp;quot;                                                                                           
##  [93] &amp;quot;      )&amp;quot;                                                                                                                     
##  [94] &amp;quot;    }&amp;quot;                                                                                                                       
##  [95] &amp;quot;  })&amp;quot;                                                                                                                        
##  [96] &amp;quot;&amp;quot;                                                                                                                            
##  [97] &amp;quot;  result&amp;quot;                                                                                                                    
##  [98] &amp;quot;}&amp;quot;                                                                                                                           
##  [99] &amp;quot;    &amp;quot;                                                                                                                        
## [100] &amp;quot;## To be copied in the UI&amp;quot;                                                                                                   
## [101] &amp;quot;# mod_load_data_ui(\&amp;quot;load_data_ui_1\&amp;quot;)&amp;quot;                                                                                      
## [102] &amp;quot;    &amp;quot;                                                                                                                        
## [103] &amp;quot;## To be copied in the server&amp;quot;                                                                                               
## [104] &amp;quot;# callModule(mod_load_data_server, \&amp;quot;load_data_ui_1\&amp;quot;)&amp;quot;                                                                      
## [105] &amp;quot; &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This scripts looks like a mini Shiny app; there’s a UI defined at the top of the script, and
then a server defined at the bottom (I’m not describing what the module does here, I’ll do that
in the video). What’s important here, is that this is a module and as such it can be reused in any
app, by simply copying the right lines of code at the right spot. See lines 100 to 104 for this,
which tells you exactly where to copy the lines to use this module. All the modules will
look the same, and have this little explanation at the bottom to tell you where you need to copy
the lines to use the modules. While building each module, you can use &lt;code&gt;{shinipsum}&lt;/code&gt; instead of
having to bother about the server logic, just to get things going, as explained above.&lt;/p&gt;
&lt;p&gt;Now, finally, let’s take a look at the actual UI of the app:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;cat&amp;quot;, args = &amp;quot;~/Documents/golemDemo/R/app_ui.R&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;#&amp;#39; The application User-Interface&amp;quot;                                                          
##  [2] &amp;quot;#&amp;#39; &amp;quot;                                                                                        
##  [3] &amp;quot;#&amp;#39; @param request Internal parameter for `{shiny}`. &amp;quot;                                       
##  [4] &amp;quot;#&amp;#39;     DO NOT REMOVE.&amp;quot;                                                                      
##  [5] &amp;quot;#&amp;#39; @import shiny&amp;quot;                                                                           
##  [6] &amp;quot;#&amp;#39; @import shinydashboard&amp;quot;                                                                  
##  [7] &amp;quot;#&amp;#39; @noRd&amp;quot;                                                                                   
##  [8] &amp;quot;app_ui &amp;lt;- function(request) {&amp;quot;                                                              
##  [9] &amp;quot;  tagList(&amp;quot;                                                                                 
## [10] &amp;quot;                                        # Leave this function for adding external resources&amp;quot;
## [11] &amp;quot;    golem_add_external_resources(),&amp;quot;                                                        
## [12] &amp;quot;                                        # List the first level UI elements here&amp;quot;            
## [13] &amp;quot;    dashboardPage(&amp;quot;                                                                         
## [14] &amp;quot;      dashboardHeader(title = \&amp;quot;Prototype: dashboard ecoles\&amp;quot;),&amp;quot;                            
## [15] &amp;quot;      dashboardSidebar(&amp;quot;                                                                    
## [16] &amp;quot;        sidebarMenu(&amp;quot;                                                                       
## [17] &amp;quot;          menuItem(\&amp;quot;Carte\&amp;quot;, tabName = \&amp;quot;Carte\&amp;quot;, icon = icon(\&amp;quot;map\&amp;quot;)),&amp;quot;                  
## [18] &amp;quot;          menuItem(\&amp;quot;Tab 2\&amp;quot;, tabName = \&amp;quot;tab_2\&amp;quot;, icon = icon(\&amp;quot;chart-line\&amp;quot;))&amp;quot;            
## [19] &amp;quot;        )&amp;quot;                                                                                  
## [20] &amp;quot;      ),&amp;quot;                                                                                   
## [21] &amp;quot;      dashboardBody(&amp;quot;                                                                       
## [22] &amp;quot;        tabItems(&amp;quot;                                                                          
## [23] &amp;quot;          tabItem(tabName = \&amp;quot;Carte\&amp;quot;,&amp;quot;                                                     
## [24] &amp;quot;                  fluidRow(&amp;quot;                                                                
## [25] &amp;quot;                    column(&amp;quot;                                                                
## [26] &amp;quot;                      width = 4,&amp;quot;                                                           
## [27] &amp;quot;                      mod_load_data_ui(\&amp;quot;load_data_ui_1\&amp;quot;),&amp;quot;                                
## [28] &amp;quot;                      mod_table_data_ui(\&amp;quot;table_data_ui_1\&amp;quot;)&amp;quot;                               
## [29] &amp;quot;                    ),&amp;quot;                                                                     
## [30] &amp;quot;                    column(&amp;quot;                                                                
## [31] &amp;quot;                      width = 6, offset = 2,&amp;quot;                                               
## [32] &amp;quot;                      mod_map_data_ui(\&amp;quot;map_data_ui_1\&amp;quot;)&amp;quot;                                   
## [33] &amp;quot;                    )&amp;quot;                                                                      
## [34] &amp;quot;                  ))&amp;quot;                                                                       
## [35] &amp;quot;        )&amp;quot;                                                                                  
## [36] &amp;quot;      )&amp;quot;                                                                                    
## [37] &amp;quot;    )&amp;quot;                                                                                      
## [38] &amp;quot;  )&amp;quot;                                                                                        
## [39] &amp;quot;}&amp;quot;                                                                                          
## [40] &amp;quot;&amp;quot;                                                                                           
## [41] &amp;quot;#&amp;#39; Add external Resources to the Application&amp;quot;                                               
## [42] &amp;quot;#&amp;#39; &amp;quot;                                                                                        
## [43] &amp;quot;#&amp;#39; This function is internally used to add external &amp;quot;                                       
## [44] &amp;quot;#&amp;#39; resources inside the Shiny application. &amp;quot;                                                
## [45] &amp;quot;#&amp;#39; &amp;quot;                                                                                        
## [46] &amp;quot;#&amp;#39; @import shiny&amp;quot;                                                                           
## [47] &amp;quot;#&amp;#39; @importFrom golem add_resource_path activate_js favicon bundle_resources&amp;quot;                
## [48] &amp;quot;#&amp;#39; @noRd&amp;quot;                                                                                   
## [49] &amp;quot;golem_add_external_resources &amp;lt;- function(){&amp;quot;                                                
## [50] &amp;quot;  &amp;quot;                                                                                         
## [51] &amp;quot;  add_resource_path(&amp;quot;                                                                       
## [52] &amp;quot;    &amp;#39;www&amp;#39;, app_sys(&amp;#39;app/www&amp;#39;)&amp;quot;                                                              
## [53] &amp;quot;  )&amp;quot;                                                                                        
## [54] &amp;quot; &amp;quot;                                                                                          
## [55] &amp;quot;  tags$head(&amp;quot;                                                                               
## [56] &amp;quot;    favicon(),&amp;quot;                                                                             
## [57] &amp;quot;    bundle_resources(&amp;quot;                                                                      
## [58] &amp;quot;      path = app_sys(&amp;#39;app/www&amp;#39;),&amp;quot;                                                           
## [59] &amp;quot;      app_title = &amp;#39;golemDemo&amp;#39;&amp;quot;                                                              
## [60] &amp;quot;    )&amp;quot;                                                                                      
## [61] &amp;quot;    # Add here other external resources&amp;quot;                                                    
## [62] &amp;quot;    # for example, you can add shinyalert::useShinyalert() &amp;quot;                                
## [63] &amp;quot;  )&amp;quot;                                                                                        
## [64] &amp;quot;}&amp;quot;                                                                                          
## [65] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;this is the “global” UI of the app. This looks like any other Shiny UI, but instead of having
many many lines of code, there’s basically only calls to the UIs of each modules (see lines 27 and 28).
And that’s it! It keeps your code quite small and much easier to reason about. You’ll find
something even simpler for the server:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;cat&amp;quot;, args = &amp;quot;~/Documents/golemDemo/R/app_server.R&amp;quot;, stdout = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;#&amp;#39; The application server-side&amp;quot;                                              
##  [2] &amp;quot;#&amp;#39; &amp;quot;                                                                         
##  [3] &amp;quot;#&amp;#39; @param input,output,session Internal parameters for {shiny}. &amp;quot;            
##  [4] &amp;quot;#&amp;#39;     DO NOT REMOVE.&amp;quot;                                                       
##  [5] &amp;quot;#&amp;#39; @import shiny&amp;quot;                                                            
##  [6] &amp;quot;#&amp;#39; @noRd&amp;quot;                                                                    
##  [7] &amp;quot;app_server &amp;lt;- function( input, output, session ) {&amp;quot;                          
##  [8] &amp;quot;  # List the first level callModules here&amp;quot;                                   
##  [9] &amp;quot;&amp;quot;                                                                            
## [10] &amp;quot;  result &amp;lt;- callModule(mod_load_data_server, \&amp;quot;load_data_ui_1\&amp;quot;)&amp;quot;            
## [11] &amp;quot;&amp;quot;                                                                            
## [12] &amp;quot;  callModule(mod_table_data_server, \&amp;quot;table_data_ui_1\&amp;quot;, result)&amp;quot;            
## [13] &amp;quot;  &amp;quot;                                                                          
## [14] &amp;quot;&amp;quot;                                                                            
## [15] &amp;quot;  selected_lines &amp;lt;- reactive({&amp;quot;                                              
## [16] &amp;quot;    if(is.null(input$`table_data_ui_1-dataset_rows_selected`)){&amp;quot;             
## [17] &amp;quot;      return(TRUE)&amp;quot;                                                          
## [18] &amp;quot;    } else {&amp;quot;                                                                
## [19] &amp;quot;      as.numeric(input$`table_data_ui_1-dataset_rows_selected`)&amp;quot;             
## [20] &amp;quot;    }&amp;quot;                                                                       
## [21] &amp;quot;  })&amp;quot;                                                                        
## [22] &amp;quot;&amp;quot;                                                                            
## [23] &amp;quot;  callModule(mod_map_data_server, \&amp;quot;map_data_ui_1\&amp;quot;, result, selected_lines)&amp;quot;
## [24] &amp;quot;&amp;quot;                                                                            
## [25] &amp;quot;}&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Line 10 calls the server side of the “load data” module, and saves the result (a data frame) into
a variable called &lt;code&gt;result&lt;/code&gt;. This result is then passed as an argument to the server side of
table data module, which simply shows a table of the data. From lines 15 to 21, I define a
variable called &lt;code&gt;selected-lines&lt;/code&gt; in which the lines that the user selects in the data table are
saved. This gave me some headaches, because I needed to find the right syntax. I was able to find
it thanks to a Stackoverflow post that I have now lost since then… but the idea is that
the indices of the selected rows are saved into a variable called &lt;code&gt;dataset_rows_selected&lt;/code&gt; and this variable name
must be appended to the name of the UI of the table where the table is. If no row is selected, then
this object should be &lt;code&gt;TRUE&lt;/code&gt;; why? Because if you filter a data frame with a condition that simply
evaluates always to &lt;code&gt;TRUE&lt;/code&gt;, you get all the rows back, and thus, all of the data frame. If you start
selecting rows, say, rows number 2, 8 and 12, then &lt;code&gt;dataset_rows_selected&lt;/code&gt; will be equal to &lt;code&gt;c(2, 8, 12)&lt;/code&gt;, and the filter will return these rows.&lt;/p&gt;
&lt;p&gt;Finally, I call the module that returns a map of Luxembourg, and pass both the data frame, saved in
the &lt;code&gt;result&lt;/code&gt; variable, and the &lt;code&gt;selected_lines&lt;/code&gt; objects as arguments. And that’s how you make modules
communicate and share data with each other, just like you would chain functions together.
I won’t go through each module, but there’s several other interesting tricks that I’ll discuss
during the video; for instance, I’m quite happy with the module that loads the data; the user can
choose between two different dataset, and the select input will update with the right columns. This
also wasn’t so easy to do, but it’ll be easier to explain during a video, so stay tuned!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Raspberry Pi 4B as a shiny server</title>
      <link>https://www.brodrigues.co/blog/2020-09-20-shiny_raspberry/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-09-20-shiny_raspberry/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2mSEEHblJqw&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/virgin_chad.png&#34; title = &#34;Not everyone can be a chad shiny dev&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This blog post will not have any code, but will document how I went from hosting apps
on &lt;a href=&#34;https://www.shinyapps.io&#34;&gt;shinyapps.io&lt;/a&gt; to hosting shiny apps on my own server, which is a Raspberry Pi 4B with 8 gigs of ram.
First of all, why hosting apps on a Raspberry Pi? And why not continue on &lt;a href=&#34;https://www.shinyapps.io&#34;&gt;shinyapps.io&lt;/a&gt;?
Or why not get one of hose nifty droplets on DigitalOcean? Well for two reasons; one is that I wanted
to have full control of the server, and learn some basic web dev/web engineering skills that I lacked. These services
simplify the process of deploying and hosting a lot, which of course is a good thing if your only
goal is to deploy apps. But I wanted to learn how to do it myself from scratch for some time.
True, with a DigitalOcean droplet, I could have learned quite a lot about the whole process as well,
but there’s a second problem; the minimum amount of processing power that the droplet needed to run
shiny came at 10€ a month. Not a fortune, but already quite expensive for me, since I just wanted
to learn some stuff on my free time. Which is why I got a Raspberry Pi 4B with 8 gigs of ram. It’s less
than 100€, and now that I have it, I can do whatever I want whenever I want to. If I don’t touch it
for several months, no harm done. And if I get tired of it, I’ll make a retro console out of it and
play some old schools games. It’s a win-win situation if you ask me.&lt;/p&gt;
&lt;p&gt;So first, you should get a Raspberry Pi. Those are quite easy to find online, and there’s many
tutorials available on how to install Ubuntu (or any other Linux distro) on it, so I won’t bother
with that. I also won’t explain to you how to ssh into your Raspberry Pi, again, there’s many tutorials
online. More importantly, is how to get Shiny on it? There’s two solutions; you either install
it from source, or you use Docker. I chose to use Docker, but maybe not in the way you’d expect;
there’s a lot of talk online about dockerizing apps, complete with all their dependencies and
environment. The advantage is that you’re guaranteed that deployment with be very smooth. But the
big disadvantage is that these dockerized apps are huge, around 1GB, or sometimes more. It is true that disk space is
quite cheap nowadays, but still… so I prefer to run a Shiny server from Docker, and then run the
apps out of this server. My apps are thus very small, and it’s only the Shiny server that is huge.
I found a Github repository from user &lt;code&gt;havlev&lt;/code&gt; that explains how to do it &lt;a href=&#34;https://github.com/hvalev/rpi-shiny-server-docker&#34;&gt;here&lt;/a&gt;.
I have followed this guide, and created my own docker container, which is based on &lt;code&gt;havlev&lt;/code&gt;’s
one. I added some dependencies (to the base Debian distro included, as well as some more R packages).&lt;/p&gt;
&lt;p&gt;If you’re in a hurry, and want to use my Docker image, you can simply type the following on your
Raspberry pi:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir shiny-server
cd shiny-server
mkdir apps
mkdir conf
mkdir logs
docker run -d -p 3838:3838 -v shiny-apps:/srv/shiny-server/ -v shiny-logs:/var/log/ -v shiny-conf:/etc/shiny-server/ --name rpi-shiny-server brodriguesco/shiny_1_5:firstcommit&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first 5 commands will create some folders that we’ll need later on, while the last one will pull
my Docker container, which is based on &lt;code&gt;havlev&lt;/code&gt;’s one, launch the server and it’ll start listening to
port 3838.&lt;/p&gt;
&lt;p&gt;I made an app (another blog post, focusing on this app, will follow soon), hosted on my Raspberry Pi
that you can find &lt;a href=&#34;http://shinybrodriguesco.duckdns.org:3838/golemDemo/&#34;&gt;here&lt;/a&gt;. I’ll also give you
some pointers on how you can achieve that.&lt;/p&gt;
&lt;p&gt;But let’s start from the beginning.&lt;/p&gt;
&lt;div id=&#34;adding-dependencies-to-a-docker-container&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Adding dependencies to a Docker container&lt;/h2&gt;
&lt;p&gt;So let’s suppose that you’re me a few weeks ago, and that you find and follow &lt;code&gt;havlev&lt;/code&gt;’s guide &lt;a href=&#34;https://github.com/hvalev/rpi-shiny-server-docker&#34;&gt;here&lt;/a&gt;.
Getting the docker running is quite easy, you just need to set up Docker, and then find the line in the
tutorial that starts with &lt;code&gt;docker run&lt;/code&gt;…. You’ll get Shiny running with its hello world app. Now,
how can you add more packages, either to the base Debian image, or R packages? For this part, I
followed &lt;a href=&#34;https://ropenscilabs.github.io/r-docker-tutorial/03-install-packages.html&#34;&gt;this guide&lt;/a&gt;.
The idea is to “log in” to the console of the base Debian distro that is running from the container.
First, find the ID of the container by typing the following command in the terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker ps&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@ubuntu:~$ docker ps
CONTAINER ID        IMAGE                                COMMAND                  CREATED              STATUS              PORTS                    NAMES
69420blazeit        brodriguesco/shiny_1_5:firstcommit   &amp;quot;/etc/shiny-server/i…&amp;quot;   About a minute ago   Up About a minute   0.0.0.0:3838-&amp;gt;3838/tcp   rpi-shiny-server&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;now with the ID in hand, you can start any command line program from your Docker container, for instance
bash:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it 69420blazeit bash&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll be “logged in” as root:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@69420blazeit:/# &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and from there, you can install Debian packages. The following two packages are necessary to install
many R packages from source, so I recommend you install them:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@69420blazeit:/# apt-get install libssl-dev libxml2-dev&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once these Debian packages are installed, you can start R by simply typing &lt;code&gt;R&lt;/code&gt; in the same console,
and install whatever packages your Shiny apps will need. In my case, I installed &lt;code&gt;{golem}&lt;/code&gt; and several
others, but this will be the subject of another blog post. We’re almost done with that; we now need
to save the changes because if you restart the container, you’ll lose all these changes. To save these
changes, let’s run the following command, but in a new terminal on your Raspberry Pi (on the
“local” Ubuntu, not the Debian running in the container):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@ubuntu:~$ docker commit -m &amp;quot;added some dependencies&amp;quot; 69420blazeit shiny_with_deps&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now you could run this container with the command from above, by replacing the adequate parts:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -p 3838:3838 -v shiny-apps:/srv/shiny-server/ -v shiny-logs:/var/log/ -v shiny-conf:/etc/shiny-server/ --name rpi-shiny-server shiny_with_depsshiny_with_deps&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;using-your-shiny-server&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using your Shiny server&lt;/h2&gt;
&lt;p&gt;Ok so now that the server is running, you can you deploy apps on it? Remember the folders that we
created at the beginning of the blog post (or that you created if you followed &lt;code&gt;havlev&lt;/code&gt;’s guide)?
This is where you’ll drop your apps, the usual way. You create a folder there, and simply put the
&lt;code&gt;ui.R&lt;/code&gt; and &lt;code&gt;server.R&lt;/code&gt; files in here, and that it. These folders can be found in your &lt;code&gt;$HOME&lt;/code&gt; directory,
and they are accessible to your docker container as well. Once you dropped one or two apps, you’ll be able to access them on a link
similar as this one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://192.168.178.55:3838/hello/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;192.168.178.55&lt;/code&gt; is the local IP address of the Raspberry Pi, &lt;code&gt;3838&lt;/code&gt; is the port the server
is listening to, and &lt;code&gt;/hello/&lt;/code&gt; is the name of the subfolder contained in the &lt;code&gt;~/shiny-server/apps&lt;/code&gt;
folder that you created before. What is left doing is making your Raspberry Pi a proper server that
can be accessed from the internet. For this, you’ll need to ask your ISP for a dynamic IP address.
Generally, you’ll have to pay some money for it; in my case, I’m paying 2€ a month. This address
can then be used to access your Raspberry Pi from the internet. The problem, is that being dynamic,
the address changes every time you restart your server. To solve this issue, you can use a free
dynamic DNS. I use &lt;a href=&#34;https://www.duckdns.org/&#34;&gt;duckdns&lt;/a&gt;. This will allow you to have domain that you
can share with the world. What’s nice is that if you follow their &lt;a href=&#34;https://www.duckdns.org/install.jsp&#34;&gt;guide&lt;/a&gt;
the redirection to the dynamic IP address will happen seamlessly every time it changes, so no need
to think about it and do it manually.&lt;/p&gt;
&lt;p&gt;Finally, you’ll also have to open up port &lt;code&gt;3838&lt;/code&gt; on your router. The procedure changes from router
to router, but you should be able to find the instructions for your router quite easily. If not, you
should also be able to get help from your ISP.&lt;/p&gt;
&lt;p&gt;The end result is that you’ll have your own Shiny server running off a Raspberry Pi, and accessible
over the internet! You’ll be able to deploy as many apps as you want, but of course, don’t forget
that you’re running all this on a Raspberry Pi. While these machines have become quite powerful over
the years, they won’t be powerful enough if you’re running some heavy duty apps with hundreds of
concurrent users.&lt;/p&gt;
&lt;p&gt;In my next blog post, I’ll walk you through the development of a Shiny app using the &lt;code&gt;{golem}&lt;/code&gt; package,
which you can find &lt;a href=&#34;http://shinybrodriguesco.duckdns.org:3838/golemDemo/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Gotta go fast with &#34;{tidytable}&#34;</title>
      <link>https://www.brodrigues.co/blog/2020-09-05-tidytable/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-09-05-tidytable/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=SXrbYw_AqQA&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/kaamelott.jpg&#34; title = &#34;If there&#39;s one good reason to learn French, it&#39;s Kaamelott&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’m back in business! After almost 5 months of hiatus, during which I was very busy with my new job, and
new house, I’m in a position where I can write again. To celebrate my comeback, I’ll introduce to
you the &lt;code&gt;{tidytable}&lt;/code&gt; package, which I learned about this week on Twitter.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{tidytable}&lt;/code&gt; is a package that allows you to manipulate &lt;code&gt;data.table&lt;/code&gt; objects with the speed of
&lt;code&gt;{data.table}&lt;/code&gt; and the convenience of the &lt;code&gt;{tidyverse}&lt;/code&gt; syntax. My first reaction when I heard about
&lt;code&gt;{tidytable}&lt;/code&gt; was &lt;em&gt;how is that different from &lt;code&gt;{dtplyr}&lt;/code&gt;&lt;/em&gt;? Well, &lt;code&gt;{dtplyr}&lt;/code&gt; focuses on providing
a &lt;code&gt;{data.table}&lt;/code&gt; backend for &lt;code&gt;{dplyr}&lt;/code&gt;, while &lt;code&gt;{tidytable}&lt;/code&gt; also allows you to use other &lt;code&gt;{tidyverse}&lt;/code&gt;
verbs on &lt;code&gt;data.table&lt;/code&gt; objects, for instance some &lt;code&gt;{tidyr}&lt;/code&gt; and &lt;code&gt;{purrr}&lt;/code&gt; verbs.&lt;/p&gt;
&lt;p&gt;Another very interesting feature of &lt;code&gt;{tidytable}&lt;/code&gt; is that it supports &lt;code&gt;{rlang}&lt;/code&gt;, which means that
you can program with &lt;code&gt;{tidytable}&lt;/code&gt;, which, as far as I know, is not possible with &lt;code&gt;{dtplyr}&lt;/code&gt;
(but fact-check me on that please).&lt;/p&gt;
&lt;p&gt;So to summarise, the speed of &lt;code&gt;{data.table}&lt;/code&gt; and the syntax of the &lt;code&gt;{tidyverse}&lt;/code&gt;, plus verbs for
&lt;code&gt;{tidyr}&lt;/code&gt; and &lt;code&gt;{purrr}&lt;/code&gt;? Sign me up!&lt;/p&gt;
&lt;p&gt;To illustrate, I have downloaded a data set and wrote a function in both a &lt;code&gt;{tidyverse}&lt;/code&gt; version
and a &lt;code&gt;{tidytable}&lt;/code&gt; version. Even though it is true that &lt;code&gt;{tidytable}&lt;/code&gt;’s syntax is very much, almost
the same as the regular &lt;code&gt;{tidyverse}&lt;/code&gt; syntax, there are some minor differences. But more on that
later. First, let’s get the data, which you can find &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction&#34;&gt;here&lt;/a&gt;.
Then, let’s load the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(data.table)
library(tidytable)
library(readr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and let’s take a look at the data a little bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;energy &amp;lt;- read.csv(&amp;quot;~/Downloads/energydata_complete.csv&amp;quot;)

head(energy)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  date Appliances lights    T1     RH_1   T2     RH_2    T3
## 1 2016-01-11 17:00:00         60     30 19.89 47.59667 19.2 44.79000 19.79
## 2 2016-01-11 17:10:00         60     30 19.89 46.69333 19.2 44.72250 19.79
## 3 2016-01-11 17:20:00         50     30 19.89 46.30000 19.2 44.62667 19.79
## 4 2016-01-11 17:30:00         50     40 19.89 46.06667 19.2 44.59000 19.79
## 5 2016-01-11 17:40:00         60     40 19.89 46.33333 19.2 44.53000 19.79
## 6 2016-01-11 17:50:00         50     40 19.89 46.02667 19.2 44.50000 19.79
##       RH_3       T4     RH_4       T5  RH_5       T6     RH_6       T7     RH_7
## 1 44.73000 19.00000 45.56667 17.16667 55.20 7.026667 84.25667 17.20000 41.62667
## 2 44.79000 19.00000 45.99250 17.16667 55.20 6.833333 84.06333 17.20000 41.56000
## 3 44.93333 18.92667 45.89000 17.16667 55.09 6.560000 83.15667 17.20000 41.43333
## 4 45.00000 18.89000 45.72333 17.16667 55.09 6.433333 83.42333 17.13333 41.29000
## 5 45.00000 18.89000 45.53000 17.20000 55.09 6.366667 84.89333 17.20000 41.23000
## 6 44.93333 18.89000 45.73000 17.13333 55.03 6.300000 85.76667 17.13333 41.26000
##     T8     RH_8       T9  RH_9    T_out Press_mm_hg RH_out Windspeed Visibility
## 1 18.2 48.90000 17.03333 45.53 6.600000       733.5     92  7.000000   63.00000
## 2 18.2 48.86333 17.06667 45.56 6.483333       733.6     92  6.666667   59.16667
## 3 18.2 48.73000 17.00000 45.50 6.366667       733.7     92  6.333333   55.33333
## 4 18.1 48.59000 17.00000 45.40 6.250000       733.8     92  6.000000   51.50000
## 5 18.1 48.59000 17.00000 45.40 6.133333       733.9     92  5.666667   47.66667
## 6 18.1 48.59000 17.00000 45.29 6.016667       734.0     92  5.333333   43.83333
##   Tdewpoint      rv1      rv2
## 1       5.3 13.27543 13.27543
## 2       5.2 18.60619 18.60619
## 3       5.1 28.64267 28.64267
## 4       5.0 45.41039 45.41039
## 5       4.9 10.08410 10.08410
## 6       4.8 44.91948 44.91948&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this data is wide, and not long. Variables, or features, &lt;code&gt;T1&lt;/code&gt; to &lt;code&gt;T9&lt;/code&gt; provide the
temperature of 9 rooms, and &lt;code&gt;RH_1&lt;/code&gt; to &lt;code&gt;RH_9&lt;/code&gt; provide the humidity of the same 9 rooms.&lt;/p&gt;
&lt;p&gt;What if I’d like to make a plot of each room’s temperature throughout the year? In this format,
it is not possible. So let’s reshape this a little bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flat_energy &amp;lt;- energy %&amp;gt;% 
  pivot_longer(cols = matches(&amp;quot;T\\d{1}&amp;quot;), names_to = &amp;quot;temperature&amp;quot;, values_to = &amp;quot;temp_value&amp;quot;) %&amp;gt;% 
  pivot_longer(cols = matches(&amp;quot;RH_\\d{1}&amp;quot;), names_to = &amp;quot;humidity&amp;quot;, values_to = &amp;quot;hum_value&amp;quot;) %&amp;gt;%
  mutate(temperature = case_when(temperature == &amp;quot;T1&amp;quot; ~ &amp;quot;kitchen&amp;quot;,
                                 temperature == &amp;quot;T2&amp;quot; ~ &amp;quot;living&amp;quot;,
                                 temperature == &amp;quot;T3&amp;quot; ~ &amp;quot;laundry&amp;quot;,
                                 temperature == &amp;quot;T4&amp;quot; ~ &amp;quot;office&amp;quot;,
                                 temperature == &amp;quot;T5&amp;quot; ~ &amp;quot;bathroom&amp;quot;,
                                 temperature == &amp;quot;T6&amp;quot; ~ &amp;quot;north&amp;quot;,
                                 temperature == &amp;quot;T7&amp;quot; ~ &amp;quot;ironing&amp;quot;,
                                 temperature == &amp;quot;T8&amp;quot; ~ &amp;quot;teenager&amp;quot;,
                                 temperature == &amp;quot;T9&amp;quot; ~ &amp;quot;parents&amp;quot;)) %&amp;gt;%  
  mutate(humidity = case_when(humidity == &amp;quot;RH_1&amp;quot; ~ &amp;quot;kitchen&amp;quot;,
                                 humidity == &amp;quot;RH_2&amp;quot; ~ &amp;quot;living&amp;quot;,
                                 humidity == &amp;quot;RH_3&amp;quot; ~ &amp;quot;laundry&amp;quot;,
                                 humidity == &amp;quot;RH_4&amp;quot; ~ &amp;quot;office&amp;quot;,
                                 humidity == &amp;quot;RH_5&amp;quot; ~ &amp;quot;bathroom&amp;quot;,
                                 humidity == &amp;quot;RH_6&amp;quot; ~ &amp;quot;north&amp;quot;,
                                 humidity == &amp;quot;RH_7&amp;quot; ~ &amp;quot;ironing&amp;quot;,
                                 humidity == &amp;quot;RH_8&amp;quot; ~ &amp;quot;teenager&amp;quot;,
                              humidity == &amp;quot;RH_9&amp;quot; ~ &amp;quot;parents&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As explained above, there are two variables that need this treatment; the temperature, and the humidity levels. In order
to plot the average monthly temperature in each room, I need to use &lt;code&gt;tidyr::pivot_longer()&lt;/code&gt; (a
little side note, I could have used &lt;code&gt;names_to = &#34;room&#34;&lt;/code&gt;, instead of &lt;code&gt;&#34;temperature&#34;&lt;/code&gt; and &lt;code&gt;&#34;humidity&#34;&lt;/code&gt;,
but there’s a reason for that. More on it below).&lt;/p&gt;
&lt;p&gt;Now let’s plot it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;flat_energy %&amp;gt;%
  mutate(month = month(date)) %&amp;gt;%  
  group_by(month, temperature) %&amp;gt;%
  summarise(avg_temp = mean(temp_value)) %&amp;gt;%  
  ggplot() +
  geom_line(aes(y = avg_temp, x = month, col = temperature)) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` regrouping output by &amp;#39;month&amp;#39; (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-09-05-tidytable_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
Ok great. But what if I had such a dataset per house for a whole city? How many datasets would that
be? And how long would these operations take?
The first step I would take if I were in this situation, would be to write a function. I would make
it general enough to work with temperature or humidity. Below is this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prepare_data &amp;lt;- function(energy, variable){

  variable &amp;lt;- enquo(variable)

  variable_label &amp;lt;- as_label(variable)

  regex_selector &amp;lt;- ifelse(variable_label == &amp;quot;temperature&amp;quot;,
                           &amp;quot;T\\d{1}&amp;quot;,
                           &amp;quot;RH_\\d{1}&amp;quot;)
energy %&amp;gt;%
  pivot_longer(cols = matches(regex_selector),
               names_to = variable_label,
               values_to = paste0(variable_label, &amp;quot;_value&amp;quot;)) %&amp;gt;%
    mutate(!!(variable) := case_when(grepl(&amp;quot;1$&amp;quot;, !!(variable)) ~ &amp;quot;kitchen&amp;quot;,
                                    grepl(&amp;quot;2$&amp;quot;, !!(variable)) ~ &amp;quot;living&amp;quot;,
                                    grepl(&amp;quot;3$&amp;quot;, !!(variable)) ~ &amp;quot;laundry&amp;quot;,
                                    grepl(&amp;quot;4$&amp;quot;, !!(variable)) ~ &amp;quot;office&amp;quot;,
                                    grepl(&amp;quot;5$&amp;quot;, !!(variable)) ~ &amp;quot;bathroom&amp;quot;,
                                    grepl(&amp;quot;6$&amp;quot;, !!(variable)) ~ &amp;quot;outside&amp;quot;,
                                    grepl(&amp;quot;7$&amp;quot;, !!(variable)) ~ &amp;quot;ironing&amp;quot;,
                                    grepl(&amp;quot;8$&amp;quot;, !!(variable)) ~ &amp;quot;teenager&amp;quot;,
                                    grepl(&amp;quot;9$&amp;quot;, !!(variable)) ~ &amp;quot;parents&amp;quot;)) %&amp;gt;%
  mutate(month = month(date)) %&amp;gt;%  
  group_by(month, !!(variable)) %&amp;gt;%
  summarise(across(.cols = ends_with(&amp;quot;_value&amp;quot;),
                   .fns = mean),
            .groups = &amp;quot;drop&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function does exactly the same thing as above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prepare_data(energy, temperature) %&amp;gt;%
  ggplot() +
  geom_line(aes(y = temperature_value, x = month, col = temperature)) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-09-05-tidytable_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, I have the exact same plot. What’s nice with this function, is that it uses many
verbs from the &lt;code&gt;{tidyverse}&lt;/code&gt; as well as the tidy eval framework for non-standard evaluation (
which is why I did not use &lt;code&gt;names_to = &#34;room&#34;&lt;/code&gt;, I wanted to use the variable label defined with
&lt;code&gt;as_label()&lt;/code&gt; and see if it works with &lt;code&gt;{tidytable}&lt;/code&gt; as well).
Ok, so now let’s imagine that I’m happy with this function, but I’d like it to run faster, and because
I’m lazy, the less I have to modify it, the happier I am. This is where &lt;code&gt;{tidytable}&lt;/code&gt; looks very
promising. Let’s rewrite the function to make it work with &lt;code&gt;{tidytable}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prepare_data_dt &amp;lt;- function(energy, variable){

  variable &amp;lt;- enquo(variable)

  variable_label &amp;lt;- as_label(variable)

  regex_selector &amp;lt;- ifelse(variable_label == &amp;quot;temperature&amp;quot;,
                           &amp;quot;T\\d{1}&amp;quot;,
                           &amp;quot;RH_\\d{1}&amp;quot;)
energy %&amp;gt;%
  pivot_longer.(cols = matches(regex_selector),
               names_to = variable_label,
               values_to = paste0(variable_label, &amp;quot;_value&amp;quot;)) %&amp;gt;%
    mutate.(!!(variable) := case_when(grepl(&amp;quot;1$&amp;quot;, !!(variable)) ~ &amp;quot;kitchen&amp;quot;,
                                    grepl(&amp;quot;2$&amp;quot;, !!(variable)) ~ &amp;quot;living&amp;quot;,
                                    grepl(&amp;quot;3$&amp;quot;, !!(variable)) ~ &amp;quot;laundry&amp;quot;,
                                    grepl(&amp;quot;4$&amp;quot;, !!(variable)) ~ &amp;quot;office&amp;quot;,
                                    grepl(&amp;quot;5$&amp;quot;, !!(variable)) ~ &amp;quot;bathroom&amp;quot;,
                                    grepl(&amp;quot;6$&amp;quot;, !!(variable)) ~ &amp;quot;outside&amp;quot;,
                                    grepl(&amp;quot;7$&amp;quot;, !!(variable)) ~ &amp;quot;ironing&amp;quot;,
                                    grepl(&amp;quot;8$&amp;quot;, !!(variable)) ~ &amp;quot;teenager&amp;quot;,
                                    grepl(&amp;quot;9$&amp;quot;, !!(variable)) ~ &amp;quot;parents&amp;quot;)) %&amp;gt;%  
  mutate.(month = month(date)) %&amp;gt;%  
  summarise_across.(.cols = ends_with(&amp;quot;_value&amp;quot;),
                    .fns = mean,
                    .by = c(month, !!(variable))) %&amp;gt;%  
  ungroup()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, it’s &lt;em&gt;almost&lt;/em&gt; the same thing. &lt;code&gt;{tidytable}&lt;/code&gt; verbs end with a &lt;code&gt;&#39;.&#39;&lt;/code&gt; and that’s
it. Well almost (again), the biggest difference is how &lt;code&gt;{tidytable}&lt;/code&gt; groups by a variable. It’s very
similar to how it’s done in &lt;code&gt;{data.table}&lt;/code&gt;, by using a &lt;code&gt;.by =&lt;/code&gt; argument to verbs that support it,
such as &lt;code&gt;summarise_across()&lt;/code&gt; (which is also, by the way, another difference with standard
&lt;code&gt;{tidyverse}&lt;/code&gt; syntax). While I’ll have to remember these, I’d argue that they’re minor differences
and if it can make my function run faster, I don’t mind!&lt;/p&gt;
&lt;p&gt;Now let’s run a little benchmark. But first, let’s define our data as a &lt;code&gt;tidytable&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;energy_tidytable &amp;lt;- as_tidytable(energy)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’re good to go:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;microbenchmark::microbenchmark(
                  energy %&amp;gt;%
                  prepare_data(temperature),
                  energy_tidytable %&amp;gt;%
                  prepare_data_dt(temperature),
                  times = 10
                )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##                                               expr      min       lq     mean
##               energy %&amp;gt;% prepare_data(temperature) 847.9709 849.6671 868.6524
##  energy_tidytable %&amp;gt;% prepare_data_dt(temperature) 820.2051 838.6647 861.9685
##    median       uq      max neval
##  861.0652 880.8200 914.4685    10
##  858.9454 873.3268 936.0147    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is nice! It does indeed run faster, and with only some minor changes to the function! And
how about using some more cores to run this function?
This can be done using &lt;code&gt;data.table::setDTthreads(n_cores)&lt;/code&gt; where &lt;code&gt;n_cores&lt;/code&gt; is the number of
cores you want to use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data.table::setDTthreads(12)
microbenchmark::microbenchmark(
                  energy %&amp;gt;%
                  prepare_data(temperature),
                  energy_tidytable %&amp;gt;%
                  prepare_data_dt(temperature),
                  times = 10
                )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unit: milliseconds
##                                               expr      min       lq     mean
##               energy %&amp;gt;% prepare_data(temperature) 832.9876 840.8000 874.3047
##  energy_tidytable %&amp;gt;% prepare_data_dt(temperature) 829.7937 831.2868 866.4383
##    median       uq      max neval
##  889.2684 898.6861 914.7178    10
##  836.8712 893.0613 997.8511    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maybe surprisingly, it did not run faster. It could very well be that my function does not really
lend itself to running in parallel, and the overhead induced by distributing the work to the
cpu cores cancels out the gains from running it in parallel. But in any case, this is really looking
very interesting. I have not tested the whole package yet, but
since the syntax is so similar to the &lt;code&gt;{tidyverse}&lt;/code&gt;, you can try really quickly to see if the &lt;code&gt;{tidytable}&lt;/code&gt;
version of the function runs faster, and if yes, I don’t really see a reason not to use it!&lt;/p&gt;
&lt;p&gt;Check out the project’s website &lt;a href=&#34;https://markfairbanks.github.io/tidytable/index.html&#34;&gt;here&lt;/a&gt;, and
follow the author’s twitter &lt;a href=&#34;https://twitter.com/markfairbanks10&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring NACE codes</title>
      <link>https://www.brodrigues.co/blog/2020-04-27-nace_explorer/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-04-27-nace_explorer/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6n9ESFJTnHs&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/industry.png&#34; title = &#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A quick one today. If you work with economic data, you’ll be confronted to NACE code sooner or later.
NACE stands for &lt;em&gt;Nomenclature statistique des Activités économiques dans la Communauté Européenne&lt;/em&gt;.
It’s a standard classification of economic activities. It has 4 levels, and you can learn more
about it &lt;a href=&#34;https://ec.europa.eu/eurostat/en/web/products-manuals-and-guidelines/-/KS-RA-07-015&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Each level adds more details; consider this example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C - Manufacturing
C10 - Manufacture of food products
C10.1 - Processing and preserving of meat and production of meat products
C10.1.1 - Processing and preserving of meat
C10.1.2 - Processing and preserving of poultry meat
C10.1.3 - Production of meat and poultry meat products&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So a company producing meat and poultry meat products would have NACE code level 4 &lt;code&gt;C10.1.3&lt;/code&gt; with it.
Today for work I had to create a nice visualisation of the hierarchy of the NACE classification.
It took me a bit of time to find a nice solution, so that’s why I’m posting it here. Who knows, it
might be useful for other people. First let’s get the data. Because finding it is not necessarily
very easy if you’re not used to navigating Eurostat’s website, I’ve put the CSV into a gist:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(data.tree)
library(igraph)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nace_code &amp;lt;- read_csv(&amp;quot;https://gist.githubusercontent.com/b-rodrigues/4218d6daa8275acce80ebef6377953fe/raw/99bb5bc547670f38569c2990d2acada65bb744b3/nace_rev2.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Order = col_double(),
##   Level = col_double(),
##   Code = col_character(),
##   Parent = col_character(),
##   Description = col_character(),
##   `This item includes` = col_character(),
##   `This item also includes` = col_character(),
##   Rulings = col_character(),
##   `This item excludes` = col_character(),
##   `Reference to ISIC Rev. 4` = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(nace_code)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 10
##    Order Level Code  Parent Description `This item incl… `This item also…
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;           
## 1 398481     1 A     &amp;lt;NA&amp;gt;   AGRICULTUR… &amp;quot;This section i… &amp;lt;NA&amp;gt;            
## 2 398482     2 01    A      Crop and a… &amp;quot;This division … This division a…
## 3 398483     3 01.1  01     Growing of… &amp;quot;This group inc… &amp;lt;NA&amp;gt;            
## 4 398484     4 01.11 01.1   Growing of… &amp;quot;This class inc… &amp;lt;NA&amp;gt;            
## 5 398485     4 01.12 01.1   Growing of… &amp;quot;This class inc… &amp;lt;NA&amp;gt;            
## 6 398486     4 01.13 01.1   Growing of… &amp;quot;This class inc… &amp;lt;NA&amp;gt;            
## # … with 3 more variables: Rulings &amp;lt;chr&amp;gt;, `This item excludes` &amp;lt;chr&amp;gt;,
## #   `Reference to ISIC Rev. 4` &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So there’s a bunch of columns we don’t need, so we’re going to ignore them. What I’ll be doing is
transforming this data frame into a data tree, using the &lt;code&gt;{data.tree}&lt;/code&gt; package. For this, I need
columns that provide the hierarchy. I’m doing this with the next chunk of code. I won’t explain
each step, but the idea is quite simple. I’m using the &lt;code&gt;Level&lt;/code&gt; column to create new columns called
&lt;code&gt;Level1&lt;/code&gt;, &lt;code&gt;Level2&lt;/code&gt;, etc. I’m then doing some cleaning:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nace_code &amp;lt;- nace_code %&amp;gt;%
  select(Level, Code)

nace_code &amp;lt;- nace_code %&amp;gt;%
  mutate(Level1 = ifelse(Level == 1, Code, NA)) %&amp;gt;%
  fill(Level1, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%  
  mutate(Level2 = ifelse(Level == 2, Code, NA)) %&amp;gt;%
  fill(Level2, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%  
  mutate(Level3 = ifelse(Level == 3, Code, NA)) %&amp;gt;%
  fill(Level3, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%  
  mutate(Level4 = ifelse(Level == 4, Code, NA)) %&amp;gt;%  
  filter(!is.na(Level4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at how the data looks now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(nace_code)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   Level Code  Level1 Level2 Level3 Level4
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; 
## 1     4 01.11 A      01     01.1   01.11 
## 2     4 01.12 A      01     01.1   01.12 
## 3     4 01.13 A      01     01.1   01.13 
## 4     4 01.14 A      01     01.1   01.14 
## 5     4 01.15 A      01     01.1   01.15 
## 6     4 01.16 A      01     01.1   01.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now create the hierarchy using by creating a column called &lt;code&gt;pathString&lt;/code&gt; and passing that
data frame to &lt;code&gt;data.tree::as.Node()&lt;/code&gt;. Because some sections, like C (manufacturing) are very large,
I do this separately for each section by using the &lt;code&gt;group_by()&lt;/code&gt;-&lt;code&gt;nest()&lt;/code&gt; trick. This way, I can
create a &lt;code&gt;data.tree&lt;/code&gt; object for each section. Finally, to create the plots, I use &lt;code&gt;igraph::as.igraph()&lt;/code&gt;
and pass this to &lt;code&gt;GGally::ggnet2()&lt;/code&gt;, which takes care of creating the plots. This took me quite
some time to figure out, but the result is a nice looking PDF that the colleagues can now use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nace_code2 &amp;lt;- nace_code %&amp;gt;%
  group_by(Level1, Level2) %&amp;gt;%
  nest() %&amp;gt;%
  mutate(nace = map(data, ~mutate(., pathString = paste(&amp;quot;NACE2&amp;quot;,
                                       Level1,
                                       Level2,
                                       Level3,
                                       Level4,
                                       sep = &amp;quot;/&amp;quot;)))) %&amp;gt;%
  mutate(plots = map(nace, ~as.igraph(as.Node(.)))) %&amp;gt;%
  mutate(plots = map(plots, ggnet2, label = TRUE))


pdf(&amp;quot;nace_maps.pdf&amp;quot;)
pull(nace_code2, plots)
dev.off()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s how the pdf looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/nace_c_10.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;If you want to read more about &lt;code&gt;{data.tree}&lt;/code&gt;, you can do so &lt;a href=&#34;https://cran.r-project.org/web/packages/data.tree/vignettes/data.tree.html&#34;&gt;here&lt;/a&gt;
and you can also read more about the &lt;code&gt;ggnet2()&lt;/code&gt; &lt;a href=&#34;https://briatte.github.io/ggnet/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>No excuse not to be a Bayesian anymore</title>
      <link>https://www.brodrigues.co/blog/2020-04-20-no_excuse/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-04-20-no_excuse/</guid>
      <description>&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Thomas_Bayes&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/mudasir.png&#34; title = &#34;There&#39;s a meme for anything nowadays&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;My first encounter with Bayesian statistics was around 10 years ago, when I was doing my econometrics
master’s degree. I was immediately very interested by the Bayesian approach to fit econometric
models, because, when you’re reading about Bayesian approaches, it just sounds so easy and natural.
You have a model, you &lt;em&gt;might&lt;/em&gt; have some prior beliefs about the models parameters, and Bayes’ rule
tells you how your beliefs should change when confronting the model to data (evidence). It is really
appealing, and what I really liked as well was the interpretation of the results. It was very natural
as well. Once your software is done estimating/training the model, you don’t actually get a vector
of values for the parameters of the model. You get whole distributions for each parameter, so-called
posterior distributions. You can then make statements like “there’s a 95% probability that this
parameter lies between 0.12 and 0.21” for instance, which is a statement that you cannot make
in a frequentist/classical framework.&lt;/p&gt;
&lt;p&gt;However, while this was very appealing to me at the time, there is no free lunch as they say. At the
time, and it was not that long ago, doing Bayesian statistics was not as straightforward as it is
now, as I will show you in this blog post. At the time, the BUGS language was still the
standard way to describe a Bayesian model and the actual estimation procedure. However, using
the BUGS language was tricky; there was WinBUGS, a Windows tool that had already been discontinued
at the time in favour of OpenBUGS, which was what I was using. The professor teaching this class,
who eventually became one of my PhD advisors, was using WinBUGS to teach, but I was using Linux at the
time already, so I went with OpenBUGS which worked with WINE, I think (WINE is a compatibility layer
that allows running some Windows programs on Linux. It is quite amazing what WINE is able to do,
so much so that Valve forked it to create Proton, which enables running Windows games on Linux
on their popular Steam platform).
Plus, I found out that there was an R package to call OpenBUGS from R and get the results back into
R seamlessly! I think that I remember that there was one for WINBUGS as well, but I also think I
remember I could not get it to work. Anyways, after some digging, I found an even better alternative
called JAGS. JAGS is open source, and is natively available for Linux. It is also able to run in parallel, which is really
useful for Bayesian inference. In any case, these were separate
languages/programs from R, and as such the user had to learn how to use them. The way they worked
was that users needed to write the Bayesian model in a separate text file. I will illustrate this
with an example that I worked on during my Master’s, back in 2011.
The example is taken from Ioannis Ntzoufras’ book &lt;em&gt;Bayesian Modeling Using WinBUGS&lt;/em&gt;.
The example can be found in chapter 7, section 7.4.2. The dataset is from Montgomery et al. (2006) and
&lt;em&gt;refers to the number of aircarft damages in 30 strike missions during the Vietnam War&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Here’s a description of the data, taken from Ntzoufras’ book:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;damage: the number of damaged locations of the aircraft&lt;/li&gt;
&lt;li&gt;type: binary variable which indicates the type of the plane (0 for A4, B for A6)&lt;/li&gt;
&lt;li&gt;bombload: the aircraft bomb load in tons&lt;/li&gt;
&lt;li&gt;airexp: the total months of aircrew experience.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The goal is to find a model for &lt;em&gt;damage&lt;/em&gt;, what variables explain the amount of damage on the aircraft?
Now, something quite interesting here, is that we only have 30 observations, and getting more
observations is &lt;em&gt;very&lt;/em&gt; costly. So what are you to do with this?&lt;/p&gt;
&lt;p&gt;First, let’s write the model down:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align}
\text{damage}_i &amp;amp; = \text{Poisson}(\lambda_i) \\
\log(\lambda_i) &amp;amp; = \beta_1 + \beta_2*\text{type}_i + \beta_3 * \text{bombload}_i + \beta_4*\text{airexp}_i
\end{align}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(i = 1, 2, 3, ..., 30\)&lt;/span&gt;. Since &lt;em&gt;damage&lt;/em&gt; is a count variable, we go with a Poisson distribution,
which only has one parameter, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;.
&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; is defined on the second line. Both these definition form the likelihood, which should be
familiar to any statistician. In JAGS and BUGS, this likelihood had to be written in a separate text file, as I mentioned
above, with a syntax that was very similar to R’s (at least for JAGS, because if memory serves, BUGS’s syntax
was &lt;em&gt;more different&lt;/em&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model{
for (i in 1:30){damage[i] ~ dpois( lambda[i] )
        log(lambda[i]) &amp;lt;- b1 + b2 * type[i] 
        + b3 * bombload[i] + b4 * airexp[i]}
b1 ~ dnorm(0, 1.0E-4)
b2 ~ dnorm(0, 1.0E-4)
b3 ~ dnorm(0, 1.0E-4)
b4 ~ dnorm(0, 1.0E-4)}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last four lines are the prior distributions on the parameters. This is something that does
not exist in frequentist statistics. Frequentists would maximise the above likelihood and call it a day.
However, the Bayesian framework allows the practitioner to add prior knowledge into the model. This
prior knowledge can come from domain knowledge or the literature. However, if the practitioner
does not have a clue about good priors, then diffuse priors can be used. Diffuse priors do not
carry much information, if at all. The priors above are diffuse; they’re normally distributed, centered
around 0 with very small precision (in the Bayesian framework, the normal distribution is
defined with two parameters, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\tau = \dfrac{1}{\sigma}\)&lt;/span&gt;). But since my student
years I have learned that using such priors is actually not a very good idea, and better alternatives
exist (priors that at least provide some regularization for instance). The Bayesian approach to
statistics is often criticized for this, because priors are not objective. If you’re not using
diffuse priors, then you’re using priors that carry some information. This information is subjective
and subjectivity is a big No-No. But should subjectivity be a No-No? After all, if you can defend
your priors, either because of domain knowledge, or because of past studies that provide some clue
why not use this information? Especially when here is very little data like in this example. Also,
you can perform a sensitivity analysis, and show how the posterior distribution of the parameters
change when your priors change. What is important is to be fully transparent about the priors you’re using, and
have clear justification for them. If these conditions are met, I don’t see why you should not use
prior information in your model. Plus, even in frequentist statistics prior knowledge is used
as well, for instance by pre-processing the data in a certain way, or by constraining the values
the parameters are allowed to take in the optimisation routine (I’m looking at you, &lt;code&gt;L-BFGS-B&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now, let’s continue with the data. To load the data, I had to manually created each variable (but maybe
JAGS now uses data frames) to pass it to &lt;code&gt;jags()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# We load the data this way since jags only takes numerical vectors, matrices or lists
# containing the names as input
damage &amp;lt;- c(0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2, 0, 1, 1, 2, 5, 1, 1, 5, 5, 7) 
type &amp;lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) 
bombload &amp;lt;- c(4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 7, 7, 7, 10, 10, 10, 12, 12, 12, 8, 8, 8, 14, 14, 14)
airexp &amp;lt;- c(91.5, 84, 76.5, 69, 61.5, 80, 72.5, 65, 57.5, 50, 103, 95.5, 88, 80.5, 73, 116.1, 100.6, 85, 69.4, 53.9, 
112.3, 96.7, 81.1, 65.6, 50, 120, 104.4, 88.9, 73.7, 57.8)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we loaded the data, we can fit the model, by first defining a vector of parameters, and
a named list for the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters &amp;lt;- c(&amp;quot;b1&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;,&amp;quot;b4&amp;quot;)
data &amp;lt;- list(&amp;quot;damage&amp;quot;,&amp;quot;type&amp;quot;,&amp;quot;bombload&amp;quot;,&amp;quot;airexp&amp;quot;)

#We don&amp;#39;t give inits to jags since it can generate appropriate initial values

#Use this on single core machines, and/or windows machines
model_fit&amp;lt;-jags(data,inits=NULL,parameters,n.iter=50000,
                model.file=&amp;quot;bugsjags.txt&amp;quot;,n.chains=4,DIC=T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that &lt;code&gt;jags()&lt;/code&gt; has an argument called &lt;code&gt;model.file&lt;/code&gt;, which is the file I showed above.
Below, the code to take a look at the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Let&amp;#39;s see the results
model_fit$BUGSoutput


model.mcmc&amp;lt;-as.mcmc(model_fit)

traceplot(model.mcmc)

xyplot(model.mcmc)

heidel.diag(model.mcmc) 

par(mfrow=c(2,3))
autocorr.plot(model.mcmc[1],auto.layout=F,ask=F)

geweke.plot(model.mcmc)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re actually not looking at this, because I’m not running the code; I only wanted to show you how
this was done 8 years ago. But why? Because now I can show you how this is done nowadays with &lt;code&gt;{rstanarm}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstanarm)

model_fit_stan &amp;lt;- stan_glm(damage ~ ., data = bombs, family = poisson)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;count&amp;#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 1.7e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.04083 seconds (Warm-up)
## Chain 1:                0.043647 seconds (Sampling)
## Chain 1:                0.084477 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &amp;#39;count&amp;#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 5e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.037986 seconds (Warm-up)
## Chain 2:                0.041253 seconds (Sampling)
## Chain 2:                0.079239 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &amp;#39;count&amp;#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 5e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.041033 seconds (Warm-up)
## Chain 3:                0.042982 seconds (Sampling)
## Chain 3:                0.084015 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &amp;#39;count&amp;#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 5e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.036928 seconds (Warm-up)
## Chain 4:                0.041124 seconds (Sampling)
## Chain 4:                0.078052 seconds (Total)
## Chain 4:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is a lot of output, but the input was a single line that should look very familiar to
practitioners used to the &lt;code&gt;glm()&lt;/code&gt; function. I only used default options, as well as the default priors.
Specifying different priors is quite simple, but I won’t discuss this here, because this blot post, while it
might look like a tutorial, is not a tutorial. What I wanted to show you is the difference that 9
years make in software development. &lt;code&gt;{stan}&lt;/code&gt; is an R package for Bayesian statistics that came
out in 2012 and which has been developed ever since. Just like JAGS and BUGS, users can write
external files with very detailed models. But for smaller, or more standard problems, &lt;code&gt;{rstanarm}&lt;/code&gt;,
makes Bayesian inference very easy and feel familiar to the traditional way of doing things and
as its name implies, uses &lt;code&gt;{stan}&lt;/code&gt; under the hood.&lt;/p&gt;
&lt;p&gt;Now let’s continue a little bit and take a look at the model summary:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_fit_stan)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model Info:
##  function:     stan_glm
##  family:       poisson [log]
##  formula:      damage ~ .
##  algorithm:    sampling
##  sample:       4000 (posterior sample size)
##  priors:       see help(&amp;#39;prior_summary&amp;#39;)
##  observations: 30
##  predictors:   4
## 
## Estimates:
##               mean   sd   10%   50%   90%
## (Intercept) -0.5    0.9 -1.6  -0.5   0.7 
## type         0.6    0.5 -0.1   0.6   1.2 
## bombload     0.2    0.1  0.1   0.2   0.3 
## airexp       0.0    0.0  0.0   0.0   0.0 
## 
## Fit Diagnostics:
##            mean   sd   10%   50%   90%
## mean_PPD 1.5    0.3  1.1   1.5   1.9  
## 
## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&amp;#39;summary.stanreg&amp;#39;)).
## 
## MCMC diagnostics
##               mcse Rhat n_eff
## (Intercept)   0.0  1.0  2504 
## type          0.0  1.0  2412 
## bombload      0.0  1.0  2262 
## airexp        0.0  1.0  2652 
## mean_PPD      0.0  1.0  3813 
## log-posterior 0.0  1.0  1902 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like for Bayesian stats, we get our parameter’s estimates. But wait! In the intro of this blog
post, I said that in Bayesian statistics, we estimate full parameter distributions. So why are we
getting point estimates? Well, these are statistics from the posterior distribution, the mean,
standard deviation and some deciles.&lt;/p&gt;
&lt;p&gt;To explore the results, I like to use &lt;code&gt;{bayestestR}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bayestestR)

describe_posterior(model_fit_stan)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Description of Posterior Distributions
## 
## Parameter   | Median | CI | CI_low | CI_high |    pd | ROPE_CI | ROPE_low | ROPE_high | ROPE_Percentage |  Rhat |  ESS
## ----------------------------------------------------------------------------------------------------------------------
## (Intercept) | -0.473 | 89 | -1.898 |   0.929 | 0.711 |      89 |   -0.100 |     0.100 |           0.082 | 0.999 | 2504
## type        |  0.577 | 89 | -0.230 |   1.365 | 0.869 |      89 |   -0.100 |     0.100 |           0.099 | 1.002 | 2412
## bombload    |  0.169 | 89 |  0.065 |   0.275 | 0.994 |      89 |   -0.100 |     0.100 |           0.108 | 1.001 | 2262
## airexp      | -0.014 | 89 | -0.028 |  -0.001 | 0.953 |      89 |   -0.100 |     0.100 |           1.000 | 1.000 | 2652&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s also actually see the posterior of, say, &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(insight)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;insight&amp;#39; was built under R version 3.6.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posteriors &amp;lt;- get_parameters(model_fit_stan)

ggplot(posteriors, aes(x = bombload)) +
  geom_density(fill = &amp;quot;cyan&amp;quot;) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-20-no_excuse_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I won’t again go into much detail, because you can read the very detailed Vignettes on &lt;code&gt;{bayestestR}&lt;/code&gt;’s
website: &lt;a href=&#34;https://easystats.github.io/bayestestR/articles/bayestestR.html&#34;&gt;Get started with Bayesian Analysis&lt;/a&gt; and
&lt;a href=&#34;https://easystats.github.io/bayestestR/articles/example1.html#describing-the-posterior-1&#34;&gt;Describing the posterior&lt;/a&gt;
which explain all of this much better than I would ever do. The code I’m showing here is basically
a copy paste of these Vignettes, so if I piqued your interest, go read those Vignettes! I also
highly recommend reading &lt;code&gt;{rstanarm}&lt;/code&gt;’s Vignettes, and grabbing the second edition of &lt;em&gt;Statistical Rethinking&lt;/em&gt;,
by Richard McElreath, it is a great intro to Bayesian statistics with &lt;code&gt;{stan}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, as the title of this blog post reads, there is no excuse not to use Bayesian statistics; from
a software point of view, it’s as simple as ever. And by the way, &lt;code&gt;{stan}&lt;/code&gt; models are supported in
&lt;code&gt;{tidymodels}&lt;/code&gt;’ &lt;code&gt;{parsnip}&lt;/code&gt; package as well, which makes things even easier!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to basic: bar plots</title>
      <link>https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=OisvDHvmKuM&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/chef.jpg&#34; title = &#34;Specialty from the chef!&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This blog post shows how to make bar plots and area charts. It’s mostly a list of recipes, indented
for myself. These are plots I have often to do in reports and would like to have the code handy
somewhere. Maybe this will be helpful to some of you as well. Actually, this post is exactly how
I started my blog post. I wanted to have a repository of recipes, and with time the blog grew to
what it is now (tutorials and me exploring methods and datasets with R).&lt;/p&gt;
&lt;div id=&#34;bar-charts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bar charts&lt;/h2&gt;
&lt;p&gt;Bar charts are quite simple plots, but there are enough variations of them that they deserve
one single blog post. However, don’t expect many explanations.&lt;/p&gt;
&lt;p&gt;Let’s first start by loading some data, and the usually required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(janitor)
library(colorspace)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(gss_cat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Very often, what one wants to show are counts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gss_cat %&amp;gt;%
  count(marital, race)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 18 x 3
##    marital       race      n
##  * &amp;lt;fct&amp;gt;         &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
##  1 No answer     Other     2
##  2 No answer     Black     2
##  3 No answer     White    13
##  4 Never married Other   633
##  5 Never married Black  1305
##  6 Never married White  3478
##  7 Separated     Other   110
##  8 Separated     Black   196
##  9 Separated     White   437
## 10 Divorced      Other   212
## 11 Divorced      Black   495
## 12 Divorced      White  2676
## 13 Widowed       Other    70
## 14 Widowed       Black   262
## 15 Widowed       White  1475
## 16 Married       Other   932
## 17 Married       Black   869
## 18 Married       White  8316&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s lump marital statuses that appear less than 10% of the time into an “Other” category:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  counts_marital_race &amp;lt;- gss_cat %&amp;gt;%
    mutate(marital = fct_lump(marital, prop = 0.1)) %&amp;gt;%
    count(marital, race)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 3
##    marital       race      n
##  * &amp;lt;fct&amp;gt;         &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
##  1 Never married Other   633
##  2 Never married Black  1305
##  3 Never married White  3478
##  4 Divorced      Other   212
##  5 Divorced      Black   495
##  6 Divorced      White  2676
##  7 Married       Other   932
##  8 Married       Black   869
##  9 Married       White  8316
## 10 Other         Other   182
## 11 Other         Black   460
## 12 Other         White  1925&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simplest bar plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(counts_marital_race) +
  geom_col(aes(x = marital, y = n, fill = race)) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now with &lt;code&gt;position = &amp;quot;dodge&amp;quot;&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(counts_marital_race) +
  geom_col(aes(x = marital, y = n, fill = race), position = &amp;quot;dodge&amp;quot;) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Moving the legend around with &lt;code&gt;theme(legend.position = ...)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(counts_marital_race) +
  geom_col(aes(x = marital, y = n, fill = race), position = &amp;quot;dodge&amp;quot;) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() +
  theme(legend.position = &amp;quot;left&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Counting by year as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  counts_marital_race_year &amp;lt;- gss_cat %&amp;gt;%
    mutate(marital = fct_lump(marital, prop = 0.1)) %&amp;gt;%
    count(year, marital, race) %&amp;gt;%
    ungroup()
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 96 x 4
##     year marital       race      n
##  * &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt;         &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
##  1  2000 Never married Other    60
##  2  2000 Never married Black   157
##  3  2000 Never married White   495
##  4  2000 Divorced      Other    20
##  5  2000 Divorced      Black    60
##  6  2000 Divorced      White   361
##  7  2000 Married       Other    78
##  8  2000 Married       Black   121
##  9  2000 Married       White  1079
## 10  2000 Other         Other    17
## # … with 86 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you want to show how a variable evolves through time, area chart are handy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;%
  group_by(year, marital) %&amp;gt;%
  summarise(n = sum(n)) %&amp;gt;%
  ggplot() +
  geom_area(aes(x = year, y = n, fill = marital)) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now with facets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;%
  ggplot() +
  geom_area(aes(x = year, y = n, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But what if I want each plot to have its own y axis?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;%
  ggplot() +
  geom_area(aes(x = year, y = n, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free_y&amp;quot;) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now doing an area chart but with relative frequencies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;% 
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;facet_wrap()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;% 
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free_y&amp;quot;) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Want to replace 2000 with “2000-01-01”? First need to create vector of prettier dates and positions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pretty_dates &amp;lt;- counts_marital_race_year %&amp;gt;%
  mutate(pretty_dates = paste0(year, &amp;quot;-01-01&amp;quot;)) %&amp;gt;%
  pull(pretty_dates) %&amp;gt;%
  unique()

position_dates &amp;lt;- counts_marital_race_year %&amp;gt;%
  pull(year) %&amp;gt;%
  unique() %&amp;gt;%
  sort() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;scale_x_continuous()&lt;/code&gt; can now use this. Using &lt;code&gt;guide = guide_axis(n.dodge = 2)&lt;/code&gt; to avoid
overlapping labels:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;%
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free_y&amp;quot;) +
  scale_x_continuous(&amp;quot;Year of survey&amp;quot;, labels = pretty_dates,
                     breaks = position_dates, guide = guide_axis(n.dodge = 2)) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Adding labels is not trivial. Here it is not working:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;% 
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free_y&amp;quot;) +
  scale_x_continuous(&amp;quot;Year of survey&amp;quot;, labels = pretty_dates,
                     breaks = position_dates, guide = guide_axis(n.dodge = 2)) +
  geom_label(aes(x = year, y = freq, label = round(100 * freq))) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another failed attempt. I leave it here for posterity.
My first idea was first to sort the grouped data set by descending frequency, and then
to reorder the factor variable &lt;code&gt;marital&lt;/code&gt; by descending position, which is the cumulative percentage.
This would work fine, if the same factor levels would have had the same order for each of the
race categories. However, this is not the case. For blacks, the most frequent category is “Never Married”.
As you can see below, this trick worked well for 2 categories out of 3:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;%
  group_by(year, race) %&amp;gt;%  
  arrange(desc(freq)) %&amp;gt;% 
  mutate(position = cumsum(freq)) %&amp;gt;% 
  mutate(marital = fct_reorder(marital, desc(position))) %&amp;gt;% 
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free&amp;quot;) +
  scale_x_continuous(&amp;quot;Year of survey&amp;quot;, labels = pretty_dates,
                     breaks = position_dates, guide = guide_axis(n.dodge = 2)) +
  geom_label(aes(x = year, y = position, label = round(100 * freq))) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So to remedy this, is not reorder too early; first, we need to reorder the factor variable by
frequency. Then, we arrange the data by the now reordered &lt;code&gt;marital&lt;/code&gt; variable, and then we can
compute the position using the cumulative frequency.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;%
  group_by(year, race) %&amp;gt;%  
  mutate(marital = fct_reorder(marital, freq)) %&amp;gt;% 
  arrange(desc(marital)) %&amp;gt;% 
  mutate(position = cumsum(freq)) %&amp;gt;% 
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free&amp;quot;) +
  scale_x_continuous(&amp;quot;Year of survey&amp;quot;, labels = pretty_dates,
                     breaks = position_dates, guide = guide_axis(n.dodge = 2)) +
  geom_label(aes(x = year, y = position, label = round(100 * freq))) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can place the labels a bit better (in the middle of their respective areas), like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts_marital_race_year %&amp;gt;% 
  group_by(race, year, marital) %&amp;gt;% 
  summarise(n = sum(n)) %&amp;gt;%  
  mutate(freq = n/sum(n)) %&amp;gt;%
  group_by(year, race) %&amp;gt;%  
  mutate(marital = fct_reorder(marital, freq)) %&amp;gt;% 
  arrange(desc(marital)) %&amp;gt;% 
  mutate(position = cumsum(freq)) %&amp;gt;% mutate(prev_pos = lag(position, default = 0)) %&amp;gt;%
  mutate(position = (position + prev_pos)/2) %&amp;gt;%  
  ggplot() +
  geom_area(aes(x = year, y = freq, fill = marital)) +
  facet_wrap(facets = vars(race), ncol = 1, scales = &amp;quot;free&amp;quot;) +
  scale_x_continuous(&amp;quot;Year of survey&amp;quot;, labels = pretty_dates,
                     breaks = position_dates, guide = guide_axis(n.dodge = 2)) +
  geom_label(aes(x = year, y = position, label = round(100 * freq))) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s focus on the variable &lt;code&gt;tvhours&lt;/code&gt;. We want to show the total watched hours, but also
the total across all the categories of &lt;code&gt;race&lt;/code&gt; and &lt;code&gt;marital&lt;/code&gt; in a faceted bar plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
  total_tv &amp;lt;- gss_cat %&amp;gt;%
    group_by(year, race, marital) %&amp;gt;%
    summarise(total_tv = sum(tvhours, na.rm = TRUE))
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 127 x 4
## # Groups:   year, race [24]
##     year race  marital       total_tv
##    &amp;lt;int&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;            &amp;lt;int&amp;gt;
##  1  2000 Other No answer            2
##  2  2000 Other Never married      103
##  3  2000 Other Separated           16
##  4  2000 Other Divorced            17
##  5  2000 Other Widowed             24
##  6  2000 Other Married            122
##  7  2000 Black Never married      452
##  8  2000 Black Separated          135
##  9  2000 Black Divorced           156
## 10  2000 Black Widowed            183
## # … with 117 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tibble has the total watched hours by year, race and marital status variables. How to add the total
by year and race categories? For this, by are first going to use the &lt;code&gt;group_split()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;total_tv_split &amp;lt;- total_tv %&amp;gt;%
  select(race, year, marital, total_tv) %&amp;gt;%
  mutate(year = as.character(year)) %&amp;gt;%  
  group_split(year, race)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: ... is ignored in group_split(&amp;lt;grouped_df&amp;gt;), please use
## group_by(..., .add = TRUE) %&amp;gt;% group_split()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have to re-order the columns with &lt;code&gt;select()&lt;/code&gt;, because when using &lt;code&gt;janitor::adorn_totals()&lt;/code&gt;, which
I will be using below to add totals, the first column must be a character column (it serves as
an identifier column).&lt;/p&gt;
&lt;p&gt;This creates a list with 3 races times 6 years, so 24 elements. Each element of the list is a tibble
with each unique combination of year and race:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(total_tv_split)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;total_tv_split[1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;list_of&amp;lt;
##   tbl_df&amp;lt;
##     race    : factor&amp;lt;f4a07&amp;gt;
##     year    : character
##     marital : factor&amp;lt;82ceb&amp;gt;
##     total_tv: integer
##   &amp;gt;
## &amp;gt;[2]&amp;gt;
## [[1]]
## # A tibble: 6 x 4
##   race  year  marital       total_tv
##   &amp;lt;fct&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt;            &amp;lt;int&amp;gt;
## 1 Other 2000  No answer            2
## 2 Other 2000  Never married      103
## 3 Other 2000  Separated           16
## 4 Other 2000  Divorced            17
## 5 Other 2000  Widowed             24
## 6 Other 2000  Married            122
## 
## [[2]]
## # A tibble: 5 x 4
##   race  year  marital       total_tv
##   &amp;lt;fct&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt;            &amp;lt;int&amp;gt;
## 1 Black 2000  Never married      452
## 2 Black 2000  Separated          135
## 3 Black 2000  Divorced           156
## 4 Black 2000  Widowed            183
## 5 Black 2000  Married            320&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why do this? To use &lt;code&gt;janitor::adorn_totals()&lt;/code&gt;, which adds row-wise totals to a data frame, or to
each data frame if a list of data frames gets passed to it. I need to still transform the data a little
bit. After using &lt;code&gt;adorn_totals()&lt;/code&gt;, I bind my list of data frames together, and then fill down the year
column (when using &lt;code&gt;adorn_totals()&lt;/code&gt;, character columns like &lt;code&gt;year&lt;/code&gt; are filled with &lt;code&gt;&amp;quot;-&amp;quot;&lt;/code&gt;, but I chose
to fill it with &lt;code&gt;NA_character_&lt;/code&gt;). I then replace the NA value from the marital column with the
string &lt;code&gt;&amp;quot;Total&amp;quot;&lt;/code&gt; and then reorder the &lt;code&gt;marital&lt;/code&gt; column by value of &lt;code&gt;total_tv&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;total_tv_split &amp;lt;- total_tv_split %&amp;gt;%
  adorn_totals(fill = NA_character_) %&amp;gt;%
  map(as.data.frame) %&amp;gt;%  
  bind_rows() %&amp;gt;%
  fill(year, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%
  mutate(marital = ifelse(is.na(marital), &amp;quot;Total&amp;quot;, marital)) %&amp;gt;%
  mutate(marital = fct_reorder(marital, total_tv))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can finally create my plot. Because I have added “Total” as a level in the &lt;code&gt;marital&lt;/code&gt; column, it
now appears seamlessly in the plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(total_tv_split) +
  geom_col(aes(x = marital, y = total_tv, fill = race)) +
  facet_wrap(facets = vars(year), nrow = 2) +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  scale_x_discrete(guide = guide_axis(n.dodge = 3)) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To finish this list of recipes, let’s do a pyramid plot now (inspiration from &lt;a href=&#34;https://stackoverflow.com/questions/14680075/simpler-population-pyramid-in-ggplot2&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_pyramid &amp;lt;- gss_cat %&amp;gt;%
  filter(year == &amp;quot;2000&amp;quot;, marital %in% c(&amp;quot;Married&amp;quot;, &amp;quot;Never married&amp;quot;)) %&amp;gt;%
  group_by(race, marital, rincome) %&amp;gt;%  
  summarise(total_tv = sum(tvhours, na.rm = TRUE))

ggplot(data_pyramid, aes(x = rincome, y = total_tv, fill = marital)) +
  geom_col(data = filter(data_pyramid, marital == &amp;quot;Married&amp;quot;)) +
  geom_col(data = filter(data_pyramid, marital == &amp;quot;Never married&amp;quot;), aes(y = total_tv * (-1))) +
  facet_wrap(facets = vars(race), nrow = 1, scales = &amp;quot;free_x&amp;quot;) +
  coord_flip() +
  scale_fill_discrete_qualitative(palette = &amp;quot;Dark 3&amp;quot;) +
  brotools::theme_blog() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-04-12-basic_ggplot2_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Happy Easter!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What would a keyboard optimised for Luxembourguish look like?</title>
      <link>https://www.brodrigues.co/blog/2020-03-26-bepo_lu/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-03-26-bepo_lu/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/user/TheReportOfTheWeek&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/small_head.jpeg&#34; title = &#34;I highly recommend his youtube channel&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;I’ve been using the BÉPO layout for my keyboard since 2010-ish, and it’s been one of the best computing
decisions I’ve ever taken. The BÉPO layout is an optimized layout for French, but it works quite well
for many European languages, English included (the only issue you might have with the BÉPO layout
for English is that the &lt;code&gt;w&lt;/code&gt; is a bit far away).&lt;/p&gt;
&lt;p&gt;To come up with the BÉPO layout, ideas from a man named August Dvorak were applied for the French
language. Today, the keyboard layout that is optimised for English is called after him, the DVORAK
layout. Dvorak’s ideas were quite simple; unlike the QWERTY layout, his layout had to be based on
character frequency of the English language. The main idea is that the most used
characters of the language should be on the home row of the keyboard. The home row is the row where
you lay your fingers on the keyboard when you are not typing (see picture below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/home_row.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The problem with the “standard” layouts, such as QWERTY, is that they’re all absolute garbage, and
not optimized at all for typing on a computer. For instance, look at the heatmap below, which shows
the most used characters on a QWERTY keyboard when typing an a standard English text:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/qwerty_heatmap.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;(Heatmap generated on &lt;a href=&#34;https://www.patrick-wied.at/projects/heatmap-keyboard/&#34; class=&#34;uri&#34;&gt;https://www.patrick-wied.at/projects/heatmap-keyboard/&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;As you can see, most of the characters used to type this text are actually outside of the home row, and
the majority of them on the left hand side of the keyboard. The idea of Dvorak was to first, put the
most used characters on the home row, and second to try to have an equal split of characters, 50% for each hand.&lt;/p&gt;
&lt;p&gt;The same text on the DVORAK layout, shows how superior it is:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dvorak_heatmap.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As you can see, this is much much better. The same idea was applied to develop the BÉPO layout for
French. And because character frequency is quite similar across languages, learning a layout such as
the BÉPO not only translates to more efficient typing for French, but also for other languages, such
as English, as already explained above.&lt;/p&gt;
&lt;p&gt;The reason I’m writing this blog post is due, in part, to the confinement situation
that many people on Earth are currently facing due to the Corona virus. I have a job where I spend
my whole day typing, and am lucky enough to be able to work from home. Which means that I’m lucky
enough to use my mechanical keyboard to work, which is really great. (I avoid taking my mechanical
keyboard with me at work, because I am never very long in the same spot, between meeting and client
assignments…). But to have a mechanical keyboard that’s easy to take with me,
I decided to buy a second mechanical keyboard, a 40% keyboard from Ergodox (see picture below):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/planck.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Because I don’t even want to see the QWERTY keycaps, I bought blank keycaps to replace the ones that
come with the keyboard. Anyway, this made me think about how crazy it is that in 2020 people still
use absolute garbage keyboard layouts (and keyboards by the way) to type on, when their job is
basically only typing all day long. It made me so angry that I even made a video, which you enjoy
&lt;a href=&#34;https://www.youtube.com/watch?v=LMkFdqEpISo&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The other thing I thought about was the specific case of Luxembourg, a country with 3 official
languages (Luxembourguish, French and German), a very large Portuguese minority, and where English
became so important in recent years that the government distributed leaflets in English to the
population (along with leaflets in French, Luxembourguish, German and Portuguese of course) explaining
what is and is not allowed during the period of containment. What would a keyboard optimized for
such a unique country look like?&lt;/p&gt;
&lt;p&gt;Of course, the answer that comes to mind quickly is to use the BÉPO layout; even though people routinely
write in at least 3 of the above-mentioned languages, French is still the one that people use most
of the time for written communication (at least, that’s my perception). The reason is that while
Luxembourguish is the national language, and the language of the native population, French has
always been the administrative language, and laws are still written in French only, even though
they’re debated in Luxembourguish in the parliament.
However, people also routinely write emails in German or English, and more and more people also
write in Luxembourguish. This means that a keyboard optimized for Luxembourguish, or rather, for
the multilinguistic nature of the Luxembourguish country, should take into account all these
different languages. Another thing to keep in mind is that Luxembourguish uses many French words,
and as such, writing these words should be easy.&lt;/p&gt;
&lt;p&gt;So let’s start with the BÉPO layout as a base. This is what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/bepo_layout.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;A heatmap of character frequencies of a French, or even English, text would show that the most used
characters are on the home row. If you compare DVORAK to BÉPO, you will see that the home row is
fairly similar. But what strikes my colleagues when they see a picture of the BÉPO layout, is the
fact that the characters &lt;code&gt;é&lt;/code&gt;, &lt;code&gt;è&lt;/code&gt;, &lt;code&gt;ê&lt;/code&gt;, &lt;code&gt;à&lt;/code&gt; and &lt;code&gt;ç&lt;/code&gt; can be accessed directly. They are so used to having
these characters only accessible by using some kind of modifier key that their first reaction is to
think that this is completely stupid. However, what is stupid, is not having these letters easily
accessible, and instead having, say, &lt;code&gt;z&lt;/code&gt; easily accessible (the French “standard” layout is called
AZERTY, which is very similar and just as stupid as the QWERTY layout. The letter &lt;code&gt;Z&lt;/code&gt; is so easy to
type on, but is almost non-existing in French!).&lt;/p&gt;
&lt;p&gt;So let’s analyze character frequencies of a Luxembourguish text and see if the BÉPO layout could be
a good fit. I used several text snippets from the Bible in Luxembourguish for this, and a few lines
of R code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;root_url &amp;lt;- &amp;quot;https://cathol.lu/article&amp;quot;

texts &amp;lt;- seq(4869,4900)

urls &amp;lt;- c(&amp;quot;https://cathol.lu/article4887&amp;quot;,
          &amp;quot;https://cathol.lu/article1851&amp;quot;,
          &amp;quot;https://cathol.lu/article1845&amp;quot;,
          &amp;quot;https://cathol.lu/article1863&amp;quot;,
          &amp;quot;https://cathol.lu/article1857&amp;quot;,
          &amp;quot;https://cathol.lu/article4885&amp;quot;,
          &amp;quot;https://cathol.lu/article1648&amp;quot;,
          &amp;quot;https://cathol.lu/article1842&amp;quot;,
          &amp;quot;https://cathol.lu/article1654&amp;quot;,
          &amp;quot;https://cathol.lu/article1849&amp;quot;,
          &amp;quot;https://cathol.lu/article1874&amp;quot;,
          &amp;quot;https://cathol.lu/article4884&amp;quot;,
          &amp;quot;https://cathol.lu/article1878&amp;quot;,
          &amp;quot;https://cathol.lu/article2163&amp;quot;,
          &amp;quot;https://cathol.lu/article2127&amp;quot;,
          &amp;quot;https://cathol.lu/article2185&amp;quot;,
          &amp;quot;https://cathol.lu/article4875&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I’ve get the urls, let’s get the text out of it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pages &amp;lt;- urls %&amp;gt;%
  map(read_html)

texts &amp;lt;- pages %&amp;gt;%
  map(~html_node(., xpath = &amp;#39;//*[(@id = &amp;quot;art_texte&amp;quot;)]&amp;#39;)) %&amp;gt;%
  map(html_text)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;texts&lt;/code&gt; is a list containing the raw text from the website. I used several functions from the &lt;code&gt;{rvest}&lt;/code&gt;
package to do this. I won’t comment on them, because this is not a tutorial about webscraping (I’ve
written several of those already), but a rant about keyboard layout gosh darn it.&lt;/p&gt;
&lt;p&gt;Anyway, let’s now take a look at the character frequencies, and put that in a neat data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters &amp;lt;- texts %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  tolower() %&amp;gt;%
  str_extract_all(pattern = &amp;quot;[:alpha:]&amp;quot;) %&amp;gt;%
  unlist() %&amp;gt;%
  table() %&amp;gt;%  
  as.data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Computing the frequencies is now easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters &amp;lt;- characters %&amp;gt;%
  mutate(frequencies = round(Freq/sum(Freq)*100, digits = 2)) %&amp;gt;%
  arrange(desc(frequencies)) %&amp;gt;%  
  janitor::clean_names()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s start with the obvious differences: there is not a single instance of the characters &lt;code&gt;è&lt;/code&gt;, &lt;code&gt;ê&lt;/code&gt;
or &lt;code&gt;ç&lt;/code&gt;, which are used in French only. There are however instances of &lt;code&gt;ü&lt;/code&gt;, &lt;code&gt;ä&lt;/code&gt;, and &lt;code&gt;ë&lt;/code&gt;. These
characters should be easily accessible, however their frequencies are so low, that they could still
only be accessible using a modifier key, and it would not be a huge issue. However, since &lt;code&gt;ç&lt;/code&gt; does
not appear at all, maybe it could be replaced by &lt;code&gt;ä&lt;/code&gt; and &lt;code&gt;ê&lt;/code&gt; could be replaced by &lt;code&gt;ë&lt;/code&gt;. But we must
keep in mind that since the average Luxembourger has to very often switch between so many languages,
I would suggest that these French characters that would be replaced should still be accessible
using a modifier such as &lt;code&gt;Alt Gr&lt;/code&gt;. As for the rest, the layout as it stands is likely quite ok.
Well, actually I know it’s ok, because when I write in Luxembourguish using the BÉPO layout, I find
it quite easy to do. But let’s grab a French and a German text, and see how the ranking
of the characters compare. Let’s get some French text:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to read the French text&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;french &amp;lt;- &amp;quot;Au commencement, Dieu créa les cieux et la terre.
La terre était informe et vide: il y avait des ténèbres à la surface de l&amp;#39;abîme, et l&amp;#39;esprit de Dieu se mouvait au-dessus des eaux.
Dieu dit: Que la lumière soit! Et la lumière fut.
Dieu vit que la lumière était bonne; et Dieu sépara la lumière d&amp;#39;avec les ténèbres.
Dieu appela la lumière jour, et il appela les ténèbres nuit. Ainsi, il y eut un soir, et il y eut un matin: ce fut le premier jour.
Dieu dit: Qu&amp;#39;il y ait une étendue entre les eaux, et qu&amp;#39;elle sépare les eaux d&amp;#39;avec les eaux.
Et Dieu fit l&amp;#39;étendue, et il sépara les eaux qui sont au-dessous de l&amp;#39;étendue d&amp;#39;avec les eaux qui sont au-dessus de l&amp;#39;étendue. Et cela fut ainsi.
Dieu appela l&amp;#39;étendue ciel. Ainsi, il y eut un soir, et il y eut un matin: ce fut le second jour.
Dieu dit: Que les eaux qui sont au-dessous du ciel se rassemblent en un seul lieu, et que le sec paraisse. Et cela fut ainsi.
Dieu appela le sec terre, et il appela l&amp;#39;amas des eaux mers. Dieu vit que cela était bon.
Puis Dieu dit: Que la terre produise de la verdure, de l&amp;#39;herbe portant de la semence, des arbres fruitiers donnant du fruit selon leur espèce et ayant en eux leur semence sur la terre. Et cela fut ainsi.
La terre produisit de la verdure, de l&amp;#39;herbe portant de la semence selon son espèce, et des arbres donnant du fruit et ayant en eux leur semence selon leur espèce. Dieu vit que cela était bon.
Ainsi, il y eut un soir, et il y eut un matin: ce fut le troisième jour.
Dieu dit: Qu&amp;#39;il y ait des luminaires dans l&amp;#39;étendue du ciel, pour séparer le jour d&amp;#39;avec la nuit; que ce soient des signes pour marquer les époques, les jours et les années;
et qu&amp;#39;ils servent de luminaires dans l&amp;#39;étendue du ciel, pour éclairer la terre. Et cela fut ainsi.
Dieu fit les deux grands luminaires, le plus grand luminaire pour présider au jour, et le plus petit luminaire pour présider à la nuit; il fit aussi les étoiles.
Dieu les plaça dans l&amp;#39;étendue du ciel, pour éclairer la terre,
pour présider au jour et à la nuit, et pour séparer la lumière d&amp;#39;avec les ténèbres. Dieu vit que cela était bon.
Ainsi, il y eut un soir, et il y eut un matin: ce fut le quatrième jour.
Dieu dit: Que les eaux produisent en abondance des animaux vivants, et que des oiseaux volent sur la terre vers l&amp;#39;étendue du ciel.
Dieu créa les grands poissons et tous les animaux vivants qui se meuvent, et que les eaux produisirent en abondance selon leur espèce; il créa aussi tout oiseau ailé selon son espèce. Dieu vit que cela était bon.
Dieu les bénit, en disant: Soyez féconds, multipliez, et remplissez les eaux des mers; et que les oiseaux multiplient sur la terre.
Ainsi, il y eut un soir, et il y eut un matin: ce fut le cinquième jour.
Dieu dit: Que la terre produise des animaux vivants selon leur espèce, du bétail, des reptiles et des animaux terrestres, selon leur espèce. Et cela fut ainsi.
Dieu fit les animaux de la terre selon leur espèce, le bétail selon son espèce, et tous les reptiles de la terre selon leur espèce. Dieu vit que cela était bon.
Puis Dieu dit: Faisons l&amp;#39;homme à notre image, selon notre ressemblance, et qu&amp;#39;il domine sur les poissons de la mer, sur les oiseaux du ciel, sur le bétail, sur toute la terre, et sur tous les reptiles qui rampent sur la terre.
Dieu créa l&amp;#39;homme à son image, il le créa à l&amp;#39;image de Dieu, il créa l&amp;#39;homme et la femme.
Dieu les bénit, et Dieu leur dit: Soyez féconds, multipliez, remplissez la terre, et l&amp;#39;assujettissez; et dominez sur les poissons de la mer, sur les oiseaux du ciel, et sur tout animal qui se meut sur la terre.
Et Dieu dit: Voici, je vous donne toute herbe portant de la semence et qui est à la surface de toute la terre, et tout arbre ayant en lui du fruit d&amp;#39;arbre et portant de la semence: ce sera votre nourriture.
Et à tout animal de la terre, à tout oiseau du ciel, et à tout ce qui se meut sur la terre, ayant en soi un souffle de vie, je donne toute herbe verte pour nourriture. Et cela fut ainsi.
Dieu vit tout ce qu&amp;#39;il avait fait et voici, cela était très bon. Ainsi, il y eut un soir, et il y eut un matin: ce fut le sixième jour.
Joe Paterno, né le 21 décembre 1926 à Brooklyn et mort le 22 janvier 2012 à State College, est un joueur et entraîneur américain de football américain universitaire. Figure historique et emblématique des Nittany Lions de Penn State entre 1966 et 2011, il est l&amp;#39;entraîneur le plus victorieux de l&amp;#39;histoire du football américain universitaire avec 409 succès en Division I. Son image est toutefois ternie en fin de carrière à cause de soupçons de négligence dans une affaire d&amp;#39;agressions sexuelles sur mineurs.

Lors de ses brillantes études de droit à l&amp;#39;université Brown, Joe Paterno joue au football américain et est entraîné par Rip Engle. Ce dernier, embauché par l&amp;#39;université de Penn State, le recrute comme entraîneur assistant en 1950. Pendant quinze saisons, l&amp;#39;assistant fait ses preuves avant de devenir entraîneur principal des Nittany Lions en 1965. Surnommé JoePa, il connaît rapidement le succès. Invaincu en 1968 et 1969, il est désiré par plusieurs franchises de la National Football League (NFL), mais refuse pour conserver son rôle d&amp;#39;éducateur. Entraîneur de l&amp;#39;équipe universitaire championne en 1982 et 1986, vainqueur des quatre principaux Bowls universitaires, il intègre le College Football Hall of Fame en 2007 alors qu&amp;#39;il est encore en activité, un accomplissement rare.

Reconnu pour ses succès sportifs, académiques et son exemplarité, JoePa est adulé comme une icône populaire dans la région de State College. Onze jours après avoir célébré sa 409e victoire avec les Lions, il est démis de ses fonctions à la suite du scandale des agressions sexuelles de l&amp;#39;Université d&amp;#39;État de Pennsylvanie. Accusé d&amp;#39;avoir couvert les abus sexuels de Jerry Sandusky, son image est ternie par cette affaire au retentissement international. Il meurt deux mois plus tard des suites d&amp;#39;un cancer du poumon.
Chacun peut publier immédiatement du contenu en ligne, à condition de respecter les règles essentielles établies par la Fondation Wikimedia et par la communauté ; par exemple, la vérifiabilité du contenu, l&amp;#39;admissibilité des articles et garder une attitude cordiale.

De nombreuses pages d’aide sont à votre disposition, notamment pour créer un article, modifier un article ou insérer une image. N’hésitez pas à poser une question pour être aidé dans vos premiers pas, notamment dans un des projets thématiques ou dans divers espaces de discussion.

Les pages de discussion servent à centraliser les réflexions et les remarques permettant d’améliorer les articles.
En 1894, l’explorateur Gustav Adolf von Götzen suivait les traces d’un missionnaire en provenance de la cote orientale d’Afrique. Pendant qu’il se rendait au Rwanda, il découvre un petit village des pécheurs appelé Ngoma qui traduit signifie tam tam, par déformation il écrivit Goma. Ngoma devint un poste belge en face de celui de Rubavu (au Rwanda) habité par les Allemands. Au début, la cohabitation entre ces deux postes n’était pas facile. À un certain moment, les chefs coutumiers du Rwanda, en complicité avec les Allemands attaquent les Belges de Goma. Ces derniers se réfugient à Bukavu et laissent les envahisseurs occuper la ville. Après des négociations, les Allemands replient vers le Rwanda et les Belges reprennent leur position initiale comme poste colonial. L’afflux des colonisateurs dans ce village joue un rôle important dans son évolution pour devenir une grande agglomération. Les colonisateurs venaient d’installer le chef lieu du district Belge à Rutshuru ou vivait l’administrateur colonial. Le chef lieu passera de Rutshuru à Goma.

En ce moment, Goma reste un poste de transaction lacustre avec Bukavu qui était une ville minière. Plus tard, Rutshuru, Masisi, Kalehe, Gisenyi, etc. déverseront leurs populations dans Goma, à la rechercher de l’emploi au près des colonisateurs. C’est en cette période que vu le jour le quartier Birere (un bidonville de Goma) autour des entrepôts, bureaux et habitations des colons. Le nom Birere (littéralement feuilles de bananier) vient du fait qu’à l’époque, les gens y construisaient en feuilles des bananiers.

La ville est la base arrière de l&amp;#39;opération Turquoise organisée en 1994 à la fin du génocide rwandais.

La ville et ses environs abriteront dans des camps autour de 650 000 réfugiés hutus de 1994 jusqu&amp;#39;à la chute du Zaïre, dont certains supposés anciens génocidaires. Selon des ONG, l&amp;#39;AFDL procède à des massacres dans les camps entre 1996 et 19971.

De 1998 à 2002/2003, la ville, sous contrôle du Rassemblement congolais pour la démocratie (RCD) pro-rwandais échappe au contrôle du gouvernement congolais.

De nombreux viols, massacres et crimes de guerre y ont été perpétrés entre 1996 et 2006 par les troupes des généraux rebelles du RCD, essentiellement sous les généraux Nkundabatware et Mutebusi.

En 2002, le Nyiragongo entra en éruption, et une coulée de lave atteignit le centre de la ville. La lave n&amp;#39;a pas atteint le lac Kivu fort heureusement, en effet ce lac est un lac méromictique et un changement brutal de chaleur aurait des conséquences graves : Éruption limnique.

Débordant de populations fuyant les violences, Goma compte en 2012 plus de 400 000 habitants. Ceux qui ne peuvent pas trouver d&amp;#39;abri remplissent les camps de réfugiés, où l&amp;#39;ONU et les ONG se débattent pour leur fournir nourriture, eau et combustible.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters_fr &amp;lt;- french %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  tolower() %&amp;gt;%
  str_extract_all(pattern = &amp;quot;[:alpha:]&amp;quot;) %&amp;gt;%
  unlist() %&amp;gt;%
  table() %&amp;gt;%  
  as.data.frame() %&amp;gt;%  
  mutate(frequencies = round(Freq/sum(Freq)*100, digits = 2)) %&amp;gt;%
  arrange(desc(frequencies)) %&amp;gt;%  
  janitor::clean_names()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now do the same for German:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to read the German text&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;german &amp;lt;- &amp;quot;Am Anfang schuf Gott Himmel und Erde.
Und die Erde war wüst und leer, und es war finster auf der Tiefe; und der Geist Gottes schwebte auf dem Wasser.
Und Gott sprach: Es werde Licht! und es ward Licht.
Und Gott sah, daß das Licht gut war. Da schied Gott das Licht von der Finsternis
und nannte das Licht Tag und die Finsternis Nacht. Da ward aus Abend und Morgen der erste Tag.
Und Gott sprach: Es werde eine Feste zwischen den Wassern, und die sei ein Unterschied zwischen den Wassern.
Da machte Gott die Feste und schied das Wasser unter der Feste von dem Wasser über der Feste. Und es geschah also.
Und Gott nannte die Feste Himmel. Da ward aus Abend und Morgen der andere Tag.
Und Gott sprach: Es sammle sich das Wasser unter dem Himmel an besondere Örter, daß man das Trockene sehe. Und es geschah also.
Und Gott nannte das Trockene Erde, und die Sammlung der Wasser nannte er Meer. Und Gott sah, daß es gut war.
Und Gott sprach: Es lasse die Erde aufgehen Gras und Kraut, das sich besame, und fruchtbare Bäume, da ein jeglicher nach seiner Art Frucht trage und habe seinen eigenen Samen bei sich selbst auf Erden. Und es geschah also.
Und die Erde ließ aufgehen Gras und Kraut, das sich besamte, ein jegliches nach seiner Art, und Bäume, die da Frucht trugen und ihren eigenen Samen bei sich selbst hatten, ein jeglicher nach seiner Art. Und Gott sah, daß es gut war.
Da ward aus Abend und Morgen der dritte Tag.
Und Gott sprach: Es werden Lichter an der Feste des Himmels, die da scheiden Tag und Nacht und geben Zeichen, Zeiten, Tage und Jahre
und seien Lichter an der Feste des Himmels, daß sie scheinen auf Erden. Und es geschah also.
Und Gott machte zwei große Lichter: ein großes Licht, das den Tag regiere, und ein kleines Licht, das die Nacht regiere, dazu auch Sterne.
Und Gott setzte sie an die Feste des Himmels, daß sie schienen auf die Erde
und den Tag und die Nacht regierten und schieden Licht und Finsternis. Und Gott sah, daß es gut war.
Da ward aus Abend und Morgen der vierte Tag.
Und Gott sprach: Es errege sich das Wasser mit webenden und lebendigen Tieren, und Gevögel fliege auf Erden unter der Feste des Himmels.
Und Gott schuf große Walfische und allerlei Getier, daß da lebt und webt, davon das Wasser sich erregte, ein jegliches nach seiner Art, und allerlei gefiedertes Gevögel, ein jegliches nach seiner Art. Und Gott sah, daß es gut war.
Und Gott segnete sie und sprach: Seid fruchtbar und mehrt euch und erfüllt das Wasser im Meer; und das Gefieder mehre sich auf Erden.
Da ward aus Abend und Morgen der fünfte Tag.
Und Gott sprach: Die Erde bringe hervor lebendige Tiere, ein jegliches nach seiner Art: Vieh, Gewürm und Tiere auf Erden, ein jegliches nach seiner Art. Und es geschah also.
Und Gott machte die Tiere auf Erden, ein jegliches nach seiner Art, und das Vieh nach seiner Art, und allerlei Gewürm auf Erden nach seiner Art. Und Gott sah, daß es gut war.
Und Gott sprach: Laßt uns Menschen machen, ein Bild, das uns gleich sei, die da herrschen über die Fische im Meer und über die Vögel unter dem Himmel und über das Vieh und über die ganze Erde und über alles Gewürm, das auf Erden kriecht.
Und Gott schuf den Menschen ihm zum Bilde, zum Bilde Gottes schuf er ihn; und schuf sie einen Mann und ein Weib.
Und Gott segnete sie und sprach zu ihnen: Seid fruchtbar und mehrt euch und füllt die Erde und macht sie euch untertan und herrscht über die Fische im Meer und über die Vögel unter dem Himmel und über alles Getier, das auf Erden kriecht.
Und Gott sprach: Seht da, ich habe euch gegeben allerlei Kraut, das sich besamt, auf der ganzen Erde und allerlei fruchtbare Bäume, die sich besamen, zu eurer Speise,
und allem Getier auf Erden und allen Vögeln unter dem Himmel und allem Gewürm, das da lebt auf Erden, daß sie allerlei grünes Kraut essen. Und es geschah also.
Und Gott sah alles an, was er gemacht hatte; und siehe da, es war sehr gut. Da ward aus Abend und Morgen der sechste Tag.
Während des Bürgerkrieges und Völkermords im nahe angrenzenden Ruanda 1994 war Goma eines der Hauptziele für Flüchtlinge. Unter diesen waren nebst Zivilisten auch Mittäter des Genozids. Nachdem über eine Million Flüchtlinge die Stadt erreicht hatten, brach in den Lagern eine Cholera-Epidemie aus, die mehrere Tausend Opfer forderte. In den Jahren 1997 und 1998, als der Bürgerkrieg im Kongo nach dem Sturz von Präsident Mobutu Sese Seko eskalierte, eroberten ruandische Regierungstruppen Goma. Im Zuge der Verfolgung von Hutu, die in der Stadt Zuflucht gesucht hatten, töteten sie auch Hunderte Unbeteiligte.

Im Jahre 2002 wurde die Stadt von einem Lavastrom aus dem etwa 14 km entfernten Nyiragongo im Norden zu großen Teilen zerstört. Viele Gebäude gerade im Stadtzentrum sowie der Flughafen Goma waren betroffen. Von den 3.000 Metern der Start- und Landebahn sind bis heute noch fast 1.000 Meter unter einer Lavaschicht begraben, so dass der internationale Verkehr ihn meidet. Rund 250.000 Einwohner der Stadt mussten flüchten. Es gab 147 Todesopfer, viele Flüchtlinge blieben obdachlos oder haben sich am Rande der Lavafelder Notunterkünfte gebaut. Seit April 2009 wird unter Führung der Welthungerhilfe das Rollfeld des Flughafens von der Lava befreit. Die Bedrohung, dass sich bei einer erneuten Eruption Lavamassen aus dem innerhalb des Vulkankraters befindlichen Lavasee erneut ins Tal und auf die Stadt ergießen, besteht nach wie vor.[3]

Am 15. April 2008 raste nach dem Start vom Flughafen Goma eine Douglas DC-9 mit 79 Passagieren und 6 Besatzungsmitgliedern über das südliche Startbahnende hinaus in das Wohn- und Marktgebiet Birere. Etwa 40 Personen aus dem angrenzenden Siedlungsgebiet kamen ums Leben, mindestens 53 Passagiere und die 6 Besatzungsmitglieder überlebten jedoch. Das Feuer aus dem brennenden Wrack konnte sich aufgrund des starken Regens nicht ausbreiten, Anwohner konnten das Feuer zusätzlich eindämmen.

Zehntausende Menschen flohen Ende Oktober 2008 aufgrund einer Offensive von Tutsi-Rebellen aus der Stadt.[4]

Am 21. November 2012 wurden große Teile der Stadt von der gegen die Zentralregierung unter Präsident Joseph Kabila kämpfenden Rebellenbewegung M23 eingenommen. Dort stationierte UNO-Friedens-Truppen griffen im Gegensatz zu früheren Aktivitäten nicht mehr ein.[5] Am 1. Dezember begannen sie nach Überschreitung eines Ultimatums der Internationalen Konferenz der Großen Seen Afrikas und zwei Resolutionen des UN-Sicherheitsrats, sich aus der Stadt zurückzuziehen.

Im Jahre 2019 wurden mehrere Einzelfälle von Ebola in der Stadt registriert, nachdem die Ebola Epidemie bereits zuvor im Ostkongo ausgebrochen war.[6]

Seit 1959 ist Goma Sitz des römisch-katholischen Bistums Goma.
Die Transporteure werden Frachtführer (in Österreich Frächter) genannt. Sie organisieren nicht den Transport, sondern führen diesen aus, meistens im Auftrag eines Spediteurs. Die Höhe der Fracht wird im Frachtvertrag vereinbart und in der Regel im Frachtbrief festgehalten. Seit mit der Transportrechtsreform 1998 in Deutschland die Erstellung eines Frachtbriefes für nationale Transporte nicht mehr zwingend erforderlich ist, sondern auch Lieferscheine, Ladelisten oder vergleichbare Papiere als Warenbegleitdokument verwendet werden können, wird zunehmend kein Frachtbrief mehr ausgestellt. Beim Frachtbrief gibt es drei Originalausfertigungen. Eine Ausfertigung verbleibt beim Absender, nachdem ihm darauf der Frachtführer die Übernahme des Frachtguts bestätigt hat. Die zweite verbleibt nach Ablieferung des Frachtguts als Ablieferbestätigung beim Frachtführer und die dritte erhält der Empfänger.

Für die Verladung des Frachtguts ist der Absender zuständig. Er ist dabei gem. § 412 HGB für eine beförderungssichere Verladung des Frachtguts verantwortlich, wohingegen der Frachtführer für die verkehrssichere Verladung (z. B. Gewichtsverteilung, Einhaltung der zulässigen Achslasten), als auch für die Ladungssicherung zu sorgen hat.

Bei Kontrollen muss der Frachtbrief den Zoll- und Polizeibehörden, sowie dem Bundesamt für Güterverkehr (BAG) ausgehändigt werden.

Es gibt anmeldepflichtige Frachtgüter, für deren Transport es einer ausdrücklichen behördlichen Genehmigung bedarf. Schwertransporte erfordern eine behördliche Ausnahmegenehmigung und bei Überschreiten bestimmter Abmessungen sind gemäß § 29 Absatz. 3 StVO (Übermäßige Straßennutzung) definitiv Begleitfahrzeuge und/oder eine Begleitung durch die Polizei vorgeschrieben, um Sicherungsmaßnahmen einzuleiten und für einen reibungslosen Ablauf zu sorgen. Fällt das zu befördernde Frachtgut unter die Gefahrgutverordnung, muss das Transportfahrzeug neben der Einhaltung gefahrgutrelevanter Vorschriften auch mit entsprechenden Warntafeln gekennzeichnet sein. Darüber hinaus benötigt dann der Fahrzeugführer und ein eventueller Beifahrer auch eine ADR-Bescheinigung.

Die Aufteilung der Frachtkosten zwischen Absender und Empfänger wird über die im Kaufvertrag festgehaltenen Lieferbedingungen geregelt, im internationalen Warenverkehr durch die Incoterms.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters_gr &amp;lt;- german %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  map(~strsplit(., split = &amp;quot;&amp;quot;)) %&amp;gt;%
  unlist() %&amp;gt;%
  tolower() %&amp;gt;%
  str_extract_all(pattern = &amp;quot;[:alpha:]&amp;quot;) %&amp;gt;%
  unlist() %&amp;gt;%
  table() %&amp;gt;%  
  as.data.frame() %&amp;gt;%  
  mutate(frequencies = round(Freq/sum(Freq)*100, digits = 2)) %&amp;gt;%
  arrange(desc(frequencies)) %&amp;gt;%
  janitor::clean_names()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now visualize how the rankings evolve between these three languages. For this, I’m using the &lt;code&gt;newggslopegraph()&lt;/code&gt;
function from the &lt;code&gt;{CGPfunctions}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters$rank &amp;lt;- seq(1, 30)
characters_fr$rank &amp;lt;- seq(1, 36)
characters_gr$rank &amp;lt;- seq(1, 28)

characters_fr &amp;lt;- characters_fr %&amp;gt;%
  select(letters = x, rank, frequencies) %&amp;gt;%
  mutate(language = &amp;quot;french&amp;quot;)

characters_gr &amp;lt;- characters_gr %&amp;gt;%
  select(letters = x, rank, frequencies) %&amp;gt;%
  mutate(language = &amp;quot;german&amp;quot;)

characters &amp;lt;- characters %&amp;gt;%
  select(letters = x, rank, frequencies) %&amp;gt;%
  mutate(language = &amp;quot;luxembourguish&amp;quot;)

characters_df &amp;lt;- bind_rows(characters, characters_fr, characters_gr)

CGPfunctions::newggslopegraph(characters_df, 
                              language,
                              rank,
                              letters,
                              Title = &amp;quot;Character frequency ranking for the Luxembourguish official languages&amp;quot;,
                              SubTitle = NULL,
                              Caption = NULL,
                              YTextSize = 4) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 methods overwritten by &amp;#39;lme4&amp;#39;:
##   method                          from
##   cooks.distance.influence.merMod car 
##   influence.merMod                car 
##   dfbeta.influence.merMod         car 
##   dfbetas.influence.merMod        car&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-03-26-bepo_lu_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;2100&#34; /&gt;&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to look at the raw data, which contains the frequencies&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;characters_df &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    letters rank frequencies       language
## 1        e    1       16.19 luxembourguish
## 2        n    2        9.61 luxembourguish
## 3        s    3        6.94 luxembourguish
## 4        a    4        6.56 luxembourguish
## 5        i    5        6.44 luxembourguish
## 6        t    6        6.16 luxembourguish
## 7        d    7        5.56 luxembourguish
## 8        r    8        5.42 luxembourguish
## 9        h    9        5.21 luxembourguish
## 10       u   10        3.76 luxembourguish
## 11       g   11        3.70 luxembourguish
## 12       m   12        3.26 luxembourguish
## 13       o   13        3.07 luxembourguish
## 14       l   14        2.81 luxembourguish
## 15       c   15        2.51 luxembourguish
## 16       w   16        2.23 luxembourguish
## 17       é   17        1.56 luxembourguish
## 18       k   18        1.42 luxembourguish
## 19       f   19        1.34 luxembourguish
## 20       ä   20        1.18 luxembourguish
## 21       z   21        1.03 luxembourguish
## 22       p   22        1.02 luxembourguish
## 23       j   23        0.78 luxembourguish
## 24       ë   24        0.72 luxembourguish
## 25       b   25        0.68 luxembourguish
## 26       v   26        0.68 luxembourguish
## 27       ü   27        0.13 luxembourguish
## 28       q   28        0.01 luxembourguish
## 29       x   29        0.01 luxembourguish
## 30       y   30        0.01 luxembourguish
## 31       e    1       15.40         french
## 32       s    2        7.81         french
## 33       i    3        7.63         french
## 34       t    4        7.52         french
## 35       a    5        7.47         french
## 36       u    6        7.03         french
## 37       r    7        6.74         french
## 38       n    8        6.70         french
## 39       l    9        6.31         french
## 40       o   10        4.74         french
## 41       d   11        4.14         french
## 42       c   12        3.00         french
## 43       p   13        2.43         french
## 44       m   14        2.39         french
## 45       é   15        1.84         french
## 46       v   16        1.42         french
## 47       b   17        1.08         french
## 48       f   18        1.08         french
## 49       g   19        0.96         french
## 50       q   20        0.82         french
## 51       x   21        0.57         french
## 52       è   22        0.51         french
## 53       h   23        0.51         french
## 54       y   24        0.44         french
## 55       à   25        0.40         french
## 56       j   26        0.37         french
## 57       z   27        0.18         french
## 58       w   28        0.14         french
## 59       î   29        0.11         french
## 60       k   30        0.11         french
## 61       ô   31        0.08         french
## 62       ç   32        0.03         french
## 63       ê   33        0.01         french
## 64       ï   34        0.01         french
## 65       ö   35        0.01         french
## 66       ù   36        0.01         french
## 67       e    1       16.58         german
## 68       n    2        9.00         german
## 69       r    3        8.05         german
## 70       a    4        6.71         german
## 71       d    5        6.55         german
## 72       t    6        6.47         german
## 73       s    7        6.38         german
## 74       i    8        6.35         german
## 75       u    9        4.63         german
## 76       h   10        4.44         german
## 77       g   11        3.78         german
## 78       l   12        3.09         german
## 79       c   13        2.80         german
## 80       m   14        2.49         german
## 81       o   15        2.29         german
## 82       f   16        2.28         german
## 83       b   17        2.12         german
## 84       w   18        1.11         german
## 85       v   19        0.85         german
## 86       z   20        0.84         german
## 87       ü   21        0.77         german
## 88       p   22        0.65         german
## 89       k   23        0.63         german
## 90       ä   24        0.34         german
## 91       ß   25        0.33         german
## 92       ö   26        0.26         german
## 93       j   27        0.19         german
## 94       y   28        0.01         german&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Certain things pop out of this plot: the rankings of the German and Luxembourguish languages are
more similar than the rankings of French and Luxembourguish, but overall, the three languages have
practically the same top 10 characters. Using the same base as the BÉPO layout should be
comfortable enough, but the characters &lt;code&gt;h&lt;/code&gt; and &lt;code&gt;g&lt;/code&gt;, which are not very common in French, are much
more common in Luxembourguish, and should thus be better placed. I would advise against using the
German ergonomic/optimized layout, however, because as I said in the beginning, French is still
probably the most written language, certainly more often written than German. So even though the
frequencies of characters are very similar between Luxembourguish and German, I would still prefer
to use the French BÉPO layout.&lt;/p&gt;
&lt;p&gt;I don’t know if there ever will be an ergonomic/optimized layout for Luxembourguish, but I sure
hope that more and more people will start using layouts such as the BÉPO, which are really great
to use. It takes some time to get used to, but in general in about one week of usage, maybe two,
you should be as fast as you were on the legacy layout.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and watch my
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;. If you want to support
my blog and channel, you could &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or
&lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Explainbility of {tidymodels} models with {iml}</title>
      <link>https://www.brodrigues.co/blog/2020-03-10-exp_tidymodels/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-03-10-exp_tidymodels/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Rhetoric&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/exp_tidymodels.jpg&#34; title = &#34;&#39;{rethoric}&#39; would be a sick package name for explainability&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;In my previous &lt;a href=&#34;https://www.brodrigues.co/blog/2020-03-08-tidymodels/&#34;&gt;blog post&lt;/a&gt;, I have shown how
you could use &lt;code&gt;{tidymodels}&lt;/code&gt; to train several machine learning models. Now, let’s take a look at
getting some explanations out of them, using the &lt;code&gt;{iml}&lt;/code&gt; package. Originally I did not intend to create
a separate blog post, but I have encountered… an issue, or bug, when using both &lt;code&gt;{iml}&lt;/code&gt; and
&lt;code&gt;{tidymodels}&lt;/code&gt; and I felt that it was important that I write about it. Maybe it’s just me that’s missing
something, and you, kind reader, might be able to give me an answer. But let’s first reload the
models from last time (the same packages as on the previous blog post are loaded):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trained_models_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[2]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[3]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[4]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[5]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see which of the models performed best (in cross-validation):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trained_models_list %&amp;gt;%
  map(show_best, metric = &amp;quot;accuracy&amp;quot;, n = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 1 x 7
##    penalty mixture .metric  .estimator  mean     n std_err
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 6.57e-10  0.0655 accuracy binary     0.916    10 0.00179
## 
## [[2]]
## # A tibble: 1 x 7
##    mtry trees .metric  .estimator  mean     n std_err
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1    13  1991 accuracy binary     0.929    10 0.00172
## 
## [[3]]
## # A tibble: 1 x 7
##   num_terms prune_method .metric  .estimator  mean     n std_err
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1         5 backward     accuracy binary     0.904    10 0.00186
## 
## [[4]]
## # A tibble: 1 x 9
##    mtry trees tree_depth learn_rate .metric  .estimator  mean     n std_err
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1    12  1245         12     0.0770 accuracy binary     0.929    10 0.00175
## 
## [[5]]
## # A tibble: 1 x 7
##   hidden_units    penalty .metric  .estimator  mean     n std_err
##          &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1           10 0.00000307 accuracy binary     0.917    10 0.00209&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seems like the second model, the random forest performed the best (highest mean accuracy with lowest
standard error). So let’s retrain the model on the whole training set and see how it fares on the
testing set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rf_specs &amp;lt;- trained_models_list[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s save the best model specification in a variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_rf_spec &amp;lt;- show_best(rf_specs, &amp;quot;accuracy&amp;quot;, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now retrain this model, using a workflow:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_rf_model &amp;lt;- rand_forest(mode = &amp;quot;classification&amp;quot;, mtry = best_rf_spec$mtry,
                           trees = best_rf_spec$trees) %&amp;gt;%
  set_engine(&amp;quot;ranger&amp;quot;)

preprocess &amp;lt;- recipe(job_search ~ ., data = pra) %&amp;gt;%
  step_dummy(all_predictors())

pra_wflow_best &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(best_rf_model)

best_model_fitted &amp;lt;- fit(pra_wflow_best, data = pra_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The following variables are not factor vectors and will be ignored:
## `hours`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and let’s take a look at the confusion matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions &amp;lt;- predict(best_model_fitted, new_data = pra_test) %&amp;gt;%
  bind_cols(pra_test)

predictions %&amp;gt;%
  mutate(job_search = as.factor(job_search)) %&amp;gt;%  
  accuracy(job_search, .pred_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 accuracy binary         0.924&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictions %&amp;gt;%
  mutate(job_search = as.factor(job_search)) %&amp;gt;%  
  conf_mat(job_search, .pred_class) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction    N    S
##          N 2539  156
##          S   64  149&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that predicting class &lt;code&gt;S&lt;/code&gt; (“Si”, meaning, “yes” in Spanish) is tricky. One would probably need
to use techniques such as &lt;code&gt;SMOTE&lt;/code&gt; to deal with this (see this &lt;a href=&#34;https://www.brodrigues.co/blog/2018-02-11-census-random_forest/&#34;&gt;blog post&lt;/a&gt;
for more info). Anyways, this is not today’s topic.&lt;/p&gt;
&lt;p&gt;Let’s say that we are satisfied with the model and want some explanations out of it. I have already
blogged about it in the past, so if you want more details, you can read this &lt;a href=&#34;https://www.brodrigues.co/blog/2018-02-11-census-random_forest/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, what is important, is that I have defined a complete workflow to deal with the data preprocessing
and then the training of the model. So I’ll be using this workflow as well to get my explainability. What I mean
with this is the following: to get explanations, we need a model, and a way to get predictions out
of it. As I have shown before, my fitted workflow is able to give me predictions. So I should have
every needed ingredient; &lt;code&gt;{iml}&lt;/code&gt;, the package that I am using for explainability provides several
functions that work all the same; you first define an object that takes as an input the fitted model,
the design matrix, the target variable and the prediction function. Let’s start with defining the
design matrix and the target variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;iml&amp;quot;)

features &amp;lt;- pra_test %&amp;gt;%
  select(-job_search)

target &amp;lt;- pra_test %&amp;gt;%
  mutate(job_search = as.factor(job_search)) %&amp;gt;%  
  select(job_search)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s define the predict function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict_wrapper &amp;lt;- function(model, newdata){
  workflows:::predict.workflow(object = model, new_data = newdata)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because a workflow is a bit special, I need to define this wrapper function that wraps the
&lt;code&gt;workflows:::predict.workflow()&lt;/code&gt; function. Normally, users should not have to deal with this function;
as you can see, to access it I had to use the very special &lt;code&gt;:::&lt;/code&gt; function. &lt;code&gt;:::&lt;/code&gt; permits users
to access &lt;em&gt;private&lt;/em&gt; functions (not sure if this is the right term; what I mean is that private functions
are used internally by the package and should not be available to users. AFAIK, this is how these
functions are called in Python). I tried simply using the &lt;code&gt;predict()&lt;/code&gt; function, which works interactively
but I was getting issues with it when I was providing it to the constructor below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predictor &amp;lt;- Predictor$new(
                         model = best_model_fitted,
                         data = features, 
                         y = target,
                         predict.fun = predict_wrapper
                       )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a &lt;code&gt;Predictor&lt;/code&gt; object from which I am now able to get explanations. For example, for
feature importance, I would write the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;feature_importance &amp;lt;- FeatureImp$new(predictor, loss = &amp;quot;ce&amp;quot;)

plot(feature_importance)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-03-10-exp_tidymodels_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And this is where I noticed that something was wrong; the variables we are looking at are
categorical variables. So why am I not seeing the categories? Why is the most important variable
the contract type, without the category of the contract type that is the most important?
Remember that I created dummy variables using a recipe. So I was expecting something like
&lt;code&gt;type_of_contract_type_1&lt;/code&gt;, &lt;code&gt;type_of_contract_type_2&lt;/code&gt;, etc… as variables.&lt;/p&gt;
&lt;p&gt;This made me want to try to fit the model “the old way”, without using workflows. So for this
I need to use the &lt;code&gt;prep()&lt;/code&gt;, &lt;code&gt;juice()&lt;/code&gt; and &lt;code&gt;bake()&lt;/code&gt; functions, which are included in the &lt;code&gt;{recipes}&lt;/code&gt;
package. I won’t go into much detail, but the idea is that &lt;code&gt;prep()&lt;/code&gt; is used to train the recipe, and
compute whatever is needed to preprocess the data (such as means and standard deviations for
normalization). For this, you should use the training data only. &lt;code&gt;juice()&lt;/code&gt; returns the preprocessed
training set, and &lt;code&gt;bake()&lt;/code&gt; is then used to preprocessed a new data set, for instance the test set,
using the same estimated parameters that were obtained with &lt;code&gt;prep()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Using workflows avoids having to do these steps manually, but what I am hoping is that doing this
manually will solve my issue. So let’s try:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# without workflows
trained_recipe &amp;lt;- prep(preprocess, training = pra_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The following variables are not factor vectors and will be ignored:
## `hours`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra_train_prep &amp;lt;- juice(trained_recipe)


best_model_fit &amp;lt;- fit(best_rf_model, job_search ~ ., data = pra_train_prep)


pra_test_bake_features &amp;lt;- bake(trained_recipe, pra_test) %&amp;gt;%
  select(-job_search)


predict_wrapper2 &amp;lt;- function(model, newdata){
  predict(object = model, new_data = newdata)
}

predictor2 &amp;lt;- Predictor$new(
                          model = best_model_fit,
                          data = pra_test_bake_features, 
                          y = target,
                          predict.fun = predict_wrapper2
                        )

feature_importance2 &amp;lt;- FeatureImp$new(predictor2, loss = &amp;quot;ce&amp;quot;)

plot(feature_importance2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-03-10-exp_tidymodels_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Eureka! As you can see, the issue is now solved; we now have all the variables that were used
for training the model, also in our explanations. I don’t know exactly what’s going on; is this a
bug? Is it because the &lt;code&gt;{workflows}&lt;/code&gt; package makes this process too streamlined that it somehow
&lt;em&gt;rebuilds&lt;/em&gt; the features and then returns the results? I have no idea. In any case, it
would seem that for the time being, doing the training and explanations without the &lt;code&gt;{workflows}&lt;/code&gt;
package is the way to go if you require explanations as well.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and watch my
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;. If you want to support
my blog and channel, you could &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or
&lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning with {tidymodels}</title>
      <link>https://www.brodrigues.co/blog/2020-03-08-tidymodels/</link>
      <pubDate>Sun, 08 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-03-08-tidymodels/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://autonxt.net/bosozoku-japans-car-tuning-subculture/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/jap_tune.jpg&#34; title = &#34;Just because you tune your models, doesn&#39;t mean you can&#39;t overfit&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;intro-what-is-tidymodels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro: what is &lt;code&gt;{tidymodels}&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;I have already written about &lt;code&gt;{tidymodels}&lt;/code&gt; in the &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-25-tidy_cv/&#34;&gt;past&lt;/a&gt;
but since then, the &lt;code&gt;{tidymodels}&lt;/code&gt; meta-package has evolved quite a lot. If you don’t know what
&lt;code&gt;{tidymodels}&lt;/code&gt; is, it is a suite of packages that make machine learning with R a breeze. R has many
packages for machine learning, each with their own syntax and function arguments. &lt;code&gt;{tidymodels}&lt;/code&gt; aims
at providing an unified interface which allows data scientists to focus on the problem they’re trying
to solve, instead of wasting time with learning package specificities.&lt;/p&gt;
&lt;p&gt;The packages included in &lt;code&gt;{tidymodels}&lt;/code&gt; are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/parsnip/articles/parsnip_Intro.html&#34;&gt;{parsnip}&lt;/a&gt; for model definition&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/recipes/&#34;&gt;{recipes}&lt;/a&gt; for data preprocessing and feature engineering&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/rsample/&#34;&gt;{rsample}&lt;/a&gt; to resample data (useful for cross-validation)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/yardstick/index.html&#34;&gt;{yardstick}&lt;/a&gt; to evaluate model performance&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/dials/index.html&#34;&gt;{dials}&lt;/a&gt; to define tuning parameters of your models&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/tune/&#34;&gt;{tune}&lt;/a&gt; for model tuning&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tidymodels.github.io/workflows/&#34;&gt;{workflows}&lt;/a&gt; which allows you to bundle everything together and train models easily&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are some others, but I will not cover these. This is a lot of packages, and you might be
worried of getting lost; however, in practice I noticed that loading &lt;code&gt;{tidymodels}&lt;/code&gt; and then using
the functions I needed was good enough. Only rarely did I need to know from which package a certain
function came, and the more you use these, the better you know them, obviously. Before continuing,
one final and important note: these packages are still in heavy development, so you might not want
to use them in production yet. I don’t know how likely it is that the api still evolves, but my guess
is that it is likely. However, even though it might be a bit early to use these packages for production
code, I think it is important to learn about them as soon as possible and see what is possible with them.&lt;/p&gt;
&lt;p&gt;As I will show you, these packages do make the process of training machine learning models a breeze, and of
course they integrate very well with the rest of the &lt;code&gt;{tidyverse}&lt;/code&gt; packages. The problem we’re going
to tackle is to understand which variables play an important role in the probability of someone looking
for a job. I’ll use Eustat’s microdata, which I already discussed in my &lt;a href=&#34;https://www.brodrigues.co/blog/2020-02-23-synthpop/&#34;&gt;previous blog post&lt;/a&gt;.
The dataset can be downloaded from &lt;a href=&#34;https://en.eustat.eus/estadisticas/tema_37/opt_0/tipo_11/temas.html&#34;&gt;here&lt;/a&gt;, and is called
&lt;em&gt;Population with relation to activity (PRA)&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem-at-hand&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem at hand&lt;/h2&gt;
&lt;p&gt;The dataset contains information on residents from the Basque country, and focuses on their labour supply.
Thus, we have information on how many hours people work a week, if they work, in which industry, what
is their educational attainment and whether they’re looking for a job.
The first step, as usual, is to load the data and required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidymodels)
library(readxl)
library(naniar)
library(janitor)
library(furrr)

list_data &amp;lt;- Sys.glob(&amp;quot;~/Documents/b-rodrigues.github.com/content/blog/MICRO*.csv&amp;quot;)

dataset &amp;lt;- map(list_data, read_csv2) %&amp;gt;%
  bind_rows()

dictionary &amp;lt;- read_xlsx(&amp;quot;~/Documents/b-rodrigues.github.com/content/blog/Microdatos_PRA_2019/diseño_registro_microdatos_pra.xlsx&amp;quot;, sheet=&amp;quot;Valores&amp;quot;,
                        col_names = FALSE)

col_names &amp;lt;- dictionary %&amp;gt;%
  filter(!is.na(...1)) %&amp;gt;%
  dplyr::select(1:2)

english &amp;lt;- readRDS(&amp;quot;~/Documents/b-rodrigues.github.com/content/blog/english_col_names.rds&amp;quot;)

col_names$english &amp;lt;- english

colnames(dataset) &amp;lt;- col_names$english

dataset &amp;lt;- janitor::clean_names(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 33
##   household_number survey_year reference_quart… territory capital   sex
##              &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1                1        2019                1 48              9     6
## 2                1        2019                1 48              9     1
## 3                2        2019                1 48              1     1
## 4                2        2019                1 48              1     6
## 5                2        2019                1 48              1     6
## 6                2        2019                1 48              1     1
## # … with 27 more variables: place_of_birth &amp;lt;dbl&amp;gt;, age &amp;lt;chr&amp;gt;, nationality &amp;lt;dbl&amp;gt;,
## #   level_of_studies_completed &amp;lt;dbl&amp;gt;, ruled_teaching_system &amp;lt;chr&amp;gt;,
## #   occupational_training &amp;lt;chr&amp;gt;, retirement_situation &amp;lt;dbl&amp;gt;,
## #   homework_situation &amp;lt;dbl&amp;gt;, part_time_employment &amp;lt;dbl&amp;gt;,
## #   short_time_cause &amp;lt;dbl&amp;gt;, job_search &amp;lt;chr&amp;gt;, search_reasons &amp;lt;dbl&amp;gt;,
## #   day_searched &amp;lt;dbl&amp;gt;, make_arrangements &amp;lt;chr&amp;gt;, search_form &amp;lt;chr&amp;gt;,
## #   search_months &amp;lt;dbl&amp;gt;, availability &amp;lt;chr&amp;gt;,
## #   relationship_with_the_activity &amp;lt;dbl&amp;gt;,
## #   relationship_with_the_activity_2 &amp;lt;chr&amp;gt;, main_occupation &amp;lt;dbl&amp;gt;,
## #   main_activity &amp;lt;chr&amp;gt;, main_professional_situation &amp;lt;dbl&amp;gt;,
## #   main_institutional_sector &amp;lt;dbl&amp;gt;, type_of_contract &amp;lt;dbl&amp;gt;, hours &amp;lt;dbl&amp;gt;,
## #   relationship &amp;lt;dbl&amp;gt;, elevator &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are many columns, most of them are categorical variables and unfortunately the levels in the
data are only some non-explicit codes. The excel file I have loaded, which I called &lt;code&gt;dictionary&lt;/code&gt;
contains the codes and their explanation. I kept the file opened while I was working, especially for
missing values imputation. Indeed, there are missing values in the data, and one should always try
to understand why before blindly imputing them. Indeed, there might be a very good reason why data
might be missing for a particular column. For instance, if children are also surveyed, they would
have an &lt;code&gt;NA&lt;/code&gt; in the, say, &lt;code&gt;main_occupation&lt;/code&gt; column which gives the main occupation of the surveyed
person. This might seem very obvious, but sometimes these reasons are not so obvious at all. You should
always go back with such questions to the data owners/producers, because if not, you will certainly
miss something very important. Anyway, the way I tackled this issue was by looking at the variables
with missing data and checking two-way tables with other variables. For instance, to go back to my
example from before, I would take a look at the two-way frequency table between &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;main_occupation&lt;/code&gt;.
If all the missing values from &lt;code&gt;main_occupation&lt;/code&gt; where only for people 16 or younger, then it would
be quite safe to assume that I was right, and I could recode these &lt;code&gt;NA&lt;/code&gt;s in &lt;code&gt;main_occupation&lt;/code&gt; to
&lt;code&gt;&amp;quot;without occupation&amp;quot;&lt;/code&gt; for instance. I’ll spare you all this exploration, and go straight to the
data cleaning:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- dataset %&amp;gt;%
  mutate(main_occupation2 = ifelse(is.na(main_occupation),
                                   &amp;quot;without_occupation&amp;quot;,
                                   main_occupation))

dataset &amp;lt;- dataset %&amp;gt;%
  mutate(main_professional_situation2 = ifelse(is.na(main_professional_situation),
                                               &amp;quot;without_occupation&amp;quot;,
                                               main_professional_situation))

# People with missing hours are actually not working, so I put them to 0
dataset &amp;lt;- dataset %&amp;gt;%
  mutate(hours = ifelse(is.na(hours), 0, hours))

# Short time gives the reason why people are working less hours than specified in their contract
dataset &amp;lt;- dataset %&amp;gt;%
  mutate(short_time_cause = ifelse(hours == 0 | is.na(short_time_cause), 
                                   &amp;quot;without_occupation&amp;quot;,
                                   short_time_cause))

dataset &amp;lt;- dataset %&amp;gt;%
  mutate(type_of_contract = ifelse(is.na(type_of_contract),
                                   &amp;quot;other_contract&amp;quot;,
                                   type_of_contract))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now apply some further cleaning:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra &amp;lt;- dataset %&amp;gt;%
  filter(age %in% c(&amp;quot;04&amp;quot;, &amp;quot;05&amp;quot;, &amp;quot;06&amp;quot;, &amp;quot;07&amp;quot;, &amp;quot;08&amp;quot;, &amp;quot;09&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11&amp;quot;, &amp;quot;12&amp;quot;, &amp;quot;13&amp;quot;)) %&amp;gt;%
  filter(retirement_situation == 4) %&amp;gt;%    
  filter(!is.na(job_search)) %&amp;gt;%  
  select(capital, sex, place_of_birth, age, nationality, level_of_studies_completed,
         occupational_training, job_search, main_occupation2, type_of_contract,
         hours, short_time_cause, homework_situation,
         main_professional_situation2) %&amp;gt;%
  mutate_at(.vars = vars(-hours), .funs=as.character) %&amp;gt;%
  mutate(job_search = as.factor(job_search))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I only keep people that are not retired and of ages where they could work. I remove rows where
&lt;code&gt;job_search&lt;/code&gt;, the target, is missing, mutate all variables but &lt;code&gt;hours&lt;/code&gt; to character and &lt;code&gt;job_search&lt;/code&gt; to factor. At
first, I made every categorical column a factor but I got problems for certain models. I think the
issue came from the recipe that I defined (I’ll talk about it below), but the problem was resolved
if categorical variables were defined as character variables. However, for certain models, the target
(I think it was &lt;code&gt;xgboost&lt;/code&gt;) needs to be a factor variable for classification problems.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the data and check if any more data is missing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(pra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;spec_tbl_df&amp;#39;, &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;: 29083 obs. of  14 variables:
##  $ capital                     : chr  &amp;quot;9&amp;quot; &amp;quot;9&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; ...
##  $ sex                         : chr  &amp;quot;6&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;6&amp;quot; ...
##  $ place_of_birth              : chr  &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; ...
##  $ age                         : chr  &amp;quot;09&amp;quot; &amp;quot;09&amp;quot; &amp;quot;11&amp;quot; &amp;quot;10&amp;quot; ...
##  $ nationality                 : chr  &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; &amp;quot;1&amp;quot; ...
##  $ level_of_studies_completed  : chr  &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;3&amp;quot; ...
##  $ occupational_training       : chr  &amp;quot;N&amp;quot; &amp;quot;N&amp;quot; &amp;quot;N&amp;quot; &amp;quot;N&amp;quot; ...
##  $ job_search                  : Factor w/ 2 levels &amp;quot;N&amp;quot;,&amp;quot;S&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ main_occupation2            : chr  &amp;quot;5&amp;quot; &amp;quot;7&amp;quot; &amp;quot;3&amp;quot; &amp;quot;2&amp;quot; ...
##  $ type_of_contract            : chr  &amp;quot;1&amp;quot; &amp;quot;other_contract&amp;quot; &amp;quot;other_contract&amp;quot; &amp;quot;1&amp;quot; ...
##  $ hours                       : num  36 40 40 40 0 0 22 38 40 0 ...
##  $ short_time_cause            : chr  &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; ...
##  $ homework_situation          : chr  &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; &amp;quot;2&amp;quot; ...
##  $ main_professional_situation2: chr  &amp;quot;4&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vis_miss(pra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-03-08-tidymodels_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The final dataset contains 29083 observations. Look’s like we’re good to go.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-the-training-resampling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setting up the training: resampling&lt;/h2&gt;
&lt;p&gt;In order to properly train a model, one needs to split the data into two: a part for trying out
models with different configuration of hyper-parameters, and another part for final evaluation of
the model. This is achieved with &lt;code&gt;rsample::initial_split()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra_split &amp;lt;- initial_split(pra, prop = 0.9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;pra_split&lt;/code&gt; now contains a training set and a testing set. We can get these by using the
&lt;code&gt;rsample::training()&lt;/code&gt; and &lt;code&gt;rsample::testing()&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra_train &amp;lt;- training(pra_split)
pra_test &amp;lt;- testing(pra_split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can’t stop here though. First we need to split the training set further, in order to perform
cross validation. Cross validation will allow us to select the best model; by best I mean a model
that has a good hyper-parameter configuration, enabling the model to generalize well to unseen data.
I do this by creating 10 splits from the training data (I won’t touch the testing data up until
the very end. This testing data is thus sometimes called the holdout set as well):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra_cv_splits &amp;lt;- vfold_cv(pra_train, v = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at this object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra_cv_splits&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## #  10-fold cross-validation 
## # A tibble: 10 x 2
##    splits               id    
##    &amp;lt;named list&amp;gt;         &amp;lt;chr&amp;gt; 
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;preprocessing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preprocessing the data&lt;/h2&gt;
&lt;p&gt;I have already pre-processed the missing values in the dataset, so there is not much more that
I can do. I will simply create dummy variables out of the categorical variables using &lt;code&gt;step_dummy()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;preprocess &amp;lt;- recipe(job_search ~ ., data = pra) %&amp;gt;%
  step_dummy(all_predictors())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;preprocess&lt;/code&gt; is a recipe that defines the transformations that must be applied to the training data
before fitting. In this case there is only one step; transforming all the predictors into dummies
(&lt;code&gt;hours&lt;/code&gt; is a numeric variable and will be ignored by this step). The recipe also defines the
formula that will be fitted by the models, &lt;code&gt;job_search ~ .&lt;/code&gt;, and takes &lt;code&gt;data&lt;/code&gt; as a further argument.
This is only to give the data frame specification to &lt;code&gt;recipe()&lt;/code&gt;: it could even be an empty data frame
with the right column names and types. This is why I give it the original data &lt;code&gt;pra&lt;/code&gt; and not the
training set &lt;code&gt;pra_train&lt;/code&gt;. Because this recipe is very simple, it could be applied to the original
raw data &lt;code&gt;pra&lt;/code&gt; and then I could do the split into training and testing set, as well as further
splitting the training set into 10 cross-validation sets. However, this is not the recommended way
of applying pre-processing steps. Pre-processing needs to happen inside the cross-validation loop,
not outside of it. Why? Suppose that you are normalizing a numeric variable, meaning, substracting
its mean from it and dividing by its standard deviation. If you do this operation outside of
cross-validation, and even worse, before splitting the data into training and testing set, you will
be leaking information from the testing set into the training set. The mean will contain information
from the testing set, which will be picked up by the model.
It is much better and “realistic” to first split the data and then apply
the pre-processing (remember that &lt;em&gt;hiding&lt;/em&gt; the test set from the model is supposed to simulate
the fact that new, completely unseen data, is thrown at your model once it’s put into production). The
same logic applies to cross-validation splits; each split contains now also a training and a testing
set (which I will be calling analysis and assessment sets, following &lt;code&gt;{tidymodels}&lt;/code&gt;’s author,
&lt;a href=&#34;https://twitter.com/topepos/status/1066131042615140353?s=20&#34;&gt;Max Kuhn&lt;/a&gt;) and thus the pre-processing
needs to be applied inside the cross-validation loop, meaning that the analysis set will be processed
on the fly.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-definition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model definition&lt;/h2&gt;
&lt;p&gt;We come now to the very interesting part: model definition. With &lt;code&gt;{parsnip}&lt;/code&gt;, another &lt;code&gt;{tidymodels}&lt;/code&gt;
package, defining models is always the same, regardless of the underlying package doing the heavy
lifting. For instance, to define a logistic regression one would simply write:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# logistic regression 
logit_tune_pra &amp;lt;- logistic_reg() %&amp;gt;%
  set_engine(&amp;quot;glm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This defines a standard logistic regression, powered by the &lt;code&gt;glm()&lt;/code&gt; &lt;em&gt;engine&lt;/em&gt; or function. The way
to do this in vanilla R would be :&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm(y ~ ., data = mydata, family = &amp;quot;binomial&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The difference here is that the formula is contained in the &lt;code&gt;glm()&lt;/code&gt; function; in our case it is
contained in the recipe, which is why I don’t repeat it in the model definition above. You might
wonder what the added value of using &lt;code&gt;{tidymodels}&lt;/code&gt; for this is. Well, suppose now that I would like
to run a logistic regression but with regularization. I would use &lt;code&gt;{glmnet}&lt;/code&gt; for this but would need
to know the specific syntax of &lt;code&gt;glmnet()&lt;/code&gt; which, as you will see, is very different than the one
for &lt;code&gt;glm()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  glmnet(x_vars[train,], y_var[train], alpha = 1, lambda = 1.6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;glmnet()&lt;/code&gt;, unlike &lt;code&gt;glm()&lt;/code&gt;, does not use a formula as an input, but two matrices, one for the design
matrix, and another for the target variable. Using &lt;code&gt;{parsnip}&lt;/code&gt;, however, I simply need to change the
engine from &lt;code&gt;&amp;quot;glm&amp;quot;&lt;/code&gt; to &lt;code&gt;&amp;quot;glmnet&amp;quot;&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# logistic regression 
logit_tune_pra &amp;lt;- logistic_reg() %&amp;gt;%
  set_engine(&amp;quot;glmnet&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes things much simpler as now users only need to learn how to use &lt;code&gt;{parsnip}&lt;/code&gt;. However,
it is of course still important to read the documentation of the original packages, because it is
were hyper-parameters are discussed. Another advantage of &lt;code&gt;{parsnip}&lt;/code&gt; is that the same words
are used to speak of the same hyper-parameters . For instance for tree-based methods, the number of
trees is sometimes &lt;code&gt;ntree&lt;/code&gt; then in another package &lt;code&gt;num_trees&lt;/code&gt;, and is again different in yet another package.
In &lt;code&gt;{parsnip}&lt;/code&gt;’s interface for tree-based methods, this parameter is simply
called &lt;code&gt;tree&lt;/code&gt;. Users can fix the value of hyper-parameters directly by passing values to, say, &lt;code&gt;tree&lt;/code&gt;
(as in &lt;code&gt;&amp;quot;tree&amp;quot; = 200&lt;/code&gt;), or they can tune these hyper-parameters. To do so, one needs to tag them, like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# logistic regression 
logit_tune_pra &amp;lt;- logistic_reg(penalty = tune(), mixture = tune()) %&amp;gt;%
  set_engine(&amp;quot;glmnet&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This defines &lt;code&gt;logit_tune_pra&lt;/code&gt; with 2 hyper-parameters that must be tuned using cross-validation,
the penalty and the amount of mixture between penalties (this is for elasticnet regularization).&lt;/p&gt;
&lt;p&gt;Now, I will define 5 different models, with different hyper-parameters to tune, and I will also
define a grid of hyper-parameters of size 10 for each model. This means that I will train these 5
models 10 times, each time with a different hyper-parameter configuration. To define the grid, I use
the &lt;code&gt;grid_max_entropy()&lt;/code&gt; function from the &lt;code&gt;{dials}&lt;/code&gt; package. This creates a grid with points that
are randomly drawn from the parameter space in a way that ensures that the combination we get
covers the whole space, or at least are not too far away from any portion of the space. Of course,
the more configuration you try, the better, but the longer the training will run.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Logistic regression
logit_tune_pra &amp;lt;- logistic_reg(penalty = tune(), mixture = tune()) %&amp;gt;%
  set_engine(&amp;quot;glmnet&amp;quot;)

# Hyperparameter grid
logit_grid &amp;lt;- logit_tune_pra %&amp;gt;%
  parameters() %&amp;gt;%
  grid_max_entropy(size = 10)

# Workflow bundling every step 
logit_wflow &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(logit_tune_pra)

# random forest
rf_tune_pra &amp;lt;- rand_forest(mtry = tune(), trees = tune()) %&amp;gt;%
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

rf_grid &amp;lt;- rf_tune_pra %&amp;gt;%
  parameters() %&amp;gt;%
  finalize(select(pra, -job_search)) %&amp;gt;%  
  grid_max_entropy(size = 10)

rf_wflow &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(rf_tune_pra)

# mars model
mars_tune_pra &amp;lt;- mars(num_terms = tune(), prod_degree = 2, prune_method = tune()) %&amp;gt;%
  set_engine(&amp;quot;earth&amp;quot;) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

mars_grid &amp;lt;- mars_tune_pra %&amp;gt;%
  parameters() %&amp;gt;%
  grid_max_entropy(size = 10)

mars_wflow &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(mars_tune_pra)

#boosted trees
boost_tune_pra &amp;lt;- boost_tree(mtry = tune(), tree = tune(),
                             learn_rate = tune(), tree_depth = tune()) %&amp;gt;%
  set_engine(&amp;quot;xgboost&amp;quot;) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

boost_grid &amp;lt;- boost_tune_pra %&amp;gt;%
  parameters() %&amp;gt;%
  finalize(select(pra, -job_search)) %&amp;gt;%  
  grid_max_entropy(size = 10)

boost_wflow &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(boost_tune_pra)

#neural nets
keras_tune_pra &amp;lt;- mlp(hidden_units = tune(), penalty = tune(), activation = &amp;quot;relu&amp;quot;) %&amp;gt;%
  set_engine(&amp;quot;keras&amp;quot;) %&amp;gt;%
  set_mode(&amp;quot;classification&amp;quot;)

keras_grid &amp;lt;- keras_tune_pra %&amp;gt;%
  parameters() %&amp;gt;%
  grid_max_entropy(size = 10)

keras_wflow &amp;lt;- workflow() %&amp;gt;%
  add_recipe(preprocess) %&amp;gt;%
  add_model(keras_tune_pra)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For each model, I defined three objects; the model itself, for instance &lt;code&gt;keras_tune_pra&lt;/code&gt;, then a
grid of hyper-parameters, and finally a workflow. To define the grid, I need to extract the parameters
to tune using the &lt;code&gt;parameters()&lt;/code&gt; function, and for tree based methods, I also need to use &lt;code&gt;finalize()&lt;/code&gt;
to set the &lt;code&gt;mtry&lt;/code&gt; parameter. This is because &lt;code&gt;mtry&lt;/code&gt; depends on the dimensions of the data (the value
of &lt;code&gt;mtry&lt;/code&gt; cannot be larger than the number of features), so I need to pass on this information
to…well, finalize the grid. Then I can choose the size of the grid and how I want to create it
(randomly, or using max entropy, or regularly spaced…).
A workflow bundles the pre-processing and the model definition together, and makes fitting the model
very easy. Workflows make it easy to run the pre-processing inside the cross-validation loop.
Workflow objects can be passed to the fitting function, as we shall see in the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-models-with-tidymodels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting models with &lt;code&gt;{tidymodels}&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Fitting one model with &lt;code&gt;{tidymodels}&lt;/code&gt; is quite easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted_model &amp;lt;- fit(model_formula, data = data_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and that’s it. If you define a workflow, which bundles pre-processing and model definition
in one package, you need to pass it to &lt;code&gt;fit()&lt;/code&gt; as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted_wflow &amp;lt;- fit(model_wflow, data = data_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, a single call to fit does not perform cross-validation. This simply trains the model on
the training data, and that’s it. To perform cross validation, you can use either &lt;code&gt;fit_resamples()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted_resamples &amp;lt;- fit_resamples(model_wflow,
                               resamples = my_cv_splits,
                               control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or &lt;code&gt;tune_grid()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tuned_model &amp;lt;- tune_grid(model_wflow,
                         resamples = my_cv_splits,
                         grid = my_grid,
                         control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you probably guessed it, &lt;code&gt;fit_resamples()&lt;/code&gt; does not perform tuning; it simply fits a model
specification (without varying hyper-parameters) to all the analysis sets contained in the
&lt;code&gt;my_cv_splits&lt;/code&gt; object (which contains the resampled training data for cross-validation), while
&lt;code&gt;tune_grid()&lt;/code&gt; does the same, but allows for varying hyper-parameters.&lt;/p&gt;
&lt;p&gt;We thus are going to use &lt;code&gt;tune_grid()&lt;/code&gt; to fit our models and perform hyper-paramater tuning.
However, since I have 5 models and 5 grids, I’ll be using &lt;code&gt;map2()&lt;/code&gt; for this. If you’re not familiar
with &lt;code&gt;map2()&lt;/code&gt;, here’s a quick example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map2(c(1, 1, 1), c(2,2,2), `+`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 3
## 
## [[2]]
## [1] 3
## 
## [[3]]
## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;map2()&lt;/code&gt; maps the &lt;code&gt;+()&lt;/code&gt; function to each element of both vectors successively. I’m going to use
this to map the &lt;code&gt;tune_grid()&lt;/code&gt; function to a list of models and a list of grids. But because this is
going to take some time to run, and because I have an AMD Ryzen 5 1600X processor with 6 physical
cores and 12 logical cores, I’ll by running this in parallel using &lt;code&gt;furrr::future_map2()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;furrr::future_map2()&lt;/code&gt; will run one model per core, and the way to do it is to simply define
how many cores I want to use, then replace &lt;code&gt;map2()&lt;/code&gt; in my code by &lt;code&gt;future_map2()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wflow_list &amp;lt;- list(logit_wflow, rf_wflow, mars_wflow, boost_wflow, keras_wflow)
grid_list &amp;lt;- list(logit_grid, rf_grid, mars_grid, boost_grid, keras_grid)

plan(multiprocess, workers = 6)

trained_models_list &amp;lt;- future_map2(.x = wflow_list,
                                   .y = grid_list,
                                   ~tune_grid(.x , resamples = pra_cv_splits, grid = .y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running this code took almost 3 hours. In the end, here is the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trained_models_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[2]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[3]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[4]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 7]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 
## [[5]]
## #  10-fold cross-validation 
## # A tibble: 10 x 4
##    splits               id     .metrics          .notes          
##  * &amp;lt;list&amp;gt;               &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;          
##  1 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold01 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  2 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold02 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  3 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold03 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  4 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold04 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  5 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold05 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  6 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold06 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  7 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold07 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  8 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold08 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
##  9 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold09 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;
## 10 &amp;lt;split [23.6K/2.6K]&amp;gt; Fold10 &amp;lt;tibble [20 × 5]&amp;gt; &amp;lt;tibble [1 × 1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now have a list of 5 tibbles containing the analysis/assessment splits, the id identifying the
cross-validation fold, a list-column containing information on model performance for that given
split and some notes (if everything goes well, notes are empty). Let’s take a look at the column
&lt;code&gt;.metrics&lt;/code&gt; of the first model and for the first fold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trained_models_list[[1]]$.metrics[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 5
##     penalty mixture .metric  .estimator .estimate
##       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
##  1 4.25e- 3  0.0615 accuracy binary         0.906
##  2 4.25e- 3  0.0615 roc_auc  binary         0.895
##  3 6.57e-10  0.0655 accuracy binary         0.908
##  4 6.57e-10  0.0655 roc_auc  binary         0.897
##  5 1.18e- 6  0.167  accuracy binary         0.908
##  6 1.18e- 6  0.167  roc_auc  binary         0.897
##  7 2.19e-10  0.371  accuracy binary         0.907
##  8 2.19e-10  0.371  roc_auc  binary         0.897
##  9 2.73e- 1  0.397  accuracy binary         0.885
## 10 2.73e- 1  0.397  roc_auc  binary         0.5  
## 11 1.72e- 6  0.504  accuracy binary         0.907
## 12 1.72e- 6  0.504  roc_auc  binary         0.897
## 13 1.25e- 9  0.633  accuracy binary         0.907
## 14 1.25e- 9  0.633  roc_auc  binary         0.897
## 15 6.62e- 6  0.880  accuracy binary         0.907
## 16 6.62e- 6  0.880  roc_auc  binary         0.897
## 17 6.00e- 1  0.899  accuracy binary         0.885
## 18 6.00e- 1  0.899  roc_auc  binary         0.5  
## 19 4.57e-10  0.989  accuracy binary         0.907
## 20 4.57e-10  0.989  roc_auc  binary         0.897&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows how the 10 different configurations of the elasticnet model performed. To see how the
model performed on the second fold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trained_models_list[[1]]$.metrics[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 5
##     penalty mixture .metric  .estimator .estimate
##       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
##  1 4.25e- 3  0.0615 accuracy binary         0.913
##  2 4.25e- 3  0.0615 roc_auc  binary         0.874
##  3 6.57e-10  0.0655 accuracy binary         0.913
##  4 6.57e-10  0.0655 roc_auc  binary         0.877
##  5 1.18e- 6  0.167  accuracy binary         0.913
##  6 1.18e- 6  0.167  roc_auc  binary         0.878
##  7 2.19e-10  0.371  accuracy binary         0.913
##  8 2.19e-10  0.371  roc_auc  binary         0.878
##  9 2.73e- 1  0.397  accuracy binary         0.901
## 10 2.73e- 1  0.397  roc_auc  binary         0.5  
## 11 1.72e- 6  0.504  accuracy binary         0.913
## 12 1.72e- 6  0.504  roc_auc  binary         0.878
## 13 1.25e- 9  0.633  accuracy binary         0.913
## 14 1.25e- 9  0.633  roc_auc  binary         0.878
## 15 6.62e- 6  0.880  accuracy binary         0.913
## 16 6.62e- 6  0.880  roc_auc  binary         0.878
## 17 6.00e- 1  0.899  accuracy binary         0.901
## 18 6.00e- 1  0.899  roc_auc  binary         0.5  
## 19 4.57e-10  0.989  accuracy binary         0.913
## 20 4.57e-10  0.989  roc_auc  binary         0.878&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hyper-Parameters are the same; it is only the cross validation fold that is different. To get the
best performing model from such objects you can use &lt;code&gt;show_best()&lt;/code&gt; which will extract the best
performing models across all the cross validation folds:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;show_best(trained_models_list[[1]], metric = &amp;quot;accuracy&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##    penalty mixture .metric  .estimator  mean     n std_err
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 6.57e-10  0.0655 accuracy binary     0.916    10 0.00179
## 2 1.18e- 6  0.167  accuracy binary     0.916    10 0.00180
## 3 1.72e- 6  0.504  accuracy binary     0.916    10 0.00182
## 4 4.57e-10  0.989  accuracy binary     0.916    10 0.00181
## 5 6.62e- 6  0.880  accuracy binary     0.916    10 0.00181&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows the 5 best configurations for elasticnet when looking at accuracy. Now how to get the best
performing elasticnet regression, random forest, boosted trees, etc? Easy, using &lt;code&gt;map()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(trained_models_list, show_best, metric = &amp;quot;accuracy&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 5 x 7
##    penalty mixture .metric  .estimator  mean     n std_err
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 6.57e-10  0.0655 accuracy binary     0.916    10 0.00179
## 2 1.18e- 6  0.167  accuracy binary     0.916    10 0.00180
## 3 1.72e- 6  0.504  accuracy binary     0.916    10 0.00182
## 4 4.57e-10  0.989  accuracy binary     0.916    10 0.00181
## 5 6.62e- 6  0.880  accuracy binary     0.916    10 0.00181
## 
## [[2]]
## # A tibble: 5 x 7
##    mtry trees .metric  .estimator  mean     n std_err
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1    13  1991 accuracy binary     0.929    10 0.00172
## 2    13  1180 accuracy binary     0.929    10 0.00168
## 3    12   285 accuracy binary     0.928    10 0.00168
## 4     8  1567 accuracy binary     0.927    10 0.00171
## 5     8   647 accuracy binary     0.927    10 0.00191
## 
## [[3]]
## # A tibble: 5 x 7
##   num_terms prune_method .metric  .estimator  mean     n std_err
##       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1         5 backward     accuracy binary     0.904    10 0.00186
## 2         5 forward      accuracy binary     0.902    10 0.00185
## 3         4 exhaustive   accuracy binary     0.901    10 0.00167
## 4         4 seqrep       accuracy binary     0.901    10 0.00167
## 5         2 backward     accuracy binary     0.896    10 0.00209
## 
## [[4]]
## # A tibble: 5 x 9
##    mtry trees tree_depth learn_rate .metric  .estimator  mean     n std_err
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1    12  1245         12   7.70e- 2 accuracy binary     0.929    10 0.00175
## 2     1   239          8   8.23e- 2 accuracy binary     0.927    10 0.00186
## 3     1   835         14   8.53e-10 accuracy binary     0.913    10 0.00232
## 4     4  1522         12   2.22e- 5 accuracy binary     0.896    10 0.00209
## 5     6   313          2   1.21e- 8 accuracy binary     0.896    10 0.00209
## 
## [[5]]
## # A tibble: 5 x 7
##   hidden_units  penalty .metric  .estimator  mean     n std_err
##          &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1           10 3.07e- 6 accuracy binary     0.917    10 0.00209
## 2            6 1.69e-10 accuracy binary     0.917    10 0.00216
## 3            4 2.32e- 7 accuracy binary     0.916    10 0.00194
## 4            7 5.52e- 5 accuracy binary     0.916    10 0.00163
## 5            8 1.13e- 9 accuracy binary     0.916    10 0.00173&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we need to test these models on the holdout set, but this post is already quite long. In the next
blog post, I will retrain the top best performing models for each type of model and see how they
fare against the holdout set. I’ll be also looking at explainability, so stay tuned!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and watch my
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;. If you want to support
my blog and channel, you could &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or
&lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Synthetic micro-datasets: a promising middle ground between data privacy and data analysis</title>
      <link>https://www.brodrigues.co/blog/2020-02-23-synthpop/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-02-23-synthpop/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/scienceshitpost/status/1218199897654120449&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/fake_car.png&#34; title = &#34;A purpoise can be assumed to be a kind of fake car.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;intro-the-need-for-microdata-and-the-risk-of-disclosure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro: the need for microdata, and the risk of disclosure&lt;/h2&gt;
&lt;p&gt;Survey and administrative data are essential for scientific research, however accessing such datasets
can be very tricky, or even impossible. In my previous job I was responsible for getting access to
such “scientific micro-datasets” from institutions like Eurostat.
In general, getting access to these micro datasets was only a question of filling out some forms
and signing NDAs. But this was true only because my previous employer was an accredited research entity.
Companies from the private sector or unaffiliated, individual, researchers cannot get access to
the microdata sets. This is because institutions that produce such datasets absolutely do not want
any type of personal information to be disclosed.&lt;/p&gt;
&lt;p&gt;For instance, with the labour force survey, a National Statistical Institute (NSI) collects
information about wages, family structure, educational attainment and much more.
If, say, a politician would answer to the survey and his answers would leak to the public that would
be disastrous for NSIs. So this is why access is restricted to accredited research institutions.
You may be asking yourself, “how could the politicians answers leak? The data is anonymized!”
Indeed it is, but in some cases that may not be enough to ensure that information does not get
disclosed. Suppose that the dataset contains enough information to allow you to know for certain
that you found said politician, assume that this politician is a 43 year old man, has two children,
a PhD in theology and lives in Strassen, one of Luxembourg-City very nice neighborhoods. It would be quite easy to
find him in the dataset and then find out his wage.&lt;/p&gt;
&lt;p&gt;To avoid this, researchers are required to perform output checking, which means going through the
set of outputs (summary tables, graphs, tables with regression coefficients…) and making sure that
it is not possible to find out individuals. For instance, in Luxembourg there are two companies in
the tobacco industry. Luxembourg’s NSI cannot release the total turnover
of the industry, because then company A would subtract its turnover from the total and find out its
competitor’s turnover. Now these are all hypothetical examples, and we might argue that the risk of
leakage is quite low, especially if NSIs make sure to lower the precision of the variables, by
providing age categories instead of the exact age for example. Or capping wages that exceed a certain
fixed amount.
In any case for now most NSIs don’t release micro data to the public, and this poses some challenges
for research. First of all, even for researchers, it would be great if the data was freely accessible.
It would allow research to go straight to data analysis and look at the structure of the data before
applying for access, with the risk of getting access to useless data.
And of course it would be great for the public at large to be able to freely access such data, for
educational purposes at the very least. It would also increase competition between research institutions
and the private sector when it comes to conducting studies using such data. Free access to the
microdata would level the playing field.
Now, some NSIs do release micro data to the public, see Eustat, the NSI from the Basque country,
an autonomous region of Spain. It is not clear to me if they also have more detailed data that is
only accessible to researchers, but the data they offer is already quite interesting.&lt;/p&gt;
&lt;p&gt;A middle ground between only releasing data to researchers and making it completely freely accessible
is to create a synthetic dataset, which does not contain any of the original records, but which still
allows to perform meaningful analyses.&lt;/p&gt;
&lt;p&gt;I’m not yet very familiar with the details of the procedure, but in this blog post I’ll use Eustat’s
microdata to generate a synthetic dataset. I’ll then perform the same analysis on both the original
dataset and the synthetic dataset. The dataset I’ll be using can be found
&lt;a href=&#34;https://en.eustat.eus/estadisticas/tema_37/opt_0/tipo_11/temas.html&#34;&gt;here&lt;/a&gt;, and is called
&lt;em&gt;Population with relation to activity (PRA)&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The Survey on the Population in Relation to Activity operation is a continuous source of
information on the characteristics and dynamics of the labour force of the Basque Country.
It records the relation to productive activity of the population resident in family households,
as well as the changes produced in labour situations; it produces indicators of conjunctural
variations in the evolution of the active population; it also estimates the degree of participation
of the population in economically non-productive activities. It offers information on the province
and capital level.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’ll then compare the results of the analyses performed on the two datasets which will hopefully be
very similar. To create the synthetic dataset, I’ll be using the &lt;code&gt;{synthpop}&lt;/code&gt; package. You can read
the detailed vignette &lt;a href=&#34;https://cran.r-project.org/web/packages/synthpop/vignettes/synthpop.pdf&#34;&gt;here - pdf warning -&lt;/a&gt;.
First, let me perform some cleaning steps. There are four datasets included in the
archive. Let’s load them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidymodels)
library(readxl)
library(synthpop)

list_data &amp;lt;- Sys.glob(&amp;quot;MICRO*.csv&amp;quot;)

dataset &amp;lt;- map(list_data, read_csv2) %&amp;gt;%
  bind_rows()

head(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The columns are labeled in Spanish so I’m copy pasting the labels into Google translate and paste
them back into my script. I saved the English names into the english.rds object for posterity.
These steps are detailed in the next lines:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dictionary &amp;lt;- read_xlsx(&amp;quot;Microdatos_PRA_2019/diseño_registro_microdatos_pra.xlsx&amp;quot;, sheet=&amp;quot;Valores&amp;quot;,
                        col_names = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New names:
## * `` -&amp;gt; ...1
## * `` -&amp;gt; ...2
## * `` -&amp;gt; ...3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;col_names &amp;lt;- dictionary %&amp;gt;%
  filter(!is.na(...1)) %&amp;gt;%
  dplyr::select(1:2)

# copy to clipboard, paste to google translate
# couldn&amp;#39;t be bothered to use an api and google cloud or whatever
#clipr::write_clip(col_names$`...2`)

#english &amp;lt;- clipr::read_clip()

english &amp;lt;- readRDS(&amp;quot;english_col_names.rds&amp;quot;)

col_names$english &amp;lt;- english

colnames(dataset) &amp;lt;- col_names$english

dataset &amp;lt;- janitor::clean_names(dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now create a function that will perform the cleaning steps:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;basic_cleaning &amp;lt;- function(dataset){
  dataset %&amp;gt;%
  dplyr::filter(age %in% c(&amp;quot;05&amp;quot;, &amp;quot;06&amp;quot;, &amp;quot;07&amp;quot;, &amp;quot;08&amp;quot;, &amp;quot;09&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;11&amp;quot;)) %&amp;gt;%
  dplyr::filter(!is.na(job_search)) %&amp;gt;%  
  dplyr::select(territory, capital, sex, place_of_birth, age, nationality, level_of_studies_completed,
                job_search, main_occupation, type_of_contract, hours) %&amp;gt;%
  dplyr::mutate_at(.vars = vars(-hours), .funs=as.factor)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-on-my-econometricians-hat&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Putting on my econometricians hat&lt;/h2&gt;
&lt;p&gt;Let’s now suppose that I’m only interested in running a logistic regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pra &amp;lt;- basic_cleaning(dataset)

head(pra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
##   territory capital sex   place_of_birth age   nationality level_of_studie…
##   &amp;lt;fct&amp;gt;     &amp;lt;fct&amp;gt;   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;           
## 1 48        9       6     1              09    1           1               
## 2 48        9       1     1              09    1           2               
## 3 48        1       1     1              11    1           3               
## 4 48        1       6     1              10    1           3               
## 5 48        9       6     1              07    1           3               
## 6 48        9       1     1              09    1           1               
## # … with 4 more variables: job_search &amp;lt;fct&amp;gt;, main_occupation &amp;lt;fct&amp;gt;,
## #   type_of_contract &amp;lt;fct&amp;gt;, hours &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logit_model &amp;lt;- glm(job_search ~ ., data = pra, family = binomial())

# Create a tidy dataset with the results of the regression
tidy_logit_model &amp;lt;- tidy(logit_model, conf.int = TRUE) %&amp;gt;%
  mutate(dataset = &amp;quot;true&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now take a look at the coefficients, by plotting their value along with their confidence
intervals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(tidy_logit_model, aes(x = term, y = estimate)) +
  geom_point(colour = &amp;quot;#82518c&amp;quot;) +
  geom_hline(yintercept = 0, colour = &amp;quot;red&amp;quot;) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), colour = &amp;quot;#657b83&amp;quot;) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, so now, how would the results change if I run the same analysis on the synthetic dataset? First,
I need to generate this synthetic dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_seed &amp;lt;- 1234

synthetic_data &amp;lt;- syn(pra, seed = my_seed)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Synthesis
## -----------
##  territory capital sex place_of_birth age nationality level_of_studies_completed job_search main_occupation type_of_contract
##  hours&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The synthetic data is generated by a single call to the &lt;code&gt;syn()&lt;/code&gt; function included in the &lt;code&gt;{synthpop}&lt;/code&gt;
package. Let’s take a look at the generated object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;synthetic_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call:
## ($call) syn(data = pra, seed = my_seed)
## 
## Number of synthesised data sets: 
## ($m)  1 
## 
## First rows of synthesised data set: 
## ($syn)
##   territory capital sex place_of_birth age nationality
## 1        48       9   1              1  06           1
## 2        01       9   6              3  09           1
## 3        48       3   1              1  08           1
## 4        48       9   6              1  11           1
## 5        20       2   6              1  09           1
## 6        48       1   6              1  11           1
##   level_of_studies_completed job_search main_occupation type_of_contract hours
## 1                          3          N               2                1    40
## 2                          1          S               9                6    10
## 3                          1          N               6             &amp;lt;NA&amp;gt;    32
## 4                          2          N               4                1    32
## 5                          3          N               5             &amp;lt;NA&amp;gt;    40
## 6                          1          S               7             &amp;lt;NA&amp;gt;    NA
## ...
## 
## Synthesising methods: 
## ($method)
##                  territory                    capital 
##                   &amp;quot;sample&amp;quot;                     &amp;quot;cart&amp;quot; 
##                        sex             place_of_birth 
##                     &amp;quot;cart&amp;quot;                     &amp;quot;cart&amp;quot; 
##                        age                nationality 
##                     &amp;quot;cart&amp;quot;                     &amp;quot;cart&amp;quot; 
## level_of_studies_completed                 job_search 
##                     &amp;quot;cart&amp;quot;                     &amp;quot;cart&amp;quot; 
##            main_occupation           type_of_contract 
##                     &amp;quot;cart&amp;quot;                     &amp;quot;cart&amp;quot; 
##                      hours 
##                     &amp;quot;cart&amp;quot; 
## 
## Order of synthesis: 
## ($visit.sequence)
##                  territory                    capital 
##                          1                          2 
##                        sex             place_of_birth 
##                          3                          4 
##                        age                nationality 
##                          5                          6 
## level_of_studies_completed                 job_search 
##                          7                          8 
##            main_occupation           type_of_contract 
##                          9                         10 
##                      hours 
##                         11 
## 
## Matrix of predictors: 
## ($predictor.matrix)
##                            territory capital sex place_of_birth age nationality
## territory                          0       0   0              0   0           0
## capital                            1       0   0              0   0           0
## sex                                1       1   0              0   0           0
## place_of_birth                     1       1   1              0   0           0
## age                                1       1   1              1   0           0
## nationality                        1       1   1              1   1           0
## level_of_studies_completed         1       1   1              1   1           1
## job_search                         1       1   1              1   1           1
## main_occupation                    1       1   1              1   1           1
## type_of_contract                   1       1   1              1   1           1
## hours                              1       1   1              1   1           1
##                            level_of_studies_completed job_search
## territory                                           0          0
## capital                                             0          0
## sex                                                 0          0
## place_of_birth                                      0          0
## age                                                 0          0
## nationality                                         0          0
## level_of_studies_completed                          0          0
## job_search                                          1          0
## main_occupation                                     1          1
## type_of_contract                                    1          1
## hours                                               1          1
##                            main_occupation type_of_contract hours
## territory                                0                0     0
## capital                                  0                0     0
## sex                                      0                0     0
## place_of_birth                           0                0     0
## age                                      0                0     0
## nationality                              0                0     0
## level_of_studies_completed               0                0     0
## job_search                               0                0     0
## main_occupation                          0                0     0
## type_of_contract                         1                0     0
## hours                                    1                1     0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, &lt;code&gt;synthetic_data&lt;/code&gt; is a list with several elements. The data is inside the &lt;code&gt;syn&lt;/code&gt; element.
Let’s extract it, and perform the same analysis from before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;syn_pra &amp;lt;- synthetic_data$syn

head(syn_pra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   territory capital sex place_of_birth age nationality
## 1        48       9   1              1  06           1
## 2        01       9   6              3  09           1
## 3        48       3   1              1  08           1
## 4        48       9   6              1  11           1
## 5        20       2   6              1  09           1
## 6        48       1   6              1  11           1
##   level_of_studies_completed job_search main_occupation type_of_contract hours
## 1                          3          N               2                1    40
## 2                          1          S               9                6    10
## 3                          1          N               6             &amp;lt;NA&amp;gt;    32
## 4                          2          N               4                1    32
## 5                          3          N               5             &amp;lt;NA&amp;gt;    40
## 6                          1          S               7             &amp;lt;NA&amp;gt;    NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;syn_pra &amp;lt;- basic_cleaning(syn_pra)

logit_model_syn &amp;lt;- glm(job_search ~ ., data = syn_pra, family = binomial())

tidy_logit_syn &amp;lt;- tidy(logit_model_syn, conf.int = TRUE) %&amp;gt;%
  mutate(dataset = &amp;quot;syn&amp;quot;)

ggplot(tidy_logit_syn, aes(x = term, y = estimate)) +
  geom_point(colour = &amp;quot;#82518c&amp;quot;) +
  geom_hline(yintercept = 0, colour = &amp;quot;red&amp;quot;) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), colour = &amp;quot;#657b83&amp;quot;) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To ease the comparison between the coefficients of the model, let’s create a single graph:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeff_models &amp;lt;- bind_rows(list(tidy_logit_model, tidy_logit_syn))

ggplot(coeff_models, aes(x = term, y = estimate, colour = dataset)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is quite interesting; generally, there is quite some overlap between the synthetic data and
the real data! There are some differences though, for instance, &lt;code&gt;main_occupation6&lt;/code&gt; is significant
with the synthetic data, but is not with the real data. There’s the possibility to generate more
than one synthetic dataset, which would very likely reduce the noise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;putting-on-my-data-scientist-hat&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Putting on my data scientist hat&lt;/h2&gt;
&lt;p&gt;Now let’s suppose that I am only interested into prediction. For this, I am going to split my dataset
into a training and testing set, then run a logistic regression and a random forest, assess the
models’ performance with 10-fold cross validation. I’ll do this on both the real and the synthetic
data. To perform the analysis, I’ll be using the &lt;code&gt;{tidymodels}&lt;/code&gt; framework; I’m going to explain
the code that follows line by line, because I’ll very likely write a blog post focusing on &lt;code&gt;{tidymodels}&lt;/code&gt;
soon.&lt;/p&gt;
&lt;p&gt;So, let’s write a function that does exactly what I explained above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;training_and_evaluating &amp;lt;- function(dataset){

  pra_split &amp;lt;- initial_split(dataset, prop = 0.8)
  
  pra_train &amp;lt;- training(pra_split)
  pra_test &amp;lt;- testing(pra_split)
  
  pra_cv_splits &amp;lt;- vfold_cv(pra_train, v = 10)
  
  preprocess &amp;lt;- recipe(job_search ~ ., data = pra) %&amp;gt;%
    step_knnimpute(all_predictors())
  
  logit_pra &amp;lt;- logistic_reg() %&amp;gt;%
    set_engine(&amp;quot;glm&amp;quot;)
  
  fitted_logit &amp;lt;- fit_resamples(preprocess,
                                model = logit_pra,
                                resamples = pra_cv_splits,
                                control = control_resamples(save_pred = TRUE))
  
  metric_logit &amp;lt;- fitted_logit$.metrics %&amp;gt;%
    bind_rows() %&amp;gt;%
    group_by(.metric) %&amp;gt;%
    summarise_at(.vars = vars(.estimate), .funs = lst(mean, sd)) %&amp;gt;%
    mutate(model = &amp;quot;logit&amp;quot;)
  
  rf_pra &amp;lt;- rand_forest(mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
    set_engine(engine = &amp;quot;ranger&amp;quot;)
  
  fitted_forest &amp;lt;- fit_resamples(preprocess,
                                model = rf_pra,
                                resamples = pra_cv_splits,
                                control = control_resamples(save_pred = TRUE))
  
  metric_forest &amp;lt;- fitted_forest$.metrics %&amp;gt;%
    bind_rows() %&amp;gt;%
    group_by(.metric) %&amp;gt;%
    summarise_at(.vars = vars(.estimate), .funs = lst(mean, sd)) %&amp;gt;%
    mutate(model = &amp;quot;forest&amp;quot;)


  bind_rows(list(metric_logit, metric_forest))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can run this function on both the real and the synthetic data, and look at the performance
of the logistic regression and of the random forest:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_data_performance &amp;lt;- training_and_evaluating(pra)

syn_data_performance &amp;lt;- training_and_evaluating(syn_pra)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_data_performance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 4
##   .metric   mean      sd model 
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 accuracy 0.882 0.00816 logit 
## 2 roc_auc  0.708 0.0172  logit 
## 3 accuracy 0.907 0.00619 forest
## 4 roc_auc  0.879 0.0123  forest&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;syn_data_performance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 4
##   .metric   mean      sd model 
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 accuracy 0.882 0.00758 logit 
## 2 roc_auc  0.691 0.0182  logit 
## 3 accuracy 0.899 0.00615 forest
## 4 roc_auc  0.857 0.0124  forest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The performance is pretty much the same!&lt;/p&gt;
&lt;p&gt;Generating synthetic data is a very promising approach, that I certainly will be using more; I think
that such approaches can also be very interesting in the private sector (not only to ease access
to microdata for researchers) especially within large
companies. For instance, it can happen that the data owners from say, an insurance company, are
not very keen on sharing sensitive client information with their data scientists. However, by generating
a synthetic dataset and sharing the synthetic data with their data science team, the data owners
avoid any chance of disclosure of sensitive information, while at the same time allowing their
data scientists to develop interesting analyses or applications on the data!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and watch my
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;. If you want to support
my blog and channel, you could &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or
&lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic discrete choice models, reinforcement learning and Harold, part 2</title>
      <link>https://www.brodrigues.co/blog/2020-02-08-harold_part2/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-02-08-harold_part2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/ZwRuneeLsCQ?t=229&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/bus.jpg&#34; title = &#34;very nice&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;In this blog post, I present a paper that has really interested me for a long time. This is part2,
where I will briefly present the model of the paper, and try to play around with the data.
If you haven’t, I suggest you read
&lt;a href=&#34;https://www.brodrigues.co/blog/2020-01-26-harold/&#34;&gt;part 1&lt;/a&gt; where I provide more context.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;rusts-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rust’s model&lt;/h2&gt;
&lt;p&gt;Welcome to part 2 of this series, which might or might not have a part 3. I have been quite busy
with this paper and especially with reinforcement learning these past couple of weeks, but in the
meantime, other &lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;things&lt;/a&gt; have taken
some of my time, so who knows if I’ll keep discussing this paper.&lt;/p&gt;
&lt;p&gt;Before going into the data, let me describe the model very broadly.
The problem is as follows: each month, Harold Zurcher must decide whether to simply perform some
basic maintenance on the buses he’s responsible for, or he can decide to completely replace the
engine. Let his utility function be as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
u(x_t, i_t, \theta_1) = \left\{
\begin{array}{lcl}
-c(x_t, \theta_1) &amp;amp; \text{if} &amp;amp; i_t = 0, \\
-[\overline{P} - \underline{P} + c(0, \theta_1)] &amp;amp; \text{if} &amp;amp; i_t = 1,\\
\end{array}\right.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt; is the state variable, the reading of the odometer at month &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(i_t\)&lt;/span&gt; is Harold Zurcher’s
decision at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(i_t = 0\)&lt;/span&gt; is the decision to keep the engine, &lt;span class=&#34;math inline&#34;&gt;\(i_t = 1\)&lt;/span&gt; is the decision to
replace. Each time the engine is replaced, the state variable &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt; regenerates to 0. That is why
John Rust, the paper’s author, calls the problem under study a regenerative optimal stopping model.
If &lt;span class=&#34;math inline&#34;&gt;\(i_t = 0\)&lt;/span&gt; (keep the engine) is chosen, then the cost of normal maintenance is &lt;span class=&#34;math inline&#34;&gt;\(c(x_t, \theta_1)\)&lt;/span&gt;,
if &lt;span class=&#34;math inline&#34;&gt;\(i_t = 1\)&lt;/span&gt; (change the engine) then the cost is &lt;span class=&#34;math inline&#34;&gt;\(\overline{P}\)&lt;/span&gt;, which is the price of the new
engine. However, it is still possible to sell the old engine for scrap value, &lt;span class=&#34;math inline&#34;&gt;\(\underline{P}\)&lt;/span&gt;. The
replacement cost is equal to &lt;span class=&#34;math inline&#34;&gt;\(c(0, \theta_1)\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(\theta_1\)&lt;/span&gt; is a vector of parameters of the
cost function to estimate.
Because Harold Zurcher is forward looking, and does not want to simply maximize the current month’s
utility, he seeks to maximize his intertemporal utility function. The optimal policy would be the
solution to the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_{\theta} = \max E\left\{ \sum_{j = t}^\infty \beta^{j-t}u(x_j, f_j, \theta_1) | x_t\right\}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is a so-called value function, which is the total reward at the solution of the problem.&lt;/p&gt;
&lt;p&gt;The state variable evolves according to a stochastic process given by the following transition
probability:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
p(x_{t+1} | x_t, i_t, \theta_2) = \left\{
\begin{array}{lllll}
\theta_2 \exp\{\theta_2(x_{t+1} - x_t)\} &amp;amp; \text{if} &amp;amp; i_t = 0 &amp;amp; \text{and} &amp;amp; x_{t+1} \geq x_t \\
\theta_2 \exp\{\theta_2(x_{t+1})\} &amp;amp; \text{if} &amp;amp; i_t = 0 &amp;amp; \text{and} &amp;amp; x_{t+1} \geq 0 \\
0 &amp;amp; \text{otherwise}\\
\end{array}\right.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\theta_2\)&lt;/span&gt; is the parameter of the exponential distribution, another parameter to estimate.
I’ll stop with one more equation, the Bellman equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
V_\theta(x_t) = \max_{i_t \in C(x_t)} [u(x_t, i_t, \theta_1) + \beta EV_\theta(x_t, i_t)]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(C(x_t) = {0, 1}\)&lt;/span&gt; is the action set. The value function is the unique solution to this Bellman equation.&lt;/p&gt;
&lt;p&gt;As you can see, this is quite complex (and I have not detailed everything!) but the advantage
of models is that one can estimate its structural parameters and put a dollar value on the expected
replacement cost, &lt;span class=&#34;math inline&#34;&gt;\(\overline{P} - \underline{P}\)&lt;/span&gt; in addition to validating the very first
hypothesis of the paper; does Harold Zurcher behave optimally?&lt;/p&gt;
&lt;p&gt;In what follows, I’ll use the &lt;code&gt;{ReinforcementLearning}&lt;/code&gt; package to try to find the optimal policy rule.
The optimal policy rule tells us what is the best action at each period. Reinforcement learning is
an approach that is widely used in machine learning to solve problems very similar to the one that
I described above. However, as we shall see, it will fail here, and there’s a very good reason
for that. First, let’s load the data that was prepared last time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_bus_data &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/rust/ee15fb87fc4ba5db28d055c97a898b328725f53c/datasets/processed_data/all_buses.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   bus_id = col_double(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   odometer_reading = col_double(),
##   replacement = col_double(),
##   bus_family = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(all_bus_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   bus_id date       odometer_reading replacement bus_family
##    &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;                &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     
## 1   4239 1974-12-01           140953           0 a452372   
## 2   4239 1975-01-01           142960           0 a452372   
## 3   4239 1975-02-01           145380           0 a452372   
## 4   4239 1975-03-01           148140           0 a452372   
## 5   4239 1975-04-01           150921           0 a452372   
## 6   4239 1975-05-01           153839           0 a452372&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the paper, the author groups the 4 following bus families, so I’ll be doing the same:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;family_group &amp;lt;- c(&amp;quot;g870&amp;quot;, &amp;quot;rt50&amp;quot;, &amp;quot;t8h203&amp;quot;, &amp;quot;a530875&amp;quot;)

group1_4 &amp;lt;- all_bus_data %&amp;gt;%
  filter(bus_family %in% family_group)

ggplot(group1_4) + 
  geom_line(aes(y = odometer_reading, x = date, group = bus_id, col = bus_family)) + 
  geom_point(aes(y = ifelse(odometer_reading*replacement == 0, NA, odometer_reading*replacement), 
                 x = date), col = &amp;quot;red&amp;quot;) +
  labs(title = paste0(&amp;quot;Odometer readings for bus families &amp;quot;, paste0(family_group, collapse = &amp;quot;, &amp;quot;)),
       caption = &amp;quot;The red dots are replacement events.&amp;quot;) + 
  theme(plot.caption = element_text(colour = &amp;quot;white&amp;quot;)) +
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 8200 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-02-08-harold_part2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are 104 buses in this subset of data. Let’s discretize
the odometer reading using the &lt;code&gt;ntile()&lt;/code&gt; function. Discretizing the state variable will make
computation faster:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group1_4 &amp;lt;- group1_4 %&amp;gt;%  
  mutate(state_at_replacement = ifelse(replacement == 1, odometer_reading, NA)) %&amp;gt;%
  group_by(bus_id) %&amp;gt;%
  fill(state_at_replacement, .direction = &amp;quot;down&amp;quot;) %&amp;gt;%
  ungroup() %&amp;gt;%  
  mutate(state_at_replacement = odometer_reading - state_at_replacement) %&amp;gt;%
  mutate(state_at_replacement = ifelse(is.na(state_at_replacement), odometer_reading, state_at_replacement)) %&amp;gt;%  
  mutate(state = ntile(state_at_replacement, 50))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let me also save the bus ids in a vector, I’ll need it later:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;buses &amp;lt;- unique(group1_4$bus_id)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use the dataset with the &lt;code&gt;{ReinforcementLearning}&lt;/code&gt; package, it must first be prepared:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group1_4 &amp;lt;- group1_4 %&amp;gt;%
  group_by(bus_id) %&amp;gt;%  
  mutate(next_state = lead(state, 1)) %&amp;gt;%
  mutate(replacement = lead(replacement, 1)) %&amp;gt;%  
  mutate(action = replacement) %&amp;gt;% 
  select(state, action, reward = replacement, next_state) %&amp;gt;%
  mutate(reward = (-1)*reward) %&amp;gt;%
  mutate(action = ifelse(is.na(action), 0, action),
         reward = ifelse(is.na(reward), 0, reward)) %&amp;gt;%  
  mutate(next_state = ifelse(is.na(next_state), state + 1, next_state)) %&amp;gt;% 
  mutate(state = as.character(state),
         next_state = as.character(next_state),
         action = as.character(action)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `bus_id`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see how the data looks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(group1_4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
## # Groups:   bus_id [1]
##   bus_id state action reward next_state
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     
## 1   5297 2     0           0 3         
## 2   5297 3     0           0 4         
## 3   5297 4     0           0 5         
## 4   5297 5     0           0 6         
## 5   5297 6     0           0 8         
## 6   5297 8     0           0 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So when action 0 (do nothing) is chosen, the value of the state is increased by one. If action
1 (replace) is chosen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group1_4 %&amp;gt;%
  filter(action == &amp;quot;1&amp;quot;) %&amp;gt;%
  head&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
## # Groups:   bus_id [6]
##   bus_id state action reward next_state
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     
## 1   5297 34    1          -1 1         
## 2   5299 42    1          -1 1         
## 3   5300 43    1          -1 1         
## 4   5301 36    1          -1 1         
## 5   5302 30    1          -1 1         
## 6   5303 49    1          -1 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The state goes back to 1, and the reward is -1.&lt;/p&gt;
&lt;p&gt;Now, let’s split the dataset into two: a training dataset and a testing dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
train_buses &amp;lt;- sample(buses, size = round(length(buses)*.8))

test_buses &amp;lt;- setdiff(buses, train_buses)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There will be 83 in the training data and 21 in the
testing data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_data &amp;lt;- group1_4 %&amp;gt;%
  filter(bus_id %in% train_buses)

test_data &amp;lt;- group1_4 %&amp;gt;%
  filter(bus_id %in% test_buses)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re finally ready to use the &lt;code&gt;{ReinforcementLearning}&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ReinforcementLearning)
model &amp;lt;- ReinforcementLearning(train_data,
                                         s = &amp;quot;state&amp;quot;,
                                         a = &amp;quot;action&amp;quot;,
                                         r = &amp;quot;reward&amp;quot;,
                                         s_new = &amp;quot;next_state&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now what’s the result?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## State-Action function Q
##     0        1
## X30 0 -0.19000
## X31 0  0.00000
## X1  0  0.00000
## X32 0  0.00000
## X2  0  0.00000
## X33 0 -0.10000
## X3  0  0.00000
## X34 0 -0.19000
## X4  0  0.00000
## X35 0  0.00000
## X5  0  0.00000
## X36 0 -0.19000
## X6  0  0.00000
## X37 0 -0.10000
## X7  0  0.00000
## X38 0  0.00000
## X8  0  0.00000
## X39 0 -0.34390
## X9  0  0.00000
## X10 0  0.00000
## X40 0 -0.10000
## X11 0  0.00000
## X41 0 -0.10000
## X12 0  0.00000
## X42 0 -0.34390
## X13 0  0.00000
## X43 0 -0.40951
## X14 0  0.00000
## X44 0 -0.19000
## X45 0 -0.34390
## X15 0  0.00000
## X46 0 -0.27100
## X16 0  0.00000
## X47 0 -0.19000
## X17 0  0.00000
## X48 0 -0.40951
## X18 0  0.00000
## X49 0 -0.34390
## X19 0  0.00000
## X50 0 -0.34390
## X20 0  0.00000
## X21 0  0.00000
## X22 0  0.00000
## X23 0  0.00000
## X24 0  0.00000
## X25 0  0.00000
## X26 0  0.00000
## X27 0  0.00000
## X28 0  0.00000
## X29 0 -0.10000
## 
## Policy
## X30 X31  X1 X32  X2 X33  X3 X34  X4 X35  X5 X36  X6 X37  X7 X38  X8 X39  X9 X10 
## &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; 
## X40 X11 X41 X12 X42 X13 X43 X14 X44 X45 X15 X46 X16 X47 X17 X48 X18 X49 X19 X50 
## &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; 
## X20 X21 X22 X23 X24 X25 X26 X27 X28 X29 
## &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; &amp;quot;0&amp;quot; 
## 
## Reward (last iteration)
## [1] -48&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the optimal policy is always to do nothing! This is actually “normal” here, as we are using historical
data; and in this data, there is no information on the likelihood of severe engine failure if one
does not replace it completely at some point! So the agent does not see the point in replacing the
engine; it costs money and does not seem to bring in any benefit!&lt;/p&gt;
&lt;p&gt;Another way of using the &lt;code&gt;{ReinforcementLearning}&lt;/code&gt; package
is to write a function that simulates the environment. One could write such a function, and add in it
a probability of severe failure with a very big cost. This probability would increase as the state
(number of miles driven) increases as well. With such a function, there would be simulations where
the cost of doing nothing would be very high, and as such, hopefully, the agent would learn that
replacing the engine once might be a better course of action than doing nothing.&lt;/p&gt;
&lt;p&gt;This might be the subject of part 3 of this series!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and watch my
&lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;. If you want to support
my blog and channel, you could &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or
&lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic discrete choice models, reinforcement learning and Harold, part 1</title>
      <link>https://www.brodrigues.co/blog/2020-01-26-harold/</link>
      <pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2020-01-26-harold/</guid>
      <description>&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://www.brodrigues.co/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=r30D3SW4OVw&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/fork.jpg&#34; title = &#34;If this blog post had an OST, this would likely be it.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I want to write about an &lt;em&gt;Econometrica&lt;/em&gt; paper written in 1987 (&lt;a href=&#34;https://www.jstor.org/stable/1911259&#34;&gt;jstor link&lt;/a&gt;) by John Rust, currently Professor of Economics at
Georgetown University, paper which has been on my mind for the past 10 years or so. Why? Because
it is a seminal paper in the econometric literature, but it is quite a bizarre one in some aspects.
In this paper, John Rust estimates a structural
dynamic discrete choice model on real data, and Professor Rust even had to develop his own novel
algorithm, which he called NFXP, which stands for &lt;em&gt;Nested Fixed Point&lt;/em&gt; algorithm, to estimate the model.
Such models hare now part of the toolbox of structural econometricians, because said models are
suited to model decision making in a changing environment. How much should you save today for
retirement? Should you go to university? If yes, which major should you choose? Should you get a
PhD? Should you have kids? How many? With whom?
As you see, kind reader, these models are at the center point of what makes life so interesting,
and sometimes so scary as well; what will be the impact of our decisions today on future rewards?
Some would say that only the Almighty would know, but structural econometricians now know as well,
thanks to John Rust.&lt;/p&gt;
&lt;p&gt;It is thus completely natural that Professor Rust chose a very important topic and gathered some
very important data to illustrate the inner workings of such a complicated, and yet fundamentally
important model.&lt;/p&gt;
&lt;p&gt;John Rust chose to tell the story of one named Harold Zurcher, superintendent of the Madison,
Wisconsin, Metropolitan Bus Company and his monthly decision making process on whether to replace
the engine of the buses of the company’s fleet, or not.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;and-thine-ears-shall-hear-a-word-behind-thee-saying-this-is-the-way-walk-ye-in-it-when-ye-turn-to-the-right-hand-and-when-ye-turn-to-the-left.-isaiah-3021&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;em&gt;And thine ears shall hear a word behind thee, saying, This is the way, walk ye in it, when ye turn to the right hand, and when ye turn to the left.&lt;/em&gt;, Isaiah 30:21&lt;/h2&gt;
&lt;p&gt;John Rust’s goal is to write down a model of Harold Zurcher’s behaviour, which he assumes follows
an optimal stopping rule: &lt;em&gt;a strategy which specifies whether or not to replace
the current bus engine each period as a function of observed and unobserved
state variables.&lt;/em&gt; But, dear reader, you might wonder, &lt;em&gt;Why model the decisions of Harold Zurcher?
Why not any other, more pressing, issue?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Quoting the author gives an answer: &lt;em&gt;Admittedly, few people are likely to take particular interest in Harold Zurcher and bus engine replacement, per se. I focus on a particular individual and a
specific capital good because it provides a simple, concrete framework to illustrate
two ideas: (i) a “bottom-up” approach for modelling replacement investment
and (ii) a “nested fixed point” algorithm for estimating dynamic programming
models of discrete choice.&lt;/em&gt; And this is what made me absolutely love this paper; I am 100% certain
that today, anyone, especially when starting an academic career, could not, and would not, write
a paper where one would model something so… non-consequential. And yet, John Rust not only wrote
such a paper, his paper is seminal in the literature of structural econometrics. For me, this is
one of the best papers I ever read. I read this paper around 2010-ish, and have thought about
it on and off since then. I now want to explore the data from his paper, and make you discover
it as well.&lt;/p&gt;
&lt;p&gt;In this blog post, I will focus on the data of the paper, which you can download in its raw,
original format or tidy format in the github repo I set up
&lt;a href=&#34;https://github.com/b-rodrigues/rust/tree/master/datasets&#34;&gt;here&lt;/a&gt;. In the next blog post, I’ll
discuss the model in greater detail, with a focus on Harold Zurcher’s decisions. I’ll then discuss
the similarities between reinforcement learning (the title of this blog post was not 100% clickbait)
and dynamic discrete stochastic models and use the &lt;code&gt;{ReinforcementLearning}&lt;/code&gt; package to try to
estimate the optimal policy. I haven’t tried the package’s function on this paper’s data yet, so
I have no idea if it’s going to work out. We’ll see.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-papers-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The paper’s data&lt;/h2&gt;
&lt;p&gt;Harold Zurcher provided monthly data on odometer readings from 162 buses of the Madison Metro fleet
to John Rust.&lt;/p&gt;
&lt;p&gt;(&lt;/p&gt;
&lt;p&gt;I sometimes wonder how this discussion went.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;- Hello Mr Zurcher, I’m an economist, my name is John Rust, and I am interested in dynamic discrete
choice models and their estimation. I would like to write an empirical paper for a prestigious journal,
and would like to know if you would be so kind as to provide me with data for my paper.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;- You what?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;)&lt;/p&gt;
&lt;p&gt;The time period goes from December, 1974 to May, 1985. There are 9 groups of buses, but for a reason
that is not explained in the paper only 8 groups of buses are studied. In addition to the monthly
odometer readings, there is also the date of a first, or second engine replacement. This is the
decision that Harold Zurcher faces each month: should he replace, or not, the engine?
This is a simplification from the author; in actuality, Harold Zurcher could also perform a routine
maintenance or replace individual components as well. The idea to focus on the third option
(complete replacement of the engine) is justified by John Rust as being part of a general
“preventive maintenance” strategy. Indeed, if a component of the engine fails at low mileage, it
is rather safe to simply replace that component. However, should one component of the engine fail
at a much higher mileage, then it is very likely that other components would fail as well in the
near future. As such, it is much safer to completely replace the engine, either with a brand new one,
or with one freshly rebuilt from the company’s machine shop. John Rust points out that Harold Zurcher
assured him that &lt;em&gt;rebuilt engines are every bit as good, if not better, than engines purchased brand
new&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now, to the data itself. The data comes in a format unlike anything I had ever seen before. Let’s take a
look at the head of one single file, for instance &lt;code&gt;a452372.asc&lt;/code&gt; (&lt;code&gt;.asc&lt;/code&gt; stands for ascii, as far as I know):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   4239 
      2 
     72 
      1 
     76 
 166100 
      0 
      0 
      0 
     12 
     74 
 140953 
 142960 
 145380 
 148140 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, on line 138, the data for the second bus of this groups starts:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   4240 
      2 
     72 
      1 
     75 
 177900 
      0 
      0 
      0 
     12 
     74 
 174402 
 175116 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and so on for each bus of this group. The other files are structured in the same way.&lt;/p&gt;
&lt;p&gt;This is quite cryptic, but thankfully, the data is well documented in the manual
of the NFXP software that John Rust wrote for this paper (remember the algorithm he wrote to
estimate the model? He shared his code with a nice manual, a very good practice that
unfortunately is not widespread enough in econometric circles, even to this day).
From this manual, we can read that the 11 first lines of the file are some kind of metadata:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Row  &lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Observation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1  &lt;/td&gt;
&lt;td&gt;bus number&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4239&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2  &lt;/td&gt;
&lt;td&gt;month purchased&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;3  &lt;/td&gt;
&lt;td&gt;year purchased&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4  &lt;/td&gt;
&lt;td&gt;month of 1st engine replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;5  &lt;/td&gt;
&lt;td&gt;year of 1st engine replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;6  &lt;/td&gt;
&lt;td&gt;odometer at replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;166100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;7  &lt;/td&gt;
&lt;td&gt;month of 2nd replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8  &lt;/td&gt;
&lt;td&gt;year of 2nd replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;9  &lt;/td&gt;
&lt;td&gt;odometer at replacement&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10  &lt;/td&gt;
&lt;td&gt;month odometer data begins&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;11  &lt;/td&gt;
&lt;td&gt;year odometer data begins&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;74&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;12  &lt;/td&gt;
&lt;td&gt;odometer reading&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;140953&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With this knowledge, the first step is thus to build a tidy data frame. To achieve this, I first
load the relevant packages, and read in all the data at once:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)

data_file_path &amp;lt;- Sys.glob(&amp;quot;datasets/*.asc&amp;quot;)

data_files &amp;lt;- map(data_file_path, read_lines)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;data_files&lt;/code&gt; is a list of 9 elements, where each element is one of the raw data files
(&lt;code&gt;a42372.asc&lt;/code&gt;, &lt;code&gt;a452374.asc&lt;/code&gt;, ….)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; str(data_files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;List of 9
 $ : chr [1:2466] &amp;quot;   4239 &amp;quot; &amp;quot;      2 &amp;quot; &amp;quot;     72 &amp;quot; &amp;quot;      1 &amp;quot; ...
 $ : chr [1:1370] &amp;quot;   4287 &amp;quot; &amp;quot;     10 &amp;quot; &amp;quot;     74 &amp;quot; &amp;quot;     11 &amp;quot; ...
 $ : chr [1:2466] &amp;quot;   5257 &amp;quot; &amp;quot;      5 &amp;quot; &amp;quot;     72 &amp;quot; &amp;quot;      6 &amp;quot; ...
 $ : chr [1:1644] &amp;quot;   5275 &amp;quot; &amp;quot;     10 &amp;quot; &amp;quot;     74 &amp;quot; &amp;quot;      9 &amp;quot; ...
 $ : chr [1:4736] &amp;quot;   5297 &amp;quot; &amp;quot;      8 &amp;quot; &amp;quot;     75 &amp;quot; &amp;quot;      4 &amp;quot; ...
 $ : chr [1:440] &amp;quot;   1334 &amp;quot; &amp;quot;      3 &amp;quot; &amp;quot;     77 &amp;quot; &amp;quot;      0 &amp;quot; ...
 $ : chr [1:540] &amp;quot;   4403 &amp;quot; &amp;quot;      5 &amp;quot; &amp;quot;     83 &amp;quot; &amp;quot;      0 &amp;quot; ...
 $ : chr [1:240] &amp;quot;   2386 &amp;quot; &amp;quot;      5 &amp;quot; &amp;quot;     81 &amp;quot; &amp;quot;      0 &amp;quot; ...
 $ : chr [1:3888] &amp;quot;   4338 &amp;quot; &amp;quot;      3 &amp;quot; &amp;quot;     79 &amp;quot; &amp;quot;      3 &amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to process all this data, I wrote this monster function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;process_bus_data &amp;lt;- function(data_file){
  data_file &amp;lt;- as.numeric(data_file)
  first_bus &amp;lt;- data_file[1]
  second_bus &amp;lt;- first_bus + 1
  second_bus_index &amp;lt;- which(data_file == second_bus)

  nb_data_points &amp;lt;- second_bus_index - 1

  nb_buses &amp;lt;- length(data_file) / nb_data_points

  indices &amp;lt;- nb_data_points * seq(1, nb_buses)

  indices &amp;lt;- c(0, indices)

  sep_data_sets &amp;lt;- map(indices, ~`[`(data_file, (. + 1):(. + nb_data_points) ))

  headers_list &amp;lt;- map(sep_data_sets, ~`[`(., 1:11))

  header_elements &amp;lt;- c(&amp;quot;bus number&amp;quot;, &amp;quot;month purchased&amp;quot;, &amp;quot;year purchased&amp;quot;,
                       &amp;quot;month of 1st engine replacement&amp;quot;, &amp;quot;year of 1st engine replacement&amp;quot;,
                       &amp;quot;odometer at replacement&amp;quot;, &amp;quot;month of 2nd replacement&amp;quot;,
                       &amp;quot;year of 2nd replacement&amp;quot;, &amp;quot;odometer at replacement&amp;quot;,
                       &amp;quot;month odometer data begins&amp;quot;, &amp;quot;year odometer data begins&amp;quot;)

  create_start_date &amp;lt;- function(one_dataset){
      one_dataset &amp;lt;- pull(one_dataset)
      month &amp;lt;- one_dataset[10]
      year &amp;lt;- paste0(&amp;quot;19&amp;quot;, one_dataset[11])

      month &amp;lt;- ifelse(nchar(month) == 1, paste0(&amp;quot;0&amp;quot;, month), month)

      ymd(paste0(year, &amp;quot;-&amp;quot;, month, &amp;quot;-01&amp;quot;))
  }

  create_first_replacement &amp;lt;- function(one_dataset){
      one_dataset &amp;lt;- pull(one_dataset, odometer_reading)
      month &amp;lt;- one_dataset[4]
      year &amp;lt;- paste0(&amp;quot;19&amp;quot;, one_dataset[5])

      month &amp;lt;- ifelse(nchar(month) == 1, paste0(&amp;quot;0&amp;quot;, month), month)

      ymd(paste0(year, &amp;quot;-&amp;quot;, month, &amp;quot;-01&amp;quot;))
  }

  create_second_replacement &amp;lt;- function(one_dataset){
      one_dataset &amp;lt;- pull(one_dataset, odometer_reading)
      month &amp;lt;- one_dataset[7]
      year &amp;lt;- paste0(&amp;quot;19&amp;quot;, one_dataset[8])

      month &amp;lt;- ifelse(nchar(month) == 1, paste0(&amp;quot;0&amp;quot;, month), month)

      ymd(paste0(year, &amp;quot;-&amp;quot;, month, &amp;quot;-01&amp;quot;))
  }

  get_bus_id &amp;lt;- function(one_dataset){
      one_dataset &amp;lt;- pull(one_dataset, odometer_reading)
      one_dataset[1]
  }

  named_headers &amp;lt;- map(headers_list, ~set_names(., header_elements))


  raw_data &amp;lt;- map(sep_data_sets, ~tibble(&amp;quot;odometer_reading&amp;quot; = .))
  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;date&amp;quot; = create_start_date(.)))
  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;first_replacement_date&amp;quot; = create_first_replacement(.)))
  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;second_replacement_date&amp;quot; = create_second_replacement(.)))
  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;bus_id&amp;quot; = get_bus_id(.)))
  raw_data &amp;lt;- map(raw_data, ~slice(., -c(1:11)))

  fill_dates &amp;lt;- function(vector){
      for(i in 2:length(vector)){
          vector[i] &amp;lt;- add_with_rollback(vector[i-1], months(1))
          # the line below can be uncommented to skip the 2 months of strike in 1980
          #vector[i] &amp;lt;- if_else(vector[i] == ymd(&amp;quot;1980-07-01&amp;quot;), add_with_rollback(vector[i], months(2)),
          #                    vector[i])
      }
      vector
  }

  raw_data &amp;lt;- raw_data %&amp;gt;%
      map(~mutate(., date = fill_dates(date)))

  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;replacement_1&amp;quot; = if_else(date == first_replacement_date, 1, 0, 0)))
  raw_data &amp;lt;- map(raw_data, ~mutate(., &amp;quot;replacement_2&amp;quot; = if_else(date == second_replacement_date, 1, 0, 0)))
  raw_data &amp;lt;- map(raw_data, ~mutate(., replacement = replacement_1 + replacement_2))
  raw_data &amp;lt;- map(raw_data, ~select(., bus_id, date, odometer_reading, replacement,
                                    -replacement_1, -replacement_2, -first_replacement_date, -second_replacement_date))

  return(raw_data)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, as usual, I didn’t write this in one go. First, I experimented bits and pieces of code on
one single dataset, and then only started putting these pieces together into this big function.&lt;/p&gt;
&lt;p&gt;I won’t go through this function line by line, because it would take me ages. I think there are
two majors things to understand in this function:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first identify the start of a particular bus’s data;&lt;/li&gt;
&lt;li&gt;second this function uses some intermediary &lt;code&gt;{purrr}&lt;/code&gt; magic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So first step, identify the start of the monthly odometer reading for one bus. For the first bus
this is quite simple, as it is simply the start of the file. But when does the data for the
second bus start? Thankfully, buses’ ids are numbers, and they’re in incrementing order in the data.
I use this to get the index of the second bus, and compute the number of rows between the id of
the first and second bus, which gives me the number of months of odometer readings for the first
bus.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  data_file &amp;lt;- as.numeric(data_file)
  first_bus &amp;lt;- data_file[1]
  second_bus &amp;lt;- first_bus + 1
  second_bus_index &amp;lt;- which(data_file == second_bus)

  nb_data_points &amp;lt;- second_bus_index - 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I get the number of buses in the data, and create a vector with all the indices of the
buses’ ids:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  nb_buses &amp;lt;- length(data_file) / nb_data_points

  indices &amp;lt;- nb_data_points * seq(1, nb_buses)

  indices &amp;lt;- c(0, indices)

  sep_data_sets &amp;lt;- map(indices, ~`[`(data_file, (. + 1):(. + nb_data_points) ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I end up with a list of lists, &lt;code&gt;sep_data_sets&lt;/code&gt;.
The first element of my list is now a list, with the data from the
&lt;code&gt;a452372.asc&lt;/code&gt; file, where each element is the data for a single bus.&lt;/p&gt;
&lt;p&gt;For instance, here is the first element of &lt;code&gt;sep_data_sets&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(sep_data_sets[[1]])
List of 19
 $ : num [1:137] 4239 2 72 1 76 ...
 $ : num [1:137] 4240 2 72 1 75 ...
 $ : num [1:137] 4241 2 72 5 75 ...
 $ : num [1:137] 4242 2 72 2 76 ...
 $ : num [1:137] 4243 2 72 4 76 ...
 $ : num [1:137] 4244 2 72 3 78 ...
 $ : num [1:137] 4245 2 72 1 75 ...
 $ : num [1:137] 4246 2 72 3 75 ...
 $ : num [1:137] 4247 2 72 9 80 ...
 $ : num [1:137] 4248 2 72 2 75 ...
 $ : num [1:137] 4249 2 72 7 75 ...
 $ : num [1:137] 4250 2 72 4 80 ...
 $ : num [1:137] 4251 2 72 1 79 ...
 $ : num [1:137] 4252 2 72 5 76 ...
 $ : num [1:137] 4253 2 72 1 77 ...
 $ : num [1:137] 4254 2 72 3 76 ...
 $ : num [1:137] 4255 2 72 1 76 ...
 $ : num [1:137] 4256 2 72 9 77 ...
 $ : num [1:137] NA NA NA NA NA NA NA NA NA NA ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So there are 18 buses in the first group of data (the last line full of NA’s is due to the fact
that I messed up my indices vector, I’ll simply remove these at the end).&lt;/p&gt;
&lt;p&gt;That’s the first step. The second step, is to make use of this list structure to apply some
cleaning functions to each dataset using &lt;code&gt;{purrr}&lt;/code&gt;. I explain the approach in my ebook, which you
can read for free
&lt;a href=&#34;https://b-rodrigues.github.io/modern_R/functional-programming.html#list-based-workflows-for-efficiency&#34;&gt;here&lt;/a&gt;.
The idea is to use a function that would work on a single element of your list, and then mapping
this over all the elements of the list. For instance, remember that the 11 first elements of
the data are some kind of header? To extract those for one single vector of observations, one
would use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_vector[1:11]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or, equivalently:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;`[`(my_vector, 1:11)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, when faced with a list of vectors, one maps this function over the whole list using &lt;code&gt;map()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(my_list_of_vectors, `[`(1:11))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the logic of this big &lt;code&gt;process_bus_data()&lt;/code&gt; function. If something’s not clear after you study
it, drop me an email or tweet.&lt;/p&gt;
&lt;p&gt;Anyways, now that I cleaned the data, here’s how it looks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_buses &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/rust/ee15fb87fc4ba5db28d055c97a898b328725f53c/datasets/processed_data/all_buses.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   bus_id = col_double(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   odometer_reading = col_double(),
##   replacement = col_double(),
##   bus_family = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(all_buses)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   bus_id date       odometer_reading replacement bus_family
##    &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;                &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;     
## 1   4239 1974-12-01           140953           0 a452372   
## 2   4239 1975-01-01           142960           0 a452372   
## 3   4239 1975-02-01           145380           0 a452372   
## 4   4239 1975-03-01           148140           0 a452372   
## 5   4239 1975-04-01           150921           0 a452372   
## 6   4239 1975-05-01           153839           0 a452372&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tidy data frame now has the bus id, the odometer readings with the right date, and whether
a replacement occurred at that date. I said the right date, but in the original documentation of
the data, John Rust mentions a two month strike in July and August 1980, and he removed these
points from the data since the odometer readings where the same. I did not skip July and August
when I created the dates, even though I have added the code to do it in the function above, because
it does not matter.&lt;/p&gt;
&lt;p&gt;I have 166 in my sample, while John Rust writes in the paper that
his sample contains 162. I do not know why I have 4 more buses.&lt;/p&gt;
&lt;p&gt;Let’s try to reproduce Table 2a of the paper (mileage at replacement):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_buses %&amp;gt;% 
    group_by(bus_id) %&amp;gt;% 
    filter(replacement == 1) %&amp;gt;% 
    group_by(bus_family) %&amp;gt;% 
    summarise_at(.vars = vars(odometer_reading), 
                 .funs = list(~max(.), ~min(.), ~mean(.), ~sd(.)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   bus_family    max    min    mean     sd
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 a452372    334393 130810 193175. 53533.
## 2 a452374    237287  82370 151495  61246.
## 3 a530872    413132 170508 278292. 78529.
## 4 a530874    325336 117986 247119  60818.
## 5 a530875    388254 120709 263405. 64556.
## 6 t8h203     273369 125643 200685. 37120.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I find different slightly results, for instance, for bus family &lt;code&gt;t8h203&lt;/code&gt; I find an average of
200’685 miles, while the original author found 199’733. This difference comes very likely from
the fact that the author probably uses the value from the header, “odometer at replacement”, at
position 6, while I use the value of the odometer at that month, which is always slightly different.&lt;/p&gt;
&lt;p&gt;Let’s try to reproduce Table 2b, as well, mileage for buses who did not have a replacement:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_buses %&amp;gt;% 
    group_by(bus_id) %&amp;gt;% 
    filter(all(replacement == 0)) %&amp;gt;% 
    group_by(bus_family) %&amp;gt;% 
    summarise_at(.vars = vars(odometer_reading), 
                 .funs = list(~max(.), ~min(.), ~mean(.), ~sd(.)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 5
##   bus_family    max   min    mean      sd
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 a452374    299040  4249 156135.  81992.
## 2 a530874    326843 13065 197547.  86692.
## 3 a530875    352450   129 188193. 104453.
## 4 d309        65045   294  30643.  17063.
## 5 g870       120151   483  49582.  32353.
## 6 rt50       161748  1743  77506.  44674.
## 7 t8h203     280802  2950 127964.  72300.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here I find exactly the same values as the author. To finish this quite long blog post, let’s
now plot the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(all_buses) + 
    geom_line(aes(y = odometer_reading, x = date, group = bus_id, col = bus_family)) + 
    labs(title = &amp;quot;Odometer readings&amp;quot;) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-01-26-harold_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s add some dots to mark the points in time where replacements happened:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(all_buses) + 
    geom_line(aes(y = odometer_reading, x = date, group = bus_id, col = bus_family)) + 
    geom_point(aes(y = ifelse(odometer_reading*replacement == 0, NA, odometer_reading*replacement), 
                              x = date), col = &amp;quot;red&amp;quot;) +
    labs(title = &amp;quot;Odometer readings and points in time where engine replacement occurred&amp;quot;) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 15840 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-01-26-harold_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s create a graph for each bus family:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(all_buses) + 
    geom_line(aes(y = odometer_reading, x = date, group = bus_id), col = &amp;quot;#82518c&amp;quot;) +
    geom_point(aes(y = ifelse(odometer_reading*replacement == 0, NA, odometer_reading*replacement), 
                              x = date), col = &amp;quot;red&amp;quot;) +
    facet_wrap(~bus_family) + 
    labs(title = &amp;quot;Odometer readings and points in time where engine replacement occurred&amp;quot;) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 15840 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2020-01-26-harold_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the next blog post, I’ll explore how recent reinforcement learning methods might help us get
the optimal policy from the data!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Intrumental variable regression and machine learning</title>
      <link>https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-Bu654lDuBk&#34;&gt; &lt;img src=&#34;https://www.brodrigues.co/img/maybe.jpg&#34; title = &#34;Every time I look at observational data and wonder if 
  this correlation could imply causation, at least this one time.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Just like the question “what’s the difference between machine learning and statistics” has shed a lot of ink (since at least &lt;a href=&#34;https://projecteuclid.org/euclid.ss/1009213726&#34;&gt;Breiman (2001)&lt;/a&gt;), the same question but where statistics is replaced by econometrics has led to a lot of discussion, as well. I like this presentation by &lt;a href=&#34;https://web.stanford.edu/class/ee380/Abstracts/140129-slides-Machine-Learning-and-Econometrics.pdf&#34;&gt;Hal Varian&lt;/a&gt; from almost 6 years ago. There’s a slide called “What econometrics can learn from machine learning”, which summarises in a few bullet points &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3&#34;&gt;Varian (2014)&lt;/a&gt; and the rest of the presentation discusses what machine learning can learn from econometrics. Varian argues that the difference between machine learning and econometrics is that machine learning focuses on prediction, while econometrics on inference and causality (and to a lesser extent prediction as well). Varian cites some methods that have been in the econometricians’ toolbox for decades (at least for some of them), such as regression discontinuity, difference in differences and instrumental variables regression. Another interesting paper is &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/jep.31.2.87&#34;&gt;Mullainathan and Spiess&lt;/a&gt;, especially the section called &lt;em&gt;What Do We (Not) Learn from Machine Learning Output?&lt;/em&gt;. The authors discuss the tempting idea of using LASSO to perform variable (feature) selection. Econometricians might be tempted to use LASSO to perform variable selection, and draw conclusions such as &lt;em&gt;The variable (feature) “Number of rooms” has not been selected by LASSO, thus it plays no role in the prediction of house prices&lt;/em&gt;. However, when variables (features) are highly correlated, LASSO selects variables essentially randomly, without any meaningful impact on model performance (for prediction). I found this paragraph quite interesting (emphasis mine):&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This problem is ubiquitous in machine learning. The very appeal of these algorithms is that they can fit many different functions. But this creates an Achilles’ heel: more functions mean a greater chance that two functions with very different coefficients can produce similar prediction quality. As a result, how an algorithm chooses between two very different functions can effectively come down to the flip of a coin. In econometric terms, while the lack of &lt;strong&gt;standard errors&lt;/strong&gt; illustrates the limitations to making inference after model selection, the challenge here is (uniform) model selection consistency itself.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Assuming that we successfully dealt with model selection, we still have to content with significance of coefficients. There is recent research into this topic, such as &lt;a href=&#34;https://arxiv.org/abs/1902.06021v1&#34;&gt;Horel and Giesecke&lt;/a&gt;, but I wonder to what extent explainability could help with this. I have been looking around for papers that discuss explainability in the context of the social sciences but have not found any. If any of the readers of this blog are aware of such papers, please let me know.&lt;/p&gt;
&lt;p&gt;Just to wrap up Mullainathan and Spiess; the authors then suggest to use machine learning mainly for prediction tasks, such as using images taken using satellites to predict future harvest size (the authors cite &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0378429012002754&#34;&gt;Lobell (2013)&lt;/a&gt;), or for tasks that have an &lt;em&gt;implicit&lt;/em&gt; prediction component. For instance in the case of instrumental variables regression, two stages least squares is often used, and the first stage is a prediction task. Propensity score matching is another prediction task, where machine learning could be used. Other examples are presented as well. In this blog post, I’ll explore two stages least squares and see what happens when a random forest is used for the first step.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;instrumental-variables-regression-using-two-stage-least-squares&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Instrumental variables regression using two-stage least squares&lt;/h2&gt;
&lt;p&gt;Let’s work out a textbook (literally) example of instrumental variable regression. The below example is taken from Wooldrige’s &lt;em&gt;Econometric analysis of cross section and panel data&lt;/em&gt;, and is an exercise made using data from Mroz (1987) &lt;em&gt;The sensitivity of an empirical model of married women’s hours of work to economic and statistical assumptions&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Let’s first load the needed packages and the data &lt;code&gt;&amp;quot;mroz&amp;quot;&lt;/code&gt; included in the &lt;code&gt;{wooldridge}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(randomForest)
library(wooldridge)
library(AER)
library(Metrics)

data(&amp;quot;mroz&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s only select the women that are in the labour force (&lt;code&gt;inlf == 1&lt;/code&gt;), and let’s run a simple linear regression. The dependent variable, or target, is &lt;code&gt;lwage&lt;/code&gt;, the logarithm of the wage, and the explanatory variables, or features are &lt;code&gt;exper&lt;/code&gt;, &lt;code&gt;expersq&lt;/code&gt; and &lt;code&gt;educ&lt;/code&gt;. For a full description of the data, click below:&lt;/p&gt;
&lt;p&gt;&lt;details&gt; &lt;summary&gt;Description of data&lt;/summary&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
mroz {wooldridge}   R Documentation
mroz

Description

Wooldridge Source: T.A. Mroz (1987), “The Sensitivity of an Empirical Model of Married Women’s Hours of Work to Economic and Statistical Assumptions,” Econometrica 55, 765-799. Professor Ernst R. Berndt, of MIT, kindly provided the data, which he obtained from Professor Mroz. Data loads lazily.

Usage

data(&amp;#39;mroz&amp;#39;)
Format

A data.frame with 753 observations on 22 variables:

inlf: =1 if in lab frce, 1975

hours: hours worked, 1975

kidslt6: # kids &amp;lt; 6 years

kidsge6: # kids 6-18

age: woman&amp;#39;s age in yrs

educ: years of schooling

wage: est. wage from earn, hrs

repwage: rep. wage at interview in 1976

hushrs: hours worked by husband, 1975

husage: husband&amp;#39;s age

huseduc: husband&amp;#39;s years of schooling

huswage: husband&amp;#39;s hourly wage, 1975

faminc: family income, 1975

mtr: fed. marg. tax rte facing woman

motheduc: mother&amp;#39;s years of schooling

fatheduc: father&amp;#39;s years of schooling

unem: unem. rate in county of resid.

city: =1 if live in SMSA

exper: actual labor mkt exper

nwifeinc: (faminc - wage*hours)/1000

lwage: log(wage)

expersq: exper^2

Used in Text

pages 249-251, 260, 294, 519-520, 530, 535, 535-536, 565-566, 578-579, 593- 595, 601-603, 619-620, 625

Source

https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&amp;amp;product_isbn_issn=9781111531041
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;working_w &amp;lt;- mroz %&amp;gt;% 
    filter(inlf == 1)

wage_lm &amp;lt;- lm(lwage ~ exper + expersq + educ, 
              data = working_w)

summary(wage_lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = lwage ~ exper + expersq + educ, data = working_w)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.08404 -0.30627  0.04952  0.37498  2.37115 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -0.5220406  0.1986321  -2.628  0.00890 ** 
## exper        0.0415665  0.0131752   3.155  0.00172 ** 
## expersq     -0.0008112  0.0003932  -2.063  0.03974 *  
## educ         0.1074896  0.0141465   7.598 1.94e-13 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6664 on 424 degrees of freedom
## Multiple R-squared:  0.1568, Adjusted R-squared:  0.1509 
## F-statistic: 26.29 on 3 and 424 DF,  p-value: 1.302e-15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we see that education is statistically significant and the effect is quite high. The return to education is about 11%. Now, let’s add some more explanatory variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wage_lm2 &amp;lt;- lm(lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage + city + educ, 
              data = working_w)

summary(wage_lm2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + 
##     huswage + city + educ, data = working_w)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.07431 -0.30500  0.05477  0.37871  2.31157 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -0.3853695  0.3163043  -1.218  0.22378    
## exper        0.0398817  0.0133651   2.984  0.00301 ** 
## expersq     -0.0007400  0.0003985  -1.857  0.06402 .  
## kidslt6     -0.0564071  0.0890759  -0.633  0.52692    
## kidsge6     -0.0143165  0.0276579  -0.518  0.60499    
## husage      -0.0028828  0.0049338  -0.584  0.55934    
## huswage      0.0177470  0.0102733   1.727  0.08482 .  
## city         0.0119960  0.0725595   0.165  0.86877    
## educ         0.0986810  0.0151589   6.510 2.16e-10 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6669 on 419 degrees of freedom
## Multiple R-squared:  0.1654, Adjusted R-squared:  0.1495 
## F-statistic: 10.38 on 8 and 419 DF,  p-value: 2.691e-13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The return to education lowers a bit, but is still significant. Now, the issue is that education is not exogenous (randomly assigned), and is thus correlated with the error term of the regression, due to an omitted variable for instance contained in the error term, that is correlated with education (for example work ethic).&lt;/p&gt;
&lt;p&gt;To deal with this, econometricians use instrumental variables (IV) regression. I won’t go into detail here; just know that this method can deal with these types of issues. The &lt;a href=&#34;https://en.wikipedia.org/wiki/Instrumental_variables_estimation&#34;&gt;Wikipedia&lt;/a&gt; page gives a good intro on what this is all about. This short &lt;a href=&#34;https://wol.iza.org/uploads/articles/250/pdfs/using-instrumental-variables-to-establish-causality.pdf&#34;&gt;paper&lt;/a&gt; is also quite interesting in introducing instrumental variables.&lt;/p&gt;
&lt;p&gt;In practice, IV is done in two steps. First, regress the endogenous variable, in our case education, on all the explanatory variables from before, plus so called instruments. Instruments are variables that are correlated with the endogenous variable, here education, but uncorrelated to the error term. They only affect the target variable through their correlation with the endogenous variable. We will be using the education level of the parents of the women, as well as the education levels of their husbands as intruments. The assumption is that the parents’, as well as the husband’s education are exogenous in the log wage of the woman. This assumption can of course be challenged, but let’s say that it holds.&lt;/p&gt;
&lt;p&gt;To conclude stage 1, we obtain the predictions of education:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_stage &amp;lt;- lm(educ ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage 
                  + city + motheduc +  fatheduc + huseduc, data = working_w)

working_w$predictions_first_stage &amp;lt;- predict(first_stage)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready for the second stage. In the regression from before:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wage_lm2 &amp;lt;- lm(lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage + city + educ, 
              data = working_w)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we now replace &lt;code&gt;educ&lt;/code&gt; with the predictions of stage 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;second_stage &amp;lt;- lm(lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage 
                   + city + predictions_first_stage,
                  data = working_w)

summary(second_stage)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + 
##     huswage + city + predictions_first_stage, data = working_w)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.13493 -0.30004  0.03046  0.37142  2.27199 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)              0.1763588  0.4206911   0.419   0.6753   
## exper                    0.0419047  0.0139885   2.996   0.0029 **
## expersq                 -0.0007881  0.0004167  -1.891   0.0593 . 
## kidslt6                 -0.0255934  0.0941128  -0.272   0.7858   
## kidsge6                 -0.0234422  0.0291914  -0.803   0.4224   
## husage                  -0.0042628  0.0051919  -0.821   0.4121   
## huswage                  0.0263802  0.0114511   2.304   0.0217 * 
## city                     0.0215685  0.0759034   0.284   0.7764   
## predictions_first_stage  0.0531993  0.0263735   2.017   0.0443 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6965 on 419 degrees of freedom
## Multiple R-squared:  0.08988,    Adjusted R-squared:  0.0725 
## F-statistic: 5.172 on 8 and 419 DF,  p-value: 3.581e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that education, now instrumented by the parents’ and the husband’s education is still significant, but the effect is much lower. The return to education is now about 5%. However, should our assumption hold, this effect is now &lt;em&gt;causal&lt;/em&gt;. However there are some caveats. The IV estimate is a local average treatment effect, meaning that we only get the effect on those individuals that were affected by the treatment. In this case, it would mean that the effect we recovered is only for women who were not planning on, say, studying, but only did so under the influence of their parents (or vice-versa).&lt;/p&gt;
&lt;p&gt;IV regression can also be achieved using the &lt;code&gt;ivreg()&lt;/code&gt; function from the &lt;code&gt;{AER}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inst_reg &amp;lt;- ivreg(lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage + city + educ 
                  | .-educ + motheduc + fatheduc + huseduc,
                  data = working_w)

summary(inst_reg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## ivreg(formula = lwage ~ exper + expersq + kidslt6 + kidsge6 + 
##     husage + huswage + city + educ | . - educ + motheduc + fatheduc + 
##     huseduc, data = working_w)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.10175 -0.30407  0.03379  0.35255  2.25107 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)  0.1763588  0.4071522   0.433   0.6651   
## exper        0.0419047  0.0135384   3.095   0.0021 **
## expersq     -0.0007881  0.0004033  -1.954   0.0514 . 
## kidslt6     -0.0255934  0.0910840  -0.281   0.7789   
## kidsge6     -0.0234422  0.0282519  -0.830   0.4071   
## husage      -0.0042628  0.0050249  -0.848   0.3967   
## huswage      0.0263802  0.0110826   2.380   0.0177 * 
## city         0.0215685  0.0734606   0.294   0.7692   
## educ         0.0531993  0.0255247   2.084   0.0377 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6741 on 419 degrees of freedom
## Multiple R-Squared: 0.1475,  Adjusted R-squared: 0.1312 
## Wald test: 5.522 on 8 and 419 DF,  p-value: 1.191e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, great, now let’s see how a machine learning practitioner who took an econometrics MOOC might tackle the issue. The first step will be to split the data into training and testing sets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
sample &amp;lt;- sample.int(n = nrow(working_w), size = floor(.90*nrow(working_w)), replace = F)
train &amp;lt;- working_w[sample, ]
test  &amp;lt;- working_w[-sample, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now run the same analysis as above, but let’s compute the RMSE of the first stage regression on the testing data as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_stage &amp;lt;- lm(educ ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage 
                  + city + motheduc +  fatheduc + huseduc, data = train)

test$predictions_first_stage &amp;lt;- predict(first_stage, newdata = test)

lm_rmse &amp;lt;- rmse(predicted = test$predictions_first_stage, actual = test$educ)

train$predictions_first_stage &amp;lt;- predict(first_stage)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first stage is done, let’s go with the second stage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;second_stage &amp;lt;- lm(lwage ~ exper + expersq + kidslt6 + kidsge6 + 
                       husage + huswage + city + predictions_first_stage,
                  data = train)

summary(second_stage)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + 
##     huswage + city + predictions_first_stage, data = train)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.09828 -0.28606  0.05248  0.37258  2.29947 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)             -0.0037711  0.4489252  -0.008  0.99330   
## exper                    0.0449370  0.0145632   3.086  0.00218 **
## expersq                 -0.0008394  0.0004344  -1.933  0.05404 . 
## kidslt6                 -0.0630522  0.0963953  -0.654  0.51345   
## kidsge6                 -0.0197164  0.0306834  -0.643  0.52089   
## husage                  -0.0034744  0.0054358  -0.639  0.52310   
## huswage                  0.0219622  0.0118602   1.852  0.06484 . 
## city                     0.0679668  0.0804317   0.845  0.39863   
## predictions_first_stage  0.0618777  0.0283253   2.185  0.02954 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6952 on 376 degrees of freedom
## Multiple R-squared:  0.1035, Adjusted R-squared:  0.08438 
## F-statistic: 5.424 on 8 and 376 DF,  p-value: 1.764e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The coefficients here are a bit different due to the splitting, but that’s not an issue. Ok, great, but our machine learning engineer is in love with random forests, so he wants to use a random forest for the prediction task of the first stage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(randomForest)

first_stage_rf &amp;lt;- randomForest(educ ~ exper + expersq + kidslt6 + kidsge6 + husage + huswage 
                  + city + motheduc +  fatheduc + huseduc, 
                               data = train)

test$predictions_first_stage_rf &amp;lt;- predict(first_stage_rf, newdata = test)

rf_rmse &amp;lt;- rmse(predicted = test$predictions_first_stage_rf, actual = test$educ)

train$predictions_first_stage_rf &amp;lt;- predict(first_stage_rf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compare the RMSE’s of the two first stages. The RMSE of the first stage using linear regression was 2.0558723 and for the random forest 2.0000417. Our machine learning engineer is happy, because the random forest has better performance. Let’s now use the predictions for the second stage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;second_stage_rf_lm &amp;lt;- lm(lwage ~ exper + expersq + kidslt6 + kidsge6 + 
                             husage + huswage + city + predictions_first_stage_rf,
                  data = train)

summary(second_stage_rf_lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = lwage ~ exper + expersq + kidslt6 + kidsge6 + husage + 
##     huswage + city + predictions_first_stage_rf, data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0655 -0.3198  0.0376  0.3710  2.3277 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)                -0.0416945  0.4824998  -0.086  0.93118   
## exper                       0.0460311  0.0145543   3.163  0.00169 **
## expersq                    -0.0008594  0.0004344  -1.978  0.04863 * 
## kidslt6                    -0.0420827  0.0952030  -0.442  0.65872   
## kidsge6                    -0.0211208  0.0306490  -0.689  0.49117   
## husage                     -0.0033102  0.0054660  -0.606  0.54514   
## huswage                     0.0229111  0.0118142   1.939  0.05322 . 
## city                        0.0688384  0.0805209   0.855  0.39314   
## predictions_first_stage_rf  0.0629275  0.0306877   2.051  0.04100 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.6957 on 376 degrees of freedom
## Multiple R-squared:  0.1021, Adjusted R-squared:  0.08302 
## F-statistic: 5.346 on 8 and 376 DF,  p-value: 2.251e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results are pretty similar. Now, why not go a bit further and use a random forest for the second stage as well?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-stage-random-forests&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Two-stage random forests&lt;/h2&gt;
&lt;p&gt;I have tried to find literature on this, but did not find anything that really fits what I’ll be doing here. Honestly, I don’t know if this is sound theoretically, but it does have intuitive appeal. Using random forests instead of the linear regressions of each stages poses at least the following question: how can we interpret the results of the second stage? As you have seen above, interpretation of the coefficients and standard errors is important, and random forests do not provide this. My idea is to use explainability techniques of black box models, such as partial dependence plots. In this setting, the whole first stage could be interpreted as a feature engineering step. Let’s do it and see what happens.&lt;/p&gt;
&lt;p&gt;We already have the first step from before, so let’s go straight to the first step:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;second_stage_rf_rf &amp;lt;- randomForest(lwage ~ exper + expersq + kidslt6 + kidsge6 + 
                                       husage + huswage + city + predictions_first_stage_rf,
                  data = train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now use the &lt;code&gt;{iml}&lt;/code&gt; package for explainability. Let’s start first by loading the package, defining a predictor object, and then get model-agnostic feature importance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;iml&amp;quot;)

predictor &amp;lt;- Predictor$new(
  model = second_stage_rf_rf, 
  data = select(test, exper, expersq,
                kidslt6, kidsge6,
                husage, huswage, city,
                predictions_first_stage_rf), 
  y = test$lwage, 
  predict.fun = predict,
  class = &amp;quot;regression&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows the ratio of the original model error and model error after permutation. A higher value indicates that this feature is important:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_rf &amp;lt;- FeatureImp$new(predictor, loss = &amp;quot;rmse&amp;quot;)

plot(imp_rf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;According to this measure of feature importance, there does not seem to be any feature that is important in predicting log wage. This is similar to the result we had with linear regression: most coefficients were not statistically significant, but some were. Does that mean that we should not trust the results of linear regression? After all, how likely is it that log wages can be modeled as a linear combination of features?&lt;/p&gt;
&lt;p&gt;Let’s see if the random forest was able to undercover strong interaction effects:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interactions &amp;lt;- Interaction$new(predictor, feature = &amp;quot;predictions_first_stage_rf&amp;quot;)

plot(interactions)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This can seem to be a surprising result: education interacts strongly with the number of kids greater than 6 in household. But is it? Depending on a woman’s age, in order to have 2 or 3 kids with ages between 6 and 18, she would have needed to start having them young, and thus could not have pursued a master’s degree, or a PhD. The interaction strength is measured as the share of variance that is explained by the interaction.&lt;/p&gt;
&lt;p&gt;Let’s now take a look at the partial dependence plots and individual conditional expectation curves. Let me quote the advantages of pdps from &lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/pdp.html#advantages-5&#34;&gt;Christoph Molnar’s&lt;/a&gt; book on interpretable machine learning:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The calculation for the partial dependence plots has a causal interpretation. We intervene on a feature and measure the changes in the predictions. In doing so, we analyze the causal relationship between the feature and the prediction. The relationship is causal for the model – because we explicitly model the outcome as a function of the features – but not necessarily for the real world!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That sounds good. If we can defend the assumption that our instruments are valid, then the relationship should between the feature and the prediction should be causal, and not only for the model. However, pdps have a shortcoming. Again, quoting Christoph Molnar:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The assumption of independence is the biggest issue with PD plots. It is assumed that the feature(s) for which the partial dependence is computed are not correlated with other features.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let’s take a look at the correlation of features&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_vars &amp;lt;- cor(select(test, exper, expersq,
                        kidslt6, kidsge6,
                        husage, huswage, city,
                        predictions_first_stage_rf)) %&amp;gt;% 
    as.data.frame() %&amp;gt;% 
    rownames_to_column() %&amp;gt;% 
    pivot_longer(-rowname, names_to = &amp;quot;vars2&amp;quot;) %&amp;gt;% 
    rename(vars1 = rowname)

head(corr_vars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   vars1 vars2    value
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 exper exper    1    
## 2 exper expersq  0.959
## 3 exper kidslt6 -0.272
## 4 exper kidsge6 -0.360
## 5 exper husage   0.487
## 6 exper huswage -0.181&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_vars %&amp;gt;% 
    mutate(value = abs(value)) %&amp;gt;% 
    filter(value != 1, value &amp;gt; 0.2) %&amp;gt;%
    filter(vars1 == &amp;quot;predictions_first_stage_rf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 3
##   vars1                      vars2   value
##   &amp;lt;chr&amp;gt;                      &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 predictions_first_stage_rf expersq 0.243
## 2 predictions_first_stage_rf kidslt6 0.292
## 3 predictions_first_stage_rf husage  0.217
## 4 predictions_first_stage_rf huswage 0.494
## 5 predictions_first_stage_rf city    0.369&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Only 5 variables have a correlation greater than 0.2 with education, and the one with highest correlation is the husband’s wage. It would seem that this situation is ideal to use pdps and ice curves. Before computing them however, let’s read about ice curves:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Individual conditional expectation curves are even more intuitive to understand than partial dependence plots. One line represents the predictions for one instance if we vary the feature of interest.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;however:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;ICE curves can only display one feature meaningfully, because two features would require the drawing of several overlaying surfaces and you would not see anything in the plot. ICE curves suffer from the same problem as PDPs: If the feature of interest is correlated with the other features, then some points in the lines might be invalid data points according to the joint feature distribution. If many ICE curves are drawn, the plot can become overcrowded and you will not see anything. The solution: Either add some transparency to the lines or draw only a sample of the lines. In ICE plots it might not be easy to see the average. This has a simple solution: Combine individual conditional expectation curves with the partial dependence plot. Unlike partial dependence plots, ICE curves can uncover heterogeneous relationships.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So great, let’s go:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inst_effect &amp;lt;- FeatureEffect$new(predictor, &amp;quot;predictions_first_stage_rf&amp;quot;, method = &amp;quot;pdp+ice&amp;quot;)

plot(inst_effect) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Interesting, we see that the curves are fairly similar, but there seem to be two groups: one group were adding education years increases wages, and another where the effect seems to remain constant.&lt;/p&gt;
&lt;p&gt;Let’s try to dig a bit deeper, and get explanations for individual predictions. For this, I create two new observations that have exactly the same features, but one without children older than 6 and another with two children older than 6:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(new_obs &amp;lt;- data.frame(
    exper = rep(10, 2),
    expersq = rep(100, 2),
    kidslt6 = rep(1, 2),
    kidsge6 = c(0, 2),
    husage = rep(35, 2),
    huswage = rep(6, 2),
    city = rep(1, 2),
    predictions_first_stage_rf = rep(10, 2)
))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   exper expersq kidslt6 kidsge6 husage huswage city
## 1    10     100       1       0     35       6    1
## 2    10     100       1       2     35       6    1
##   predictions_first_stage_rf
## 1                         10
## 2                         10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what the model predicts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(second_stage_rf_rf, newdata = new_obs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2 
## 1.139720 1.216423&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try to understand the difference between these two predictions. For this, we will be using Shapley values as described &lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/shapley.html&#34;&gt;here&lt;/a&gt;. Shapley values use game theory to compute the contribution of each feature towards the prediction of one particular observation. Interpretation of the Shapley values is as follows (quoting Christoph Molnar’s book): &lt;em&gt;Given the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let’s compute the Shapley values of all the features:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shapley_1 &amp;lt;-  Shapley$new(predictor, x.interest = new_obs[1, ], sample.size = 100)
shapley_2 &amp;lt;-  Shapley$new(predictor, x.interest = new_obs[2, ], sample.size = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(shapley_1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(shapley_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-06-explainability_econometrics_files/figure-html/unnamed-chunk-22-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The average prediction is 1.21 and the prediction for the first new observation is 1.14, which is 0.07 below the average prediction. This difference of 0.07 is the sum of the Shapley values. For the second observation, the prediction is 1.22, so 0.01 above the average prediction. The order and magnitude of contributions is not the same as well; and surprisingly, the contribution of the instrumented education to the prediction is negative.&lt;/p&gt;
&lt;p&gt;Ok, let’s end this here. I’m quite certain that explainability methods will help econometricians adopt more machine learning methods in the future, and I am also excited to see the research of causality in machine learning and AI continue.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and &lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple data imputation and explainability</title>
      <link>https://www.brodrigues.co/blog/2019-11-02-mice_exp/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-11-02-mice_exp/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://xkcd.com/303/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/kermit.png&#34; title = &#34;It is always so tempting&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Imputing missing values is quite an important task, but in my experience, very often, it is performed
using very simplistic approaches. The basic approach is to impute missing values for
numerical features using the average of each feature, or using the mode for categorical features.
There are better ways of imputing missing values, for instance by predicting the values using
a regression model, or KNN. However, imputing only once is not enough, because each imputed
value carries with it a certain level of uncertainty. To account for this, it is better to perform
multiple imputation. This means that if you impute your dataset 10 times, you’ll end up with 10
different datasets. Then, you should perform your analysis 10 times, for instance, if training
a machine learning model, you should train it on the 10 datasets (and do a train/test split
for each, even potentially tune a model for each). Finally, you should pool the results of
these 10 analyses.&lt;/p&gt;
&lt;p&gt;I have met this approach in the social sciences and statistical literature in general, but
very rarely in machine learning. Usually, in the social sciences, explainability is the goal of
fitting statistical models to data, and the approach I described above is very well suited for this.
Fit 10 (linear) regressions to each imputed dataset, and then pool the estimated coefficients/weights
together. Rubin’s rule is used to pool these estimates. You can read more about this rule
&lt;a href=&#34;https://bookdown.org/mwheymans/bookmi/rubins-rules.html&#34;&gt;here&lt;/a&gt;.
In machine learning, the task is very often prediction; in this case, you should pool the
predictions. Computing the average and other statistics of the predictions
seem to work just fine in practice.&lt;/p&gt;
&lt;p&gt;However, if you are mainly interested in explainability, how should you proceed? I’ve thought a
bit about it, and the answer, is “exactly the same way”… I think.
What I’m sure about, is you should impute m times, run the analysis m times
(which in this case will include getting explanations) and then pool. So the idea is to be able to
pool explanations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explainability-in-the-standard-case-no-missing-values&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explainability in the “standard” case (no missing values)&lt;/h2&gt;
&lt;p&gt;To illustrate this idea, I’ll be using the &lt;code&gt;{mice}&lt;/code&gt; package for multiple imputation,
&lt;code&gt;{h2o}&lt;/code&gt; for the machine learning bit and&lt;code&gt;{iml}&lt;/code&gt; for explainability. Note that I could have used
any other machine learning package instead of &lt;code&gt;{h2o}&lt;/code&gt; as &lt;code&gt;{iml}&lt;/code&gt; is totally &lt;em&gt;package-agnostic&lt;/em&gt;.
However, I have been experimenting with &lt;code&gt;{h2o}&lt;/code&gt;’s automl implementation lately, so I happened
to have code on hand. Let’s start with the “standard” case where the data does not have any missing
values.&lt;/p&gt;
&lt;p&gt;First let’s load the needed packages and initialize &lt;code&gt;h2o&lt;/code&gt; functions with &lt;code&gt;h2o.init()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Ecdat)
library(mice)
library(h2o)
library(iml)
h2o.init()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll be using the &lt;code&gt;DoctorContacts&lt;/code&gt; data. Here’s a description:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view the description of the data&lt;/summary&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DoctorContacts              package:Ecdat              R Documentation

Contacts With Medical Doctor

Description:

     a cross-section from 1977-1978

     _number of observations_ : 20186

Usage:

     data(DoctorContacts)
     
Format:

     A time serie containing :

     mdu number of outpatient visits to a medical doctor

     lc log(coinsrate+1) where coinsurance rate is 0 to 100

     idp individual deductible plan ?

     lpi log(annual participation incentive payment) or 0 if no payment

     fmde log(max(medical deductible expenditure)) if IDP=1 and MDE&amp;gt;1
          or 0 otherw

     physlim physical limitation ?

     ndisease number of chronic diseases

     health self-rate health (excellent,good,fair,poor)

     linc log of annual family income (in \$)

     lfam log of family size

     educdec years of schooling of household head

     age exact age

     sex sex (male,female)

     child age less than 18 ?

     black is household head black ?

Source:

     Deb, P.  and P.K.  Trivedi (2002) “The Structure of Demand for
     Medical Care: Latent Class versus Two-Part Models”, _Journal of
     Health Economics_, *21*, 601-625.

References:

     Cameron, A.C.  and P.K.  Trivedi (2005) _Microeconometrics :
     methods and applications_, Cambridge, pp. 553-556 and 565.&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;The task is to predict &lt;code&gt;&amp;quot;mdu&amp;quot;&lt;/code&gt;, the number of outpatient visits to an MD. Let’s prepare the data
and split it into 3; a training, validation and holdout set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;DoctorContacts&amp;quot;)

contacts &amp;lt;- as.h2o(DoctorContacts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;splits &amp;lt;- h2o.splitFrame(data=contacts, ratios = c(0.7, 0.2))

original_train &amp;lt;- splits[[1]]

validation &amp;lt;- splits[[2]]

holdout &amp;lt;- splits[[3]]

features_names &amp;lt;- setdiff(colnames(original_train), &amp;quot;mdu&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you see, the ratios argument &lt;code&gt;c(0.7, 0.2)&lt;/code&gt; does not add up to 1.
This means that the first of the splits will have 70% of the data, the second split 20% and
the final 10% will be the holdout set.&lt;/p&gt;
&lt;p&gt;Let’s first go with a poisson regression. To obtain the same results as with R’s built-in &lt;code&gt;glm()&lt;/code&gt;
function, I use the options below, as per H2o’s glm
&lt;a href=&#34;http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html#faq&#34;&gt;faq&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you read Cameron and Trivedi’s &lt;em&gt;Microeconometrics&lt;/em&gt;, where this data is presented in the
context of count models, you’ll see that they also fit a negative binomial model 2 to this data,
as it allows for overdispersion. Here, I’ll stick to a simple poisson regression, simply
because the goal of this blog post is not to get the best model; as explained in the beginning,
this is an attempt at pooling explanations when doing multiple imputation (and it’s also because
GBMs, which I use below, do not handle the negative binomial model).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm_model &amp;lt;- h2o.glm(y = &amp;quot;mdu&amp;quot;, x = features_names,
                     training_frame = original_train,
                     validation_frame = validation,
                     compute_p_values = TRUE,
                     solver = &amp;quot;IRLSM&amp;quot;,
                     lambda = 0,
                     remove_collinear_columns = TRUE,
                     score_each_iteration = TRUE,
                     family = &amp;quot;poisson&amp;quot;, 
                     link = &amp;quot;log&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have this simple model, which returns the (almost) same results as R’s &lt;code&gt;glm()&lt;/code&gt; function,
I can take a look at coefficients and see which are important, because GLMs are easily
interpretable:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view &lt;code&gt;h2o.glm()&lt;/code&gt;’s output&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(glm_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Model Details:
## ==============
## 
## H2ORegressionModel: glm
## Model Key:  GLM_model_R_1572735931328_5 
## GLM Model: summary
##    family link regularization number_of_predictors_total
## 1 poisson  log           None                         16
##   number_of_active_predictors number_of_iterations  training_frame
## 1                          16                    5 RTMP_sid_8588_3
## 
## H2ORegressionMetrics: glm
## ** Reported on training data. **
## 
## MSE:  17.6446
## RMSE:  4.200547
## MAE:  2.504063
## RMSLE:  0.8359751
## Mean Residual Deviance :  3.88367
## R^2 :  0.1006768
## Null Deviance :64161.44
## Null D.o.F. :14131
## Residual Deviance :54884.02
## Residual D.o.F. :14115
## AIC :83474.52
## 
## 
## H2ORegressionMetrics: glm
## ** Reported on validation data. **
## 
## MSE:  20.85941
## RMSE:  4.56721
## MAE:  2.574582
## RMSLE:  0.8403465
## Mean Residual Deviance :  4.153042
## R^2 :  0.09933874
## Null Deviance :19667.55
## Null D.o.F. :4078
## Residual Deviance :16940.26
## Residual D.o.F. :4062
## AIC :25273.25
## 
## 
## 
## 
## Scoring History: 
##             timestamp   duration iterations negative_log_likelihood
## 1 2019-11-03 00:33:46  0.000 sec          0             64161.43611
## 2 2019-11-03 00:33:46  0.004 sec          1             56464.99004
## 3 2019-11-03 00:33:46  0.020 sec          2             54935.05581
## 4 2019-11-03 00:33:47  0.032 sec          3             54884.19756
## 5 2019-11-03 00:33:47  0.047 sec          4             54884.02255
## 6 2019-11-03 00:33:47  0.063 sec          5             54884.02255
##   objective
## 1   4.54015
## 2   3.99554
## 3   3.88728
## 4   3.88368
## 5   3.88367
## 6   3.88367
## 
## Variable Importances: (Extract with `h2o.varimp`) 
## =================================================
## 
##        variable relative_importance scaled_importance  percentage
## 1    black.TRUE          0.67756097        1.00000000 0.236627982
## 2   health.poor          0.48287163        0.71266152 0.168635657
## 3  physlim.TRUE          0.33962316        0.50124369 0.118608283
## 4   health.fair          0.25602066        0.37785627 0.089411366
## 5      sex.male          0.19542639        0.28842628 0.068249730
## 6      ndisease          0.16661902        0.24591001 0.058189190
## 7      idp.TRUE          0.15703578        0.23176627 0.054842384
## 8    child.TRUE          0.09988003        0.14741114 0.034881600
## 9          linc          0.09830075        0.14508030 0.034330059
## 10           lc          0.08126160        0.11993253 0.028379394
## 11         lfam          0.07234463        0.10677213 0.025265273
## 12         fmde          0.06622332        0.09773781 0.023127501
## 13      educdec          0.06416087        0.09469387 0.022407220
## 14  health.good          0.05501613        0.08119732 0.019213558
## 15          age          0.03167598        0.04675000 0.011062359
## 16          lpi          0.01938077        0.02860373 0.006768444&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;As a bonus, let’s see the output of the &lt;code&gt;glm()&lt;/code&gt; function:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view &lt;code&gt;glm()&lt;/code&gt;’s output&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_tibble &amp;lt;- as_tibble(original_train)

r_glm &amp;lt;- glm(mdu ~ ., data = train_tibble,
            family = poisson(link = &amp;quot;log&amp;quot;))

summary(r_glm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = mdu ~ ., family = poisson(link = &amp;quot;log&amp;quot;), data = train_tibble)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.7039  -1.7890  -0.8433   0.4816  18.4703  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)  0.0005100  0.0585681   0.009   0.9931    
## lc          -0.0475077  0.0072280  -6.573 4.94e-11 ***
## idpTRUE     -0.1794563  0.0139749 -12.841  &amp;lt; 2e-16 ***
## lpi          0.0129742  0.0022141   5.860 4.63e-09 ***
## fmde        -0.0166968  0.0042265  -3.951 7.80e-05 ***
## physlimTRUE  0.3182780  0.0126868  25.087  &amp;lt; 2e-16 ***
## ndisease     0.0222300  0.0007215  30.811  &amp;lt; 2e-16 ***
## healthfair   0.2434235  0.0192873  12.621  &amp;lt; 2e-16 ***
## healthgood   0.0231824  0.0115398   2.009   0.0445 *  
## healthpoor   0.4608598  0.0329124  14.003  &amp;lt; 2e-16 ***
## linc         0.0826053  0.0062208  13.279  &amp;lt; 2e-16 ***
## lfam        -0.1194981  0.0106904 -11.178  &amp;lt; 2e-16 ***
## educdec      0.0205582  0.0019404  10.595  &amp;lt; 2e-16 ***
## age          0.0041397  0.0005152   8.035 9.39e-16 ***
## sexmale     -0.2096761  0.0104668 -20.032  &amp;lt; 2e-16 ***
## childTRUE    0.1529588  0.0179179   8.537  &amp;lt; 2e-16 ***
## blackTRUE   -0.6231230  0.0176758 -35.253  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 64043  on 14096  degrees of freedom
## Residual deviance: 55529  on 14080  degrees of freedom
## AIC: 84052
## 
## Number of Fisher Scoring iterations: 6&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;I could also use the excellent &lt;code&gt;{ggeffects}&lt;/code&gt; package to see the marginal effects of
different variables, for instance &lt;code&gt;&amp;quot;linc&amp;quot;&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggeffects)

ggeffect(r_glm, &amp;quot;linc&amp;quot;) %&amp;gt;% 
    ggplot(aes(x, predicted)) +
    geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = &amp;quot;#0f4150&amp;quot;) +
    geom_line(colour = &amp;quot;#82518c&amp;quot;) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that as “linc” (and other covariates are held constant), the target variable increases.&lt;/p&gt;
&lt;p&gt;Let’s also take a look at the marginal effect of a categorical variable, namely &lt;code&gt;&amp;quot;sex&amp;quot;&lt;/code&gt;:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view another example of marginal effects&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggeffects)

ggeffect(r_glm, &amp;quot;sex&amp;quot;) %&amp;gt;% 
    ggplot(aes(x, predicted)) +
    geom_point(colour = &amp;quot;#82518c&amp;quot;) +
    geom_errorbar(aes(x, ymin = conf.low, ymax = conf.high), colour = &amp;quot;#82518c&amp;quot;) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;
&lt;/details&gt;
&lt;p&gt;In the case of the &lt;code&gt;&amp;quot;sex&amp;quot;&lt;/code&gt; variable, men have significantly less doctor contacts than women.&lt;/p&gt;
&lt;p&gt;Now, let’s suppose that I want to train a model with a more complicated name, in order to justify
my salary. Suppose I go with one of those nifty &lt;em&gt;black-box&lt;/em&gt; models, for instance a GBM, which
very likely will perform better than the GLM from before. GBMs are available in &lt;code&gt;{h2o}&lt;/code&gt; via the
&lt;code&gt;h2o.gbm()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gbm_model &amp;lt;- h2o.gbm(y = &amp;quot;mdu&amp;quot;, x = features_names,
            training_frame = original_train,
            validation_frame = validation,
            distribution = &amp;quot;poisson&amp;quot;,
            score_each_iteration = TRUE,
            ntrees = 110,
            max_depth = 20,
            sample_rate = 0.6,
            col_sample_rate = 0.8,
            col_sample_rate_per_tree = 0.9,
            learn_rate = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To find a set of good hyper-parameter values, I actually used &lt;code&gt;h2o.automl()&lt;/code&gt; and then used the
returned parameter values from the leader model. Maybe I’ll write another blog post about
&lt;code&gt;h2o.automl()&lt;/code&gt; one day, it’s quite cool. Anyways, now, how do I get me some explainability out of
this? The model does perform better than the GLM as indicated by all the different metrics, but
now I cannot compute any marginal effects, or anything like that. I do get feature importance
by default with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h2o.varimp(gbm_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Variable Importances: 
##    variable relative_importance scaled_importance percentage
## 1       age       380350.093750          1.000000   0.214908
## 2      linc       282274.343750          0.742143   0.159492
## 3  ndisease       245862.718750          0.646412   0.138919
## 4       lpi       173552.734375          0.456297   0.098062
## 5   educdec       148186.265625          0.389605   0.083729
## 6      lfam       139174.312500          0.365911   0.078637
## 7      fmde        94193.585938          0.247650   0.053222
## 8    health        86160.679688          0.226530   0.048683
## 9       sex        63502.667969          0.166958   0.035881
## 10       lc        50674.968750          0.133232   0.028633
## 11  physlim        45328.382812          0.119175   0.025612
## 12    black        26376.841797          0.069349   0.014904
## 13      idp        24809.185547          0.065227   0.014018
## 14    child         9382.916992          0.024669   0.005302&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but that’s it. And had I chosen a different “black-box” model, not based on trees, then I would
not even have that.
Thankfully, there’s the amazing &lt;code&gt;{iml}&lt;/code&gt; package that contains a lot of functions for model-agnostic
explanations. If you are not familiar with this package and the methods it implements, I highly
encourage you to read the free online &lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/&#34;&gt;ebook&lt;/a&gt;
written by the packages author, Christoph Molnar
(who you can follow on &lt;a href=&#34;https://twitter.com/ChristophMolnar&#34;&gt;Twitter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Out of the box, &lt;code&gt;{iml}&lt;/code&gt; works with several machine learning frameworks, such as &lt;code&gt;{caret}&lt;/code&gt; or &lt;code&gt;{mlr}&lt;/code&gt;
but not with &lt;code&gt;{h2o}&lt;/code&gt;. However, this is not an issue; you only need to create a predict function
which returns a data frame (&lt;code&gt;h2o.predict()&lt;/code&gt; used for prediction with h2o models returns an
h2o frame). I have found this interesting blog post from
&lt;a href=&#34;https://www.business-science.io/business/2018/08/13/iml-model-interpretability.html&#34;&gt;business-science.io&lt;/a&gt;
which explains how to do this. I highly recommend you read this blog post, as it goes much deeper
into the capabilities of &lt;code&gt;{iml}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So let’s write a predict function that &lt;code&gt;{iml}&lt;/code&gt; can use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#source: https://www.business-science.io/business/2018/08/13/iml-model-interpretability.html
predict_for_iml &amp;lt;- function(model, newdata){
  as_tibble(h2o.predict(model, as.h2o(newdata)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let’s now create a &lt;code&gt;Predictor&lt;/code&gt; object. These objects are used by &lt;code&gt;{iml}&lt;/code&gt; to create explanations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;just_features &amp;lt;- as_tibble(holdout[, 2:15])
actual_target &amp;lt;- as_tibble(holdout[, 1])

predictor_original &amp;lt;- Predictor$new(
  model = gbm_model, 
  data = just_features, 
  y = actual_target, 
  predict.fun = predict_for_iml
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;predictor_original&lt;/code&gt; can now be used to compute all kinds of explanations. I won’t go into much
detail here, as this blog post is already quite long (and I haven’t even reached what I actually
want to write about yet) and you can read more on the before-mentioned blog post or directly
from Christoph Molnar’s ebook linked above.&lt;/p&gt;
&lt;p&gt;First, let’s compute a partial dependence plot, which shows the marginal effect of a variable
on the outcome. This is to compare it to the one from the GLM model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;feature_effect_original &amp;lt;- FeatureEffect$new(predictor_original, &amp;quot;linc&amp;quot;, method = &amp;quot;pdp&amp;quot;)

plot(feature_effect_original) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;feature_effect_original &amp;lt;- FeatureEffect$new(predictor_original, &amp;quot;linc&amp;quot;, method = &amp;quot;pdp&amp;quot;)

plot(feature_effect_original) +
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Quite similar to the marginal effects from the GLM!
Let’s now compute model-agnostic feature importances:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;feature_importance_original &amp;lt;- FeatureImp$new(predictor_original, loss = &amp;quot;mse&amp;quot;)

plot(feature_importance_original)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And finally, the interaction effect of the &lt;code&gt;sex&lt;/code&gt; variable interacted with all the others:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interaction_sex_original &amp;lt;- Interaction$new(predictor_original, feature = &amp;quot;sex&amp;quot;)

plot(interaction_sex_original)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok so let’s assume that I’m happy with these explanations, and do need or want to go further.
This would be the end of it in an ideal world, but this is not an ideal world unfortunately,
but it’s the best we’ve got. In the real world, it often happens that data comes with missing values.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;missing-data-and-explainability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Missing data and explainability&lt;/h2&gt;
&lt;p&gt;As explained in the beginning, I’ve been wondering how to deal with missing values when the goal
of the analysis is explainability. How can the explanations be pooled? Let’s start
with creating a data set with missing values, then perform multiple imputation, then perform
the analysis.&lt;/p&gt;
&lt;p&gt;First, let me create a &lt;code&gt;patterns&lt;/code&gt; matrix, that I will pass to the &lt;code&gt;ampute()&lt;/code&gt; function from the
&lt;code&gt;{mice}&lt;/code&gt; package. This function creates a dataset with missing values, and by using its &lt;code&gt;patterns&lt;/code&gt;
argument, I can decide which columns should have missing values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;patterns &amp;lt;- -1*(diag(1, nrow = 15, ncol = 15) - 1)

patterns[ ,c(seq(1, 6), c(9, 13))] &amp;lt;- 0

amputed_train &amp;lt;- ampute(as_tibble(original_train), prop = 0.1, patterns = patterns, mech = &amp;quot;MNAR&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Data is made numeric because the calculation of weights requires
## numeric data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the missingness pattern:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;naniar::vis_miss(amputed_train$amp) + 
    brotools::theme_blog() + 
      theme(axis.text.x=element_text(angle=90, hjust=1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, so now let’s suppose that this was the dataset I was given. As a serious data scientist,
I decide to perform multiple imputation first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imputed_train_data &amp;lt;- mice(data = amputed_train$amp, m = 10)

long_train_data &amp;lt;- complete(imputed_train_data, &amp;quot;long&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So because I performed multiple imputation 10 times, I now have 10 different datasets. I should
now perform my analysis on these 10 datasets, which means I should run my GBM on each of them,
and then get out the explanations for each of them. So let’s do just that. But first, let’s
change the columns back to how they were; to perform amputation, the factor columns were
converted to numbers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;long_train_data &amp;lt;- long_train_data %&amp;gt;% 
    mutate(idp = ifelse(idp == 1, FALSE, TRUE),
           physlim = ifelse(physlim == 1, FALSE, TRUE),
           health = as.factor(case_when(health == 1 ~ &amp;quot;excellent&amp;quot;,
                              health == 2 ~ &amp;quot;fair&amp;quot;,
                              health == 3 ~ &amp;quot;good&amp;quot;, 
                              health == 4 ~  &amp;quot;poor&amp;quot;)),
           sex = as.factor(ifelse(sex == 1, &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;)),
           child = ifelse(child == 1, FALSE, TRUE),
           black = ifelse(black == 1, FALSE, TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so now we’re ready to go. I will use the &lt;code&gt;h2o.gbm()&lt;/code&gt; function on each imputed data set.
For this, I’ll use the &lt;code&gt;group_by()&lt;/code&gt;-&lt;code&gt;nest()&lt;/code&gt; trick which consists in grouping the dataset by
the &lt;code&gt;.imp&lt;/code&gt; column, then nesting it, then mapping the &lt;code&gt;h2o.gbm()&lt;/code&gt; function to each imputed
dataset. If you are not familiar with this, you can read
&lt;a href=&#34;https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/&#34;&gt;this other&lt;/a&gt; blog post, which
explains the approach. I define a custom function, &lt;code&gt;train_on_imputed_data()&lt;/code&gt; to run &lt;code&gt;h2o.gbm()&lt;/code&gt; on
each imputed data set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_on_imputed_data &amp;lt;- function(long_data){
    long_data %&amp;gt;% 
        group_by(.imp) %&amp;gt;% 
        nest() %&amp;gt;% 
        mutate(model = map(data, ~h2o.gbm(y = &amp;quot;mdu&amp;quot;, x = features_names,
            training_frame = as.h2o(.),
            validation_frame = validation,
            distribution = &amp;quot;poisson&amp;quot;,
            score_each_iteration = TRUE,
            ntrees = 110,
            max_depth = 20,
            sample_rate = 0.6,
            col_sample_rate = 0.8,
            col_sample_rate_per_tree = 0.9,
            learn_rate = 0.05)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the training takes place:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_trained &amp;lt;- train_on_imputed_data(long_train_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;imp_trained&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_trained&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
## # Groups:   .imp [10]
##     .imp            data model     
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;lt;df[,16]&amp;gt;&amp;gt; &amp;lt;list&amp;gt;    
##  1     1   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  2     2   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  3     3   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  4     4   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  5     5   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  6     6   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  7     7   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  8     8   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
##  9     9   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;
## 10    10   [14,042 × 16] &amp;lt;H2ORgrsM&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the column &lt;code&gt;model&lt;/code&gt; contains one model for each imputed dataset. Now comes the
part I wanted to write about (finally): getting explanations out of this. Getting the explanations
from each model is not the hard part, that’s easily done using some &lt;code&gt;{tidyverse}&lt;/code&gt; magic (if
you’re following along, run this bit of code below, and go make dinner, have dinner, and
wash the dishes, because it takes time to run):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;make_predictors &amp;lt;- function(model){
    Predictor$new(
        model = model, 
        data = just_features, 
        y = actual_target, 
        predict.fun = predict_for_iml
        )
}

make_effect &amp;lt;- function(predictor_object, feature = &amp;quot;linc&amp;quot;, method = &amp;quot;pdp&amp;quot;){
    FeatureEffect$new(predictor_object, feature, method)
}

make_feat_imp &amp;lt;- function(predictor_object, loss = &amp;quot;mse&amp;quot;){
    FeatureImp$new(predictor_object, loss)
}

make_interactions &amp;lt;- function(predictor_object, feature = &amp;quot;sex&amp;quot;){
    Interaction$new(predictor_object, feature = feature)
}

imp_trained &amp;lt;- imp_trained %&amp;gt;%
    mutate(predictors = map(model, make_predictors)) %&amp;gt;% 
    mutate(effect_linc = map(predictors, make_effect)) %&amp;gt;% 
    mutate(feat_imp = map(predictors, make_feat_imp)) %&amp;gt;% 
    mutate(interactions_sex = map(predictors, make_interactions))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok so now that I’ve got these explanations, I am done with my analysis. This is the time to
pool the results together. Remember, in the case of regression models as used in the social
sciences, this means averaging the estimated model parameters and using Rubin’s rule to
compute their standard errors. But in this case, this is not so obvious. Should the
explanations be averaged? Should I instead analyse them one by one, and see if they differ?
My gut feeling is that they shouldn’t differ much, but who knows? Perhaps the answer is doing
a bit of both. I have checked online for a paper that would shed some light into this, but
have not found any. So let’s take a closer look to the explanations. Let’s look at feature
importance:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view the 10 feature importances&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_trained %&amp;gt;% 
    pull(feat_imp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1 ndisease     1.0421605   1.362672      1.467244          22.03037
## 2     fmde     0.8611917   1.142809      1.258692          18.47583
## 3      lpi     0.8706659   1.103367      1.196081          17.83817
## 4   health     0.8941010   1.098014      1.480508          17.75164
## 5       lc     0.8745229   1.024288      1.296668          16.55970
## 6    black     0.7537278   1.006294      1.095054          16.26879
## 
## [[2]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1      age      0.984304   1.365702      1.473146          22.52529
## 2     linc      1.102023   1.179169      1.457907          19.44869
## 3 ndisease      1.075821   1.173938      1.642938          19.36241
## 4     fmde      1.059303   1.150112      1.281291          18.96944
## 5       lc      0.837573   1.132719      1.200556          18.68257
## 6  physlim      0.763757   1.117635      1.644434          18.43379
## 
## [[3]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1      age     0.8641304   1.334382      1.821797          21.62554
## 2    black     1.0553001   1.301338      1.429119          21.09001
## 3     fmde     0.8965085   1.208761      1.360217          19.58967
## 4 ndisease     1.0577766   1.203418      1.651611          19.50309
## 5     linc     0.9299725   1.114041      1.298379          18.05460
## 6      sex     0.9854144   1.091391      1.361406          17.68754
## 
## [[4]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##   feature importance.05 importance importance.95 permutation.error
## 1 educdec     0.9469049   1.263961      1.358115          20.52909
## 2     age     1.0980269   1.197441      1.763202          19.44868
## 3  health     0.8539843   1.133338      1.343389          18.40753
## 4    linc     0.7608811   1.123423      1.328756          18.24649
## 5     lpi     0.8203850   1.103394      1.251688          17.92118
## 6   black     0.9476909   1.089861      1.328960          17.70139
## 
## [[5]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##   feature importance.05 importance importance.95 permutation.error
## 1     lpi     0.9897789   1.336405      1.601778          22.03791
## 2 educdec     0.8701162   1.236741      1.424602          20.39440
## 3     age     0.8537786   1.181242      1.261411          19.47920
## 4    lfam     1.0185313   1.133158      1.400151          18.68627
## 5     idp     0.9502284   1.069772      1.203147          17.64101
## 6    linc     0.8600586   1.042453      1.395231          17.19052
## 
## [[6]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##   feature importance.05 importance importance.95 permutation.error
## 1      lc     0.7707383   1.208190      1.379422          19.65436
## 2     sex     0.9309901   1.202629      1.479511          19.56391
## 3    linc     1.0549563   1.138404      1.624217          18.51912
## 4     lpi     0.9360817   1.135198      1.302084          18.46696
## 5 physlim     0.7357272   1.132525      1.312584          18.42349
## 6   child     1.0199964   1.109120      1.316306          18.04274
## 
## [[7]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1     linc     0.9403425   1.262994      1.511122          20.65942
## 2       lc     1.0481333   1.233136      1.602796          20.17103
## 3 ndisease     1.1612194   1.212454      1.320208          19.83272
## 4  educdec     0.7924637   1.197343      1.388218          19.58554
## 5     lfam     0.8423790   1.178545      1.349884          19.27805
## 6      age     0.9125829   1.168297      1.409525          19.11043
## 
## [[8]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1      age     1.1281736   1.261273      1.609524          20.55410
## 2   health     0.9134557   1.240597      1.432366          20.21716
## 3     lfam     0.7469043   1.182294      1.345910          19.26704
## 4      lpi     0.8088552   1.160863      1.491139          18.91779
## 5 ndisease     1.0756671   1.104357      1.517278          17.99695
## 6     fmde     0.6929092   1.093465      1.333544          17.81946
## 
## [[9]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1  educdec     1.0188109   1.287697      1.381982          20.92713
## 2      lpi     0.9853336   1.213095      1.479002          19.71473
## 3     linc     0.8354715   1.195344      1.254350          19.42625
## 4      age     0.9980451   1.179371      1.383545          19.16666
## 5 ndisease     1.0492685   1.176804      1.397398          19.12495
## 6     lfam     1.0814043   1.166626      1.264592          18.95953
## 
## [[10]]
## Interpretation method:  FeatureImp 
## error function: mse
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##    feature importance.05 importance importance.95 permutation.error
## 1      age     0.9538824   1.211869      1.621151          19.53671
## 2      sex     0.9148921   1.211253      1.298311          19.52678
## 3     lfam     0.8227355   1.093094      1.393815          17.62192
## 4 ndisease     0.8282127   1.090779      1.205994          17.58459
## 5       lc     0.7004401   1.060870      1.541697          17.10244
## 6   health     0.8137149   1.058324      1.183639          17.06138&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;As you can see, the feature importances are quite different from each other, but I don’t think
this comes from the imputations, but rather from the fact that feature importance
&lt;em&gt;depends on shuffling the feature, which adds randomness to the measurement&lt;/em&gt;
(source: &lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/feature-importance.html#disadvantages-9&#34; class=&#34;uri&#34;&gt;https://christophm.github.io/interpretable-ml-book/feature-importance.html#disadvantages-9&lt;/a&gt;).
To mitigate this, Christoph Molnar suggests repeating the the permutation and averaging the
importance measures; I think that this would be my approach for &lt;em&gt;pooling&lt;/em&gt; as well.&lt;/p&gt;
&lt;p&gt;Let’s now take a look at interactions:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view the 10 interactions&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_trained %&amp;gt;% 
    pull(interactions_sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.07635197
## 2      idp:sex   0.08172754
## 3      lpi:sex   0.10704357
## 4     fmde:sex   0.11267146
## 5  physlim:sex   0.04099073
## 6 ndisease:sex   0.16314524
## 
## [[2]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.10349820
## 2      idp:sex   0.07432519
## 3      lpi:sex   0.11651413
## 4     fmde:sex   0.18123926
## 5  physlim:sex   0.12952808
## 6 ndisease:sex   0.14528876
## 
## [[3]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.05919320
## 2      idp:sex   0.05586197
## 3      lpi:sex   0.24253335
## 4     fmde:sex   0.05240474
## 5  physlim:sex   0.06404969
## 6 ndisease:sex   0.14508072
## 
## [[4]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.02775529
## 2      idp:sex   0.02050390
## 3      lpi:sex   0.11781130
## 4     fmde:sex   0.11084240
## 5  physlim:sex   0.17932694
## 6 ndisease:sex   0.07181589
## 
## [[5]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.12873151
## 2      idp:sex   0.03681428
## 3      lpi:sex   0.15879389
## 4     fmde:sex   0.16952900
## 5  physlim:sex   0.07031520
## 6 ndisease:sex   0.10567463
## 
## [[6]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.15320481
## 2      idp:sex   0.08645037
## 3      lpi:sex   0.16674641
## 4     fmde:sex   0.14671054
## 5  physlim:sex   0.09236257
## 6 ndisease:sex   0.14605618
## 
## [[7]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.04072960
## 2      idp:sex   0.05641868
## 3      lpi:sex   0.19491959
## 4     fmde:sex   0.07119644
## 5  physlim:sex   0.05777469
## 6 ndisease:sex   0.16555363
## 
## [[8]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.04979709
## 2      idp:sex   0.06036898
## 3      lpi:sex   0.14009307
## 4     fmde:sex   0.10927688
## 5  physlim:sex   0.08761533
## 6 ndisease:sex   0.20544585
## 
## [[9]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.08572075
## 2      idp:sex   0.12254979
## 3      lpi:sex   0.17532347
## 4     fmde:sex   0.12557420
## 5  physlim:sex   0.05084209
## 6 ndisease:sex   0.13977328
## 
## [[10]]
## Interpretation method:  Interaction 
## 
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##       .feature .interaction
## 1       lc:sex   0.08636490
## 2      idp:sex   0.04807331
## 3      lpi:sex   0.17922280
## 4     fmde:sex   0.05728403
## 5  physlim:sex   0.09392774
## 6 ndisease:sex   0.13408956&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;It would seem that interactions are a bit more stable. Let’s average the values; for this
I need to access the &lt;code&gt;results&lt;/code&gt; element of the interactions object and the result out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interactions_sex_result &amp;lt;- imp_trained %&amp;gt;% 
    mutate(interactions_results = map(interactions_sex, function(x)(x$results))) %&amp;gt;% 
    pull()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;interactions_sex_result&lt;/code&gt; is a list of dataframes, which means I can bind the rows together and
compute whatever I need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;interactions_sex_result %&amp;gt;% 
    bind_rows() %&amp;gt;% 
    group_by(.feature) %&amp;gt;% 
    summarise_at(.vars = vars(.interaction), 
                 .funs = funs(mean, sd, low_ci = quantile(., 0.05), high_ci = quantile(., 0.95)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 x 5
##    .feature       mean     sd low_ci high_ci
##    &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 age:sex      0.294  0.0668 0.181    0.369
##  2 black:sex    0.117  0.0286 0.0763   0.148
##  3 child:sex    0.0817 0.0308 0.0408   0.125
##  4 educdec:sex  0.148  0.0411 0.104    0.220
##  5 fmde:sex     0.114  0.0443 0.0546   0.176
##  6 health:sex   0.130  0.0190 0.104    0.151
##  7 idp:sex      0.0643 0.0286 0.0278   0.106
##  8 lc:sex       0.0811 0.0394 0.0336   0.142
##  9 lfam:sex     0.149  0.0278 0.125    0.198
## 10 linc:sex     0.142  0.0277 0.104    0.179
## 11 lpi:sex      0.160  0.0416 0.111    0.221
## 12 ndisease:sex 0.142  0.0356 0.0871   0.187
## 13 physlim:sex  0.0867 0.0415 0.0454   0.157&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That seems pretty good. Now, what about the partial dependence? Let’s take a closer look:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to view the 10 pdps&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_trained %&amp;gt;% 
    pull(effect_linc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.652445   pdp
## 2 0.5312226 1.687522   pdp
## 3 1.0624453 1.687522   pdp
## 4 1.5936679 1.687522   pdp
## 5 2.1248905 1.685088   pdp
## 6 2.6561132 1.694112   pdp
## 
## [[2]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.813449   pdp
## 2 0.5312226 1.816195   pdp
## 3 1.0624453 1.816195   pdp
## 4 1.5936679 1.816195   pdp
## 5 2.1248905 1.804457   pdp
## 6 2.6561132 1.797238   pdp
## 
## [[3]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.906515   pdp
## 2 0.5312226 2.039318   pdp
## 3 1.0624453 2.039318   pdp
## 4 1.5936679 2.039318   pdp
## 5 2.1248905 2.002970   pdp
## 6 2.6561132 2.000922   pdp
## 
## [[4]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.799552   pdp
## 2 0.5312226 2.012634   pdp
## 3 1.0624453 2.012634   pdp
## 4 1.5936679 2.012634   pdp
## 5 2.1248905 1.982425   pdp
## 6 2.6561132 1.966392   pdp
## 
## [[5]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.929158   pdp
## 2 0.5312226 1.905171   pdp
## 3 1.0624453 1.905171   pdp
## 4 1.5936679 1.905171   pdp
## 5 2.1248905 1.879721   pdp
## 6 2.6561132 1.869113   pdp
## 
## [[6]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 2.147697   pdp
## 2 0.5312226 2.162393   pdp
## 3 1.0624453 2.162393   pdp
## 4 1.5936679 2.162393   pdp
## 5 2.1248905 2.119923   pdp
## 6 2.6561132 2.115131   pdp
## 
## [[7]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.776742   pdp
## 2 0.5312226 1.957938   pdp
## 3 1.0624453 1.957938   pdp
## 4 1.5936679 1.957938   pdp
## 5 2.1248905 1.933847   pdp
## 6 2.6561132 1.885287   pdp
## 
## [[8]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 2.020647   pdp
## 2 0.5312226 2.017981   pdp
## 3 1.0624453 2.017981   pdp
## 4 1.5936679 2.017981   pdp
## 5 2.1248905 1.981122   pdp
## 6 2.6561132 2.017604   pdp
## 
## [[9]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.811189   pdp
## 2 0.5312226 2.003053   pdp
## 3 1.0624453 2.003053   pdp
## 4 1.5936679 2.003053   pdp
## 5 2.1248905 1.938150   pdp
## 6 2.6561132 1.918518   pdp
## 
## [[10]]
## Interpretation method:  FeatureEffect 
## features: linc[numerical]
## grid size: 20
## 
## Analysed predictor: 
## Prediction task: unknown 
## 
## 
## Analysed data:
## Sampling from data.frame with 2013 rows and 14 columns.
## 
## Head of results:
##        linc   .y.hat .type
## 1 0.0000000 1.780325   pdp
## 2 0.5312226 1.850203   pdp
## 3 1.0624453 1.850203   pdp
## 4 1.5936679 1.850203   pdp
## 5 2.1248905 1.880805   pdp
## 6 2.6561132 1.881305   pdp&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;As you can see, the values are quite similar. I think that in the case of plots, the best way
to visualize the impact of the imputation is to simply plot all the lines in a single plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;effect_linc_results &amp;lt;- imp_trained %&amp;gt;% 
    mutate(effect_linc_results = map(effect_linc, function(x)(x$results))) %&amp;gt;% 
    select(.imp, effect_linc_results) %&amp;gt;% 
    unnest(effect_linc_results)

effect_linc_results %&amp;gt;% 
    bind_rows() %&amp;gt;% 
    ggplot() + 
    geom_line(aes(y = .y.hat, x = linc, group = .imp), colour = &amp;quot;#82518c&amp;quot;) + 
    brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-11-02-mice_exp_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, the partial dependence plot seems to behave in a very similar way across the different
imputed datasets!&lt;/p&gt;
&lt;p&gt;To conclude, I think that the approach I suggest here is nothing revolutionary; it is consistent
with the way one should conduct an analysis with multiple imputed datasets. However, the pooling
step is non-trivial and there is no magic recipe; it really depends on the goal of the analysis
and what you want or need to show.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cluster multiple time series using K-means</title>
      <link>https://www.brodrigues.co/blog/2019-10-12-cluster_ts/</link>
      <pubDate>Sun, 13 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-10-12-cluster_ts/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Elbow_method_(clustering)&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/deepfried_elbow.jpg&#34; title = &#34;A life saving skill&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have been recently confronted to the issue of finding similarities among time-series and though
about using k-means to cluster them. To illustrate the method, I’ll be using data from the
Penn World Tables, readily available in R (inside the &lt;code&gt;{pwt9}&lt;/code&gt; package):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(pwt9)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, of all, let’s only select the needed columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pwt &amp;lt;- pwt9.0 %&amp;gt;%
select(country, year, avh)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;avh&lt;/code&gt; contains the average worked hours for a given country and year. The data looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(pwt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          country year avh
## ABW-1950   Aruba 1950  NA
## ABW-1951   Aruba 1951  NA
## ABW-1952   Aruba 1952  NA
## ABW-1953   Aruba 1953  NA
## ABW-1954   Aruba 1954  NA
## ABW-1955   Aruba 1955  NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For each country, there’s yearly data on the &lt;code&gt;avh&lt;/code&gt; variable. The goal here is to cluster the different
countries by looking at how similar they are on the &lt;code&gt;avh&lt;/code&gt; variable. Let’s do some further cleaning.
The k-means implementation in R expects a wide data frame (currently my data frame is in the long
format) and no missing values. These could potentially be imputed, but I can’t be bothered:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pwt_wide &amp;lt;- pwt %&amp;gt;%
  pivot_wider(names_from = year, values_from = avh)  %&amp;gt;%
  filter(!is.na(`1950`)) %&amp;gt;%
  mutate_at(vars(-country), as.numeric)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To convert my data frame from long to wide, I use the fresh &lt;code&gt;pivot_wider()&lt;/code&gt; function, instead of the
less intuitive &lt;code&gt;spread()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;We’re ready to use the k-means algorithm. To know how many clusters I should aim for, I’ll be using
the elbow method (if you’re not familiar with this method, click on the image at the very top of
this post):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wss &amp;lt;- map_dbl(1:5, ~{kmeans(select(pwt_wide, -country), ., nstart=50,iter.max = 15 )$tot.withinss})

n_clust &amp;lt;- 1:5

elbow_df &amp;lt;- as.data.frame(cbind(&amp;quot;n_clust&amp;quot; = n_clust, &amp;quot;wss&amp;quot; = wss))


ggplot(elbow_df) +
geom_line(aes(y = wss, x = n_clust), colour = &amp;quot;#82518c&amp;quot;) +
theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-10-12-cluster_ts_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like 3 clusters is a good choice. Let’s now run the kmeans algorithm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clusters &amp;lt;- kmeans(select(pwt_wide, -country), centers = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;clusters&lt;/code&gt; is a list with several interesting items. The item &lt;code&gt;centers&lt;/code&gt; contains the “average”
time series:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(centers &amp;lt;- rownames_to_column(as.data.frame(clusters$centers), &amp;quot;cluster&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   cluster     1950     1951     1952     1953     1954     1955     1956
## 1       1 2110.440 2101.273 2088.947 2074.273 2066.617 2053.391 2034.926
## 2       2 2086.509 2088.571 2084.433 2081.939 2078.756 2078.710 2074.175
## 3       3 2363.600 2350.774 2338.032 2325.375 2319.011 2312.083 2308.483
##       1957     1958     1959     1960     1961     1962     1963     1964
## 1 2021.855 2007.221 1995.038 1985.904 1978.024 1971.618 1963.780 1962.983
## 2 2068.807 2062.021 2063.687 2060.176 2052.070 2044.812 2038.939 2037.488
## 3 2301.355 2294.556 2287.556 2279.773 2272.899 2262.781 2255.690 2253.431
##       1965     1966     1967     1968     1969     1970     1971     1972
## 1 1952.945 1946.961 1928.445 1908.354 1887.624 1872.864 1855.165 1825.759
## 2 2027.958 2021.615 2015.523 2007.176 2001.289 1981.906 1967.323 1961.269
## 3 2242.775 2237.216 2228.943 2217.717 2207.037 2190.452 2178.955 2167.124
##       1973     1974     1975     1976     1977     1978     1979     1980
## 1 1801.370 1770.484 1737.071 1738.214 1713.395 1693.575 1684.215 1676.703
## 2 1956.755 1951.066 1933.527 1926.508 1920.668 1911.488 1904.316 1897.103
## 3 2156.304 2137.286 2125.298 2118.138 2104.382 2089.717 2083.036 2069.678
##       1981     1982     1983     1984     1985     1986     1987     1988
## 1 1658.894 1644.019 1636.909 1632.371 1623.901 1615.320 1603.383 1604.331
## 2 1883.376 1874.730 1867.266 1861.386 1856.947 1849.568 1848.748 1847.690
## 3 2055.658 2045.501 2041.428 2030.095 2040.210 2033.289 2028.345 2029.290
##       1989     1990     1991     1992     1993     1994     1995     1996
## 1 1593.225 1586.975 1573.084 1576.331 1569.725 1567.599 1567.113 1558.274
## 2 1842.079 1831.907 1823.552 1815.864 1823.824 1830.623 1831.815 1831.648
## 3 2031.741 2029.786 1991.807 1974.954 1973.737 1975.667 1980.278 1988.728
##       1997     1998     1999     2000     2001     2002     2003     2004
## 1 1555.079 1555.071 1557.103 1545.349 1530.207 1514.251 1509.647 1522.389
## 2 1835.372 1836.030 1839.857 1827.264 1813.477 1781.696 1786.047 1781.858
## 3 1985.076 1961.219 1966.310 1959.219 1946.954 1940.110 1924.799 1917.130
##       2005     2006     2007     2008     2009     2010     2011     2012
## 1 1514.492 1512.872 1515.299 1514.055 1493.875 1499.563 1503.049 1493.862
## 2 1775.167 1776.759 1773.587 1771.648 1734.559 1736.098 1742.143 1735.396
## 3 1923.496 1912.956 1902.156 1897.550 1858.657 1861.875 1861.608 1850.802
##       2013     2014
## 1 1485.589 1486.991
## 2 1729.973 1729.543
## 3 1848.158 1851.829&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;clusters&lt;/code&gt; also contains the &lt;code&gt;cluster&lt;/code&gt; item, which tells me to which cluster the different countries
belong to. I can easily add this to the original data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pwt_wide &amp;lt;- pwt_wide %&amp;gt;% 
  mutate(cluster = clusters$cluster)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s prepare the data for visualisation. I have to go back to a long data frame for this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pwt_long &amp;lt;- pwt_wide %&amp;gt;%
  pivot_longer(cols=c(-country, -cluster), names_to = &amp;quot;year&amp;quot;, values_to = &amp;quot;avh&amp;quot;) %&amp;gt;%
  mutate(year = ymd(paste0(year, &amp;quot;-01-01&amp;quot;)))

centers_long &amp;lt;- centers %&amp;gt;%
  pivot_longer(cols = -cluster, names_to = &amp;quot;year&amp;quot;, values_to = &amp;quot;avh&amp;quot;) %&amp;gt;%  
  mutate(year = ymd(paste0(year, &amp;quot;-01-01&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And I can now plot the different time series, by cluster and highlight the “average” time series
for each cluster as well (yellow line):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_line(data = pwt_long, aes(y = avh, x = year, group = country), colour = &amp;quot;#82518c&amp;quot;) +
  facet_wrap(~cluster, nrow = 1) + 
  geom_line(data = centers_long, aes(y = avh, x = year, group = cluster), col = &amp;quot;#b58900&amp;quot;, size = 2) +
  theme_blog() +
  labs(title = &amp;quot;Average hours worked in several countries&amp;quot;, 
       caption = &amp;quot;The different time series have been clustered using k-means.
                 Cluster 1: Belgium, Switzerland, Germany, Denmark, France, Luxembourg, Netherlands,
                 Norway, Sweden.\nCluster 2: Australia, Colombia, Ireland, Iceland, Japan, Mexico,
                 Portugal, Turkey.\nCluster 3: Argentina, Austria, Brazil, Canada, Cyprus, Spain, Finland,
                 UK, Italy, New Zealand, Peru, USA, Venezuela&amp;quot;) +
  theme(plot.caption = element_text(colour = &amp;quot;white&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-10-12-cluster_ts_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Split-apply-combine for Maximum Likelihood Estimation of a linear model</title>
      <link>https://www.brodrigues.co/blog/2019-10-05-parallel_maxlik/</link>
      <pubDate>Sat, 05 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-10-05-parallel_maxlik/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www.univ-orleans.fr/deg/masters/ESA/CH/Chapter2_MLE.pdf&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/hieforth.png&#34; title = &#34;click with thy mouse hither to wot moe about maximum plausability estimation&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;div id=&#34;intro&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intro&lt;/h2&gt;
&lt;p&gt;Maximum likelihood estimation is a very useful technique to fit a model to data used a lot in
econometrics and other sciences, but seems, at least to my knowledge, to not be so well known by
machine learning practitioners (but I may be wrong about that). Other useful techniques to confront models to data
used in econometrics are the minimum distance family of techniques such as the general method of
moments or Bayesian approaches, while machine learning practitioners seem to favor the minimization
of a loss function (the mean squared error in the case of linear regression for instance).&lt;/p&gt;
&lt;p&gt;When I taught at the university, students had often some problems to understand the technique.
It is true that it is not as easy to understand as ordinary least squares, but I’ll try to explain
to the best of my abilities.&lt;/p&gt;
&lt;p&gt;Given a sample of data, what is the unknown probability distribution
that &lt;em&gt;most likely&lt;/em&gt; generated it? For instance, if your sample only contains 0’s and 1’s, and
the proportion of 1’s is 80%, what do you think is the most likely distribution that generated it?
The probability distribution that &lt;em&gt;most likely&lt;/em&gt; generated such a dataset is a binomial distribution
with probability of success equal to 80%. It &lt;em&gt;might have been&lt;/em&gt; a binomial distribution with probability
of success equal to, say, 60%, but the &lt;em&gt;most likely&lt;/em&gt; one is one with probability of success equal
to 80%.&lt;/p&gt;
&lt;p&gt;To perform maximum likelihood estimation, one thus needs to assume a certain probability distribution,
and then look for the parameters that maximize the likelihood that this distribution generated the
observed data. So, now the question is, how to maximize this likelihood? And mathematically speaking,
what is a &lt;em&gt;likelihood&lt;/em&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-theory&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some theory&lt;/h2&gt;
&lt;p&gt;First of all, let’s assume that each observation from your dataset not only was generated from the
same distribution, but that each observation is also independent from each other. For instance, if in your sample
you have data on people’s wages and socio-economic background, it is safe to assume, under certain
circumstances, that the observations are independent.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; be random variables, and &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; be their realizations (actual observed values).
Let’s assume that the &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt; are distributed according
to a certain probability distribution &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; with density &lt;span class=&#34;math inline&#34;&gt;\(f(\theta)\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is
a parameter of said distribution.
Because our sample is composed of i.i.d. random variables, the probability that it was generated by
our distribution &lt;span class=&#34;math inline&#34;&gt;\(D(\theta)\)&lt;/span&gt; is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\prod_{i=1}^N Pr(X_i = x_i)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is customary to take the log of this expression:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log(\prod_{i=1}^N Pr(X_i = x_i)) = \sum_{i=1}^N \log(Pr(X_i = x_i))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The expression above is called the &lt;em&gt;log-likelihood&lt;/em&gt;, &lt;span class=&#34;math inline&#34;&gt;\(logL(\theta; x_1, ..., x_N)\)&lt;/span&gt;. Maximizing this
function yields &lt;span class=&#34;math inline&#34;&gt;\(\theta^*\)&lt;/span&gt;, the value of the parameter that makes the sample the most probable.
In the case of linear regression, the density function to use is the one from the Normal distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;maximum-likelihood-of-the-linear-model-as-an-example-of-the-split-apply-combine-strategy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Maximum likelihood of the linear model as an example of the split-apply-combine strategy&lt;/h2&gt;
&lt;p&gt;Hadley Wickham’s seminal paper, &lt;a href=&#34;https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf&#34;&gt;The Split-Apply-Combine Strategy for Data Analysis&lt;/a&gt;
presents the &lt;em&gt;split-apply-combine&lt;/em&gt; strategy, which should remind the reader of the map-reduce
framework from Google. The idea is to recognize that in some cases big problems are simply an
aggregation of smaller problems. This is the case for Maximum Likelihood Estimation of the linear
model as well.
The picture below illustrates how Maximum Likelihood works, in the standard case:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/maxlik_1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Let’s use R to do exactly this. Let’s first start by simulating some data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
size &amp;lt;- 500000

x1 &amp;lt;- rnorm(size)
x2 &amp;lt;- rnorm(size)
x3 &amp;lt;- rnorm(size)

dep_y &amp;lt;- 1.5 + 2*x1 + 3*x2 + 4*x3 + rnorm(size)

x_data &amp;lt;- cbind(dep_y, 1, x1, x2, x3)

x_df &amp;lt;- as.data.frame(x_data) %&amp;gt;%
  rename(iota = V2)

head(x_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       dep_y iota         x1          x2         x3
## 1  1.637044    1  0.2287198  0.91609653 -0.4006215
## 2 -1.684578    1  1.2780291 -0.02468559 -1.4020914
## 3  1.289595    1  1.0524842  0.30206515 -0.3553641
## 4 -3.769575    1 -2.5763576  0.13864796 -0.3181661
## 5 13.110239    1 -0.9376462  0.77965301  3.0351646
## 6  5.059152    1  0.7488792 -0.10049061  0.1307225&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that this is done, let’s write a function to perform Maximum Likelihood Estimation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loglik_linmod &amp;lt;- function(parameters, x_data){
  sum_log_likelihood &amp;lt;- x_data %&amp;gt;%
    mutate(log_likelihood =
             dnorm(dep_y,
                   mean = iota*parameters[1] + x1*parameters[2] + x2*parameters[3] + x3*parameters[4],
                   sd = parameters[5],
                   log = TRUE)) %&amp;gt;%
    summarise(sum(log_likelihood))

  -1 * sum_log_likelihood
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function returns minus the log likelihood, because &lt;code&gt;optim()&lt;/code&gt; which I will be using to optimize
the log-likelihood function minimizes functions by default (minimizing the opposite of a function is the
same as maximizing a function). Let’s optimize the function and see if we’re able to find the
parameters of the data generating process, &lt;code&gt;1.5, 2, 3, 4&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; (the standard deviation of the
error term):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optim(c(1,1,1,1,1), loglik_linmod, x_data = x_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We successfully find the parameters of our data generating process!&lt;/p&gt;
&lt;p&gt;Now, what if I’d like to distribute the computation of the contribution to the likelihood of each
observations across my 12 cores? The goal is not necessarily to speed up the computations but
to be able to handle larger than RAM data. If I have data that is too large to fit in memory,
I could split it into chunks, compute the contributions to the likelihood of each chunk, sum
everything again, and voila! This is illustrated below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/maxlik_2.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;To do this, I use the &lt;code&gt;{disk.frame}&lt;/code&gt; package, and only need to change my &lt;code&gt;loglik_linmod()&lt;/code&gt; function
slightly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;disk.frame&amp;quot;)
x_diskframe &amp;lt;- as.disk.frame(x_df) #Convert the data frame to a disk.frame

loglik_linmod_df &amp;lt;- function(parameters, x_data){
  sum_log_likelihood &amp;lt;- x_data %&amp;gt;%
    mutate(log_likelihood =
             dnorm(dep_y,
                   mean = iota*parameters[1] + x1*parameters[2] + x2*parameters[3] + x3*parameters[4],
                   sd = parameters[5],
                   log = TRUE)) %&amp;gt;% 
    chunk_summarise(sum(log_likelihood))

  out &amp;lt;- sum_log_likelihood %&amp;gt;%
    collect() %&amp;gt;%
    pull() %&amp;gt;%
    sum()

  -out
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function is applied to each chunk, and &lt;code&gt;chunk_summarise()&lt;/code&gt; computes the sum of the contributions
inside each chunk. Thus, I first need to use &lt;code&gt;collect()&lt;/code&gt; to transfer the chunk-wise sums in memory
and then use &lt;code&gt;pull()&lt;/code&gt; to convert it to an atomic vector, and finally sum them all again.&lt;/p&gt;
&lt;p&gt;Let’s now optimize this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optim(rep(1, 5), loglik_linmod_df, x_data = x_diskframe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $par
## [1] 1.5351722 1.9566144 3.0067978 4.0202956 0.9889412
## 
## $value
## [1] 709977.2
## 
## $counts
## function gradient 
##      502       NA 
## 
## $convergence
## [1] 1
## 
## $message
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is how you can use the split-apply-combine approach for maximum likelihood estimation of a
linear model! This approach is quite powerful, and the familiar &lt;code&gt;map()&lt;/code&gt; and &lt;code&gt;reduce()&lt;/code&gt; functions
included in &lt;code&gt;{purrr}&lt;/code&gt; can also help with this task. However, this only works if you can split your
problem into chunks, which is sometimes quite hard to achieve.&lt;/p&gt;
&lt;p&gt;However, as usual, there is rarely a need to write your own functions, as &lt;code&gt;{disk.frame}&lt;/code&gt; includes
the &lt;code&gt;dfglm()&lt;/code&gt; function which can be used to estimate any generalized linear model using &lt;code&gt;disk.frame&lt;/code&gt; objects!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>{disk.frame} is epic</title>
      <link>https://www.brodrigues.co/blog/2019-09-03-disk_frame/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-09-03-disk_frame/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/3XMTyi_H4q4&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/disk_frame.png&#34; title = &#34;Zhuo Jia Dai&#39;s talk at useR!2019&#34; width=&#34;750&#34; height=&#34;500&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Note: When I started writing this blog post, I encountered a bug and filed a &lt;a href=&#34;https://github.com/xiaodaigh/disk.frame/issues/141&#34;&gt;bug report&lt;/a&gt;
that I encourage you to read. The responsiveness of the developer was exemplary. Not only did Zhuo
solve the issue in record time, he provided ample code snippets to illustrate the solutions. Hats off
to him!&lt;/p&gt;
&lt;p&gt;This blog post is a short presentation of &lt;code&gt;{disk.frame}&lt;/code&gt; a package that makes it easy to work with
data that is too large to fit on RAM, but not large enough that it could be called big data. Think
data that is around 30GB for instance, or more, but nothing at the level of TBs.&lt;/p&gt;
&lt;p&gt;I have already written a blog post about this topic, using Spark and the R library &lt;code&gt;{sparklyr}&lt;/code&gt;, where
I showed how to set up &lt;code&gt;{sparklyr}&lt;/code&gt; to import 30GB of data. I will import the same file here, and
run a very simple descriptive analysis. If you need context about the file I’ll be using, just
read the &lt;a href=&#34;https://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data/&#34;&gt;previous blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first step, as usual, is to load the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(disk.frame)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to specify how many cores you want to dedicate to &lt;code&gt;{disk.frame}&lt;/code&gt;; of course, the
more cores you use, the faster the operations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setup_disk.frame(workers = 6)
options(future.globals.maxSize = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;setup_disk.frame(workers = 6)&lt;/code&gt; means that 6 cpu threads will be dedicated to importing and working
on the data. The second line, &lt;code&gt;future.globals.maxSize = Inf&lt;/code&gt; means that an &lt;em&gt;unlimited amount of data will be passed from worker to worker&lt;/em&gt;,
as described in the documentation.&lt;/p&gt;
&lt;p&gt;Now comes the interesting bit. If you followed the previous blog post, you should have a 30GB
csv file. This file was obtained by merging a lot of smaller sized csv files. In practice, you should
keep the files separated, and NOT merge them. This makes things much easier. However, as I said before,
I want to be in the situation, which already happened to me in the past, where I get a big-sized
csv file and I am to provide an analysis on that data. So, let’s try to read in that big file, which
I called &lt;code&gt;combined.csv&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_to_data &amp;lt;- &amp;quot;path/to/data/&amp;quot;

flights.df &amp;lt;- csv_to_disk.frame(
  paste0(path_to_data, &amp;quot;combined.csv&amp;quot;), 
  outdir = paste0(path_to_data, &amp;quot;combined.df&amp;quot;),
  in_chunk_size = 2e6,
  backend = &amp;quot;LaF&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s go through these lines, one at a time. In the first line, I simply define the path
to the folder that contains the data. The next chunk is where I read in the data using the
&lt;code&gt;csv_to_disk_frame()&lt;/code&gt; function. The first option is simply the path to the csv file. The second
option &lt;code&gt;outdir =&lt;/code&gt; is where you need to define the directory that will hold the intermediary files,
which are in the fst format. This folder, that contains these fst files, is the &lt;code&gt;disk.frame&lt;/code&gt;.
fst files are created by the &lt;code&gt;{fst}&lt;/code&gt; package, which &lt;em&gt;provides a fast, easy and flexible way to serialize data frames&lt;/em&gt;.
This means that files that are in that format can be read and written much much faster than by
other means (see a benchmark of &lt;code&gt;{fst}&lt;/code&gt; &lt;a href=&#34;https://www.fstpackage.org/&#34;&gt;here&lt;/a&gt;).
The next time you want to import the data, you can use the &lt;code&gt;disk.frame()&lt;/code&gt; function and point it to
the &lt;code&gt;combined.df&lt;/code&gt; folder. &lt;code&gt;in_chunk_size =&lt;/code&gt; specifies how many lines are to be read in one swoop,
and &lt;code&gt;backend =&lt;/code&gt; is the underlying engine that reads in the data, in this case the &lt;code&gt;{LaF}&lt;/code&gt; package.
The default backend is &lt;code&gt;{data.table}&lt;/code&gt; and there is also a &lt;code&gt;{readr}&lt;/code&gt; backend. As written in the
note at the beginning of the blog post, I encourage you to read the github issue to learn why I am
using the &lt;code&gt;LaF&lt;/code&gt; backend (the &lt;code&gt;{data.table}&lt;/code&gt; and &lt;code&gt;{readr}&lt;/code&gt; backend work as well).&lt;/p&gt;
&lt;p&gt;Now, let’s try to replicate what I did in my previous blog post, namely, computing the average
delay in departures per day. With &lt;code&gt;{disk.frame}&lt;/code&gt;, one has to be very careful about something
important however; all the &lt;code&gt;group_by()&lt;/code&gt; operations are performed &lt;em&gt;per chunk&lt;/em&gt;. This means that a second
&lt;code&gt;group_by()&lt;/code&gt; call might be needed. For more details, I encourage you to read the &lt;a href=&#34;http://diskframe.com/articles/intro-disk-frame.html#grouping&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code below is what I want to perform; group by day, and compute the average daily flight delay:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_dep_delay &amp;lt;- flights.df %&amp;gt;%
  group_by(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  summarise(mean_delay = mean(DEP_DELAY, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, because with &lt;code&gt;{disk.frame}&lt;/code&gt;, &lt;code&gt;group_by()&lt;/code&gt; calls are performed per chunk, the code must now
be changed. The first step is to compute the sum of delays within each chunk, and count the number
of days within each chunk. This is the time consuming part:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic &amp;lt;- Sys.time()
mean_dep_delay &amp;lt;- flights.df %&amp;gt;%
  group_by(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  summarise(sum_delay = sum(DEP_DELAY, na.rm = TRUE), n = n()) %&amp;gt;%
  collect()
(toc = Sys.time() - tic)
Time difference of 1.805515 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is pretty impressive! It is much faster than with &lt;code&gt;{sparklyr}&lt;/code&gt;. But we’re not done yet, we
still need to compute the average:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_dep_delay &amp;lt;- mean_dep_delay %&amp;gt;%
  group_by(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  summarise(mean_delay = sum(sum_delay)/sum(n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to keep in mind that &lt;code&gt;group_by()&lt;/code&gt; works by chunks when dealing with &lt;code&gt;disk.frame&lt;/code&gt;
objects.&lt;/p&gt;
&lt;p&gt;To conclude, we can plot the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)
dep_delay &amp;lt;- mean_dep_delay %&amp;gt;%
  arrange(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  mutate(date = ymd(paste(YEAR, MONTH, DAY_OF_MONTH, sep = &amp;quot;-&amp;quot;)))

ggplot(dep_delay, aes(date, mean_delay)) +
  geom_smooth(colour = &amp;quot;#82518c&amp;quot;) + 
  brotools::theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-09-03-disk_frame_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{disk.frame}&lt;/code&gt; is really promising, and I will monitor this package very closely. I might write
another blog post about it, focusing this time on using machine learning with &lt;code&gt;disk.frame&lt;/code&gt; objects.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modern R with the tidyverse is available on Leanpub</title>
      <link>https://www.brodrigues.co/blog/2019-08-17-modern_r/</link>
      <pubDate>Sat, 17 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-08-17-modern_r/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/cover_modern.png&#34; title = &#34;Click here to go to Leanpub&#34; width=&#34;500&#34; height=&#34;647&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Yesterday I released an ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;,
called &lt;em&gt;Modern R with the tidyverse&lt;/em&gt;, which you can also
read for free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this blog post, I want to give some context.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Modern R with the tidyverse&lt;/em&gt; is the second ebook I release on Leanpub. I released the first one, called
&lt;a href=&#34;https://leanpub.com/fput&#34;&gt;Functional programming and unit testing for data munging with R&lt;/a&gt; around
Christmas 2016 (I’ve retired it on Leanpub, but you can still read it for free
&lt;a href=&#34;https://b-rodrigues.github.io/fput/&#34;&gt;here&lt;/a&gt;) . I just had moved back to my home country of
Luxembourg and started a new job as a research assistant at the statistical national institute.
Since then, lots of things happened; I’ve changed jobs and joined PwC Luxembourg as a data scientist,
was promoted to manager, finished my PhD, and most importantly of all, I became a father.&lt;/p&gt;
&lt;p&gt;Through all this, I continued blogging and working on a new ebook, called &lt;em&gt;Modern R with the tidyverse&lt;/em&gt;.
At first, this was supposed to be a separate book from the first one, but as I continued writing,
I realized that updating and finishing the first one, would take a lot of effort, and also, that
it wouldn’t make much sense in keeping both separated. So I decided to merge the content from the
first ebook with the second, and update everything in one go.&lt;/p&gt;
&lt;p&gt;My very first notes were around 50 pages if memory serves, and I used them to teach R at the
University of Strasbourg while I employed there as a research and teaching assistant and working
on my PhD. These notes were the basis of &lt;em&gt;Functional programming and unit testing for data munging with R&lt;/em&gt;
and now &lt;em&gt;Modern R&lt;/em&gt;. Chapter 2 of &lt;em&gt;Modern R&lt;/em&gt; is almost a simple copy and paste from these notes
(with more sections added). These notes were first written around 2012-2013ish.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Modern R&lt;/em&gt; is the kind of text I would like to have had when I first started playing around with R,
sometime around 2009-2010. It starts from the beginning, but also goes quite into details in the
later chapters. For instance, the section on
&lt;a href=&#34;https://b-rodrigues.github.io/modern_R/functional-programming.html#modeling-with-functional-programming&#34;&gt;modeling with functional programming&lt;/a&gt;
is quite advanced, but I believe that readers that read through all the book and reached that part
would be armed with all the needed knowledge to follow. At least, this is my hope.&lt;/p&gt;
&lt;p&gt;Now, the book is still not finished. Two chapters are missing, but it should not take me long to
finish them as I already have drafts lying around. However, exercises might still be in wrong
places, and more are required. Also, generally, more polishing is needed.&lt;/p&gt;
&lt;p&gt;As written in the first paragraph of this section, the book is available on
&lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;. Unlike my previous ebook, this one costs money;
a minimum price of 4.99$ and a recommended price of 14.99$, but as mentioned you can read it for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;online&lt;/a&gt;. I’ve hesitated to give it a minimum price of
0$, but I figured that since the book can be read for free online, and that Leanpub has a 45 days
return policy where readers can get 100% reimbursed, no questions asked (and keep the downloaded
ebook), readers were not taking a lot of risks by buying it for 5 bucks. I sure hope however that
readers will find that this ebook is worth at least 5 bucks!&lt;/p&gt;
&lt;p&gt;Now why should you read it? There’s already a lot of books on learning how to use R. Well, I don’t
really want to convince you to read it. But some people do seem to like my style of writing and my
blog posts, so I guess these same people, or similar people, might like the ebook. Also, I think
that this ebook covers a lot of different topics, enough of them to make you an efficient R user.
But as I’ve written in the introduction of &lt;em&gt;Modern R&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;So what you can expect from this book is that this book is not the only one you should read.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Anyways, hope you’ll enjoy &lt;em&gt;Modern R&lt;/em&gt;, suggestions, criticisms and reviews welcome!&lt;/p&gt;
&lt;p&gt;By the way, the cover of the book is a painting by John William Waterhouse, depicting Diogenes of Sinope,
an ancient Greek philosopher, and absolute mad lad. Read his Wikipedia page, it’s worth it.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;, or buy my ebook on &lt;a href=&#34;https://leanpub.com/modern_tidyverse&#34;&gt;Leanpub&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using linear models with binary dependent variables, a simulation study</title>
      <link>https://www.brodrigues.co/blog/2019-08-14-lpm/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-08-14-lpm/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://psyarxiv.com/4gmbv&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/illegal.png&#34; title = &#34;Even psychologists are not safe&#34; width=&#34;800&#34; height=&#34;612&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This blog post is an excerpt of my ebook Modern R with the tidyverse that you can read for free
&lt;a href=&#34;https://b-rodrigues.github.io/modern_R/functional-programming.html#modeling-with-functional-programming&#34;&gt;here&lt;/a&gt;.
This is taken from Chapter 8, in which I discuss advanced functional programming methods for
modeling.&lt;/p&gt;
&lt;p&gt;As written just above (note: as written above &lt;em&gt;in the book&lt;/em&gt;), &lt;code&gt;map()&lt;/code&gt; simply applies a function
to a list of inputs, and in the previous
section we mapped &lt;code&gt;ggplot()&lt;/code&gt; to generate many plots at once. This approach can also be used to
map any modeling functions, for instance &lt;code&gt;lm()&lt;/code&gt; to a list of datasets.&lt;/p&gt;
&lt;p&gt;For instance, suppose that you wish to perform a Monte Carlo simulation. Suppose that you are
dealing with a binary choice problem; usually, you would use a logistic regression for this.&lt;/p&gt;
&lt;p&gt;However, in certain disciplines, especially in the social sciences, the so-called Linear Probability
Model is often used as well. The LPM is a simple linear regression, but unlike the standard setting
of a linear regression, the dependent variable, or target, is a binary variable, and not a continuous
variable. Before you yell “Wait, that’s illegal”, you should know that in practice LPMs do a good
job of estimating marginal effects, which is what social scientists and econometricians are often
interested in. Marginal effects are another way of interpreting models, giving how the outcome
(or the target) changes given a change in a independent variable (or a feature). For instance,
a marginal effect of 0.10 for age would mean that probability of success would increase by 10% for
each added year of age.&lt;/p&gt;
&lt;p&gt;There has been a lot of discussion on logistic regression vs LPMs, and there are pros and cons
of using LPMs. Micro-econometricians are still fond of LPMs, even though the pros of LPMs are
not really convincing. However, quoting Angrist and Pischke:&lt;/p&gt;
&lt;p&gt;“While a nonlinear model may fit the CEF (population conditional expectation function) for LDVs
(limited dependent variables) more closely than a linear model, when it comes to marginal effects,
this probably matters little” (source: &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;so LPMs are still used for estimating marginal effects.&lt;/p&gt;
&lt;p&gt;Let us check this assessment with one example. First, we simulate some data, then
run a logistic regression and compute the marginal effects, and then compare with a LPM:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
x1 &amp;lt;- rnorm(100)
x2 &amp;lt;- rnorm(100)
  
z &amp;lt;- .5 + 2*x1 + 4*x2

p &amp;lt;- 1/(1 + exp(-z))

y &amp;lt;- rbinom(100, 1, p)

df &amp;lt;- tibble(y = y, x1 = x1, x2 = x2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This data generating process generates data from a binary choice model. Fitting the model using a
logistic regression allows us to recover the structural parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logistic_regression &amp;lt;- glm(y ~ ., data = df, family = binomial(link = &amp;quot;logit&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see a summary of the model fit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(logistic_regression)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = y ~ ., family = binomial(link = &amp;quot;logit&amp;quot;), data = df)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.91941  -0.44872   0.00038   0.42843   2.55426  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)   0.0960     0.3293   0.292 0.770630    
## x1            1.6625     0.4628   3.592 0.000328 ***
## x2            3.6582     0.8059   4.539 5.64e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 138.629  on 99  degrees of freedom
## Residual deviance:  60.576  on 97  degrees of freedom
## AIC: 66.576
## 
## Number of Fisher Scoring iterations: 7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do recover the parameters that generated the data, but what about the marginal effects? We can
get the marginal effects easily using the &lt;code&gt;{margins}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(margins)

margins(logistic_regression)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Average marginal effects&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## glm(formula = y ~ ., family = binomial(link = &amp;quot;logit&amp;quot;), data = df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      x1     x2
##  0.1598 0.3516&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, even better, we can compute the &lt;em&gt;true&lt;/em&gt; marginal effects, since we know the data
generating process:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;meffects &amp;lt;- function(dataset, coefs){
  X &amp;lt;- dataset %&amp;gt;% 
  select(-y) %&amp;gt;% 
  as.matrix()
  
  dydx_x1 &amp;lt;- mean(dlogis(X%*%c(coefs[2], coefs[3]))*coefs[2])
  dydx_x2 &amp;lt;- mean(dlogis(X%*%c(coefs[2], coefs[3]))*coefs[3])
  
  tribble(~term, ~true_effect,
          &amp;quot;x1&amp;quot;, dydx_x1,
          &amp;quot;x2&amp;quot;, dydx_x2)
}

(true_meffects &amp;lt;- meffects(df, c(0.5, 2, 4)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   term  true_effect
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 x1          0.175
## 2 x2          0.350&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so now what about using this infamous Linear Probability Model to estimate the marginal effects?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lpm &amp;lt;- lm(y ~ ., data = df)

summary(lpm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ ., data = df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.83953 -0.31588 -0.02885  0.28774  0.77407 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.51340    0.03587  14.314  &amp;lt; 2e-16 ***
## x1           0.16771    0.03545   4.732 7.58e-06 ***
## x2           0.31250    0.03449   9.060 1.43e-14 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.3541 on 97 degrees of freedom
## Multiple R-squared:  0.5135, Adjusted R-squared:  0.5034 
## F-statistic: 51.18 on 2 and 97 DF,  p-value: 6.693e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s not too bad, but maybe it could have been better in other circumstances. Perhaps if we had more
observations, or perhaps for a different set of structural parameters the results of the LPM
would have been closer. The LPM estimates the marginal effect of &lt;code&gt;x1&lt;/code&gt; to be
0.1677134 vs 0.1597956
for the logistic regression and for &lt;code&gt;x2&lt;/code&gt;, the LPM estimation is 0.3124966
vs 0.351607. The &lt;em&gt;true&lt;/em&gt; marginal effects are
0.1750963 and 0.3501926 for &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt; respectively.&lt;/p&gt;
&lt;p&gt;Just as to assess the accuracy of a model data scientists perform cross-validation, a Monte Carlo
study can be performed to asses how close the estimation of the marginal effects using a LPM is
to the marginal effects derived from a logistic regression. It will allow us to test with datasets
of different sizes, and generated using different structural parameters.&lt;/p&gt;
&lt;p&gt;First, let’s write a function that generates data. The function below generates 10 datasets of size
100 (the code is inspired by this &lt;a href=&#34;https://stats.stackexchange.com/a/46525&#34;&gt;StackExchange answer&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_datasets &amp;lt;- function(coefs = c(.5, 2, 4), sample_size = 100, repeats = 10){

  generate_one_dataset &amp;lt;- function(coefs, sample_size){
  x1 &amp;lt;- rnorm(sample_size)
  x2 &amp;lt;- rnorm(sample_size)
  
  z &amp;lt;- coefs[1] + coefs[2]*x1 + coefs[3]*x2

  p &amp;lt;- 1/(1 + exp(-z))

  y &amp;lt;- rbinom(sample_size, 1, p)

  df &amp;lt;- tibble(y = y, x1 = x1, x2 = x2)
  }

  simulations &amp;lt;- rerun(.n = repeats, generate_one_dataset(coefs, sample_size))
 
  tibble(&amp;quot;coefs&amp;quot; = list(coefs), &amp;quot;sample_size&amp;quot; = sample_size, &amp;quot;repeats&amp;quot; = repeats, &amp;quot;simulations&amp;quot; = list(simulations))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s first generate one dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_dataset &amp;lt;- generate_datasets(repeats = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;one_dataset&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_dataset&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 4
##   coefs     sample_size repeats simulations
##   &amp;lt;list&amp;gt;          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;     
## 1 &amp;lt;dbl [3]&amp;gt;         100       1 &amp;lt;list [1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the tibble with the simulated data is inside a list-column called &lt;code&gt;simulations&lt;/code&gt;.
Let’s take a closer look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(one_dataset$simulations)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ :List of 1
##   ..$ :Classes &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;: 100 obs. of  3 variables:
##   .. ..$ y : int [1:100] 0 1 1 1 0 1 1 0 0 1 ...
##   .. ..$ x1: num [1:100] 0.437 1.06 0.452 0.663 -1.136 ...
##   .. ..$ x2: num [1:100] -2.316 0.562 -0.784 -0.226 -1.587 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The structure is quite complex, and it’s important to understand this, because it will have an
impact on the next lines of code; it is a list, containing a list, containing a dataset! No worries
though, we can still map over the datasets directly, by using &lt;code&gt;modify_depth()&lt;/code&gt; instead of &lt;code&gt;map()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s fit a LPM and compare the estimation of the marginal effects with the &lt;em&gt;true&lt;/em&gt; marginal
effects. In order to have some confidence in our results,
we will not simply run a linear regression on that single dataset, but will instead simulate hundreds,
then thousands and ten of thousands of data sets, get the marginal effects and compare
them to the true ones (but here I won’t simulate more than 500 datasets).&lt;/p&gt;
&lt;p&gt;Let’s first generate 10 datasets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;many_datasets &amp;lt;- generate_datasets()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now comes the tricky part. I have this object, &lt;code&gt;many_datasets&lt;/code&gt; looking like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;many_datasets&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 4
##   coefs     sample_size repeats simulations
##   &amp;lt;list&amp;gt;          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;     
## 1 &amp;lt;dbl [3]&amp;gt;         100      10 &amp;lt;list [10]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I would like to fit LPMs to the 10 datasets. For this, I will need to use all the power of functional
programming and the &lt;code&gt;{tidyverse}&lt;/code&gt;. I will be adding columns to this data frame using &lt;code&gt;mutate()&lt;/code&gt;
and mapping over the &lt;code&gt;simulations&lt;/code&gt; list-column using &lt;code&gt;modify_depth()&lt;/code&gt;. The list of data frames is
at the second level (remember, it’s a list containing a list containing data frames).&lt;/p&gt;
&lt;p&gt;I’ll start by fitting the LPMs, then using &lt;code&gt;broom::tidy()&lt;/code&gt; I will get a nice data frame of the
estimated parameters. I will then only select what I need, and then bind the rows of all the
data frames. I will do the same for the &lt;em&gt;true&lt;/em&gt; marginal effects.&lt;/p&gt;
&lt;p&gt;I highly suggest that you run the following lines, one after another. It is complicated to understand
what’s going on if you are not used to such workflows. However, I hope to convince you that once
it will click, it’ll be much more intuitive than doing all this inside a loop. Here’s the code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- many_datasets %&amp;gt;% 
  mutate(lpm = modify_depth(simulations, 2, ~lm(y ~ ., data = .x))) %&amp;gt;% 
  mutate(lpm = modify_depth(lpm, 2, broom::tidy)) %&amp;gt;% 
  mutate(lpm = modify_depth(lpm, 2, ~select(., term, estimate))) %&amp;gt;% 
  mutate(lpm = modify_depth(lpm, 2, ~filter(., term != &amp;quot;(Intercept)&amp;quot;))) %&amp;gt;% 
  mutate(lpm = map(lpm, bind_rows)) %&amp;gt;% 
  mutate(true_effect = modify_depth(simulations, 2, ~meffects(., coefs = coefs[[1]]))) %&amp;gt;% 
  mutate(true_effect = map(true_effect, bind_rows))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is how results looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   coefs     sample_size repeats simulations lpm             true_effect    
##   &amp;lt;list&amp;gt;          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;      &amp;lt;list&amp;gt;          &amp;lt;list&amp;gt;         
## 1 &amp;lt;dbl [3]&amp;gt;         100      10 &amp;lt;list [10]&amp;gt; &amp;lt;tibble [20 × … &amp;lt;tibble [20 × …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a closer look to the &lt;code&gt;lpm&lt;/code&gt; and &lt;code&gt;true_effect&lt;/code&gt; columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results$lpm&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 20 x 2
##    term  estimate
##    &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 x1       0.228
##  2 x2       0.353
##  3 x1       0.180
##  4 x2       0.361
##  5 x1       0.165
##  6 x2       0.374
##  7 x1       0.182
##  8 x2       0.358
##  9 x1       0.125
## 10 x2       0.345
## 11 x1       0.171
## 12 x2       0.331
## 13 x1       0.122
## 14 x2       0.309
## 15 x1       0.129
## 16 x2       0.332
## 17 x1       0.102
## 18 x2       0.374
## 19 x1       0.176
## 20 x2       0.410&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results$true_effect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 20 x 2
##    term  true_effect
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
##  1 x1          0.183
##  2 x2          0.366
##  3 x1          0.166
##  4 x2          0.331
##  5 x1          0.174
##  6 x2          0.348
##  7 x1          0.169
##  8 x2          0.339
##  9 x1          0.167
## 10 x2          0.335
## 11 x1          0.173
## 12 x2          0.345
## 13 x1          0.157
## 14 x2          0.314
## 15 x1          0.170
## 16 x2          0.340
## 17 x1          0.182
## 18 x2          0.365
## 19 x1          0.161
## 20 x2          0.321&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s bind the columns, and compute the difference between the &lt;em&gt;true&lt;/em&gt; and estimated marginal
effects:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulation_results &amp;lt;- results %&amp;gt;% 
  mutate(difference = map2(.x = lpm, .y = true_effect, bind_cols)) %&amp;gt;% 
  mutate(difference = map(difference, ~mutate(., difference = true_effect - estimate))) %&amp;gt;% 
  mutate(difference = map(difference, ~select(., term, difference))) %&amp;gt;% 
  pull(difference) %&amp;gt;% 
  .[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the simulation results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulation_results %&amp;gt;% 
  group_by(term) %&amp;gt;% 
  summarise(mean = mean(difference), 
            sd = sd(difference))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term     mean     sd
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1     0.0122 0.0370
## 2 x2    -0.0141 0.0306&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Already with only 10 simulated datasets, the difference in means is not significant. Let’s rerun
the analysis, but for difference sizes. In order to make things easier, we can put all the code
into a nifty function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo &amp;lt;- function(coefs, sample_size, repeats){
  many_datasets &amp;lt;- generate_datasets(coefs, sample_size, repeats)
  
  results &amp;lt;- many_datasets %&amp;gt;% 
    mutate(lpm = modify_depth(simulations, 2, ~lm(y ~ ., data = .x))) %&amp;gt;% 
    mutate(lpm = modify_depth(lpm, 2, broom::tidy)) %&amp;gt;% 
    mutate(lpm = modify_depth(lpm, 2, ~select(., term, estimate))) %&amp;gt;% 
    mutate(lpm = modify_depth(lpm, 2, ~filter(., term != &amp;quot;(Intercept)&amp;quot;))) %&amp;gt;% 
    mutate(lpm = map(lpm, bind_rows)) %&amp;gt;% 
    mutate(true_effect = modify_depth(simulations, 2, ~meffects(., coefs = coefs[[1]]))) %&amp;gt;% 
    mutate(true_effect = map(true_effect, bind_rows))

  simulation_results &amp;lt;- results %&amp;gt;% 
    mutate(difference = map2(.x = lpm, .y = true_effect, bind_cols)) %&amp;gt;% 
    mutate(difference = map(difference, ~mutate(., difference = true_effect - estimate))) %&amp;gt;% 
    mutate(difference = map(difference, ~select(., term, difference))) %&amp;gt;% 
    pull(difference) %&amp;gt;% 
    .[[1]]

  simulation_results %&amp;gt;% 
    group_by(term) %&amp;gt;% 
    summarise(mean = mean(difference), 
              sd = sd(difference))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, let’s run the simulation for different parameters and sizes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(.5, 2, 4), 100, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term      mean     sd
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    -0.00826 0.0291
## 2 x2    -0.00732 0.0412&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(.5, 2, 4), 100, 100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term     mean     sd
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    0.00360 0.0392
## 2 x2    0.00517 0.0446&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(.5, 2, 4), 100, 500)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term       mean     sd
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    -0.00152  0.0371
## 2 x2    -0.000701 0.0423&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(pi, 6, 9), 100, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term      mean     sd
##   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    -0.00829 0.0546
## 2 x2     0.00178 0.0370&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(pi, 6, 9), 100, 100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term     mean     sd
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    0.0107  0.0608
## 2 x2    0.00831 0.0804&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monte_carlo(c(pi, 6, 9), 100, 500)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   term     mean     sd
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 x1    0.00879 0.0522
## 2 x2    0.0113  0.0668&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that, at least for this set of parameters, the LPM does a good job of estimating marginal
effects.&lt;/p&gt;
&lt;p&gt;Now, this study might in itself not be very interesting to you, but I believe the general approach
is quite useful and flexible enough to be adapted to all kinds of use-cases.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistical matching, or when one single data source is not enough</title>
      <link>https://www.brodrigues.co/blog/2019-07-19-statmatch/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-07-19-statmatch/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Row_and_column_vectors&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/columns.jpg&#34; title = &#34;Not that kind of columns&#34; width=&#34;1119&#34; height=&#34;720&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I was recently asked how to go about matching several datasets where different samples of
individuals were interviewed. This sounds like a big problem; say that you have dataset A and B,
and that A contain one sample of individuals, and B another sample of individuals, then how could
you possibly match the datasets? Matching datasets requires a common identifier, for instance,
suppose that A contains socio-demographic information on a sample of individuals I, while B,
contains information on wages and hours worked on the same sample of individuals I, then yes,
it will be possible to match/merge/join both datasets.&lt;/p&gt;
&lt;p&gt;But that was not what I was asked about; I was asked about a situation where the same population
gets sampled twice, and each sample answers to a different survey. For example the first survey
is about labour market information and survey B is about family structure. Would it be possible to
combine the information from both datasets?&lt;/p&gt;
&lt;p&gt;To me, this sounded a bit like missing data imputation problem, but where all the information
about the variables of interest was missing! I started digging a bit, and found that not only there
was already quite some literature on it, there is even a package for this, called &lt;code&gt;{StatMatch}&lt;/code&gt; with
a very detailed &lt;a href=&#34;https://cran.r-project.org/web/packages/StatMatch/vignettes/Statistical_Matching_with_StatMatch.pdf&#34;&gt;vignette&lt;/a&gt;.
The vignette is so detailed, that I will not write any code, I just wanted to share this package!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Curly-Curly, the successor of Bang-Bang</title>
      <link>https://www.brodrigues.co/blog/2019-06-20-tidy_eval_saga/</link>
      <pubDate>Sat, 29 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-06-20-tidy_eval_saga/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Row_and_column_vectors&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/curly.jpg&#34; title = &#34;Not that kind of columns&#34; width=&#34;1119&#34; height=&#34;720&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Writing functions that take data frame columns as arguments is a problem that most R users have been
confronted with at some point. There are different ways to tackle this issue, and this blog post will
focus on the solution provided by the latest release of the &lt;code&gt;{rlang}&lt;/code&gt; package. You can read the
announcement &lt;a href=&#34;https://www.tidyverse.org/articles/2019/06/rlang-0-4-0/&#34;&gt;here&lt;/a&gt;, which explains really
well what was wrong with the old syntax, and how the new syntax works now.&lt;/p&gt;
&lt;p&gt;I have written about the problem of writing functions that use data frame columns as arguments
&lt;a href=&#34;https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/&#34;&gt;three years ago&lt;/a&gt;
and &lt;a href=&#34;https://www.brodrigues.co/blog/2017-08-27-why_tidyeval/&#34;&gt;two year ago&lt;/a&gt; too.
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/&#34;&gt;Last year&lt;/a&gt;, I wrote a
blog post that showed how to map a list of functions to a list of datasets with a list of columns
as arguments that used the &lt;code&gt;!!quo(column_name)&lt;/code&gt; syntax (the &lt;code&gt;!!&lt;/code&gt; is pronounced &lt;em&gt;bang-bang&lt;/em&gt;).
Now, there is a new sheriff in town, &lt;code&gt;{{}}&lt;/code&gt;, introduced in &lt;code&gt;{rlang}&lt;/code&gt; version 0.4.0 that makes
things even easier. The suggested pronunciation of &lt;code&gt;{{}}&lt;/code&gt; is &lt;em&gt;curly-curly&lt;/em&gt;, but there is no
&lt;a href=&#34;https://twitter.com/JonTheGeek/status/1144815369766547456&#34;&gt;consensus yet&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, let’s load the &lt;code&gt;{tidyverse}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s suppose that I need to write a function that takes a data frame, as well as a column from
this data frame as arguments:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;how_many_na &amp;lt;- function(dataframe, column_name){
  dataframe %&amp;gt;%
    filter(is.na(column_name)) %&amp;gt;%
    count()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try this function out on the &lt;code&gt;starwars&lt;/code&gt; data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(starwars)

head(starwars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 13
##   name  height  mass hair_color skin_color eye_color birth_year gender
##   &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 Luke…    172    77 blond      fair       blue            19   male  
## 2 C-3PO    167    75 &amp;lt;NA&amp;gt;       gold       yellow         112   &amp;lt;NA&amp;gt;  
## 3 R2-D2     96    32 &amp;lt;NA&amp;gt;       white, bl… red             33   &amp;lt;NA&amp;gt;  
## 4 Dart…    202   136 none       white      yellow          41.9 male  
## 5 Leia…    150    49 brown      light      brown           19   female
## 6 Owen…    178   120 brown, gr… light      blue            52   male  
## # … with 5 more variables: homeworld &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;, films &amp;lt;list&amp;gt;,
## #   vehicles &amp;lt;list&amp;gt;, starships &amp;lt;list&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there are missing values in the &lt;code&gt;hair_color&lt;/code&gt; column. Let’s try to count how many
missing values are in this column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;how_many_na(starwars, hair_color)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error: object &amp;#39;hair_color&amp;#39; not found&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R cannot find the &lt;code&gt;hair_color&lt;/code&gt; column, and yet it is in the data! Well, this is actually exactly
the issue. The issue is that the column is inside the dataframe, but when calling the function
with &lt;code&gt;hair_color&lt;/code&gt; as the second argument, R is looking for a variable called &lt;code&gt;hair_color&lt;/code&gt; that
does not exist. What about trying with &lt;code&gt;&amp;quot;hair_color&amp;quot;&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;how_many_na(starwars, &amp;quot;hair_color&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       n
##   &amp;lt;int&amp;gt;
## 1     0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we get something, but something wrong!&lt;/p&gt;
&lt;p&gt;One way to solve this issue, is to not use the &lt;code&gt;filter()&lt;/code&gt; function, and instead rely on base R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;how_many_na_base &amp;lt;- function(dataframe, column_name){
  na_index &amp;lt;- is.na(dataframe[, column_name])
  nrow(dataframe[na_index, column_name])
}

how_many_na_base(starwars, &amp;quot;hair_color&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works, but not using the &lt;code&gt;{tidyverse}&lt;/code&gt; at all is not an option, at least for me. For instance,
the next function, which uses a grouping variable, would be difficult to implement without the
&lt;code&gt;{tidyverse}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise_groups &amp;lt;- function(dataframe, grouping_var, column_name){
  dataframe %&amp;gt;%
    group_by(grouping_var) %&amp;gt;%  
    summarise(mean(column_name, na.rm = TRUE))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calling this function results in the following error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error: Column `grouping_var` is unknown&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before the release of &lt;code&gt;{rlang}&lt;/code&gt; 0.4.0 this is was the solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise_groups &amp;lt;- function(dataframe, grouping_var, column_name){

  grouping_var &amp;lt;- enquo(grouping_var)
  column_name &amp;lt;- enquo(column_name)
  mean_name &amp;lt;- paste0(&amp;quot;mean_&amp;quot;, quo_name(column_name))

  dataframe %&amp;gt;%
    group_by(!!grouping_var) %&amp;gt;%  
    summarise(!!(mean_name) := mean(!!column_name, na.rm = TRUE))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The core of the function remained very similar to the version from before, but now one has to
use the &lt;code&gt;enquo()&lt;/code&gt;-&lt;code&gt;!!&lt;/code&gt; syntax. While not overly difficult to use, it is cumbersome.&lt;/p&gt;
&lt;p&gt;Now this can be simplified using the new &lt;code&gt;{{}}&lt;/code&gt; syntax:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise_groups &amp;lt;- function(dataframe, grouping_var, column_name){

  dataframe %&amp;gt;%
    group_by({{grouping_var}}) %&amp;gt;%  
    summarise({{column_name}} := mean({{column_name}}, na.rm = TRUE))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Much easier and cleaner! You still have to use the &lt;code&gt;:=&lt;/code&gt; operator instead of &lt;code&gt;=&lt;/code&gt; for the column name
however. Also, from my understanding, if you want to modify the column names, for instance in this
case return &lt;code&gt;&amp;quot;mean_height&amp;quot;&lt;/code&gt; instead of &lt;code&gt;height&lt;/code&gt; you have to keep using the &lt;code&gt;enquo()&lt;/code&gt;-&lt;code&gt;!!&lt;/code&gt; syntax.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intermittent demand, Croston and Die Hard</title>
      <link>https://www.brodrigues.co/blog/2019-06-12-intermittent/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-06-12-intermittent/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Christmas_films&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/diehard.jpg&#34; title = &#34;Die Hard is the best Christmas movie&#34; width=&#34;600&#34; height=&#34;400&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have recently been confronted to a kind of data set and problem that I was not even aware existed:
intermittent demand data. Intermittent demand arises when the demand for a certain good arrives
sporadically. Let’s take a look at an example, by analyzing the number of downloads for the &lt;code&gt;{RDieHarder}&lt;/code&gt;
package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tsintermittent)
library(nnfor)
library(cranlogs)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rdieharder &amp;lt;- cran_downloads(&amp;quot;RDieHarder&amp;quot;, from = &amp;quot;2017-01-01&amp;quot;)

ggplot(rdieharder) +
  geom_line(aes(y = count, x = date), colour = &amp;quot;#82518c&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-06-12-intermittent_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s take a look at just one month of data, because the above plot is not very clear, because of
the outlier just before 2019… I wonder now, was that on Christmas day?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rdieharder %&amp;gt;%
  filter(count == max(count))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         date count    package
## 1 2018-12-21   373 RDieHarder&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not exactly on Christmas day, but almost! Anyways, let’s look at one month of data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;january_2018 &amp;lt;- rdieharder %&amp;gt;%
  filter(between(date, as.Date(&amp;quot;2018-01-01&amp;quot;), as.Date(&amp;quot;2018-02-01&amp;quot;)))

ggplot(january_2018) +
  geom_line(aes(y = count, x = date), colour = &amp;quot;#82518c&amp;quot;) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-06-12-intermittent_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, it is clear that this will be tricky to forecast. There is no discernible pattern,
no trend, no seasonality… nothing that would make it “easy” for a model to learn how to forecast
such data.&lt;/p&gt;
&lt;p&gt;This is typical intermittent demand data. Specific methods have been developed to forecast such
data, the most well-known being Croston, as detailed in
&lt;a href=&#34;https://www.jstor.org/stable/3007885?seq=1#page_scan_tab_contents&#34;&gt;this paper&lt;/a&gt;.
A function to estimate such models is available in the &lt;code&gt;{tsintermittent}&lt;/code&gt; package, written by
&lt;a href=&#34;https://kourentzes.com/forecasting/2014/06/23/intermittent-demand-forecasting-package-for-r/&#34;&gt;Nikolaos Kourentzes&lt;/a&gt;
who also wrote another package, &lt;code&gt;{nnfor}&lt;/code&gt;, which uses Neural Networks to forecast time series data.
I am going to use both to try to forecast the intermittent demand for the &lt;code&gt;{RDieHarder}&lt;/code&gt; package
for the year 2019.&lt;/p&gt;
&lt;p&gt;Let’s first load these packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tsintermittent)
library(nnfor)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And as usual, split the data into training and testing sets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_data &amp;lt;- rdieharder %&amp;gt;%
  filter(date &amp;lt; as.Date(&amp;quot;2019-01-01&amp;quot;)) %&amp;gt;%
  pull(count) %&amp;gt;%
  ts()

test_data &amp;lt;- rdieharder %&amp;gt;%
  filter(date &amp;gt;= as.Date(&amp;quot;2019-01-01&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s consider three models; a naive one, which simply uses the mean of the training set as the
forecast for all future periods, Croston’s method, and finally a Neural Network from the &lt;code&gt;{nnfor}&lt;/code&gt;
package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;naive_model &amp;lt;- mean(train_data)

croston_model &amp;lt;- crost(train_data, h = 163)

nn_model &amp;lt;- mlp(train_data, reps = 1, hd.auto.type = &amp;quot;cv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in preprocess(y, m, lags, keep, difforder, sel.lag,
## allow.det.season, : No inputs left in the network after pre-selection,
## forcing AR(1).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nn_model_forecast &amp;lt;- forecast(nn_model, h = 163)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;crost()&lt;/code&gt; function estimates Croston’s model, and the &lt;code&gt;h&lt;/code&gt; argument produces the
forecast for the next 163 days. &lt;code&gt;mlp()&lt;/code&gt; trains a multilayer perceptron, and the &lt;code&gt;hd.auto.type = &amp;quot;cv&amp;quot;&lt;/code&gt;
argument means that 5-fold cross-validation will be used to find the best number of hidden nodes. I
then obtain the forecast using the &lt;code&gt;forecast()&lt;/code&gt; function. As you can read from the Warning message
above, the Neural Network was replaced by an auto-regressive model, AR(1), because no inputs were
left after pre-selection… I am not exactly sure what that means, but if I remove the big outlier
from before, this warning message disappears, and a Neural Network is successfully trained.&lt;/p&gt;
&lt;p&gt;In order to rank the models, I follow &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0169207006000239&#34;&gt;this paper&lt;/a&gt;
from Rob J. Hyndman, who wrote a very useful book titled &lt;a href=&#34;https://otexts.com/fpp2/&#34;&gt;Forecasting: Principles and Practice&lt;/a&gt;,
and use the Mean Absolute Scaled Error, or MASE. You can also read &lt;a href=&#34;https://robjhyndman.com/papers/foresight.pdf&#34;&gt;this shorter pdf&lt;/a&gt;
which also details how to use MASE to measure the accuracy for intermittent demand. Here is the
function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mase &amp;lt;- function(train_ts, test_ts, outsample_forecast){

  naive_insample_forecast &amp;lt;- stats::lag(train_ts)

  insample_mae &amp;lt;- mean(abs(train_ts - naive_insample_forecast), na.rm = TRUE)
  error_outsample &amp;lt;- test_ts - outsample_forecast

  ase &amp;lt;- error_outsample / insample_mae
  mean(abs(ase), na.rm = TRUE)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is now easy to compute the models’ accuracies:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mase(train_data, test_data$count, naive_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.764385&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mase(train_data, test_data$count, croston_model$component$c.out[1])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.397611&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mase(train_data, test_data$count, nn_model_forecast$mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.767357&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Croston’s method is the one that performs best from the three. Maybe surprisingly, the naive method
performs just as well as the Neural Network! (or rather, the AR(1) model) Let’s also plot the predictions
with the true values from the test set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test_data &amp;lt;- test_data %&amp;gt;%
  mutate(naive_model_forecast = naive_model,
         croston_model_forecast = croston_model$component$c.out[1],
         nn_model_forecast = nn_model_forecast$mean) %&amp;gt;%
  select(-package) %&amp;gt;%
  rename(actual_value = count)


test_data_longer &amp;lt;- test_data %&amp;gt;%
  gather(models, value,
         actual_value, naive_model_forecast, croston_model_forecast, nn_model_forecast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: attributes are not identical across measure variables;
## they will be dropped&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(test_data_longer) +
  geom_line(aes(y = value, x = date, colour = models)) +
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-06-12-intermittent_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Just to make sure I didn’t make a mistake when writing the &lt;code&gt;mase()&lt;/code&gt; function, let’s use the
&lt;code&gt;accuracy()&lt;/code&gt; function from the &lt;code&gt;{forecast}&lt;/code&gt; package and compare the result for the Neural Network:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(forecast)
accuracy(nn_model_forecast, x = test_data$actual_value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       ME     RMSE      MAE  MPE MAPE      MASE       ACF1
## Training set 0.001929409 14.81196 4.109577  NaN  Inf 0.8437033 0.05425074
## Test set     8.211758227 12.40199 8.635563 -Inf  Inf 1.7673570         NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is the same, so it does seem like the naive method is not that bad, actually! Now, in
general, intermittent demand series have a lot of 0 values, which is not really the case here. I
still think that the methodology fits to this particular data set.&lt;/p&gt;
&lt;p&gt;How else would you have forecast this data? Let me know via twitter!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using cosine similarity to find matching documents: a tutorial using Seneca&#39;s letters to his friend Lucilius</title>
      <link>https://www.brodrigues.co/blog/2019-06-04-cosine_sim/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-06-04-cosine_sim/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Seneca_the_Younger&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/seneca.png&#34; title = &#34;Seneca the Younger&#34; width=&#34;400&#34; height=&#34;600&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Lately I’ve been interested in trying to cluster documents, and to find similar documents based on their contents.
In this blog post, I will use &lt;a href=&#34;https://en.wikisource.org/wiki/Moral_letters_to_Lucilius&#34;&gt;Seneca’s &lt;em&gt;Moral letters to Lucilius&lt;/em&gt;&lt;/a&gt;
and compute the pairwise &lt;a href=&#34;https://en.wikipedia.org/wiki/Cosine_similarity&#34;&gt;cosine similarity&lt;/a&gt; of his 124 letters.
Computing the cosine similarity between two vectors returns how similar these vectors are. A cosine
similarity of 1 means that the angle between the two vectors is 0, and thus both vectors have the
same direction.
Seneca’s Moral letters to Lucilius deal mostly with philosophical topics, as Seneca was, among many other
things, a philosopher of the stoic school. The stoic school of philosophy is quite
interesting, but it has been unfortunately misunderstood, especially in modern times. There is now a renewed interest for
this school, see &lt;a href=&#34;https://en.wikipedia.org/wiki/Modern_Stoicism&#34;&gt;Modern Stoicism&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first step is to scrape the letters. The code below scrapes the letters, and saves them into a list.
I first start by writing a function that gets the raw text. Note the &lt;code&gt;xpath&lt;/code&gt; argument of the &lt;code&gt;html_nodes()&lt;/code&gt;
function. I obtained this complex expression by using the &lt;a href=&#34;https://selectorgadget.com/&#34;&gt;SelectorGadget&lt;/a&gt;
extension for Google Chrome, and then selecting the right element of the web page.
See this &lt;a href=&#34;https://i.imgur.com/2cntugt.png&#34;&gt;screenshot&lt;/a&gt; if my description was not very clear.&lt;/p&gt;
&lt;p&gt;Then, the &lt;code&gt;extract_text()&lt;/code&gt; function extracts the text from the letter. The only line that might be
a bit complex is &lt;code&gt;discard(~`==`(., &amp;quot;&amp;quot;))&lt;/code&gt; which removes every empty line.&lt;/p&gt;
&lt;p&gt;Finally, there’s the &lt;code&gt;get_letter()&lt;/code&gt; function that actually gets the letter by calling the first two
functions. In the last line, I get all the letters into a list by mapping the list of urls to the
&lt;code&gt;get_letter()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)

base_url &amp;lt;- &amp;quot;https://en.wikisource.org/wiki/Moral_letters_to_Lucilius/Letter_&amp;quot;

letter_numbers &amp;lt;- seq(1, 124)

letter_urls &amp;lt;- paste0(base_url, letter_numbers)

get_raw_text &amp;lt;- function(base_url, letter_number){
  paste0(base_url, letter_number) %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(xpath =&amp;#39;//*[contains(concat( &amp;quot; &amp;quot;, @class, &amp;quot; &amp;quot; ), concat( &amp;quot; &amp;quot;, &amp;quot;mw-parser-output&amp;quot;, &amp;quot; &amp;quot; ))]&amp;#39;) %&amp;gt;%  
    html_text()
}


extract_text &amp;lt;- function(raw_text, letter_number){
  raw_text &amp;lt;- raw_text %&amp;gt;%
    str_split(&amp;quot;\n&amp;quot;) %&amp;gt;%  
    flatten_chr() %&amp;gt;%  
    discard(~`==`(., &amp;quot;&amp;quot;))

  start &amp;lt;- 5

  end &amp;lt;- str_which(raw_text, &amp;quot;Footnotes*&amp;quot;)

  raw_text[start:(end-1)] %&amp;gt;%
    str_remove_all(&amp;quot;\\[\\d{1,}\\]&amp;quot;) %&amp;gt;%
    str_remove_all(&amp;quot;\\[edit\\]&amp;quot;)
}

get_letter &amp;lt;- function(base_url, letter_number){

  raw_text &amp;lt;- get_raw_text(base_url, letter_number)

  extract_text(raw_text, letter_number)
}

letters_to_lucilius &amp;lt;- map2(base_url, letter_numbers, get_letter)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the letters saved in a list, we need to process the text a little bit. In order
to compute the cosine similarity between the letters, I need to somehow represent them as vectors.
There are several ways of doing this, and I am going to compute the tf-idf of each letter. The tf-idf
will give me a vector for each letter, with zero and non-zero values. Zero values represent words
that are common to all letters, and thus do not have any &lt;em&gt;predictive power&lt;/em&gt;. Non-zero values are
words that are not present in all letters, but maybe only a few. I expect that letters that
discuss death for example, will have the word death in them, and letters that do not discuss death
will not have this word. The word death thus has what I call &lt;em&gt;predictive power&lt;/em&gt;, in that it helps
us distinguish the letters discussing death from the other letters that do not discuss it. The same
reasoning can be applied for any topic.&lt;/p&gt;
&lt;p&gt;So, to get the tf-idf of each letter, I first need to put them in a tidy dataset. I will use the
&lt;code&gt;{tidytext}&lt;/code&gt; package for this. First, I load the required packages, convert each letter to a
dataframe of one column that contains the text, and save the letter’s titles into another list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidytext)
library(SnowballC)
library(stopwords)
library(text2vec)

letters_to_lucilius_df &amp;lt;- map(letters_to_lucilius, ~tibble(&amp;quot;text&amp;quot; = .))

letter_titles &amp;lt;- letters_to_lucilius_df %&amp;gt;%
  map(~slice(., 1)) %&amp;gt;%
  map(pull)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I add this title to each dataframe as a new column, called title:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;letters_to_lucilius_df &amp;lt;-  map2(.x = letters_to_lucilius_df, .y = letter_titles,
                                ~mutate(.x, title = .y)) %&amp;gt;%
  map(~slice(., -1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now use &lt;code&gt;unnest_tokens()&lt;/code&gt; to transform the datasets. Before, I had the whole text of the letter
in one column. After using &lt;code&gt;unnest_tokens()&lt;/code&gt; I now have a dataset with one row per word. This will
make it easy to compute frequencies by letters, or what I am interested in, the tf-idf of each letter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tokenized_letters &amp;lt;- letters_to_lucilius_df %&amp;gt;%
  bind_rows() %&amp;gt;%
  group_by(title) %&amp;gt;%
  unnest_tokens(word, text)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now remove stopwords, using the data containing in the &lt;code&gt;{stopwords}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stopwords_en &amp;lt;- tibble(&amp;quot;word&amp;quot; = stopwords(&amp;quot;en&amp;quot;, source  = &amp;quot;smart&amp;quot;))

tokenized_letters &amp;lt;- tokenized_letters %&amp;gt;%
  anti_join(stopwords_en) %&amp;gt;%
  filter(!str_detect(word, &amp;quot;\\d{1,}&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;word&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next step, wordstemming, meaning, going from “dogs” to “dog”, or from “was” to “be”. If you do not
do wordstemming, “dogs” and “dog” will be considered different words, even though they are not.
&lt;code&gt;wordStem()&lt;/code&gt; is a function from &lt;code&gt;{SnowballC}&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tokenized_letters &amp;lt;- tokenized_letters %&amp;gt;%
  mutate(word = wordStem(word, language = &amp;quot;en&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, I can compute the tf-idf of each letter and cast the data as a sparse matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tfidf_letters &amp;lt;- tokenized_letters %&amp;gt;%
  count(title, word, sort  = TRUE) %&amp;gt;%
  bind_tf_idf(word, title, n)

sparse_matrix &amp;lt;- tfidf_letters %&amp;gt;%
  cast_sparse(title, word, tf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the sparse matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sparse_matrix[1:10, 1:4]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 10 x 4 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
##                                                                   thing
## CXIII. On the Vitality of the Soul and Its Attributes       0.084835631
## LXVI. On Various Aspects of Virtue                          0.017079890
## LXXXVII. Some Arguments in Favour of the Simple Life        0.014534884
## CXVII. On Real Ethics as Superior to Syllogistic Subtleties 0.025919732
## LXXVI. On Learning Wisdom in Old Age                        0.021588946
## CII. On the Intimations of Our Immortality                  0.014662757
## CXXIV. On the True Good as Attained by Reason               0.010139417
## XCIV. On the Value of Advice                                0.009266409
## LXXXI. On Benefits                                          0.007705479
## LXXXV. On Some Vain Syllogisms                              0.013254786
##                                                                     live
## CXIII. On the Vitality of the Soul and Its Attributes       0.0837751856
## LXVI. On Various Aspects of Virtue                          .           
## LXXXVII. Some Arguments in Favour of the Simple Life        0.0007267442
## CXVII. On Real Ethics as Superior to Syllogistic Subtleties 0.0050167224
## LXXVI. On Learning Wisdom in Old Age                        0.0025906736
## CII. On the Intimations of Our Immortality                  0.0019550342
## CXXIV. On the True Good as Attained by Reason               .           
## XCIV. On the Value of Advice                                0.0023166023
## LXXXI. On Benefits                                          0.0008561644
## LXXXV. On Some Vain Syllogisms                              0.0022091311
##                                                                   good
## CXIII. On the Vitality of the Soul and Its Attributes       0.01166490
## LXVI. On Various Aspects of Virtue                          0.04132231
## LXXXVII. Some Arguments in Favour of the Simple Life        0.04578488
## CXVII. On Real Ethics as Superior to Syllogistic Subtleties 0.04849498
## LXXVI. On Learning Wisdom in Old Age                        0.04663212
## CII. On the Intimations of Our Immortality                  0.05180841
## CXXIV. On the True Good as Attained by Reason               0.06717364
## XCIV. On the Value of Advice                                0.01081081
## LXXXI. On Benefits                                          0.01626712
## LXXXV. On Some Vain Syllogisms                              0.01472754
##                                                                 precept
## CXIII. On the Vitality of the Soul and Its Attributes       .          
## LXVI. On Various Aspects of Virtue                          .          
## LXXXVII. Some Arguments in Favour of the Simple Life        .          
## CXVII. On Real Ethics as Superior to Syllogistic Subtleties .          
## LXXVI. On Learning Wisdom in Old Age                        .          
## CII. On the Intimations of Our Immortality                  .          
## CXXIV. On the True Good as Attained by Reason               0.001267427
## XCIV. On the Value of Advice                                0.020463320
## LXXXI. On Benefits                                          .          
## LXXXV. On Some Vain Syllogisms                              .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can consider each row of this matrix as the vector representing a letter, and thus compute the
cosine similarity between letters. For this, I am using the &lt;code&gt;sim2()&lt;/code&gt; function from the &lt;code&gt;{text2vec}&lt;/code&gt;
package. I then create the &lt;code&gt;get_similar_letters()&lt;/code&gt; function that returns similar letters for a
given reference letter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;similarities &amp;lt;- sim2(sparse_matrix, method = &amp;quot;cosine&amp;quot;, norm = &amp;quot;l2&amp;quot;) 

get_similar_letters &amp;lt;- function(similarities, reference_letter, n_recommendations = 3){
  sort(similarities[reference_letter, ], decreasing = TRUE)[1:(2 + n_recommendations)]
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_similar_letters(similarities, 19)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          XXX. On Conquering the Conqueror 
##                                 1.0000000 
##                  XXIV. On Despising Death 
##                                 0.6781600 
##      LXXXII. On the Natural Fear of Death 
##                                 0.6639736 
## LXX. On the Proper Time to Slip the Cable 
##                                 0.5981706 
## LXXVIII. On the Healing Power of the Mind 
##                                 0.4709679&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_similar_letters(similarities, 99)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              LXI. On Meeting Death Cheerfully 
##                                                     1.0000000 
##                     LXX. On the Proper Time to Slip the Cable 
##                                                     0.5005015 
## XCIII. On the Quality, as Contrasted with the Length, of Life 
##                                                     0.4631796 
##                         CI. On the Futility of Planning Ahead 
##                                                     0.4503093 
##                              LXXVII. On Taking One&amp;#39;s Own Life 
##                                                     0.4147019&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_similar_letters(similarities, 32)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                    LIX. On Pleasure and Joy 
##                                                   1.0000000 
##          XXIII. On the True Joy which Comes from Philosophy 
##                                                   0.4743672 
##                          CIX. On the Fellowship of Wise Men 
##                                                   0.4526835 
## XC. On the Part Played by Philosophy in the Progress of Man 
##                                                   0.4498278 
##         CXXIII. On the Conflict between Pleasure and Virtue 
##                                                   0.4469312&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_similar_letters(similarities, 101)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    X. On Living to Oneself 
##                                  1.0000000 
##          LXXIII. On Philosophers and Kings 
##                                  0.3842292 
##                  XLI. On the God within Us 
##                                  0.3465457 
##                       XXXI. On Siren Songs 
##                                  0.3451388 
## XCV. On the Usefulness of Basic Principles 
##                                  0.3302794&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see from these examples, this seems to be working quite well: the first title is the
title of the reference letter, will the next 3 are the suggested letters. The problem is that my
matrix is not in the right order, and thus reference letter 19 does not correspond to letter 19
of Seneca… I have to correct that, but not today.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The never-ending editor war (?)</title>
      <link>https://www.brodrigues.co/blog/2019-05-19-spacemacs/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-05-19-spacemacs/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Death_mask&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/typical_emacs_user.gif&#34; title = &#34;typical emacs user working&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The creation of this blog post was prompted by this tweet, asking an age-old question:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;qam&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://twitter.com/spacemacs?ref_src=twsrc%5Etfw&#34;&gt;@spacemacs&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bruno Rodrigues (@brodriguesco@fosstodon.org) (@brodriguesco) &lt;a href=&#34;https://twitter.com/brodriguesco/status/1128981852558123008?ref_src=twsrc%5Etfw&#34;&gt;May 16, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;This is actually a very important question, that I have been asking myself for a long time. An IDE,
and plain text editors, are a very important tools to anyone writing code. Most working hours are spent
within such a program, which means that one has to be careful about choosing the right one, and
once a choice is made, one has, in my humble opinion, learn as many features of this program as
possible to become as efficient as possible.&lt;/p&gt;
&lt;p&gt;As you can notice from the tweet above, I suggested the use of &lt;a href=&#34;http://spacemacs.org/&#34;&gt;Spacemacs&lt;/a&gt;…
and my tweet did not get any likes or retweets (as of the 19th of May, sympathetic readers of this
blog have liked the tweet). It is to set this great injustice straight that I
decided to write this blog post.&lt;/p&gt;
&lt;p&gt;Spacemacs is a strange beast; if vi and Emacs had a baby, it would certainly look like Spacemacs.
So first of all, to understand what is Spacemacs, one has to know a bit about vi and Emacs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/vim.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;vi is a text editor with 43 years of history now. You might have heard of Vim (Vi IMproved) which is a
modern clone of vi, from 1991. More recently, another clone has been getting popular, Neovim, started
in 2014. Whatever version of vi however, its basic way of functioning remains the same. vi is a modal
editor, meaning that the user has to switch between different modes to work on a text file.
When vi is first started, the program will be in &lt;em&gt;Normal&lt;/em&gt; mode. In this mode, trying to type a word
will likely result in nothing, or unexpected behaviour; unexpected, if you’re not familiar with vi.
For instance, in &lt;em&gt;Normal&lt;/em&gt; mode, typing &lt;strong&gt;j&lt;/strong&gt; will not show the character &lt;strong&gt;j&lt;/strong&gt; on your screen.
Instead, this will move the cursor down one line. Typing &lt;strong&gt;p&lt;/strong&gt; will paste, &lt;strong&gt;u&lt;/strong&gt; will undo the
last action, &lt;strong&gt;y&lt;/strong&gt; will yank (copy) etc…&lt;/p&gt;
&lt;p&gt;To type text, first, one has to enter &lt;em&gt;Insert&lt;/em&gt; mode, by typing &lt;strong&gt;i&lt;/strong&gt; while in &lt;em&gt;Normal&lt;/em&gt; mode. Only
then is it possible to write text. To go back to &lt;em&gt;Normal&lt;/em&gt; mode, type &lt;strong&gt;ESC&lt;/strong&gt;. Other modes are
&lt;em&gt;Visual&lt;/em&gt; mode (from &lt;em&gt;Normal&lt;/em&gt; mode press &lt;strong&gt;v&lt;/strong&gt;), which allows the user to select text and &lt;em&gt;Command-line&lt;/em&gt;
mode which can be entered by keying &lt;strong&gt;:&lt;/strong&gt; from &lt;em&gt;Normal&lt;/em&gt; mode and allows to enter commands.&lt;/p&gt;
&lt;p&gt;Now you might be wondering why anyone would use such a convoluted way to type text. Well, this is
because one can chain these commands quite easily to perform repetitive tasks very quickly.
For instance, to delete a word, one types &lt;strong&gt;daw&lt;/strong&gt; (in &lt;em&gt;Normal&lt;/em&gt; mode), &lt;strong&gt;d&lt;/strong&gt;elete &lt;strong&gt;a&lt;/strong&gt; &lt;strong&gt;w&lt;/strong&gt;ord.
To delete the next 3 words, you can type &lt;strong&gt;3daw&lt;/strong&gt;. To edit the text between, for instance, &lt;strong&gt;()&lt;/strong&gt;
you would type &lt;strong&gt;ci(&lt;/strong&gt; (while in &lt;em&gt;Normal&lt;/em&gt; mode and anywhere between the braces
containing the text to edit), &lt;strong&gt;c&lt;/strong&gt;hange &lt;strong&gt;i&lt;/strong&gt;n &lt;strong&gt;(&lt;/strong&gt;. Same logic applies for &lt;strong&gt;ci[&lt;/strong&gt; for instance. Can you guess
what &lt;strong&gt;ciw&lt;/strong&gt; does? If you are in &lt;em&gt;Normal&lt;/em&gt; mode, and you want to change the word the cursor is on, this
command will erase the word and put you in &lt;em&gt;Insert&lt;/em&gt; mode so that you can write the new word.&lt;/p&gt;
&lt;p&gt;These are just basic reasons why vi (or its clones) are awesome. It is also possible to automate
very long and complex tasks using macros. One starts a macro by typing &lt;strong&gt;q&lt;/strong&gt; and then any letter of
the alphabet to name it, for instance &lt;strong&gt;a&lt;/strong&gt;. The user then performs the actions needed, types &lt;strong&gt;q&lt;/strong&gt;
again to stop the recording of the macro, and can then execute the macro with &lt;strong&gt;&lt;span class=&#34;citation&#34;&gt;@a&lt;/span&gt;&lt;/strong&gt;. If the user
needs to execute the macro say, 10 times, &lt;strong&gt;10@‌‌a&lt;/strong&gt; does the trick. It is possible to extend vi’s
functionalities by using plugins, but more on that down below.&lt;/p&gt;
&lt;p&gt;vi keybindings have inspired a lot of other programs. For instance, you can get extensions
for popular web browsers that mimick vi keybindings, such as
&lt;a href=&#34;https://github.com/tridactyl/tridactyl&#34;&gt;Tridayctl&lt;/a&gt; for Firefox, or &lt;a href=&#34;http://vimium.github.io/&#34;&gt;Vivium&lt;/a&gt;
for Chromium (or Google Chrome). There are even browsers that are built from scratch with support
for vi keybinds, such as my personal favorite, &lt;a href=&#34;http://qutebrowser.org/&#34;&gt;qutebrowser&lt;/a&gt;. You can even
go further and use a tiling window manager on GNU-Linux, for instance &lt;a href=&#34;https://i3wm.org/&#34;&gt;i3&lt;/a&gt;, which
I use, or &lt;a href=&#34;https://xmonad.org/&#34;&gt;xmonad&lt;/a&gt;. You might need to configure those to behave more like vi,
but it is possible. This means that by learning one set of keyboard shortcuts,
(and the logic behind chaining the keystrokes to achieve what you want), you can master several
different programs. This blog post only deals with the editor part, but as you can see, if you
go down the rabbit hole enough, a new exciting world opens up.&lt;/p&gt;
&lt;p&gt;I will show some common vi operations below, but before that let’s discuss Emacs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/emacs.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I am not really familiar with Emacs; I know that Emacs users only swear by it (just like vi users
only swear by vi), and that Emacs is not a modal editor. However, it contains a lot of functions
that you can use by pressing &lt;strong&gt;ESC&lt;/strong&gt;, &lt;strong&gt;CTRL&lt;/strong&gt;, &lt;strong&gt;ALT&lt;/strong&gt; or &lt;strong&gt;META&lt;/strong&gt; (&lt;strong&gt;META&lt;/strong&gt; is the Windows key on a
regular PC keyboard) followed by regular keys. So the approach is different, but it is widely
accepted that productivity of proficient Emacs users is very high too. Emacs was started in 1985,
and the most popular clone is GNU Emacs. Emacs also features modes, but not in the same sense as vi.
There are major and minor modes.
For instance, if you’re editing a Python script, Emacs will be in Python mode, or if editing a Markdown
file Emacs will be in Markdown mode. This will change the available functions to the user, as well
as provide other niceties, such as auto-completion.
Emacs is also easily extensible, which is another reason why it is so popular.
Users can install packages for Emacs, just like R users would do for R, to extend Emacs’ capabilities.
For instance, a very important package if you plan to use Emacs for statistics or data science is
&lt;code&gt;ESS&lt;/code&gt;, &lt;code&gt;E&lt;/code&gt;macs &lt;code&gt;S&lt;/code&gt;peaks &lt;code&gt;S&lt;/code&gt;tatistics. Emacs contains other very high quality packages, and it seems
to me (but don’t quote me on that) that Emacs’ packages are more mature and feature-rich than vi’s
plugins. However, vi keybindings are really awesome. This is, I believe, what
&lt;a href=&#34;https://twitter.com/syl20bnr&#34;&gt;Sylvain Benner&lt;/a&gt; was thinking when he developed Spacemacs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/spacemacs.png&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Spacemacs’ motto is that &lt;em&gt;The best editor is neither Emacs nor Vim, it’s Emacs and Vim!&lt;/em&gt;.
Spacemacs is a version, or distribution of Emacs, that has a very specific way of doing things. However,
since it’s built on top of Emacs, all of Emacs’ packages are available to the user, notably &lt;em&gt;Evil&lt;/em&gt;,
which is a package that makes Emacs mimick vi’s modal mode and keybindings (the name of this
package tells you everything you need to know about what Emacs users think of vi users 😀)&lt;/p&gt;
&lt;p&gt;Not only does Spacemacs support Emacs packages, but Spacemacs also features so-called &lt;em&gt;layers&lt;/em&gt;, which
are configuration files that integrate one, or several packages, seamlessly into Spacemacs particular
workflow. This particular workflow is what gave Spacemacs its name.
Instead of relying on &lt;strong&gt;ESC&lt;/strong&gt;, &lt;strong&gt;CTRL&lt;/strong&gt;, &lt;strong&gt;ALT&lt;/strong&gt; or &lt;strong&gt;META&lt;/strong&gt; like Emacs, users can launch functions
by typing &lt;strong&gt;Space&lt;/strong&gt; in &lt;em&gt;Normal&lt;/em&gt; mode and then a sequence of letters. For instance, &lt;strong&gt;Spaceqr&lt;/strong&gt; restarts Spacemacs.
And what’s more, you don’t actually need to learn these new key sequences. When you type &lt;strong&gt;Space&lt;/strong&gt;,
the minibuffer, a little popup window at the bottom of Spacemacs, appears and shows you all the options
that you can type. For instance, typing &lt;strong&gt;b&lt;/strong&gt; after &lt;strong&gt;Space&lt;/strong&gt; opens up the buffer menu. Buffers are
what could be called tabs in Rstudio. Here you can chose to &lt;em&gt;delete&lt;/em&gt; a buffer, with &lt;strong&gt;d&lt;/strong&gt;, create
a new buffer with &lt;strong&gt;N&lt;/strong&gt;, and many more options.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/minibuffer.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Enough text, let’s get into the videos. But keep in mind the following: the videos below show the
keystrokes I am typing to perform the actions. However, because I use the BÉPO keyboard layout,
which is the french equivalent of the DVORAK layout, the keystrokes will be different than those
in a regular vi guide, which are mainly written for the QWERTY layout.
Also, to use Spacemacs for R, you need to enable the &lt;strong&gt;ESS&lt;/strong&gt; layer, which I show how to do at the end.
Enabling this layer will turn on auto-completion, as well as provide documentation in real time
for your function in the minibuffer:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/spacemacs_autocompletion.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/spacemacs_doc.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first video shows Spacemacs divided into two windows. On the left, I am navigating around code
using the &lt;strong&gt;T&lt;/strong&gt; (move down) and &lt;strong&gt;S&lt;/strong&gt; (move up) keys. To execute a region that I select, I type
&lt;strong&gt;Spacemrr&lt;/strong&gt; (this stands for &lt;strong&gt;M&lt;/strong&gt;ajor mode &lt;strong&gt;R&lt;/strong&gt;un &lt;strong&gt;R&lt;/strong&gt;egion). Then around second 5, I key &lt;strong&gt;O&lt;/strong&gt;
which switches to &lt;em&gt;Insert&lt;/em&gt; mode one line below the line I was, type &lt;code&gt;head(mtcars)&lt;/code&gt; and then
&lt;strong&gt;ESC&lt;/strong&gt; to switch back to &lt;em&gt;Normal&lt;/em&gt; mode and run the line with
&lt;strong&gt;Spacemrl&lt;/strong&gt; (&lt;strong&gt;M&lt;/strong&gt;ajor mode &lt;strong&gt;R&lt;/strong&gt;un &lt;strong&gt;L&lt;/strong&gt;ine).&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_01_running_lines.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;In this video, I show you how to switch between windows. Type &lt;strong&gt;SpaceN&lt;/strong&gt; to switch to window N. At
the end, I key &lt;strong&gt;dd&lt;/strong&gt; which deletes a whole line.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_02_switching_windows.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;In the video below, I show how to use the pipe operator with &lt;strong&gt;Spacemm&lt;/strong&gt;. This is a keyboard shortcut
that I have defined myself. You can also spot the auto-completion at work in this video. To run
the code, I first select it with &lt;strong&gt;V&lt;/strong&gt;, which selects the whole line the cursor is currently at
and enters &lt;em&gt;Visual&lt;/em&gt; mode. I then select the lines below with &lt;strong&gt;T&lt;/strong&gt; and run the region with &lt;strong&gt;Spacemrr&lt;/strong&gt;.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_03_pipe.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Here I show how plotting behaves. When a plot is created, a new window is opened with the plot. This
is a major shortcoming of using Spacemacs for R programming; there is not a dedicated buffer for
plots, and it only shows the very last one created, so there is no way to keep all the plots created in
the current session in a neat, dedicated buffer. It seems to be possible using
&lt;a href=&#34;https://github.com/erikriverson/org-mode-R-tutorial/blob/master/org-mode-R-tutorial.org&#34;&gt;Org-mode&lt;/a&gt;,
which is an Emacs mode for writing notes, todos, and authoring documents. But I haven’t explored
this option yet, mainly because in my case, only looking at one plot at a time is ok.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_04_ggplot.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Here I show how to quickly add text to the top of the document when at the cursor is at the bottom: I try to use
the &lt;code&gt;tabyl()&lt;/code&gt; function found in the &lt;code&gt;{janitor}&lt;/code&gt; package, which I forgot to load. I quickly go all the
way up with &lt;strong&gt;gg&lt;/strong&gt;, then key &lt;strong&gt;yy&lt;/strong&gt; to copy the first line, then &lt;strong&gt;P&lt;/strong&gt; to paste it on the line below
(&lt;strong&gt;p&lt;/strong&gt; would paste it on the same line), type &lt;strong&gt;fv&lt;/strong&gt;, to &lt;strong&gt;f&lt;/strong&gt;ind the letter v from the word “tidyverse”,
then type &lt;strong&gt;liw&lt;/strong&gt; (which is the BÉPO equivalent of &lt;strong&gt;ciw&lt;/strong&gt; for &lt;strong&gt;C&lt;/strong&gt;hange &lt;strong&gt;I&lt;/strong&gt;n &lt;strong&gt;W&lt;/strong&gt;ord) and
finally change “tidyverse” to “janitor”. This seems overly complex, but once you get used to this
way of working, you will wonder why you hadn’t tried vi sooner.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_05_janitor.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Here I show how to do block comment. &lt;strong&gt;8gg&lt;/strong&gt; jumps to the 8th line, &lt;strong&gt;CTRLv&lt;/strong&gt; starts block visual
mode, which allows me to select a block of text. I select the first column of the text, &lt;strong&gt;G&lt;/strong&gt; to
jump all the way down, then &lt;strong&gt;A&lt;/strong&gt; to enter insert mode at the end of the selection (actually, it
would have been more logical to use &lt;strong&gt;I&lt;/strong&gt;, which enters insert mode at the beginning of the selection)
of the line and then add “#” to comment.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_06_block_comment.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Here I show how to delete a block of text:&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_07_block_delete.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Search and replace, by entering &lt;em&gt;command-line&lt;/em&gt; mode (look at the very bottom of the window):&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_08_search_replace_undo.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;I forgot to add “,” characters on a bunch of lines. I add the first “,” to the first line, go down
and press &lt;strong&gt;ESC&lt;/strong&gt; to exit &lt;em&gt;Insert&lt;/em&gt; mode. Now in &lt;strong&gt;Normal&lt;/strong&gt; mode, I type &lt;strong&gt;.&lt;/strong&gt; to execute the last
command, which is &lt;em&gt;inserting a “,” character and going down a line&lt;/em&gt;. This &lt;em&gt;dot command&lt;/em&gt; is a feature
of vi, and it will always redo the last performed change.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_09_dot.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;But instead of typing &lt;strong&gt;.&lt;/strong&gt; six times, just type &lt;strong&gt;6.&lt;/strong&gt; and be done with it:&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_09b_repeated_dot.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;What if you want to do something more complex, involving several commands? Here the &lt;em&gt;dot command&lt;/em&gt;
won’t be enough, since it only replicates the last command, not more. For this you
can define macros with **&lt;span class=&#34;citation&#34;&gt;@*&lt;/span&gt;*. I look for the “,” character, twice, and put the rest of the characters
in the next line with enter. I then repeat this operation by executing the macro using &lt;strong&gt;@‌‌a&lt;/strong&gt;
repeatedly (&lt;strong&gt;@‌‌a&lt;/strong&gt; because I saved the actions in &lt;strong&gt;a&lt;/strong&gt;, but it could have been any other letter).
I then undo my changes and execute the macro 5 times with &lt;strong&gt;5@‌‌a&lt;/strong&gt;.&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_10_macros.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Here I show the undo tree (by typing &lt;strong&gt;Spaceua&lt;/strong&gt;), which is a feature Spacemacs inherited from
Emacs: it makes undoing changes and going back to a previous version of your script very easily:&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_11_undo_tree.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;Finally, I show my Spacemacs configuration file. I show where one needs to specify the layers one wishes
to use. For R, the ESS layer (which is a configuration file for the ESS Emacs package) is mandatory.
As I explained above, it is also possible to use Emacs packages for which no layer is available.
These are the packages under &lt;code&gt;dotspacemacs-additional-packages&lt;/code&gt;. In my case I use:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotspacemacs-additional-packages &amp;#39;(polymode
                                  poly-R
                                  poly-noweb
                                  poly-markdown)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which makes working with RMarkdown possible. &lt;code&gt;polymode&lt;/code&gt; enables simultaneous Major modes, which is
needed for RMarkdown (because RMarkdown files mix Markdown and R).&lt;/p&gt;
&lt;div&gt;
&lt;video width=&#34;838&#34; height=&#34;436&#34; src=&#34;https://www.brodrigues.co/img/spacemacs_12_config.mp4&#34; controls=&#34;true&#34; /&gt;
&lt;/div&gt;
&lt;p&gt;That’s the end of this long post. Spacemacs is really a joy to use, but the learning curve is quite
steep. However, it is definitely worth it. There are so many packages available for Emacs (and hence
Spacemacs) that allow you to browse the web, play games, listen to music, send and read emails…
that a recurrent joke is that Emacs is &lt;em&gt;a very nice operating system, but it lacks
a decent editor&lt;/em&gt;. If that’s the case, Spacemacs is the perfect operating system, because it includes
the greatest editor, vi.&lt;/p&gt;
&lt;p&gt;If you’re interested and and want to learn more about vi, I advise you to read the following book
&lt;a href=&#34;https://www.ossblog.org/wp-content/uploads/2017/06/vim-recipes.pdf&#34;&gt;Vim Recipes&lt;/a&gt; (pdf warning, free)
or &lt;a href=&#34;https://pragprog.com/book/dnvim2/practical-vim-second-edition&#34;&gt;Practical Vim, Edit Text at the Speed of thought&lt;/a&gt;
(not free, but worth every cent), and &lt;a href=&#34;https://leanpub.com/VimLikeAPro&#34;&gt;Use Vim Like a Pro&lt;/a&gt;, which
I have not read, but it looks quite good, and is free too if you want. Now this only covers the
vi part, not the Emacs aspects of Spacemacs, but you don’t really need to know about Emacs to
use Spacemacs. I had 0 experience with Emacs, and still have 0 experience with it. I only learned
how to configure Spacemacs, which does not require any previous experience. To find the packages
you need, as usual, use any search engine of your liking.&lt;/p&gt;
&lt;p&gt;The last point I want to address is the built-in Vim mode of Rstudio. While it works, it does not
work 100% as regular Vim, and worst of all, does not support, as far as I know, any other keyboard
layout than QWERTY, which is a nogo for me.&lt;/p&gt;
&lt;p&gt;In any case, if you’re looking to learn something new that you can use for many programs, including
Rstudio, learn Vim, and then give Spacemacs a try. Chaining keystrokes to edit text gets addictive
very quickly.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For reference, here is my &lt;code&gt;dotspacemacs/user-config&lt;/code&gt;, which is where I defined the shortcut for
the &lt;code&gt;%&amp;gt;%&lt;/code&gt; operator.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(defun dotspacemacs/user-config ()
  &amp;quot;Configuration for user code:
This function is called at the very end of Spacemacs startup, after layer
configuration.
Put your configuration code here, except for variables that should be set
before packages are loaded.&amp;quot;
;;; R modes
  (add-to-list &amp;#39;auto-mode-alist &amp;#39;(&amp;quot;\\.md&amp;quot; . poly-markdown-mode))
  (add-to-list &amp;#39;auto-mode-alist &amp;#39;(&amp;quot;\\.Snw&amp;quot; . poly-noweb+r-mode))
  (add-to-list &amp;#39;auto-mode-alist &amp;#39;(&amp;quot;\\.Rnw&amp;quot; . poly-noweb+r-mode))
  (add-to-list &amp;#39;auto-mode-alist &amp;#39;(&amp;quot;\\.Rmd&amp;quot; . poly-markdown+r-mode))

  ;; (require &amp;#39;poly-R)
  ;; (require &amp;#39;poly-markdown)
  ;; (add-to-list &amp;#39;auto-mode-alist &amp;#39;(&amp;quot;\\.Rmd&amp;quot; . poly-markdown+r-mode))

  (global-company-mode t)
  (global-hl-line-mode 1) ; Enable/Disable current line highlight
  (setq-default fill-column 99)
  (setq-default auto-fill-mode t)
  ;; ESS shortcuts
  (spacemacs/set-leader-keys &amp;quot;mdt&amp;quot; &amp;#39;ess-r-devtools-test-package)
  (spacemacs/set-leader-keys &amp;quot;mrl&amp;quot; &amp;#39;ess-eval-line)
  (spacemacs/set-leader-keys &amp;quot;mrr&amp;quot; &amp;#39;ess-eval-region)
  (spacemacs/set-leader-keys &amp;quot;mdb&amp;quot; &amp;#39;ess-r-devtools-build-package)
  (spacemacs/set-leader-keys &amp;quot;mdd&amp;quot; &amp;#39;ess-r-devtools-document-package)
  (spacemacs/set-leader-keys &amp;quot;mdl&amp;quot; &amp;#39;ess-r-devtools-load-package)
  (spacemacs/set-leader-keys &amp;quot;mdc&amp;quot; &amp;#39;ess-r-devtools-check-package)
  (spacemacs/set-leader-keys &amp;quot;mdp&amp;quot; &amp;#39;ess-r-package-mode)
  (add-hook &amp;#39;ess-mode-hook
            (lambda ()
              (ess-toggle-underscore nil)))
  (define-key evil-normal-state-map (kbd &amp;quot;SPC mm&amp;quot;)
            (lambda ()
              (interactive)
              (insert &amp;quot; %&amp;gt;% &amp;quot;)
              (evil-insert-state)
              ))
  ;; Move lines around
  (spacemacs/set-leader-keys &amp;quot;MS&amp;quot; &amp;#39;move-text-line-up)
  (spacemacs/set-leader-keys &amp;quot;MT&amp;quot; &amp;#39;move-text-line-down)
  (setq-default whitespace-mode t)
  (setq-default whitespace-style (quote (spaces tabs newline space-mark tab-mark newline-mark)))
  (setq-default whitespace-display-mappings
        ;; all numbers are Unicode codepoint in decimal. try (insert-char 182 ) to see it
        &amp;#39;(
          (space-mark 32 [183] [46]) ; 32 SPACE, 183 MIDDLE DOT 「·」, 46 FULL STOP 「.」
          (newline-mark 10 [9226 10]) ; 10 LINE FEED
          (tab-mark 9 [9655 9] [92 9]) ; 9 TAB, 9655 WHITE RIGHT-POINTING TRIANGLE 「▷」
          ))
  (setq-default TeX-view-program-selection
         &amp;#39;((output-pdf &amp;quot;PDF Viewer&amp;quot;)))
  (setq-default TeX-view-program-list
        &amp;#39;((&amp;quot;PDF Viewer&amp;quot; &amp;quot;okular %o&amp;quot;)))
  (setq-default indent-tabs-mode nil)
  (setq-default tab-width 2)
   ;; (setq org-default-notes-file (concat org-directory &amp;quot;/agenda/notes.org&amp;quot;))
   (add-hook &amp;#39;prog-mode-hook &amp;#39;spacemacs/toggle-fill-column-indicator-on)
   (add-hook &amp;#39;text-mode-hook &amp;#39;spacemacs/toggle-fill-column-indicator-on)
   (add-hook &amp;#39;markdown-mode-hook &amp;#39;spacemacs/toggle-fill-column-indicator-on)
  )&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>For posterity: install {xml2} on GNU/Linux distros</title>
      <link>https://www.brodrigues.co/blog/2019-05-18-xml2/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-05-18-xml2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Death_mask&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/napoleon_death_mask.jpg&#34; title = &#34;I will probably be the only reader of this blog post&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Today I’ve removed my system’s R package and installed MRO instead. While re-installing all packages,
I’ve encountered one of the most frustrating error message for someone installing packages from
source:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error : /tmp/Rtmpw60aCp/R.INSTALL7819efef27e/xml2/man/read_xml.Rd:47: unable to load shared object
&amp;#39;/usr/lib64/R/library/xml2/libs/xml2.so&amp;#39;: 
libicui18n.so.58: cannot open shared object file: No such file or directory ERROR: 
installing Rd objects failed for package ‘xml2’ &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This library, &lt;code&gt;libicui18n.so.58&lt;/code&gt; is a pain in the butt. However, you can easily install it if you
install miniconda. After installing miniconda, you can look for it with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[19-05-18 18:26] cbrunos in ~/ ➤ locate libicui18n.so.58

/home/cbrunos/miniconda3/lib/libicui18n.so.58
/home/cbrunos/miniconda3/lib/libicui18n.so.58.2
/home/cbrunos/miniconda3/pkgs/icu-58.2-h9c2bf20_1/lib/libicui18n.so.58
/home/cbrunos/miniconda3/pkgs/icu-58.2-h9c2bf20_1/lib/libicui18n.so.58.2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now you need to tell R where to look for this library. The
&lt;a href=&#34;https://stackoverflow.com/a/47851648&#34;&gt;following Stackoverflow&lt;/a&gt; answer saved the day. Add the following
lines to &lt;code&gt;R_HOME/etc/ldpaths&lt;/code&gt; (in my case, it was in &lt;code&gt;/opt/microsoft/ropen/3.5.2/lib64/R/etc/&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/username/miniconda3/lib/
export LD_LIBRARY_PATH&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and try to install &lt;code&gt;xml2&lt;/code&gt; again, and it should work! If not, just abandon the idea of using R and
switch to doing data science with VBA, it’ll be less frustrating.&lt;/p&gt;
&lt;p&gt;Something else, if you install Microsoft R Open, you’ll be stuck with some older packages, because
by default MRO uses a snapshot of CRAN from a given day as a mirror. To get the freshest packages,
add the following line to your &lt;code&gt;.Rprofile&lt;/code&gt; file (which should be located in your &lt;code&gt;HOME&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;options(repos = c(CRAN = &amp;quot;http://cran.rstudio.com/&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to finish this short blog post, add the following line to your &lt;code&gt;.Rprofile&lt;/code&gt;
if you get the following error messages when trying to install a package from github:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;remotes::install_github(&amp;#39;rstudio/DT&amp;#39;) Downloading GitHub repo rstudio/DT@master tar: 
This does not look like a tar archive gzip: stdin: unexpected end of file tar: Child returned 
status 1 tar: Error is not recoverable: exiting now tar: This does not look like a tar archive 
gzip: stdin: unexpected end of file tar: Child returned status 1 tar: Error is not recoverable: 
exiting now Error in getrootdir(untar(src, list = TRUE)) : length(file_list) &amp;gt; 0 is not TRUE Calls: 
&amp;lt;Anonymous&amp;gt; ... source_pkg -&amp;gt; decompress -&amp;gt; getrootdir -&amp;gt; stopifnot In addition: Warning messages: 1: 
In utils::untar(tarfile, ...) : ‘tar -xf &amp;#39;/tmp/RtmpitCFRe/file2677442609b8.tar.gz&amp;#39; -C 
&amp;#39;/tmp/RtmpitCFRe/remotes267752f2629f&amp;#39;’ returned error code 2 2: 
In system(cmd, intern = TRUE) : running command &amp;#39;tar -tf &amp;#39;/tmp/RtmpitCFRe/file2677442609b8.tar.gz&amp;#39;&amp;#39; 
had status 2 Execution halted&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The solution, which can found &lt;a href=&#34;https://github.com/r-lib/remotes/issues/350#issuecomment-493649792&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;options(&amp;quot;download.file.method&amp;quot; = &amp;quot;libcurl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fast food, causality and R packages, part 2</title>
      <link>https://www.brodrigues.co/blog/2019-05-04-diffindiff_part2/</link>
      <pubDate>Sat, 04 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-05-04-diffindiff_part2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Joke&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/distracted_economist.jpg&#34; title = &#34;Soon, humanity will only communicate in memes&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I am currently working on a package for the R programming language; its initial goal was to simply
distribute the data used in the Card and Krueger 1994 paper that you can read
&lt;a href=&#34;http://davidcard.berkeley.edu/papers/njmin-aer.pdf&#34;&gt;here&lt;/a&gt; (PDF warning). However, I decided that I
would add code to perform diff-in-diff.&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&#34;https://www.brodrigues.co/blog/2019-04-28-diffindiff_part1/&#34;&gt;previous blog post&lt;/a&gt; I showed
how to set up the structure of your new package. In this blog post, I will only focus on getting
Card and Krueger’s data and prepare it for distribution. The next blog posts will focus on writing
a function to perform difference-in-differences.&lt;/p&gt;
&lt;p&gt;If you want to distribute data through a package, you first need to use the &lt;code&gt;usethis::use_data_raw()&lt;/code&gt;
function (as shown in part 1).&lt;/p&gt;
&lt;p&gt;This creates a &lt;code&gt;data-raw&lt;/code&gt; folder, and inside you will find the &lt;code&gt;DATASET.R&lt;/code&gt; script. You can edit this
script to prepare the data.&lt;/p&gt;
&lt;p&gt;First, let’s download the data from Card’s website, unzip it and load the data into R. All these
operations will be performed from R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tempfile_path &amp;lt;- tempfile()

download.file(&amp;quot;http://davidcard.berkeley.edu/data_sets/njmin.zip&amp;quot;, destfile = tempfile_path)

tempdir_path &amp;lt;- tempdir()

unzip(tempfile_path, exdir = tempdir_path)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To download and unzip a file from R, first, you need to define where you want to save the file. Because
I am not interested in keeping the downloaded file, I use the &lt;code&gt;tempfile()&lt;/code&gt; function to get a temporary
file in my &lt;code&gt;/tmp/&lt;/code&gt; folder (which is the folder that contains temporary files and folders in a GNU+Linux
system). Then, using &lt;code&gt;download.file()&lt;/code&gt; I download the file, and save it in my temporary file. I then
create a temporary directory using &lt;code&gt;tempdir()&lt;/code&gt; (the idea is the same as with &lt;code&gt;tempfile()&lt;/code&gt;), and use
this folder to save the files that I will unzip, using the &lt;code&gt;unzip()&lt;/code&gt; function. This folder now contains
several files:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;check.sas
codebook
public.csv
read.me
survey1.nj
survey2.nj&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;check.sas&lt;/code&gt; is the SAS script Card and Krueger used. It’s interesting, because it is quite simple,
quite short (170 lines long) and yet the impact of Card and Krueger’s research was and has been
very important for the field of econometrics. This script will help me define my own functions.
&lt;code&gt;codebook&lt;/code&gt;, you guessed it, contains the variables’ descriptions. I will use this to name the columns
of the data and to write the dataset’s documentation.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;public.csv&lt;/code&gt; is the data. It does not contain any column names:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 46 1 0 0 0 0 0 1 0 0  0 30.00 15.00  3.00   .    19.0   .   1    .  2  6.50 16.50  1.03  1.03  0.52  3  3 1 1 111792  1  3.50 35.00  3.00  4.30  26.0  0.08 1 2  6.50 16.50  1.03   .    0.94  4  4    
 49 2 0 0 0 0 0 1 0 0  0  6.50  6.50  4.00   .    26.0   .   0    .  2 10.00 13.00  1.01  0.90  2.35  4  3 1 1 111292  .  0.00 15.00  4.00  4.45  13.0  0.05 0 2 10.00 13.00  1.01  0.89  2.35  4  4    
506 2 1 0 0 0 0 1 0 0  0  3.00  7.00  2.00   .    13.0  0.37 0  30.0 2 11.00 10.00  0.95  0.74  2.33  3  3 1 1 111292  .  3.00  7.00  4.00  5.00  19.0  0.25 . 1 11.00 11.00  0.95  0.74  2.33  4  3    
 56 4 1 0 0 0 0 1 0 0  0 20.00 20.00  4.00  5.00  26.0  0.10 1   0.0 2 10.00 12.00  0.87  0.82  1.79  2  2 1 1 111492  .  0.00 36.00  2.00  5.25  26.0  0.15 0 2 10.00 12.00  0.92  0.79  0.87  2  2    
 61 4 1 0 0 0 0 1 0 0  0  6.00 26.00  5.00  5.50  52.0  0.15 1   0.0 3 10.00 12.00  0.87  0.77  1.65  2  2 1 1 111492  . 28.00  3.00  6.00  4.75  13.0  0.15 0 2 10.00 12.00  1.01  0.84  0.95  2  2    
 62 4 1 0 0 0 0 1 0 0  2  0.00 31.00  5.00  5.00  26.0  0.07 0  45.0 2 10.00 12.00  0.87  0.77  0.95  2  2 1 1 111492  .   .     .     .     .    26.0   .   0 2 10.00 12.00   .    0.84  1.79  3  3    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Missing data is defined by &lt;code&gt;.&lt;/code&gt; and the delimiter is the space character. &lt;code&gt;read.me&lt;/code&gt; is a README file.
Finally, &lt;code&gt;survey1.nj&lt;/code&gt; and &lt;code&gt;survey2.nj&lt;/code&gt; are the surveys that were administered to the fast food
restaurants’ managers; one in February (before the raise) and the second one in November
(after the minimum wage raise).&lt;/p&gt;
&lt;p&gt;The next lines import the codebook:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codebook &amp;lt;- read_lines(file = paste0(tempdir_path, &amp;quot;/codebook&amp;quot;))

variable_names &amp;lt;- codebook %&amp;gt;%
    `[`(8:59) %&amp;gt;%
    `[`(-c(5, 6, 13, 14, 32, 33)) %&amp;gt;%
    str_sub(1, 13) %&amp;gt;%
    str_squish() %&amp;gt;%
    str_to_lower()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once I import the codebook, I select lines 8 to 59 using the &lt;code&gt;`[`()&lt;/code&gt; function.
If you’re not familiar with this notation, try the following in a console:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 100)[1:10]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and compare:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 100) %&amp;gt;% 
  `[`(., 1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;both are equivalent, as you can see. You can also try the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 + 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 %&amp;gt;% 
  `+`(., 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the same trick, I remove lines that I do not need, and then using &lt;code&gt;stringr::str_sub(1, 13)&lt;/code&gt;
I only keep the first 13 characters (which are the variable names, plus some white space characters)
and then, to remove all the unneeded white space characters I use &lt;code&gt;stringr::squish()&lt;/code&gt;, and then
change the column names to lowercase.&lt;/p&gt;
&lt;p&gt;I then load the data, and add the column names that I extracted before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- read_table2(paste0(tempdir_path, &amp;quot;/public.dat&amp;quot;),
                      col_names = FALSE)

dataset &amp;lt;- dataset %&amp;gt;%
    select(-X47) %&amp;gt;%
    `colnames&amp;lt;-`(., variable_names) %&amp;gt;%
    mutate_all(as.numeric) %&amp;gt;%
    mutate(sheet = as.character(sheet))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I use the same trick as before. I rename the 47th column, which is empty,
I name the columns with &lt;code&gt;`colnames&amp;lt;-`()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After this, I perform some data cleaning. It’s mostly renaming categories of categorical variables,
and creating a “true” panel format. Several variables were measured at several points in time. Variables
that were measured a second time have a “2” at the end of their name. I remove these variables,
and add an observation data variable. So my data as twice as many rows as the original data, but
that format makes it way easier to work with. Below you can read the full code:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- dataset %&amp;gt;%
    mutate(chain = case_when(chain == 1 ~ &amp;quot;bk&amp;quot;,
                             chain == 2 ~ &amp;quot;kfc&amp;quot;,
                             chain == 3 ~ &amp;quot;roys&amp;quot;,
                             chain == 4 ~ &amp;quot;wendys&amp;quot;)) %&amp;gt;%
    mutate(state = case_when(state == 1 ~ &amp;quot;New Jersey&amp;quot;,
                             state == 0 ~ &amp;quot;Pennsylvania&amp;quot;)) %&amp;gt;%
    mutate(region = case_when(southj == 1 ~ &amp;quot;southj&amp;quot;,
              centralj == 1 ~ &amp;quot;centralj&amp;quot;,
              northj == 1 ~ &amp;quot;northj&amp;quot;,
              shore == 1 ~ &amp;quot;shorej&amp;quot;,
              pa1 == 1 ~ &amp;quot;pa1&amp;quot;,
              pa2 == 1 ~ &amp;quot;pa2&amp;quot;)) %&amp;gt;%
    mutate(meals = case_when(meals == 0 ~ &amp;quot;None&amp;quot;,
                             meals == 1 ~ &amp;quot;Free meals&amp;quot;,
                             meals == 2 ~ &amp;quot;Reduced price meals&amp;quot;,
                             meals == 3 ~ &amp;quot;Both free and reduced price meals&amp;quot;)) %&amp;gt;%
    mutate(meals2 = case_when(meals2 == 0 ~ &amp;quot;None&amp;quot;,
                             meals2 == 1 ~ &amp;quot;Free meals&amp;quot;,
                             meals2 == 2 ~ &amp;quot;Reduced price meals&amp;quot;,
                             meals2 == 3 ~ &amp;quot;Both free and reduced price meals&amp;quot;)) %&amp;gt;%
    mutate(status2 = case_when(status2 == 0 ~ &amp;quot;Refused 2nd interview&amp;quot;,
                               status2 == 1 ~ &amp;quot;Answered 2nd interview&amp;quot;,
                               status2 == 2 ~ &amp;quot;Closed for renovations&amp;quot;,
                               status2 == 3 ~ &amp;quot;Closed permanently&amp;quot;,
                               status2 == 4 ~ &amp;quot;Closed for highway construction&amp;quot;,
                               status2 == 5 ~ &amp;quot;Closed due to Mall fire&amp;quot;)) %&amp;gt;%
    mutate(co_owned = if_else(co_owned == 1, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;)) %&amp;gt;%
    mutate(bonus = if_else(bonus == 1, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;)) %&amp;gt;%
    mutate(special2 = if_else(special2 == 1, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;)) %&amp;gt;%
    mutate(type2 = if_else(type2 == 1, &amp;quot;Phone&amp;quot;, &amp;quot;Personal&amp;quot;)) %&amp;gt;%
    select(sheet, chain, co_owned, state, region, everything()) %&amp;gt;%
    select(-southj, -centralj, -northj, -shore, -pa1, -pa2) %&amp;gt;%
    mutate(date2 = lubridate::mdy(date2)) %&amp;gt;%
    rename(open2 = open2r) %&amp;gt;%
    rename(firstinc2 = firstin2)

dataset1 &amp;lt;- dataset %&amp;gt;%
    select(-ends_with(&amp;quot;2&amp;quot;), -sheet, -chain, -co_owned, -state, -region, -bonus) %&amp;gt;%
    mutate(type = NA_character_,
           status = NA_character_,
           date = NA)

dataset2 &amp;lt;- dataset %&amp;gt;%
    select(ends_with(&amp;quot;2&amp;quot;)) %&amp;gt;%
    #mutate(bonus = NA_character_) %&amp;gt;%
    rename_all(~str_remove(., &amp;quot;2&amp;quot;))

other_cols &amp;lt;- dataset %&amp;gt;%
    select(sheet, chain, co_owned, state, region, bonus)

other_cols_1 &amp;lt;- other_cols %&amp;gt;%
    mutate(observation = &amp;quot;February 1992&amp;quot;)

other_cols_2 &amp;lt;- other_cols %&amp;gt;%
    mutate(observation = &amp;quot;November 1992&amp;quot;)

dataset1 &amp;lt;- bind_cols(other_cols_1, dataset1)
dataset2 &amp;lt;- bind_cols(other_cols_2, dataset2)

njmin &amp;lt;- bind_rows(dataset1, dataset2) %&amp;gt;%
    select(sheet, chain, state, region, observation, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;The line I would like to comment is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset %&amp;gt;%
    select(-ends_with(&amp;quot;2&amp;quot;), -sheet, -chain, -co_owned, -state, -region, -bonus)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This select removes every column that ends with the character “2” (among others). I split the data
in two, to then bind the rows together and thus create my long dataset. I then save the data
into the &lt;code&gt;data/&lt;/code&gt; folder:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_data(njmin, overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This saves the data as an &lt;code&gt;.rda&lt;/code&gt; file. To enable users to read the data by typing &lt;code&gt;data(&#34;njmin&#34;)&lt;/code&gt;,
you need to create a &lt;code&gt;data.R&lt;/code&gt; script in the &lt;code&gt;R/&lt;/code&gt; folder. You can read my &lt;code&gt;data.R&lt;/code&gt; script below:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; Data from the Card and Krueger 1994 paper *Minimum Wages and Employment: A Case Study of the Fast-Food Industry in New Jersey and Pennsylvania*
#&amp;#39;
#&amp;#39; This dataset was downloaded and distributed with the permission of David Card. The original
#&amp;#39; data contains 410 observations and 46 variables. The data distributed in this package is
#&amp;#39; exactly the same, but was changed from a wide to a long dataset, which is better suited for
#&amp;#39; manipulation with *tidyverse* functions.
#&amp;#39;
#&amp;#39; @format A data frame with 820 rows and 28 variables:
#&amp;#39; \describe{
#&amp;#39;   \item{\code{sheet}}{Sheet number (unique store id).}
#&amp;#39;   \item{\code{chain}}{The fastfood chain: bk is Burger King, kfc is Kentucky Fried Chicken, wendys is Wendy&amp;#39;s, roys is Roy Rogers.}
#&amp;#39;   \item{\code{state}}{State where the restaurant is located.}
#&amp;#39;   \item{\code{region}}{pa1 is northeast suburbs of Phila, pa2 is Easton etc, centralj is central NJ, northj is northern NJ, southj is south NJ.}
#&amp;#39;   \item{\code{observation}}{Date of first (February 1992) and second (November 1992) observation.}
#&amp;#39;   \item{\code{co_owned}}{&amp;quot;Yes&amp;quot; if company owned.}
#&amp;#39;   \item{\code{ncalls}}{Number of call-backs. Is 0 if contacted on first call.}
#&amp;#39;   \item{\code{empft}}{Number full-time employees.}
#&amp;#39;   \item{\code{emppt}}{Number part-time employees.}
#&amp;#39;   \item{\code{nmgrs}}{Number of managers/assistant managers.}
#&amp;#39;   \item{\code{wage_st}}{Starting wage ($/hr).}
#&amp;#39;   \item{\code{inctime}}{Months to usual first raise.}
#&amp;#39;   \item{\code{firstinc}}{Usual amount of first raise (\$/hr).}
#&amp;#39;   \item{\code{bonus}}{&amp;quot;Yes&amp;quot; if cash bounty for new workers.}
#&amp;#39;   \item{\code{pctaff}}{\% of employees affected by new minimum.}
#&amp;#39;   \item{\code{meals}}{Free/reduced priced code.}
#&amp;#39;   \item{\code{open}}{Hour of opening.}
#&amp;#39;   \item{\code{hrsopen}}{Number of hours open per day.}
#&amp;#39;   \item{\code{psode}}{Price of medium soda, including tax.}
#&amp;#39;   \item{\code{pfry}}{Price of small fries, including tax.}
#&amp;#39;   \item{\code{pentree}}{Price of entree, including tax.}
#&amp;#39;   \item{\code{nregs}}{Number of cash registers in store.}
#&amp;#39;   \item{\code{nregs11}}{Number of registers open at 11:00 pm.}
#&amp;#39;   \item{\code{type}}{Type of 2nd interview.}
#&amp;#39;   \item{\code{status}}{Status of 2nd interview.}
#&amp;#39;   \item{\code{date}}{Date of 2nd interview.}
#&amp;#39;   \item{\code{nregs11}}{&amp;quot;Yes&amp;quot; if special program for new workers.}
#&amp;#39; }
#&amp;#39; @source \url{http://davidcard.berkeley.edu/data_sets.html}
&amp;quot;njmin&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;I have documented the data, and using &lt;code&gt;roxygen2::royxgenise()&lt;/code&gt; to create the dataset’s documentation.&lt;/p&gt;
&lt;p&gt;The data can now be used to create some nifty plots:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(njmin, aes(wage_st)) + geom_density(aes(fill = state), alpha = 0.3) +
    facet_wrap(vars(observation)) + theme_blog() +
    theme(legend.title = element_blank(), plot.caption = element_text(colour = &amp;quot;white&amp;quot;)) +
    labs(title = &amp;quot;Distribution of starting wage rates in fast food restaurants&amp;quot;,
         caption = &amp;quot;On April 1st, 1992, New Jersey&amp;#39;s minimum wage rose from $4.25 to $5.05. Source: Card and Krueger (1994)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 41 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-05-04-diffindiff_part2_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the next blog post, I am going to write a first function to perform diff and diff, and we will
learn how to make it available to users, document and test it!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fast food, causality and R packages, part 1</title>
      <link>https://www.brodrigues.co/blog/2019-04-28-diffindiff_part1/</link>
      <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-04-28-diffindiff_part1/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Joke&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/distracted_economist.jpg&#34; title = &#34;Soon, humanity will only communicate in memes&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I am currently working on a package for the R programming language; its initial goal was to simply
distribute the data used in the Card and Krueger 1994 paper that you can read
&lt;a href=&#34;http://davidcard.berkeley.edu/papers/njmin-aer.pdf&#34;&gt;here&lt;/a&gt; (PDF warning).&lt;/p&gt;
&lt;p&gt;The gist of the paper is to try to answer the following question: &lt;em&gt;Do increases in minimum wages reduce employment?&lt;/em&gt;
According to Card and Krueger’s paper from 1994, no.
The authors studied a change in legislation in New Jersey which increased the minimum wage from $4.25 an hour to
$5.05 an hour. The neighbourghing state of Pennsylvania did not introduce such an increase. The authors thus used
the State of Pennsylvania as a control for the State of New Jersey and studied how the increase in minimum wage impacted
the employment in fast food restaurants and found, against what economic theory predicted, an
increase and not a decrease in employment.
The authors used a method called difference-in-differences to asses the impact of the minimum wage increase.&lt;/p&gt;
&lt;p&gt;This result was and still is controversial, with subsequent studies finding subtler results.
For instance, showing that there is a reduction in employment following an increase in minimum wage,
but only for large restaurants (see Ropponen and Olli, 2011).&lt;/p&gt;
&lt;p&gt;Anyways, this blog post will discuss how to create a package using to distribute the data. In a future
blog post, I will discuss preparing the data to make it available as a demo dataset inside the
package, and then writing and documenting functions.&lt;/p&gt;
&lt;p&gt;The first step to create a package, is to create a new project:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/package_01.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Select “New Directory”:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/package_02.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Then “R package”:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/package_03.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;and on the window that appears, you can choose the name of the package, as well as already some
starting source files:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/package_04.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Also, I’d highly recommend you click on the “Create a git repository” box and use git within your
project for reproducibility and sharing your code more easily. If you do not know git, there’s a lot of
online resources to get you started. It’s not super difficult, but it does require making some new
habits, which can take some time.&lt;/p&gt;
&lt;p&gt;I called my package &lt;code&gt;{diffindiff}&lt;/code&gt;, and clicked on “Create Project”. This opens up a new project
with a &lt;code&gt;hello.R&lt;/code&gt; script, which gives you some pointers:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Hello, world!
#
# This is an example function named &amp;#39;hello&amp;#39; 
# which prints &amp;#39;Hello, world!&amp;#39;.
#
# You can learn more about package authoring with RStudio at:
#
#   http://r-pkgs.had.co.nz/
#
# Some useful keyboard shortcuts for package authoring:
#
#   Install Package:           &amp;#39;Ctrl + Shift + B&amp;#39;
#   Check Package:             &amp;#39;Ctrl + Shift + E&amp;#39;
#   Test Package:              &amp;#39;Ctrl + Shift + T&amp;#39;

hello &amp;lt;- function() {
  print(&amp;quot;Hello, world!&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, to simplify the creation of your package, I highly recommend you use the &lt;code&gt;{usethis}&lt;/code&gt; package.
&lt;code&gt;{usethis}&lt;/code&gt; removes a lot of the pain involved in creating packages.&lt;/p&gt;
&lt;p&gt;For instance, want to start by adding a README file? Simply run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_readme_md()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;✔ Setting active project to &amp;#39;/path/to/your/package/diffindiff&amp;#39;
✔ Writing &amp;#39;README.md&amp;#39;
● Modify &amp;#39;README.md&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a &lt;code&gt;README.md&lt;/code&gt; file in the root directory of your package. Simply change that file, and that’s it.&lt;/p&gt;
&lt;p&gt;The next step could be setting up your package to work with &lt;code&gt;{roxygen2}&lt;/code&gt;, which is very useful for
writing documentation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_roxygen_md()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;✔ Setting Roxygen field in DESCRIPTION to &amp;#39;list(markdown = TRUE)&amp;#39;
✔ Setting RoxygenNote field in DESCRIPTION to &amp;#39;6.1.1&amp;#39;
● Run `devtools::document()`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See how the output tells you to run &lt;code&gt;devtools::document()&lt;/code&gt;? This function will document your package,
transforming the comments you write to describe your functions to documentation and managing the NAMESPACE
file. Let’s run this function too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::document()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Updating diffindiff documentation
First time using roxygen2. Upgrading automatically...
Loading diffindiff
Warning: The existing &amp;#39;NAMESPACE&amp;#39; file was not generated by roxygen2, and will not be overwritten.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might have a similar message than me, telling you that the NAMESPACE file was not generated by
&lt;code&gt;{roxygen2}&lt;/code&gt;, and will thus not be overwritten. Simply remove the file and run &lt;code&gt;devtools::document()&lt;/code&gt;
again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::document()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Updating diffindiff documentation
First time using roxygen2. Upgrading automatically...
Writing NAMESPACE
Loading diffindiff&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But what is actually the NAMESPACE file? This file is quite important, as it details where your
package’s functions have to look for in order to use other functions. This means that if your package needs function
&lt;code&gt;foo()&lt;/code&gt; from package &lt;code&gt;{bar}&lt;/code&gt;, it will consistently look for &lt;code&gt;foo()&lt;/code&gt; inside &lt;code&gt;{bar}&lt;/code&gt; and not confuse
it with, say, the &lt;code&gt;foo()&lt;/code&gt; function from the &lt;code&gt;{barley}&lt;/code&gt; package, even if you load &lt;code&gt;{barley}&lt;/code&gt; after
&lt;code&gt;{bar}&lt;/code&gt; in your interactive session. This can seem confusing now, but in the next blog posts I will
detail this, and you will see that it’s not that difficult. Just know that it is an important file,
and that you do not have to edit it by hand.&lt;/p&gt;
&lt;p&gt;Next, I like to run the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_pipe()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;✔ Adding &amp;#39;magrittr&amp;#39; to Imports field in DESCRIPTION
✔ Writing &amp;#39;R/utils-pipe.R&amp;#39;
● Run `devtools::document()`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes the now famous &lt;code&gt;%&amp;gt;%&lt;/code&gt; function available internally to your package (so you can use it
to write the functions that will be included in your package) but also available to the users that
will load the package.&lt;/p&gt;
&lt;p&gt;Your package is still missing a license. If you plan on writing a package for your own personal use,
for instance, a collection of functions, there is no need to think about licenses. But if you’re making
your package available through CRAN, then you definitely need to think about it. For this package,
I’ll be using the MIT license, because the package will distribute data which I do not own (I’ve got permission
from Card to re-distribute it) and thus I think it would be better to use a permissive license (I don’t know
if the GPL, another license, which is stricter in terms of redistribution, could be used in this case).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_mit_license()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;✔ Setting License field in DESCRIPTION to &amp;#39;MIT + file LICENSE&amp;#39;
✔ Writing &amp;#39;LICENSE.md&amp;#39;
✔ Adding &amp;#39;^LICENSE\\.md$&amp;#39; to &amp;#39;.Rbuildignore&amp;#39;
✔ Writing &amp;#39;LICENSE&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re almost done setting up the structure of the package. If we forget something though, it’s not an issue,
we’ll just have to run the right &lt;code&gt;use_*&lt;/code&gt; function later on. Let’s finish by preparing the folder
that will contains the script to prepare the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;usethis::use_data_raw()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;✔ Creating &amp;#39;data-raw/&amp;#39;
✔ Adding &amp;#39;^data-raw$&amp;#39; to &amp;#39;.Rbuildignore&amp;#39;
✔ Writing &amp;#39;data-raw/DATASET.R&amp;#39;
● Modify &amp;#39;data-raw/DATASET.R&amp;#39;
● Finish the data preparation script in &amp;#39;data-raw/DATASET.R&amp;#39;
● Use `usethis::use_data()` to add prepared data to package&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates the &lt;code&gt;data-raw&lt;/code&gt; folder with the &lt;code&gt;DATASET.R&lt;/code&gt; script inside. This is the script that will
contain the code to download and prepare datasets that you want to include in your package. This will
be the subject of the next blog post.&lt;/p&gt;
&lt;p&gt;Let’s now finish by documenting the package, and pushing everything to Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::document()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following lines will only work if you set up the Github repo:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git add .
git commit -am &amp;quot;first commit&amp;quot;
git push origin master&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Historical newspaper scraping with {tesseract} and R</title>
      <link>https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cliometrics&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/clio.jpg&#34; title = &#34;Historical newspapers as a source to practice cliometrics?&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have been playing around with historical newspapers data for some months now. The “obvious” type of analysis
to do is NLP, but there is also a lot of numerical data inside historical newspapers.
For instance, you can find these tables that show the market prices of the day in the &lt;em&gt;L’Indépendance Luxembourgeoise&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/market_price_table.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;I wanted to see how easy it was to extract these tables from the newspapers and then make it available.
It was a bit more complicated than anticipated.&lt;/p&gt;
&lt;div id=&#34;download-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download data&lt;/h2&gt;
&lt;p&gt;The first step is to download the data. For this, I have used the code &lt;a href=&#34;https://twitter.com/yvesmaurer&#34;&gt;&lt;code&gt;@yvesmaurer&lt;/code&gt;&lt;/a&gt; which you
can find &lt;a href=&#34;https://github.com/ymaurer/eluxemburgensia-opendata-ark&#34;&gt;here&lt;/a&gt;. This code makes it easy to download individual
pages of certain newspapers,
for instance &lt;a href=&#34;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F1drtkj%2Fpages%2F1/full/full/0/default.jpg&#34;&gt;this one&lt;/a&gt;. The
pages I am interested in are pages 3, which contain the tables I need, for example
&lt;a href=&#34;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F1drtkj%2Fpages%2F3/full/full/0/default.jpg&#34;&gt;here&lt;/a&gt;.
&lt;a href=&#34;https://twitter.com/yvesmaurer&#34;&gt;&lt;code&gt;@yvesmaurer&lt;/code&gt;&lt;/a&gt;’s code makes it easy to find the download links, which look like
this: &lt;code&gt;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F1drtkj%2Fpages%2F3/full/full/0/default.jpg&lt;/code&gt;. It is also possible to
crop the image by changing some parameters &lt;a href=&#34;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fwsvhwh%2Fpages%2F3/pct:74,0,100,100/full/0/default.jpg&#34;&gt;like so&lt;/a&gt;.
This is helpful, because it makes the image smaller. The tables I’m interested in are always in the last column, so I can can use
this feature to get smaller images. However, not every issue contains these tables, and I only want to download the ones
that have these tables. So I wrote the following code to download the images I’m interested in:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(magick)
library(tesseract)
library(furrr)

download_image &amp;lt;- function(link){

    print(link)

    isok &amp;lt;- image_read(link) %&amp;gt;%
        ocr(engine = &amp;quot;fra&amp;quot;) %&amp;gt;%
        str_to_lower() %&amp;gt;%
        str_detect(&amp;quot;marché de luxembourg&amp;quot;)

    if(isok){
        date_link &amp;lt;- link %&amp;gt;%
            str_replace(&amp;quot;pages%2f3&amp;quot;, &amp;quot;pages%2f1&amp;quot;) %&amp;gt;%
            str_replace(&amp;quot;pct:74,0,100,100&amp;quot;, &amp;quot;pct:76,1,17,5&amp;quot;)

        paper_date &amp;lt;- image_read(date_link) %&amp;gt;%
            ocr(engine = &amp;quot;fra&amp;quot;) %&amp;gt;%
            str_squish() %&amp;gt;%
            str_remove(&amp;quot;%&amp;quot;) %&amp;gt;%
            str_remove(&amp;quot;&amp;amp;&amp;quot;) %&amp;gt;%
            str_remove(&amp;quot;/&amp;quot;)

        ark &amp;lt;- link %&amp;gt;%
            str_sub(53, 60)

        download.file(link, paste0(&amp;quot;indep_pages/&amp;quot;, ark, &amp;quot;-&amp;quot;, paper_date, &amp;quot;.jpg&amp;quot;))
    } else {
        NULL
        }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code only downloads
an image if the &lt;code&gt;ocr()&lt;/code&gt; from the {tesseract} (which does, you guessed it, OCR) detects the string “marché de luxembourg” which
is the title of the tables. This is a bit extreme, because if a single letter cannot be correctly detected by the OCR, the page will not
be downloaded. But I figured that if this string could not be easily recognized, this would be a canary telling me that the text
inside the table would also not be easily recognized. So it might be extreme, but my hope was that it would make detecting
the table itself easier. Turned out it wasn’t so easy, but more on this later.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing images&lt;/h2&gt;
&lt;p&gt;Now that I have the images, I will prepare them to make character recognition easier. To do this, I’m using the &lt;code&gt;{magick}&lt;/code&gt;
package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(magick)
library(tesseract)
library(furrr)

prepare_image &amp;lt;- function(image_path){
    image &amp;lt;- image_read(image_path)

    image &amp;lt;- image %&amp;gt;%
        image_modulate(brightness = 150) %&amp;gt;%
        image_convolve(&amp;#39;DoG:0,0,2&amp;#39;, scaling = &amp;#39;1000, 100%&amp;#39;) %&amp;gt;%
        image_despeckle(times = 10)

    image_write(image, paste0(getwd(), &amp;quot;/edited/&amp;quot;, str_remove(image_path, &amp;quot;.jpg&amp;quot;), &amp;quot;edited.jpg&amp;quot;))
}


image_paths &amp;lt;- dir(path = &amp;quot;indep_pages&amp;quot;, pattern = &amp;quot;*.jpg&amp;quot;, full.names = TRUE)

plan(multiprocess, workers = 8)

image_paths %&amp;gt;%
    future_map(prepare_image)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The picture below shows the result:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/table_and_edit.jpg&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Now comes the complicated part, which is going from the image above, to the dataset below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;good_fr,good_en,unit,market_date,price,source_url
Froment,Wheat,hectolitre,1875-08-28,23,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Métail,Meslin,hectolitre,1875-08-28,21,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Seigle,Rye,hectolitre,1875-08-28,15,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Orge,Barley,hectolitre,1875-08-28,16,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Orge mondé,Pot Barley,kilogram,1875-08-28,0.85,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Orge perlé,Pearl barley,kilogram,1875-08-28,0.8,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Avoine,Oats,hectolitre,1875-08-28,8.5,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg
Pois,Peas,hectolitre,1875-08-28,NA,https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F02grxj%2Fpages%2F1/full/full/0/default.jpg&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ocr-with-tesseract&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;OCR with {tesseract}&lt;/h2&gt;
&lt;p&gt;The first step was to get the date. For this, I have used the following function, which will then
be used inside another function, which will extract the data and prices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(magick)
library(tesseract)
library(furrr)
library(janitor)

is_empty_line &amp;lt;- function(line){
    ifelse(line == &amp;quot;&amp;quot;, TRUE, FALSE)
}

Sys.setlocale(&amp;#39;LC_TIME&amp;#39;, &amp;quot;fr_FR&amp;quot;)

get_date &amp;lt;- function(string, annee){

    liste_mois &amp;lt;- c(&amp;quot;janvier&amp;quot;, &amp;quot;février&amp;quot;, &amp;quot;mars&amp;quot;, &amp;quot;avril&amp;quot;, &amp;quot;mai&amp;quot;, &amp;quot;juin&amp;quot;, &amp;quot;juillet&amp;quot;,
                    &amp;quot;août&amp;quot;, &amp;quot;septembre&amp;quot;, &amp;quot;octobre&amp;quot;, &amp;quot;novembre&amp;quot;, &amp;quot;décembre&amp;quot;)

    raw_date &amp;lt;- string %&amp;gt;%
      str_to_lower() %&amp;gt;%
        str_remove_all(&amp;quot;\\.&amp;quot;) %&amp;gt;%
        str_extract(&amp;quot;\\d{1,2} .{3,9}(\\s+)?\\d{0,4}&amp;quot;) %&amp;gt;%
        str_split(&amp;quot;\\s+&amp;quot;, simplify = TRUE)

    if(ncol(raw_date) == 2){
        raw_date &amp;lt;- cbind(raw_date, &amp;quot;annee&amp;quot;)
    }

    raw_date[1, 3] &amp;lt;- annee

    raw_date &amp;lt;- str_to_lower(raw_date[1:1, 1:3])

    long_month &amp;lt;- case_when(
      raw_date[2] == &amp;quot;janv&amp;quot; ~ &amp;quot;janvier&amp;quot;,
      raw_date[2] == &amp;quot;févr&amp;quot; ~ &amp;quot;février&amp;quot;,
      raw_date[2] == &amp;quot;sept&amp;quot; ~ &amp;quot;septembre&amp;quot;,
      raw_date[2] == &amp;quot;oct&amp;quot; ~ &amp;quot;octobre&amp;quot;,
      raw_date[2] == &amp;quot;nov&amp;quot; ~ &amp;quot;novembre&amp;quot;,
      raw_date[2] == &amp;quot;dec&amp;quot; ~ &amp;quot;décembre&amp;quot;,
      TRUE ~ as.character(raw_date[2]))

    raw_date[2] &amp;lt;- long_month

    is_it_date &amp;lt;- as.Date(paste0(raw_date, collapse = &amp;quot;-&amp;quot;), format = &amp;quot;%d-%b-%Y&amp;quot;) %&amp;gt;%
        is.na() %&amp;gt;% `!`()

    if(is_it_date){
        return(as.Date(paste0(raw_date, collapse = &amp;quot;-&amp;quot;), format = &amp;quot;%d-%b-%Y&amp;quot;))
    } else {
        if(!(raw_date[2] %in% liste_mois)){
            raw_date[2] &amp;lt;- liste_mois[stringdist::amatch(raw_date[2], liste_mois, maxDist = 2)]
            return(as.Date(paste0(raw_date, collapse = &amp;quot;-&amp;quot;), format = &amp;quot;%d-%b-%Y&amp;quot;))
        }
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function is more complicated than I had hoped. This is because dates come in different formats.
For example, there are dates written like this “21 Janvier 1872”, or “12 Septembre” or “12 sept.”.
The biggest problem here is that sometimes the year is missing. I deal with this in the next
function, which is again, more complicated than what I had hoped. I won’t go into details and
explain every step of the function above, but the idea is to extract the data from the raw text,
replace abbreviated months with the full month name if needed, and then check if I get a valid date.
If not, I try my luck with &lt;code&gt;stringdist::amatch()&lt;/code&gt;, to try to match, say “jonvier” with “janvier”.
This is in case the OCR made a mistake. I am not very happy with this solution, because it is very
approximative, but oh well.&lt;/p&gt;
&lt;p&gt;The second step is to get the data. I noticed that the rows stay consistent, but do change
after June 1st 1876. So I simply hardcoded the goods names, and was only concerned with extracting
the prices. I also apply some manual corrections inside the function; mainly dates that were
wrongly recognized by the OCR engine, and which were causing problems. Again, not an optimal solution,
the other alternative was to simply drop this data, which I did not want to do. Here is the function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_table &amp;lt;- function(image_path){

  image &amp;lt;- image_read(image_path)

  annee &amp;lt;- image_path %&amp;gt;%
    str_extract(&amp;quot;187\\d&amp;quot;)

  ark &amp;lt;- image_path %&amp;gt;%
    str_sub(22, 27)

  source_url &amp;lt;- str_glue(&amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F{ark}%2Fpages%2F1/full/full/0/default.jpg&amp;quot;,
                         ark = ark)

  text &amp;lt;- ocr(image, engine = &amp;quot;fra&amp;quot;)

    text &amp;lt;- text %&amp;gt;%
      str_split(&amp;quot;\n&amp;quot;) %&amp;gt;%
      unlist %&amp;gt;%
      str_squish() %&amp;gt;%
      str_remove_all(&amp;quot;^.{1,10}$&amp;quot;) %&amp;gt;%
      discard(is_empty_line) %&amp;gt;%
      str_replace(&amp;quot;Mercuriale du \\+ Nov. 1831.&amp;quot;, &amp;quot;Mercuriale du 4 Nov. 1831.&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;….u .T juillet.&amp;quot;, &amp;quot;du 7 juillet&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;octobré&amp;quot;, &amp;quot;octobre&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;AT octobre&amp;quot;, &amp;quot;17 octobre&amp;quot;) %&amp;gt;% # correction for &amp;quot;f8g6kq8-18  LUNDI 19 OCTOBRÉ 1874. BUREAUX de fa RÉDACTIGedited.jpg&amp;quot;
      str_replace(&amp;quot;T norembre&amp;quot;, &amp;quot;7 novembre&amp;quot;) %&amp;gt;%  # correction for fcrhrn5-LE 8  LUNDI 9 NOVEMBRE 1874 BUREAUX de la RÉDedited.jpg
      str_replace(&amp;quot;À oc demain 5&amp;quot;, &amp;quot;27 mai&amp;quot;) %&amp;gt;% # correction for fd61vzp-MARDI 50. MAI 1876 BUREAUX de la. RED, n VE DE L’ADMINISTRAedited.jpg
      str_replace(&amp;quot;G&amp;quot;, &amp;quot;6&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;Hercariale du 80 nov. 1872,&amp;quot;, &amp;quot;du 30 novembre 1872&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;….u .T juillet.&amp;quot;, &amp;quot;du 7 juillet&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;Rs ne its du 28-octobré.: :!: :&amp;quot;, &amp;quot;28 octobre&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;De routes due 98-juilléle. à eat&amp;quot;, &amp;quot;28 juillet&amp;quot;) %&amp;gt;%
      str_replace(&amp;quot;\\| Mereariale dn 14 dre. 1872,&amp;quot;, &amp;quot;14 décembre 1872&amp;quot;)


  start &amp;lt;- text %&amp;gt;%
    str_which(&amp;quot;MARCH(É|E).*D(E|É).*LUXEMBOUR(G|6)&amp;quot;) + 2

  start &amp;lt;- ifelse(is_empty(start), str_which(text, &amp;quot;.*D.*UXEM.*&amp;quot;) + 2, start)

  end &amp;lt;- start + 40

  pricing_date &amp;lt;- text[start - 1] %&amp;gt;%
    str_remove(&amp;quot;%&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;er&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;\\.+&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;\\*&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;®&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;:&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;\\?&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;\\$&amp;quot;, &amp;quot;9&amp;quot;) %&amp;gt;%
    str_remove(&amp;quot;°&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;‘du 14août.. - ; En&amp;quot;, &amp;quot;14 août&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;OP PE CN AP PP&amp;quot;, &amp;quot;du 28 juin&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;‘ du 81 janvi Le&amp;quot;, &amp;quot;31 janvier&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;\\| \\| du AT août&amp;quot;, &amp;quot;17 août&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;Su”  du 81 juillet. L&amp;quot;, &amp;quot;31 juillet&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;0 du 29 avril \&amp;quot; \\|&amp;quot;, &amp;quot;29 avril&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;LU 0 du 28 ail&amp;quot;, &amp;quot;28 avril&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;Rs ne its du 28-octobre :!: :&amp;quot;, &amp;quot;23 octobre&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;7 F \\|  du 13 octobre LA LOTS&amp;quot;, &amp;quot;13 octobre&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;À. du 18 juin UT ET&amp;quot;, &amp;quot;13 juin&amp;quot;)


  market_date &amp;lt;- get_date(pricing_date, annee)

  items &amp;lt;- c(&amp;quot;Froment&amp;quot;, &amp;quot;Métail&amp;quot;, &amp;quot;Seigle&amp;quot;, &amp;quot;Orge&amp;quot;, &amp;quot;Orge mondé&amp;quot;, &amp;quot;Orge perlé&amp;quot;, &amp;quot;Avoine&amp;quot;, &amp;quot;Pois&amp;quot;, &amp;quot;Haricots&amp;quot;,
             &amp;quot;Lentilles&amp;quot;, &amp;quot;Pommes de terre&amp;quot;, &amp;quot;Bois de hêtre&amp;quot;, &amp;quot;Bois de chêne&amp;quot;, &amp;quot;Beurre&amp;quot;, &amp;quot;Oeufs&amp;quot;, &amp;quot;Foin&amp;quot;,
             &amp;quot;Paille&amp;quot;, &amp;quot;Viande de boeuf&amp;quot;, &amp;quot;Viande de vache&amp;quot;, &amp;quot;Viande de veau&amp;quot;, &amp;quot;Viande de mouton&amp;quot;,
             &amp;quot;Viande fraîche de cochon&amp;quot;, &amp;quot;Viande fumée de cochon&amp;quot;, &amp;quot;Haricots&amp;quot;, &amp;quot;Pois&amp;quot;, &amp;quot;Lentilles&amp;quot;,
             &amp;quot;Farines de froment&amp;quot;, &amp;quot;Farines de méteil&amp;quot;, &amp;quot;Farines de seigle&amp;quot;)

  items_en &amp;lt;- c(&amp;quot;Wheat&amp;quot;, &amp;quot;Meslin&amp;quot;, &amp;quot;Rye&amp;quot;, &amp;quot;Barley&amp;quot;, &amp;quot;Pot Barley&amp;quot;, &amp;quot;Pearl barley&amp;quot;, &amp;quot;Oats&amp;quot;, &amp;quot;Peas&amp;quot;, &amp;quot;Beans&amp;quot;,
    &amp;quot;Lentils&amp;quot;, &amp;quot;Potatoes&amp;quot;, &amp;quot;Beech wood&amp;quot;, &amp;quot;Oak wood&amp;quot;, &amp;quot;Butter&amp;quot;, &amp;quot;Eggs&amp;quot;, &amp;quot;Hay&amp;quot;, &amp;quot;Straw&amp;quot;, &amp;quot;Beef meat&amp;quot;,
    &amp;quot;Cow meat&amp;quot;, &amp;quot;Veal meat&amp;quot;, &amp;quot;Sheep meat&amp;quot;, &amp;quot;Fresh pig meat&amp;quot;, &amp;quot;Smoked pig meat&amp;quot;, &amp;quot;Beans&amp;quot;, &amp;quot;Peas&amp;quot;,
    &amp;quot;Lentils&amp;quot;, &amp;quot;Wheat flours&amp;quot;, &amp;quot;Meslin flours&amp;quot;, &amp;quot;Rye flours&amp;quot;)


  unit &amp;lt;- c(&amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;hectolitre&amp;quot;,
            &amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;hectolitre&amp;quot;, &amp;quot;stere&amp;quot;, &amp;quot;stere&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;dozen&amp;quot;,
            &amp;quot;500 kilogram&amp;quot;, &amp;quot;500 kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;,
            &amp;quot;kilogram&amp;quot;, &amp;quot;litre&amp;quot;, &amp;quot;litre&amp;quot;, &amp;quot;litre&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;, &amp;quot;kilogram&amp;quot;)

  # starting with june 1876, the order of the items changes
  items_06_1876 &amp;lt;- c(&amp;quot;Froment&amp;quot;, &amp;quot;Métail&amp;quot;, &amp;quot;Seigle&amp;quot;, &amp;quot;Orge&amp;quot;, &amp;quot;Avoine&amp;quot;, &amp;quot;Pois&amp;quot;, &amp;quot;Haricots&amp;quot;, &amp;quot;Lentilles&amp;quot;,
                     &amp;quot;Pommes de terre&amp;quot;, &amp;quot;Farines de froment&amp;quot;, &amp;quot;Farines de méteil&amp;quot;, &amp;quot;Farines de seigle&amp;quot;, &amp;quot;Orge mondé&amp;quot;,
                     &amp;quot;Beurre&amp;quot;, &amp;quot;Oeufs&amp;quot;, &amp;quot;Foins&amp;quot;, &amp;quot;Paille&amp;quot;, &amp;quot;Bois de hêtre&amp;quot;, &amp;quot;Bois de chêne&amp;quot;, &amp;quot;Viande de boeuf&amp;quot;, &amp;quot;Viande de vache&amp;quot;,
                     &amp;quot;Viande de veau&amp;quot;, &amp;quot;Viande de mouton&amp;quot;, &amp;quot;Viande fraîche de cochon&amp;quot;, &amp;quot;Viande fumée de cochon&amp;quot;)

  items_06_1876_en &amp;lt;- c(&amp;quot;Wheat&amp;quot;, &amp;quot;Meslin&amp;quot;, &amp;quot;Rye&amp;quot;, &amp;quot;Barley&amp;quot;, &amp;quot;Oats&amp;quot;, &amp;quot;Peas&amp;quot;, &amp;quot;Beans&amp;quot;, &amp;quot;Lentils&amp;quot;,
                        &amp;quot;Potatoes&amp;quot;, &amp;quot;Wheat flours&amp;quot;, &amp;quot;Meslin flours&amp;quot;, &amp;quot;Rye flours&amp;quot;, &amp;quot;Pot barley&amp;quot;,
                        &amp;quot;Butter&amp;quot;, &amp;quot;Eggs&amp;quot;, &amp;quot;Hay&amp;quot;, &amp;quot;Straw&amp;quot;, &amp;quot;Beechwood&amp;quot;, &amp;quot;Oakwood&amp;quot;, &amp;quot;Beef meat&amp;quot;, &amp;quot;Cow meat&amp;quot;,
                        &amp;quot;Veal meat&amp;quot;, &amp;quot;Sheep meat&amp;quot;, &amp;quot;Fresh pig meat&amp;quot;, &amp;quot;Smoked pig meat&amp;quot;)

  units_06_1876 &amp;lt;- c(rep(&amp;quot;hectolitre&amp;quot;, 9), rep(&amp;quot;kilogram&amp;quot;, 5), &amp;quot;douzaine&amp;quot;, rep(&amp;quot;500 kilogram&amp;quot;, 2),
                     &amp;quot;stere&amp;quot;, &amp;quot;stere&amp;quot;, rep(&amp;quot;kilogram&amp;quot;, 6))

  raw_data &amp;lt;- text[start:end]

  prices &amp;lt;- raw_data %&amp;gt;%
    str_replace_all(&amp;quot;©&amp;quot;, &amp;quot;0&amp;quot;) %&amp;gt;%
    str_extract(&amp;quot;\\d{1,2}\\s\\d{2}&amp;quot;) %&amp;gt;%
    str_replace(&amp;quot;\\s&amp;quot;, &amp;quot;\\.&amp;quot;) %&amp;gt;%
    as.numeric

  if(is.na(prices[1])){
    prices &amp;lt;- tail(prices, -1)
  } else {
    prices &amp;lt;- prices
  }

  if(market_date &amp;lt; as.Date(&amp;quot;01-06-1876&amp;quot;, format = &amp;quot;%d-%m-%Y&amp;quot;)){
    prices &amp;lt;- prices[1:length(items)]
    tibble(&amp;quot;good_fr&amp;quot; = items, &amp;quot;good_en&amp;quot; = items_en, &amp;quot;unit&amp;quot; = unit, &amp;quot;market_date&amp;quot; = market_date,
           &amp;quot;price&amp;quot; = prices, &amp;quot;source_url&amp;quot; = source_url)
  } else {
    prices &amp;lt;- prices[1:length(items_06_1876_en)]
    tibble(&amp;quot;good_fr&amp;quot; = items_06_1876, &amp;quot;good_en&amp;quot; = items_06_1876_en, &amp;quot;unit&amp;quot; = units_06_1876,
           &amp;quot;market_date&amp;quot; = market_date, &amp;quot;price&amp;quot; = prices, &amp;quot;source_url&amp;quot; = source_url)
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As I wrote previously, I had to deal with the missing year in the date inside this function. To do
that, I extracted the year from the name of the file, and pasted it then into the date. The file
name contains the data because the function in the function that downloads the files I also performed
OCR on the first page, to get the date of the newspaper issue. The sole purpose of this was to
get the year. Again, the function is more complex than what I hoped, but it did work well overall.
There are still mistakes in the data, for example sometimes the prices are in the wrong order;
meaning that they’re “shifted”, for example instead of the prices for eggs, I have the prices of the
good that comes next. So obviously be careful if you decide to analyze the data, and double-check
if something seems weird. I have made the data available on Luxembourg Open Data Portal,
&lt;a href=&#34;https://data.public.lu/fr/datasets/digitised-luxembourg-historical-newspapers-journaux-historiques-luxembourgeois-numerises/#resource-community-27293c42-22e5-4811-aee8-89d6f7fa9533&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analyzing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analyzing the data&lt;/h2&gt;
&lt;p&gt;And now, to the fun part. I want to know what was the price of smoked pig meat, and how it varied
through time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(ggplot2)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price &amp;lt;- read_csv(&amp;quot;https://download.data.public.lu/resources/digitised-luxembourg-historical-newspapers-journaux-historiques-luxembourgeois-numerises/20190407-183605/market-price.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   good_fr = col_character(),
##   good_en = col_character(),
##   unit = col_character(),
##   market_date = col_date(format = &amp;quot;&amp;quot;),
##   price = col_double(),
##   source_url = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Smoked pig meat&amp;quot;) %&amp;gt;%
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of smoked pig meat at the Luxembourg-City market in the 19th century&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 2 rows containing missing values (geom_path).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, there is a huge spike somewhere in 1874. Maybe there was a very severe smoked pig
meat shortage that caused the prices to increase dramatically, but the more likely explanation is
that there was some sort of mistake, either in the OCR step, or when I extracted the prices, and somehow
that particular price of smoked pig meat is actually the price of another, more expensive good.&lt;/p&gt;
&lt;p&gt;So let’s only consider prices that are below, say, 20 franks, which is already very high:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Smoked pig meat&amp;quot;) %&amp;gt;%
    filter(price &amp;lt; 20) %&amp;gt;% 
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of smoked pig meat at the Luxembourg-City market in the 1870s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, some prices are very high. Let’s check if it’s a mistake:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;% 
    filter(good_en == &amp;quot;Smoked pig meat&amp;quot;) %&amp;gt;% 
    filter(between(price, 5, 20)) %&amp;gt;% 
    pull(source_url)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fbs2fs6%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [2] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fd61vzp%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [3] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fjdwb6m%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [4] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fng14m3%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [5] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fw9jdrb%2Fpages%2F1/full/full/0/default.jpg&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you go to the first url, you will land on the first page of the newspaper. To check the table,
you need to check the third page, by changing this part of the url “pages%2F1” to this “pages%2F3”.&lt;/p&gt;
&lt;p&gt;You will then find the following:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/price_smoked_pig.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the price was 2.5, but the OCR returned 7.5. This is a problem that is unavoidable
with OCR; there is no way of knowing a priori if characters were not well recognized. It is actually
quite interesting how the price for smoked pig meat stayed constant through all these years.
A density plot shows that most prices were around 2.5:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;% 
    filter(good_en == &amp;quot;Smoked pig meat&amp;quot;) %&amp;gt;% 
    filter(price &amp;lt; 20) %&amp;gt;% 
    ggplot() + 
    geom_density(aes(price), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What about another good, say, barley?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Barley&amp;quot;) %&amp;gt;%
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of barley at the Luxembourg-City market in the 1870s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here again, we see some very high spikes, most likely due to errors. Let’s try to limit the prices
to likely values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Barley&amp;quot;) %&amp;gt;%
    filter(between(price, 10, 40)) %&amp;gt;%
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of barley at the Luxembourg-City market in the 1870s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;% 
    filter(good_en == &amp;quot;Barley&amp;quot;) %&amp;gt;% 
    ggplot() + 
    geom_density(aes(price), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 39 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s finish this with one of my favourite legume, lentils:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Lentils&amp;quot;) %&amp;gt;%
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of lentils at the Luxembourg-City market in the 1870s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;% 
    filter(good_en == &amp;quot;Lentils&amp;quot;) %&amp;gt;% 
    ggplot() + 
    geom_density(aes(price), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 79 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All these 0’s might be surprising, but in most cases, they are actually true zeros! For example,
you can check this
&lt;a href=&#34;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fwsvhwh%2Fpages%2F3/pct:74,0,100,100/full/0/default.jpg&#34;&gt;issue&lt;/a&gt;.
This very likely means that no lentils were available that day at the market.
Let’s get rid of the 0s and other extreme values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Lentils&amp;quot;) %&amp;gt;%
    filter(between(price, 1, 40)) %&amp;gt;% 
    ggplot(aes(x = market_date, y = price)) +
    geom_line(aes(group = 1), colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() + 
    labs(title = &amp;quot;Prices of lentils at the Luxembourg-City market in the 1870s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-04-07-historical_newspaper_scraping_tesseract_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I would like to see if the spikes above 30 are errors or not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;% 
    filter(good_en == &amp;quot;Lentils&amp;quot;) %&amp;gt;% 
    filter(between(price, 30, 40)) %&amp;gt;% 
    pull(source_url)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F04mb5t%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [2] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fb8zp31%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [3] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fkzrj53%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [4] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fs8sw2v%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [5] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fsjptsk%2Fpages%2F1/full/full/0/default.jpg&amp;quot;
## [6] &amp;quot;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2Fwk65b6%2Fpages%2F1/full/full/0/default.jpg&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The price was recognized as being 35, and turns out it was correct as you can see
&lt;a href=&#34;https://iiif.eluxemburgensia.lu/iiif/2/ark:%2F70795%2F04mb5t%2Fpages%2F3/full/full/0/default.jpg&#34;&gt;here&lt;/a&gt;.
This is quite interesting, because the average price was way lower than that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;market_price %&amp;gt;%
    filter(good_en == &amp;quot;Lentils&amp;quot;) %&amp;gt;%
    filter(between(price, 1, 40)) %&amp;gt;% 
    summarise(mean_price = mean(price), 
              sd_price = sd(price))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   mean_price sd_price
##        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1       20.8     5.82&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m going to finish here; it was an interesting project, and I can’t wait for more newspapers to be
digitized and OCR to work even better. There is a lot more historical data trapped in these newspapers
that could provide a lot insights on Luxembourg’s society in the 19th century.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Get text from pdfs or images using OCR: a tutorial with {tesseract} and {magick}</title>
      <link>https://www.brodrigues.co/blog/2019-03-31-tesseract/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-03-31-tesseract/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Michel_Rodange&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/michelrodange.jpg&#34; title = &#34;The high school I attended was named after this gentleman&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this blog post I’m going to show you how you can extract text from scanned pdf files, or pdf files
where no text recognition was performed. (For pdfs where text recognition was performed, you can
read my &lt;a href=&#34;https://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/&#34;&gt;other blog post&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The pdf I’m going to use can be downloaded from &lt;a href=&#34;http://www.luxemburgensia.bnl.lu/cgi/getPdf1_2.pl?mode=item&amp;amp;id=7110&#34;&gt;here&lt;/a&gt;.
It’s a poem titled, &lt;em&gt;D’Léierchen (Dem Léiweckerche säi Lidd)&lt;/em&gt;,
written by Michel Rodange, arguably Luxembourg’s most well known writer and poet. Michel Rodange is
mostly known for his fable, &lt;em&gt;Renert oder De Fuuß am Frack an a Ma’nsgrëßt&lt;/em&gt;, starring a central European
&lt;a href=&#34;https://en.wikipedia.org/wiki/Reynard_the_Fox&#34;&gt;trickster anthropomorphic red fox&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/d4/Reynard-the-fox.jpg&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Anyway, back to the point of this blog post. How can we get data from a pdf where no text recognition
was performed (or, how can we get text from an image)? The pdf we need the text from looks like
this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dleierchen_03.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;To get the text from the pdf, we can use the &lt;code&gt;{tesseract}&lt;/code&gt; package, which provides bindings to the &lt;code&gt;tesseract&lt;/code&gt; program.
&lt;code&gt;tesseract&lt;/code&gt; is an open source OCR engine developed by Google. This means that first you will need
to install the &lt;code&gt;tesseract&lt;/code&gt; program on your system. You can follow the intructions from &lt;code&gt;tesseract&lt;/code&gt;’s
github &lt;a href=&#34;https://github.com/tesseract-ocr/tesseract&#34;&gt;page&lt;/a&gt;. &lt;code&gt;tesseract&lt;/code&gt; is currently at version 4.&lt;/p&gt;
&lt;p&gt;Before applying OCR to a pdf, let’s first use the &lt;code&gt;{pdftools}&lt;/code&gt; package to convert the pdf to png.
This is because &lt;code&gt;{tesseract}&lt;/code&gt; requires images as input (if you provide a pdf file, it will
converted on the fly). Let’s first load the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tesseract)
library(pdftools)
library(magick)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now let’s convert the pdf to png files (in plural, because we’ll get one image per page of the pdf):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pngfile &amp;lt;- pdftools::pdf_convert(&amp;quot;path/to/pdf&amp;quot;, dpi = 600)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will generate 14 png files. I erase the ones that are not needed, such as the title page. Now,
let’s read in all the image files:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path &amp;lt;- dir(path = &amp;quot;path/to/pngs&amp;quot;, pattern = &amp;quot;*.png&amp;quot;, full.names = TRUE)

images &amp;lt;- map(path, magick::image_read)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;images&lt;/code&gt; object is a list of &lt;code&gt;magick-image&lt;/code&gt;s, which we can parse. BUUUUUT! There’s a problem.
The text is laid out in two columns. Which means that the first line after performing OCR will be
the first line of the first column, and the first line of the second column joined together. Same
for the other lines of course. So ideally, I’d need to split the file in the middle, and then
perform OCR. This is easily done with the &lt;code&gt;{magick}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_half &amp;lt;- map(images, ~image_crop(., geometry = &amp;quot;2307x6462&amp;quot;))

second_half &amp;lt;- map(images, ~image_crop(., geometry = &amp;quot;2307x6462+2307+0&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because the pngs are 4614 by 6962 pixels, I can get the first half of the png by cropping at
“2307x6462” (I decrease the height a bit to get rid of the page number), and the second half by
applying the same logic, but starting the cropping at the “2307+0” position. The result looks like
this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dleierchen_cropped.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Much better! Now I need to join these two lists together. I cannot simply join them. Consider
the following example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one &amp;lt;- list(1, 3, 5)

two &amp;lt;- list(2, 4, 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the setup I currently have; &lt;code&gt;first_half&lt;/code&gt; contains odd pages, and &lt;code&gt;second_half&lt;/code&gt; contains
even pages. The result I want would look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list(1, 2, 3, 4, 5, 6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1
## 
## [[2]]
## [1] 2
## 
## [[3]]
## [1] 3
## 
## [[4]]
## [1] 4
## 
## [[5]]
## [1] 5
## 
## [[6]]
## [1] 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is a very elegant solution, with &lt;code&gt;reduce2()&lt;/code&gt; from the &lt;code&gt;{purrr}&lt;/code&gt; package. &lt;code&gt;reduce()&lt;/code&gt; takes one
list and a function, and … &lt;em&gt;reduces&lt;/em&gt; the list to a single element. For instance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reduce(list(1, 2, 3), paste)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1 2 3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;reduce2()&lt;/code&gt; is very similar, but takes in two lists, but the second list must be one element shorter:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reduce2(list(1, 2, 3), list(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;), paste)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1 2 a 3 b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we cannot simply use &lt;code&gt;reduce2()&lt;/code&gt; on lists &lt;code&gt;one&lt;/code&gt; and &lt;code&gt;two&lt;/code&gt;, because they’re the same length. So let’s
prepend a value to &lt;code&gt;one&lt;/code&gt;, using the &lt;code&gt;prepend()&lt;/code&gt; function of &lt;code&gt;{purrr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prepend(one, 0) %&amp;gt;% 
    reduce2(two, c)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0 1 2 3 4 5 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Exactly what we need! Let’s apply this trick to our lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;merged_list &amp;lt;- prepend(first_half, NA) %&amp;gt;% 
    reduce2(second_half, c) %&amp;gt;% 
    discard(is.na)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve prepended &lt;code&gt;NA&lt;/code&gt; to the first list, and then used &lt;code&gt;reduce2()&lt;/code&gt; and then used &lt;code&gt;discard(is.na)&lt;/code&gt; to
remove the &lt;code&gt;NA&lt;/code&gt; I’ve added at the start. Now, we can use OCR to get the text:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;text_list &amp;lt;- map(merged_list, ocr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ocr()&lt;/code&gt; uses a model trained on English by default, and even though there is a model trained on
Luxembourguish, the one trained on English works better! Very likely because the English model was trained
on a lot more data than the Luxembourguish one. I was worried the English model was not going to
recognize characters such as &lt;code&gt;é&lt;/code&gt;, but no, it worked quite well.&lt;/p&gt;
&lt;p&gt;This is how it looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;text_list

[[1]]
[1] &amp;quot;Lhe\n| Kaum huet d’Feld dat fréndlecht Feier\nVun der Aussentssonn gesunn\nAs mam Plou aus Stall a Scheier\n* D’lescht e Bauer ausgezunn.\nFir de Plou em nach ze dreiwen\nWar sai Jéngelchen alaert,\nDeen nét wéllt doheem méi bleiwen\n8 An esouz um viischte Paerd.\nOp der Schéllche stoung ze denken\nD’Léierche mam Hierz voll Lidder\nFir de Béifchen nach ze zanken\n12 Duckelt s’an de Som sech nidder.\nBis e laascht war, an du stémmt se\nUn e Liddchen, datt et kraacht\nOp der Nouteleder klémmt se\n16 Datt dem Béifchen d’Haerz alt laacht.\nAn du sot en: Papp, ech mengen\nBal de Vull dee kénnt och schwatzen.\nLauschter, sot de Papp zum Klengen,\n20 Ech kann d’Liddchen iwersetzen.\nI\nBas de do, mii léiwe Fréndchen\nMa de Wanter dee war laang!\nKuck, ech hat keng fréilech Sténnchen\n24 *T war fir dech a mech mer baang.\nAn du koum ech dech besichen\nWell du goungs nét méi eraus\nMann wat hues jo du eng Kichen\n28 Wat eng Scheier wat en Haus.\nWi zerguttster, a wat Saachen!\nAn déng Frache gouf mer Brout.\nAn déng Kanner, wi se laachen,\n32, An hir Backelcher, wi rout!\nJo, bei dir as Rot nét deier!\nJo a kuck mer wat eng Méscht.\nDat gét Saache fir an d’Scheier\n36 An och Sué fir an d’Késcht.\nMuerges waars de schuns um Dreschen\nIr der Daudes d’Schung sech stréckt\nBas am Do duurch Wis a Paschen\n40 Laascht all Waassergruef geschréckt.\n&amp;quot;
....
....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to split at the &lt;code&gt;&#34;\n&#34;&lt;/code&gt; character:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;text_list &amp;lt;- text_list %&amp;gt;% 
    map(., ~str_split(., &amp;quot;\n&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The end result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;text_list

[[1]]
[[1]][[1]]
 [1] &amp;quot;Lhe&amp;quot;                                      &amp;quot;| Kaum huet d’Feld dat fréndlecht Feier&amp;quot; 
 [3] &amp;quot;Vun der Aussentssonn gesunn&amp;quot;              &amp;quot;As mam Plou aus Stall a Scheier&amp;quot;         
 [5] &amp;quot;* D’lescht e Bauer ausgezunn.&amp;quot;            &amp;quot;Fir de Plou em nach ze dreiwen&amp;quot;          
 [7] &amp;quot;War sai Jéngelchen alaert,&amp;quot;               &amp;quot;Deen nét wéllt doheem méi bleiwen&amp;quot;       
 [9] &amp;quot;8 An esouz um viischte Paerd.&amp;quot;            &amp;quot;Op der Schéllche stoung ze denken&amp;quot;       
[11] &amp;quot;D’Léierche mam Hierz voll Lidder&amp;quot;         &amp;quot;Fir de Béifchen nach ze zanken&amp;quot;          
[13] &amp;quot;12 Duckelt s’an de Som sech nidder.&amp;quot;      &amp;quot;Bis e laascht war, an du stémmt se&amp;quot;      
[15] &amp;quot;Un e Liddchen, datt et kraacht&amp;quot;           &amp;quot;Op der Nouteleder klémmt se&amp;quot;             
[17] &amp;quot;16 Datt dem Béifchen d’Haerz alt laacht.&amp;quot; &amp;quot;An du sot en: Papp, ech mengen&amp;quot;          
[19] &amp;quot;Bal de Vull dee kénnt och schwatzen.&amp;quot;     &amp;quot;Lauschter, sot de Papp zum Klengen,&amp;quot;     
[21] &amp;quot;20 Ech kann d’Liddchen iwersetzen.&amp;quot;       &amp;quot;I&amp;quot;                                       
[23] &amp;quot;Bas de do, mii léiwe Fréndchen&amp;quot;           &amp;quot;Ma de Wanter dee war laang!&amp;quot;             
[25] &amp;quot;Kuck, ech hat keng fréilech Sténnchen&amp;quot;    &amp;quot;24 *T war fir dech a mech mer baang.&amp;quot;    
[27] &amp;quot;An du koum ech dech besichen&amp;quot;             &amp;quot;Well du goungs nét méi eraus&amp;quot;            
[29] &amp;quot;Mann wat hues jo du eng Kichen&amp;quot;           &amp;quot;28 Wat eng Scheier wat en Haus.&amp;quot;         
[31] &amp;quot;Wi zerguttster, a wat Saachen!&amp;quot;           &amp;quot;An déng Frache gouf mer Brout.&amp;quot;          
[33] &amp;quot;An déng Kanner, wi se laachen,&amp;quot;           &amp;quot;32, An hir Backelcher, wi rout!&amp;quot;         
[35] &amp;quot;Jo, bei dir as Rot nét deier!&amp;quot;            &amp;quot;Jo a kuck mer wat eng Méscht.&amp;quot;           
[37] &amp;quot;Dat gét Saache fir an d’Scheier&amp;quot;          &amp;quot;36 An och Sué fir an d’Késcht.&amp;quot;          
[39] &amp;quot;Muerges waars de schuns um Dreschen&amp;quot;      &amp;quot;Ir der Daudes d’Schung sech stréckt&amp;quot;     
[41] &amp;quot;Bas am Do duurch Wis a Paschen&amp;quot;           &amp;quot;40 Laascht all Waassergruef geschréckt.&amp;quot; 
[43] &amp;quot;&amp;quot;  
...
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perfect! Some more cleaning would be needed though. For example, I need to remove the little
annotations that are included:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dleierchen_anot.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;I don’t know yet how I’m going to do that.I also need to remove the line numbers at the beginning
of every fourth line, but this is easily done with a simple regular expression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str_remove_all(c(&amp;quot;12 bla&amp;quot;, &amp;quot;blb&amp;quot;, &amp;quot;123 blc&amp;quot;), &amp;quot;^\\d{1,}\\s+&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;bla&amp;quot; &amp;quot;blb&amp;quot; &amp;quot;blc&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this will be left for a future blog post!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pivoting data frames just got easier thanks to `pivot_wide()` and `pivot_long()`</title>
      <link>https://www.brodrigues.co/blog/2019-03-20-pivot/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-03-20-pivot/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/R2u0sN9stbA?t=69&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/pivot.jpg&#34; title = &#34;You know where this leads&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt; Update: &lt;code&gt;pivot_wide()&lt;/code&gt; and &lt;code&gt;pivot_long()&lt;/code&gt; are now called &lt;code&gt;pivot_wider()&lt;/code&gt; and &lt;code&gt;pivot_longer()&lt;/code&gt;,
    so the code below needs to be updated accondingly.&lt;/p&gt;

&lt;p&gt;There’s a lot going on in the development version of &lt;code&gt;{tidyr}&lt;/code&gt;. New functions for pivoting data
frames, &lt;code&gt;pivot_wide()&lt;/code&gt; and &lt;code&gt;pivot_long()&lt;/code&gt; are coming, and will replace the current functions,
&lt;code&gt;spread()&lt;/code&gt; and &lt;code&gt;gather()&lt;/code&gt;. &lt;code&gt;spread()&lt;/code&gt; and &lt;code&gt;gather()&lt;/code&gt; will remain in the package though:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;You may have heard a rumour that gather/spread are going away. This is simply not true (they’ll stay around forever) but I am working on better replacements which you can learn about at &lt;a href=&#34;https://t.co/sU2GzWeBaf&#34;&gt;https://t.co/sU2GzWeBaf&lt;/a&gt;. Now is a great time for feedback! &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;&lt;/p&gt;&amp;mdash; Hadley Wickham (@hadleywickham) &lt;a href=&#34;https://twitter.com/hadleywickham/status/1108107722128613377?ref_src=twsrc%5Etfw&#34;&gt;March 19, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;If you want to try out these new functions, you need to install the development version of &lt;code&gt;{tidyr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;tidyverse/tidyr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you can read the vignette &lt;a href=&#34;https://tidyr.tidyverse.org/dev/articles/pivot.html#many-variables-in-column-names&#34;&gt;here&lt;/a&gt;.
Because these functions are still being developed, some more changes might be introduced, but I guess
that the main functionality will not change much.&lt;/p&gt;
&lt;p&gt;Let’s play around with these functions and the &lt;code&gt;mtcars&lt;/code&gt; data set. First let’s load the packages and
the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
data(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s create a wide dataset, by &lt;em&gt;spreading&lt;/em&gt; the levels of the “am” column to two new columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide1 &amp;lt;- mtcars %&amp;gt;% 
    pivot_wide(names_from = &amp;quot;am&amp;quot;, values_from = &amp;quot;mpg&amp;quot;) 

mtcars_wide1 %&amp;gt;% 
    select(`0`, `1`, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 11
##      `0`   `1`   cyl  disp    hp  drat    wt  qsec    vs  gear  carb
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  NA    21       6  160    110  3.9   2.62  16.5     0     4     4
##  2  NA    21       6  160    110  3.9   2.88  17.0     0     4     4
##  3  NA    22.8     4  108     93  3.85  2.32  18.6     1     4     1
##  4  21.4  NA       6  258    110  3.08  3.22  19.4     1     3     1
##  5  18.7  NA       8  360    175  3.15  3.44  17.0     0     3     2
##  6  18.1  NA       6  225    105  2.76  3.46  20.2     1     3     1
##  7  14.3  NA       8  360    245  3.21  3.57  15.8     0     3     4
##  8  24.4  NA       4  147.    62  3.69  3.19  20       1     4     2
##  9  22.8  NA       4  141.    95  3.92  3.15  22.9     1     4     2
## 10  19.2  NA       6  168.   123  3.92  3.44  18.3     1     4     4
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;pivot_wide()&lt;/code&gt;’s arguments are quite explicit: &lt;code&gt;names_from =&lt;/code&gt; is where you specify the column that
will be spread across the data frame, meaning, the levels of this column will become new columns.
&lt;code&gt;values_from =&lt;/code&gt; is where you specify the column that will fill in the values of the new columns.&lt;/p&gt;
&lt;p&gt;“0” and “1” are the new columns (“am” had two levels, &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;), which contain the miles per
gallon for manual and automatic cars respectively. Let’s also take a look at the data frame itself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide1 %&amp;gt;% 
    select(`0`, `1`, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 11
##      `0`   `1`   cyl  disp    hp  drat    wt  qsec    vs  gear  carb
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  NA    21       6  160    110  3.9   2.62  16.5     0     4     4
##  2  NA    21       6  160    110  3.9   2.88  17.0     0     4     4
##  3  NA    22.8     4  108     93  3.85  2.32  18.6     1     4     1
##  4  21.4  NA       6  258    110  3.08  3.22  19.4     1     3     1
##  5  18.7  NA       8  360    175  3.15  3.44  17.0     0     3     2
##  6  18.1  NA       6  225    105  2.76  3.46  20.2     1     3     1
##  7  14.3  NA       8  360    245  3.21  3.57  15.8     0     3     4
##  8  24.4  NA       4  147.    62  3.69  3.19  20       1     4     2
##  9  22.8  NA       4  141.    95  3.92  3.15  22.9     1     4     2
## 10  19.2  NA       6  168.   123  3.92  3.44  18.3     1     4     4
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now suppose that we want to spread the values of “am” times “cyl”, and filling the data with the
values of “mpg”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide2 &amp;lt;- mtcars %&amp;gt;% 
    pivot_wide(names_from = c(&amp;quot;am&amp;quot;, &amp;quot;cyl&amp;quot;), values_from = &amp;quot;mpg&amp;quot;) 

mtcars_wide2 %&amp;gt;% 
    select(matches(&amp;quot;^0|1&amp;quot;), everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 14
##    `1_6` `1_4` `0_6` `0_8` `0_4` `1_8`  disp    hp  drat    wt  qsec    vs
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1    21  NA    NA    NA    NA      NA  160    110  3.9   2.62  16.5     0
##  2    21  NA    NA    NA    NA      NA  160    110  3.9   2.88  17.0     0
##  3    NA  22.8  NA    NA    NA      NA  108     93  3.85  2.32  18.6     1
##  4    NA  NA    21.4  NA    NA      NA  258    110  3.08  3.22  19.4     1
##  5    NA  NA    NA    18.7  NA      NA  360    175  3.15  3.44  17.0     0
##  6    NA  NA    18.1  NA    NA      NA  225    105  2.76  3.46  20.2     1
##  7    NA  NA    NA    14.3  NA      NA  360    245  3.21  3.57  15.8     0
##  8    NA  NA    NA    NA    24.4    NA  147.    62  3.69  3.19  20       1
##  9    NA  NA    NA    NA    22.8    NA  141.    95  3.92  3.15  22.9     1
## 10    NA  NA    19.2  NA    NA      NA  168.   123  3.92  3.44  18.3     1
## # … with 22 more rows, and 2 more variables: gear &amp;lt;dbl&amp;gt;, carb &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this is easily achieved by simply providing more columns to &lt;code&gt;names_from =&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, it is also possible to use an optional data set which contains the specifications of the
new columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spec &amp;lt;- mtcars %&amp;gt;% 
    expand(am, cyl, .value = &amp;quot;mpg&amp;quot;) %&amp;gt;%
    unite(&amp;quot;.name&amp;quot;, am, cyl, remove = FALSE)

mtcars_spec&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   .name    am   cyl .value
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 0_4       0     4 mpg   
## 2 0_6       0     6 mpg   
## 3 0_8       0     8 mpg   
## 4 1_4       1     4 mpg   
## 5 1_6       1     6 mpg   
## 6 1_8       1     8 mpg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This optional data set defines how the columns “0_4”, “0_6” etc are constructed, and also the
value that shall be used to fill in the values. “am” and “cyl” will be used to create the “.name”
and the “mpg” column will be used for the “.value”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    pivot_wide(spec = mtcars_spec) %&amp;gt;% 
    select(matches(&amp;quot;^0|1&amp;quot;), everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 14
##    `0_4` `0_6` `0_8` `1_4` `1_6` `1_8`  disp    hp  drat    wt  qsec    vs
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  NA    NA    NA    NA      21    NA  160    110  3.9   2.62  16.5     0
##  2  NA    NA    NA    NA      21    NA  160    110  3.9   2.88  17.0     0
##  3  NA    NA    NA    22.8    NA    NA  108     93  3.85  2.32  18.6     1
##  4  NA    21.4  NA    NA      NA    NA  258    110  3.08  3.22  19.4     1
##  5  NA    NA    18.7  NA      NA    NA  360    175  3.15  3.44  17.0     0
##  6  NA    18.1  NA    NA      NA    NA  225    105  2.76  3.46  20.2     1
##  7  NA    NA    14.3  NA      NA    NA  360    245  3.21  3.57  15.8     0
##  8  24.4  NA    NA    NA      NA    NA  147.    62  3.69  3.19  20       1
##  9  22.8  NA    NA    NA      NA    NA  141.    95  3.92  3.15  22.9     1
## 10  NA    19.2  NA    NA      NA    NA  168.   123  3.92  3.44  18.3     1
## # … with 22 more rows, and 2 more variables: gear &amp;lt;dbl&amp;gt;, carb &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using a spec is especially useful if you need to make new levels that are not in the data.
For instance, suppose that there are actually 10-cylinder cars too, but they do not appear in our
sample. We would like to make the fact that they’re missing explicit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spec2 &amp;lt;- mtcars %&amp;gt;% 
    expand(am, &amp;quot;cyl&amp;quot; = c(cyl, 10), .value = &amp;quot;mpg&amp;quot;) %&amp;gt;%
    unite(&amp;quot;.name&amp;quot;, am, cyl, remove = FALSE)

mtcars_spec2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 4
##   .name    am   cyl .value
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
## 1 0_4       0     4 mpg   
## 2 0_6       0     6 mpg   
## 3 0_8       0     8 mpg   
## 4 0_10      0    10 mpg   
## 5 1_4       1     4 mpg   
## 6 1_6       1     6 mpg   
## 7 1_8       1     8 mpg   
## 8 1_10      1    10 mpg&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    pivot_wide(spec = mtcars_spec2) %&amp;gt;% 
    select(matches(&amp;quot;^0|1&amp;quot;), everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 16
##    `0_4` `0_6` `0_8` `0_10` `1_4` `1_6` `1_8` `1_10`  disp    hp  drat
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  NA    NA    NA       NA  NA      21    NA     NA  160    110  3.9 
##  2  NA    NA    NA       NA  NA      21    NA     NA  160    110  3.9 
##  3  NA    NA    NA       NA  22.8    NA    NA     NA  108     93  3.85
##  4  NA    21.4  NA       NA  NA      NA    NA     NA  258    110  3.08
##  5  NA    NA    18.7     NA  NA      NA    NA     NA  360    175  3.15
##  6  NA    18.1  NA       NA  NA      NA    NA     NA  225    105  2.76
##  7  NA    NA    14.3     NA  NA      NA    NA     NA  360    245  3.21
##  8  24.4  NA    NA       NA  NA      NA    NA     NA  147.    62  3.69
##  9  22.8  NA    NA       NA  NA      NA    NA     NA  141.    95  3.92
## 10  NA    19.2  NA       NA  NA      NA    NA     NA  168.   123  3.92
## # … with 22 more rows, and 5 more variables: wt &amp;lt;dbl&amp;gt;, qsec &amp;lt;dbl&amp;gt;,
## #   vs &amp;lt;dbl&amp;gt;, gear &amp;lt;dbl&amp;gt;, carb &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we now have two more columns have been added, and they are full of NA’s.&lt;/p&gt;
&lt;p&gt;Now, let’s try to go from wide to long data sets, using &lt;code&gt;pivot_long()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide1 %&amp;gt;% 
  pivot_long(cols = c(`1`, `0`), names_to = &amp;quot;am&amp;quot;, values_to = &amp;quot;mpg&amp;quot;) %&amp;gt;% 
  select(am, mpg, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 11
##    am      mpg   cyl  disp    hp  drat    wt  qsec    vs  gear  carb
##    &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1      21       6   160   110  3.9   2.62  16.5     0     4     4
##  2 0      NA       6   160   110  3.9   2.62  16.5     0     4     4
##  3 1      21       6   160   110  3.9   2.88  17.0     0     4     4
##  4 0      NA       6   160   110  3.9   2.88  17.0     0     4     4
##  5 1      22.8     4   108    93  3.85  2.32  18.6     1     4     1
##  6 0      NA       4   108    93  3.85  2.32  18.6     1     4     1
##  7 1      NA       6   258   110  3.08  3.22  19.4     1     3     1
##  8 0      21.4     6   258   110  3.08  3.22  19.4     1     3     1
##  9 1      NA       8   360   175  3.15  3.44  17.0     0     3     2
## 10 0      18.7     8   360   175  3.15  3.44  17.0     0     3     2
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The arguments of &lt;code&gt;pivot_long()&lt;/code&gt; are quite explicit too, and similar to the ones in &lt;code&gt;pivot_wide()&lt;/code&gt;.
&lt;code&gt;cols =&lt;/code&gt; is where the user specifies the columns that need to be pivoted. &lt;code&gt;names_to =&lt;/code&gt; is where
the user can specify the name of the new columns, whose levels will be exactly the ones specified
to &lt;code&gt;cols =&lt;/code&gt;. &lt;code&gt;values_to =&lt;/code&gt; is where the user specifies the column name of the new column that
will contain the values.&lt;/p&gt;
&lt;p&gt;It is also possible to specify the columns that should not be transformed, by using &lt;code&gt;-&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide1 %&amp;gt;% 
  pivot_long(cols = -matches(&amp;quot;^[[:alpha:]]&amp;quot;), names_to = &amp;quot;am&amp;quot;, values_to = &amp;quot;mpg&amp;quot;) %&amp;gt;% 
  select(am, mpg, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 11
##    am      mpg   cyl  disp    hp  drat    wt  qsec    vs  gear  carb
##    &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1      21       6   160   110  3.9   2.62  16.5     0     4     4
##  2 0      NA       6   160   110  3.9   2.62  16.5     0     4     4
##  3 1      21       6   160   110  3.9   2.88  17.0     0     4     4
##  4 0      NA       6   160   110  3.9   2.88  17.0     0     4     4
##  5 1      22.8     4   108    93  3.85  2.32  18.6     1     4     1
##  6 0      NA       4   108    93  3.85  2.32  18.6     1     4     1
##  7 1      NA       6   258   110  3.08  3.22  19.4     1     3     1
##  8 0      21.4     6   258   110  3.08  3.22  19.4     1     3     1
##  9 1      NA       8   360   175  3.15  3.44  17.0     0     3     2
## 10 0      18.7     8   360   175  3.15  3.44  17.0     0     3     2
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here the columns that should not be modified are all those that start with a letter, hence the “&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;”
regular expression. It is also possible to remove all the &lt;code&gt;NA&lt;/code&gt;’s from the data frame, with &lt;code&gt;na.rm =&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide1 %&amp;gt;% 
  pivot_long(cols = c(`1`, `0`), names_to = &amp;quot;am&amp;quot;, values_to = &amp;quot;mpg&amp;quot;, na.rm = TRUE) %&amp;gt;% 
  select(am, mpg, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 11
##    am      mpg   cyl  disp    hp  drat    wt  qsec    vs  gear  carb
##    &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1      21       6  160    110  3.9   2.62  16.5     0     4     4
##  2 1      21       6  160    110  3.9   2.88  17.0     0     4     4
##  3 1      22.8     4  108     93  3.85  2.32  18.6     1     4     1
##  4 0      21.4     6  258    110  3.08  3.22  19.4     1     3     1
##  5 0      18.7     8  360    175  3.15  3.44  17.0     0     3     2
##  6 0      18.1     6  225    105  2.76  3.46  20.2     1     3     1
##  7 0      14.3     8  360    245  3.21  3.57  15.8     0     3     4
##  8 0      24.4     4  147.    62  3.69  3.19  20       1     4     2
##  9 0      22.8     4  141.    95  3.92  3.15  22.9     1     4     2
## 10 0      19.2     6  168.   123  3.92  3.44  18.3     1     4     4
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also pivot data frames where the names of the columns are made of two or more variables,
for example in our &lt;code&gt;mtcars_wide2&lt;/code&gt; data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide2 %&amp;gt;% 
    select(matches(&amp;quot;^0|1&amp;quot;), everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 14
##    `1_6` `1_4` `0_6` `0_8` `0_4` `1_8`  disp    hp  drat    wt  qsec    vs
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1    21  NA    NA    NA    NA      NA  160    110  3.9   2.62  16.5     0
##  2    21  NA    NA    NA    NA      NA  160    110  3.9   2.88  17.0     0
##  3    NA  22.8  NA    NA    NA      NA  108     93  3.85  2.32  18.6     1
##  4    NA  NA    21.4  NA    NA      NA  258    110  3.08  3.22  19.4     1
##  5    NA  NA    NA    18.7  NA      NA  360    175  3.15  3.44  17.0     0
##  6    NA  NA    18.1  NA    NA      NA  225    105  2.76  3.46  20.2     1
##  7    NA  NA    NA    14.3  NA      NA  360    245  3.21  3.57  15.8     0
##  8    NA  NA    NA    NA    24.4    NA  147.    62  3.69  3.19  20       1
##  9    NA  NA    NA    NA    22.8    NA  141.    95  3.92  3.15  22.9     1
## 10    NA  NA    19.2  NA    NA      NA  168.   123  3.92  3.44  18.3     1
## # … with 22 more rows, and 2 more variables: gear &amp;lt;dbl&amp;gt;, carb &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All the columns that start with either “0” or “1” must be pivoted:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide2 %&amp;gt;% 
  pivot_long(cols = matches(&amp;quot;0|1&amp;quot;), names_to = &amp;quot;am_cyl&amp;quot;, values_to = &amp;quot;mpg&amp;quot;, na.rm = TRUE) %&amp;gt;% 
  select(am_cyl, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 10
##    am_cyl  disp    hp  drat    wt  qsec    vs  gear  carb   mpg
##    &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1_6     160    110  3.9   2.62  16.5     0     4     4  21  
##  2 1_6     160    110  3.9   2.88  17.0     0     4     4  21  
##  3 1_4     108     93  3.85  2.32  18.6     1     4     1  22.8
##  4 0_6     258    110  3.08  3.22  19.4     1     3     1  21.4
##  5 0_8     360    175  3.15  3.44  17.0     0     3     2  18.7
##  6 0_6     225    105  2.76  3.46  20.2     1     3     1  18.1
##  7 0_8     360    245  3.21  3.57  15.8     0     3     4  14.3
##  8 0_4     147.    62  3.69  3.19  20       1     4     2  24.4
##  9 0_4     141.    95  3.92  3.15  22.9     1     4     2  22.8
## 10 0_6     168.   123  3.92  3.44  18.3     1     4     4  19.2
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, there is one new column, “am_cyl” which must still be transformed by separating “am_cyl” into two new columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide2 %&amp;gt;% 
  pivot_long(cols = matches(&amp;quot;0|1&amp;quot;), names_to = &amp;quot;am_cyl&amp;quot;, values_to = &amp;quot;mpg&amp;quot;, na.rm = TRUE) %&amp;gt;% 
  separate(am_cyl, into = c(&amp;quot;am&amp;quot;, &amp;quot;cyl&amp;quot;), sep = &amp;quot;_&amp;quot;) %&amp;gt;% 
  select(am, cyl, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 11
##    am    cyl    disp    hp  drat    wt  qsec    vs  gear  carb   mpg
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1     6      160    110  3.9   2.62  16.5     0     4     4  21  
##  2 1     6      160    110  3.9   2.88  17.0     0     4     4  21  
##  3 1     4      108     93  3.85  2.32  18.6     1     4     1  22.8
##  4 0     6      258    110  3.08  3.22  19.4     1     3     1  21.4
##  5 0     8      360    175  3.15  3.44  17.0     0     3     2  18.7
##  6 0     6      225    105  2.76  3.46  20.2     1     3     1  18.1
##  7 0     8      360    245  3.21  3.57  15.8     0     3     4  14.3
##  8 0     4      147.    62  3.69  3.19  20       1     4     2  24.4
##  9 0     4      141.    95  3.92  3.15  22.9     1     4     2  22.8
## 10 0     6      168.   123  3.92  3.44  18.3     1     4     4  19.2
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to achieve this using a data frame with the specification of what you need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_spec_long &amp;lt;- mtcars_wide2 %&amp;gt;% 
  pivot_long_spec(matches(&amp;quot;0|1&amp;quot;), values_to = &amp;quot;mpg&amp;quot;) %&amp;gt;% 
  separate(name, c(&amp;quot;am&amp;quot;, &amp;quot;cyl&amp;quot;), sep = &amp;quot;_&amp;quot;)

mtcars_spec_long&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   .name .value am    cyl  
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1_6   mpg    1     6    
## 2 1_4   mpg    1     4    
## 3 0_6   mpg    0     6    
## 4 0_8   mpg    0     8    
## 5 0_4   mpg    0     4    
## 6 1_8   mpg    1     8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Providing this spec to &lt;code&gt;pivot_long()&lt;/code&gt; solves the issue:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars_wide2 %&amp;gt;% 
  pivot_long(spec = mtcars_spec_long, na.rm = TRUE) %&amp;gt;% 
  select(am, cyl, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 32 x 11
##    am    cyl    disp    hp  drat    wt  qsec    vs  gear  carb   mpg
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 1     6      160    110  3.9   2.62  16.5     0     4     4  21  
##  2 1     6      160    110  3.9   2.88  17.0     0     4     4  21  
##  3 1     4      108     93  3.85  2.32  18.6     1     4     1  22.8
##  4 0     6      258    110  3.08  3.22  19.4     1     3     1  21.4
##  5 0     8      360    175  3.15  3.44  17.0     0     3     2  18.7
##  6 0     6      225    105  2.76  3.46  20.2     1     3     1  18.1
##  7 0     8      360    245  3.21  3.57  15.8     0     3     4  14.3
##  8 0     4      147.    62  3.69  3.19  20       1     4     2  24.4
##  9 0     4      141.    95  3.92  3.15  22.9     1     4     2  22.8
## 10 0     6      168.   123  3.92  3.44  18.3     1     4     4  19.2
## # … with 22 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Stay tuned to Hadley Wickham’s &lt;a href=&#34;https://twitter.com/hadleywickham&#34;&gt;twitter&lt;/a&gt; as there will definitely
be announcements soon!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;[:alpha:]&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Classification of historical newspapers content: a tutorial combining R, bash and Vowpal Wabbit, part 2</title>
      <link>https://www.brodrigues.co/blog/2019-03-05-historical_vowpal_part2/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-03-05-historical_vowpal_part2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/BilPXIt0R2w?t=41&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wabbit_reading.jpg&#34; title = &#34;Vowpal Wabbit is fast as heck&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.brodrigues.co/blog/2019-03-03-historical_vowpal/&#34;&gt;part 1&lt;/a&gt; of this series I set
up Vowpal Wabbit to classify newspapers content. Now, let’s use the model to make predictions and
see how and if we can improve the model. Then, let’s train the model on the whole data.&lt;/p&gt;
&lt;div id=&#34;step-1-prepare-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: prepare the data&lt;/h2&gt;
&lt;p&gt;The first step consists in importing the test data and preparing it. The test data need not be large
and thus can be imported and worked on in R.&lt;/p&gt;
&lt;p&gt;I need to remove the target column from the test set, or else it will be used to make predictions.
If you do not remove this column the accuracy of the model will be very high, but it will be wrong
since, of course, you do not have the target column at running time… because it is the column
that you want to predict!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;yardstick&amp;quot;)

small_test &amp;lt;- read_delim(&amp;quot;data_split/small_test.txt&amp;quot;, &amp;quot;|&amp;quot;,
                      escape_double = FALSE, col_names = FALSE,
                      trim_ws = TRUE)

small_test %&amp;gt;%
    mutate(X1= &amp;quot; &amp;quot;) %&amp;gt;%
    write_delim(&amp;quot;data_split/small_test2.txt&amp;quot;, col_names = FALSE, delim = &amp;quot;|&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wrote the data in a file called &lt;code&gt;small_test2.txt&lt;/code&gt; and can now use my model to make predictions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;-t -i vw_models/small_oaa.model data_split/small_test2.txt -p data_split/small_oaa.predict&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The predictions get saved in the file &lt;code&gt;small_oaa.predict&lt;/code&gt;, which is a plain text file. Let’s add these
predictions to the original test set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_predictions &amp;lt;- read_delim(&amp;quot;data_split/small_oaa.predict&amp;quot;, &amp;quot;|&amp;quot;,
                          escape_double = FALSE, col_names = FALSE,
                          trim_ws = TRUE)

small_test &amp;lt;- small_test %&amp;gt;%
    rename(truth = X1) %&amp;gt;%
    mutate(truth = factor(truth, levels = c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;5&amp;quot;)))

small_predictions &amp;lt;- small_predictions %&amp;gt;%
    rename(predictions = X1) %&amp;gt;%
    mutate(predictions = factor(predictions, levels = c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;5&amp;quot;)))

small_test &amp;lt;- small_test %&amp;gt;%
    bind_cols(small_predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-use-the-model-and-test-data-to-evaluate-performance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: use the model and test data to evaluate performance&lt;/h2&gt;
&lt;p&gt;We can use the several metrics included in &lt;code&gt;{yardstick}&lt;/code&gt; to evaluate the model’s performance:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(small_test, truth = truth, estimate = predictions)

accuracy(small_test, truth = truth, estimate = predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          Truth
Prediction  1  2  3  4  5
         1 51 15  2 10  1
         2 11  6  3  1  0
         3  0  0  0  0  0
         4  0  0  0  0  0
         5  0  0  0  0  0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A tibble: 1 x 3
  .metric  .estimator .estimate
  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
1 accuracy multiclass     0.570&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the model never predicted class &lt;code&gt;3&lt;/code&gt;, &lt;code&gt;4&lt;/code&gt; or &lt;code&gt;5&lt;/code&gt;. Can we improve by adding some
regularization? Let’s find out!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-adding-regularization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: adding regularization&lt;/h2&gt;
&lt;p&gt;Before trying regularization, let’s try changing the cost function from the logistic function to the
hinge function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Train the model
hinge_oaa_fit &amp;lt;- system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;--oaa 5 -d data_split/small_train.txt --loss_function hinge -f vw_models/hinge_oaa.model&amp;quot;, stderr = TRUE)

system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;-i vw_models/hinge_oaa.model -t -d data_split/small_test2.txt -p data_split/hinge_oaa.predict&amp;quot;)


predictions &amp;lt;- read_delim(&amp;quot;data_split/hinge_oaa.predict&amp;quot;, &amp;quot;|&amp;quot;,
                          escape_double = FALSE, col_names = FALSE,
                          trim_ws = TRUE)

test &amp;lt;- test %&amp;gt;%
    select(-predictions)

predictions &amp;lt;- predictions %&amp;gt;%
    rename(predictions = X1) %&amp;gt;%
    mutate(predictions = factor(predictions, levels = c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;5&amp;quot;)))

test &amp;lt;- test %&amp;gt;%
    bind_cols(predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(test, truth = truth, estimate = predictions)

accuracy(test, truth = truth, estimate = predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          Truth
Prediction   1   2   3   4   5
         1 411 120  45  92   1
         2 355 189  12  17   0
         3  11   2   0   0   0
         4  36   4   0   1   0
         5   3   0   3   0   0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A tibble: 1 x 3
  .metric  .estimator .estimate
  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
1 accuracy multiclass     0.462&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, didn’t work out so well, but at least we now know how to change the loss function. Let’s go
back to the logistic loss and add some regularization. First, let’s train the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regul_oaa_fit &amp;lt;- system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;--oaa 5 --l1 0.005 --l2 0.005 -d data_split/small_train.txt -f vw_models/small_regul_oaa.model&amp;quot;, stderr = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can use it for prediction:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;-i vw_models/small_regul_oaa.model -t -d data_split/test2.txt -p data_split/small_regul_oaa.predict&amp;quot;)


predictions &amp;lt;- read_delim(&amp;quot;data_split/small_regul_oaa.predict&amp;quot;, &amp;quot;|&amp;quot;,
                          escape_double = FALSE, col_names = FALSE,
                          trim_ws = TRUE)

test &amp;lt;- test %&amp;gt;%
    select(-predictions)

predictions &amp;lt;- predictions %&amp;gt;%
    rename(predictions = X1) %&amp;gt;%
    mutate(predictions = factor(predictions, levels = c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;4&amp;quot;, &amp;quot;5&amp;quot;)))

test &amp;lt;- test %&amp;gt;%
    bind_cols(predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now use it for predictions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(test, truth = truth, estimate = predictions)

accuracy(test, truth = truth, estimate = predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          Truth
Prediction   1   2   3   4   5
         1 816 315  60 110   1
         2   0   0   0   0   0
         3   0   0   0   0   0
         4   0   0   0   0   0
         5   0   0   0   0   0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A tibble: 1 x 3
  .metric  .estimator .estimate
  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
1 accuracy multiclass     0.627&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So accuracy improved, but the model only predicts class 1 now… let’s try with other hyper-parameters values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;regul_oaa_fit &amp;lt;- system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;--oaa 5 --l1 0.00015 --l2 0.00015 -d data_split/small_train.txt -f vw_models/small_regul_oaa.model&amp;quot;, stderr = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(test, truth = truth, estimate = predictions)

accuracy(test, truth = truth, estimate = predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          Truth
Prediction   1   2   3   4   5
         1 784 300  57 108   1
         2  32  14   3   2   0
         3   0   1   0   0   0
         4   0   0   0   0   0
         5   0   0   0   0   0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A tibble: 1 x 3
  .metric  .estimator .estimate
  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
1 accuracy multiclass     0.613&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So accuracy is lower than previously, but at least more categories get correctly predicted. Depending
on your needs, you should consider different metrics. Especially for classification problems, you might
not be interested in accuracy, in particular if the data is severely unbalanced.&lt;/p&gt;
&lt;p&gt;Anyhow, to finish this blog post, let’s train the model on the whole data and measure the time it
takes to run the full model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-training-on-the-whole-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 4: Training on the whole data&lt;/h2&gt;
&lt;p&gt;Let’s first split the whole data into a training and a testing set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nb_lines &amp;lt;- system2(&amp;quot;cat&amp;quot;, args = &amp;quot;text_fr.txt | wc -l&amp;quot;, stdout = TRUE)

system2(&amp;quot;split&amp;quot;, args = paste0(&amp;quot;-l&amp;quot;, floor(as.numeric(nb_lines)*0.995), &amp;quot; text_fr.txt data_split/&amp;quot;))

system2(&amp;quot;mv&amp;quot;, args = &amp;quot;data_split/aa data_split/train.txt&amp;quot;)
system2(&amp;quot;mv&amp;quot;, args = &amp;quot;data_split/ab data_split/test.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The whole data contains 260247 lines, and the training set weighs 667MB, which is quite large. Let’s train
the simple multiple classifier on the data and see how long it takes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic &amp;lt;- Sys.time()
oaa_fit &amp;lt;- system2(&amp;quot;/home/cbrunos/miniconda3/bin/vw&amp;quot;, args = &amp;quot;--oaa 5 -d data_split/train.txt -f vw_models/oaa.model&amp;quot;, stderr = TRUE)
Sys.time() - tic&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Time difference of 4.73266 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, you read that right. Training the classifier on 667MB of data took less than 5 seconds!&lt;/p&gt;
&lt;p&gt;Let’s take a look at the final object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;oaa_fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; [1] &amp;quot;final_regressor = vw_models/oaa.model&amp;quot;                                   
 [2] &amp;quot;Num weight bits = 18&amp;quot;                                                    
 [3] &amp;quot;learning rate = 0.5&amp;quot;                                                     
 [4] &amp;quot;initial_t = 0&amp;quot;                                                           
 [5] &amp;quot;power_t = 0.5&amp;quot;                                                           
 [6] &amp;quot;using no cache&amp;quot;                                                          
 [7] &amp;quot;Reading datafile = data_split/train.txt&amp;quot;                                 
 [8] &amp;quot;num sources = 1&amp;quot;                                                         
 [9] &amp;quot;average  since         example        example  current  current  current&amp;quot;
[10] &amp;quot;loss     last          counter         weight    label  predict features&amp;quot;
[11] &amp;quot;1.000000 1.000000            1            1.0        2        1      253&amp;quot;
[12] &amp;quot;0.500000 0.000000            2            2.0        2        2      499&amp;quot;
[13] &amp;quot;0.250000 0.000000            4            4.0        2        2        6&amp;quot;
[14] &amp;quot;0.250000 0.250000            8            8.0        1        1     2268&amp;quot;
[15] &amp;quot;0.312500 0.375000           16           16.0        1        1      237&amp;quot;
[16] &amp;quot;0.250000 0.187500           32           32.0        1        1      557&amp;quot;
[17] &amp;quot;0.171875 0.093750           64           64.0        1        1      689&amp;quot;
[18] &amp;quot;0.179688 0.187500          128          128.0        2        2      208&amp;quot;
[19] &amp;quot;0.144531 0.109375          256          256.0        1        1      856&amp;quot;
[20] &amp;quot;0.136719 0.128906          512          512.0        4        4        4&amp;quot;
[21] &amp;quot;0.122070 0.107422         1024         1024.0        1        1     1353&amp;quot;
[22] &amp;quot;0.106934 0.091797         2048         2048.0        1        1      571&amp;quot;
[23] &amp;quot;0.098633 0.090332         4096         4096.0        1        1       43&amp;quot;
[24] &amp;quot;0.080566 0.062500         8192         8192.0        1        1      885&amp;quot;
[25] &amp;quot;0.069336 0.058105        16384        16384.0        1        1      810&amp;quot;
[26] &amp;quot;0.062683 0.056030        32768        32768.0        2        2      467&amp;quot;
[27] &amp;quot;0.058167 0.053650        65536        65536.0        1        1       47&amp;quot;
[28] &amp;quot;0.056061 0.053955       131072       131072.0        1        1      495&amp;quot;
[29] &amp;quot;&amp;quot;                                                                        
[30] &amp;quot;finished run&amp;quot;                                                            
[31] &amp;quot;number of examples = 258945&amp;quot;                                             
[32] &amp;quot;weighted example sum = 258945.000000&amp;quot;                                    
[33] &amp;quot;weighted label sum = 0.000000&amp;quot;                                           
[34] &amp;quot;average loss = 0.054467&amp;quot;                                                 
[35] &amp;quot;total feature number = 116335486&amp;quot;  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s use the test set and see how the model fares:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(test, truth = truth, estimate = predictions)

accuracy(test, truth = truth, estimate = predictions)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          Truth
Prediction   1   2   3   4   5
         1 537 175  52 100   1
         2 271 140   8   9   0
         3   1   0   0   0   0
         4   7   0   0   1   0
         5   0   0   0   0   0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# A tibble: 1 x 3
  .metric  .estimator .estimate
  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
1 accuracy multiclass     0.521&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Better accuracy can certainly be achieved with hyper-parameter tuning… maybe the subject for a
future blog post? In any case I am very impressed with Vowpal Wabbit and am certainly looking forward
to future developments of &lt;code&gt;{RVowpalWabbit}&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Classification of historical newspapers content: a tutorial combining R, bash and Vowpal Wabbit, part 1</title>
      <link>https://www.brodrigues.co/blog/2019-03-03-historical_vowpal/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-03-03-historical_vowpal/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/BilPXIt0R2w?t=41&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wabbit_reading.jpg&#34; title = &#34;Vowpal Wabbit is fast as heck&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Can I get enough of historical newspapers data? Seems like I don’t. I already wrote four
(&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers/&#34;&gt;1&lt;/a&gt;,
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/&#34;&gt;2&lt;/a&gt;,
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-31-newspapers_shiny_app/&#34;&gt;3&lt;/a&gt; and
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-02-04-newspapers_shiny_app_tutorial/&#34;&gt;4&lt;/a&gt;) blog posts, but
there’s still a lot to explore. This blog post uses a new batch of data announced on twitter:&lt;/p&gt;
&lt;div style=&#34;text-align:center&#34;;&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/ralph_marschall_tweet.png&#34; style=&#34;width:80%;&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and this data could not have arrived at a better moment, since something else got announced via Twitter
recently:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;RVowpalWabbit 0.0.13: Keeping CRAN happy&lt;br&gt;R Interface to the &amp;#39;Vowpal Wabbit&amp;#39; fast out-of-core learner&lt;a href=&#34;https://t.co/XXXbfMqrgT&#34;&gt;https://t.co/XXXbfMqrgT&lt;/a&gt;&lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/rcpp?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rcpp&lt;/a&gt; &lt;a href=&#34;https://t.co/XQwNdpK2dc&#34;&gt;pic.twitter.com/XQwNdpK2dc&lt;/a&gt;&lt;/p&gt;&amp;mdash; Dirk Eddelbuettel (@eddelbuettel) &lt;a href=&#34;https://twitter.com/eddelbuettel/status/1098941963527700480?ref_src=twsrc%5Etfw&#34;&gt;February 22, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;I wanted to try using &lt;a href=&#34;https://github.com/VowpalWabbit/vowpal_wabbit&#34;&gt;Vowpal Wabbit&lt;/a&gt;
for a couple of weeks now because it seems to be the perfect
tool for when you’re dealing with what I call &lt;em&gt;big-ish&lt;/em&gt; data: data that is not big data, and might
fit in your RAM, but is still a PITA to deal with. It can be data that is large enough to take 30
seconds to be imported into R, and then every operation on it lasts for minutes, and estimating/training
a model on it might eat up all your RAM. Vowpal Wabbit avoids all this because it’s an online-learning
system. Vowpal Wabbit is capable of training a model with data that it sees on the fly, which means
VW can be used for real-time machine learning, but also for when the training data is very large.
Each row of the data gets streamed into VW which updates the estimated parameters of the model
(or weights) in real time. So no need to first import all the data into R!&lt;/p&gt;
&lt;p&gt;The goal of this blog post is to get started with VW, and build a very simple logistic model
to classify documents using the historical newspapers data from the National Library of Luxembourg,
which you can download &lt;a href=&#34;https://data.bnl.lu/data/historical-newspapers/&#34;&gt;here&lt;/a&gt; (scroll down and
download the &lt;em&gt;Text Analysis Pack&lt;/em&gt;). The goal is not to build the best model, but &lt;em&gt;a&lt;/em&gt; model. Several
steps are needed for this: prepare the data, install VW and train a model using &lt;code&gt;{RVowpalWabbit}&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;step-1-preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: Preparing the data&lt;/h2&gt;
&lt;p&gt;The data is in a neat &lt;code&gt;.xml&lt;/code&gt; format, and extracting what I need will be easy. However, the input
format for VW is a bit unusual; it resembles &lt;em&gt;.psv&lt;/em&gt; files (&lt;strong&gt;P&lt;/strong&gt;ipe &lt;strong&gt;S&lt;/strong&gt;eparated &lt;strong&gt;V&lt;/strong&gt;alues) but
allows for more flexibility. I will not dwell much into it, but for our purposes, the file must
look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1 | this is the first observation, which in our case will be free text
2 | this is another observation, its label, or class, equals 2
4 | this is another observation, of class 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first column, before the “|” is the target class we want to predict, and the second column
contains free text.&lt;/p&gt;
&lt;p&gt;The raw data looks like this:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the raw data&lt;/summary&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;OAI-PMH xmlns=&amp;quot;http://www.openarchives.org/OAI/2.0/&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xsi:schemaLocation=&amp;quot;http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd&amp;quot;&amp;gt;
&amp;lt;responseDate&amp;gt;2019-02-28T11:13:01&amp;lt;/responseDate&amp;gt;
&amp;lt;request&amp;gt;http://www.eluxemburgensia.lu/OAI&amp;lt;/request&amp;gt;
&amp;lt;ListRecords&amp;gt;
&amp;lt;record&amp;gt;
&amp;lt;header&amp;gt;
&amp;lt;identifier&amp;gt;digitool-publish:3026998-DTL45&amp;lt;/identifier&amp;gt;
&amp;lt;datestamp&amp;gt;2019-02-28T11:13:01Z&amp;lt;/datestamp&amp;gt;
&amp;lt;/header&amp;gt;
&amp;lt;metadata&amp;gt;
&amp;lt;oai_dc:dc xmlns:oai_dc=&amp;quot;http://www.openarchives.org/OAI/2.0/oai_dc/&amp;quot; xmlns:dc=&amp;quot;http://purl.org/dc/elements/1.1/&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xmlns:dcterms=&amp;quot;http://purl.org/dc/terms/&amp;quot; xsi:schemaLocation=&amp;quot;http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd&amp;quot;&amp;gt;
&amp;lt;dc:identifier&amp;gt;
https://persist.lu/ark:/70795/6gq1q1/articles/DTL45
&amp;lt;/dc:identifier&amp;gt;
&amp;lt;dc:source&amp;gt;newspaper/indeplux/1871-12-29_01&amp;lt;/dc:source&amp;gt;
&amp;lt;dcterms:isPartOf&amp;gt;L&amp;#39;indépendance luxembourgeoise&amp;lt;/dcterms:isPartOf&amp;gt;
&amp;lt;dcterms:isReferencedBy&amp;gt;
issue:newspaper/indeplux/1871-12-29_01/article:DTL45
&amp;lt;/dcterms:isReferencedBy&amp;gt;
&amp;lt;dc:date&amp;gt;1871-12-29&amp;lt;/dc:date&amp;gt;
&amp;lt;dc:publisher&amp;gt;Jean Joris&amp;lt;/dc:publisher&amp;gt;
&amp;lt;dc:relation&amp;gt;3026998&amp;lt;/dc:relation&amp;gt;
&amp;lt;dcterms:hasVersion&amp;gt;
http://www.eluxemburgensia.lu/webclient/DeliveryManager?pid=3026998#panel:pp|issue:3026998|article:DTL45
&amp;lt;/dcterms:hasVersion&amp;gt;
&amp;lt;dc:description&amp;gt;
CONSEIL COMMUNAL de la ville de Luxembourg. Séance du 23 décembre 1871. (Suite.) Art. 6. Glacière communale. M. le Bourgmcstr ¦ . Le collège échevinal propose un autro mode de se procurer de la glace. Nous avons dépensé 250 fr. cha- que année pour distribuer 30 kilos do glace; c’est une trop forte somme pour un résultat si minime. Nous aurions voulu nous aboucher avec des fabricants de bière ou autres industriels qui nous auraient fourni de la glace en cas de besoin. L’architecte qui été chargé de passer un contrat, a été trouver des négociants, mais ses démarches n’ont pas abouti. 
&amp;lt;/dc:description&amp;gt;
&amp;lt;dc:title&amp;gt;
CONSEIL COMMUNAL de la ville de Luxembourg. Séance du 23 décembre 1871. (Suite.)
&amp;lt;/dc:title&amp;gt;
&amp;lt;dc:type&amp;gt;ARTICLE&amp;lt;/dc:type&amp;gt;
&amp;lt;dc:language&amp;gt;fr&amp;lt;/dc:language&amp;gt;
&amp;lt;dcterms:extent&amp;gt;863&amp;lt;/dcterms:extent&amp;gt;
&amp;lt;/oai_dc:dc&amp;gt;
&amp;lt;/metadata&amp;gt;
&amp;lt;/record&amp;gt;
&amp;lt;/ListRecords&amp;gt;
&amp;lt;/OAI-PMH&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;I need several things from this file:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The title of the newspaper: &lt;code&gt;&amp;lt;dcterms:isPartOf&amp;gt;L&#39;indépendance luxembourgeoise&amp;lt;/dcterms:isPartOf&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The type of the article: &lt;code&gt;&amp;lt;dc:type&amp;gt;ARTICLE&amp;lt;/dc:type&amp;gt;&lt;/code&gt;. Can be Article, Advertisement, Issue, Section or Other.&lt;/li&gt;
&lt;li&gt;The contents: &lt;code&gt;&amp;lt;dc:description&amp;gt;CONSEIL COMMUNAL de la ville de Luxembourg. Séance du ....&amp;lt;/dc:description&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will only focus on newspapers in French, even though newspapers in German also had articles in French.
This is because the tag &lt;code&gt;&amp;lt;dc:language&amp;gt;fr&amp;lt;/dc:language&amp;gt;&lt;/code&gt; is not always available. If it were, I could
simply look for it and extract all the content in French easily, but unfortunately this is not the case.&lt;/p&gt;
&lt;p&gt;First of all, let’s get the data into R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;xml2&amp;quot;)
library(&amp;quot;furrr&amp;quot;)

files &amp;lt;- list.files(path = &amp;quot;export01-newspapers1841-1878/&amp;quot;, all.files = TRUE, recursive = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This results in a character vector with the path to all the files:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(files)
[1] &amp;quot;000/1400000/1400000-ADVERTISEMENT-DTL78.xml&amp;quot;   &amp;quot;000/1400000/1400000-ADVERTISEMENT-DTL79.xml&amp;quot;  
[3] &amp;quot;000/1400000/1400000-ADVERTISEMENT-DTL80.xml&amp;quot;   &amp;quot;000/1400000/1400000-ADVERTISEMENT-DTL81.xml&amp;quot;  
[5] &amp;quot;000/1400000/1400000-MODSMD_ARTICLE1-DTL34.xml&amp;quot; &amp;quot;000/1400000/1400000-MODSMD_ARTICLE2-DTL35.xml&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I write a function that does the needed data preparation steps. I describe what the function
does in the comments inside:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_vw &amp;lt;- function(xml_file){

    # read in the xml file
    file &amp;lt;- read_xml(paste0(&amp;quot;export01-newspapers1841-1878/&amp;quot;, xml_file))

    # Get the newspaper
    newspaper &amp;lt;- xml_find_all(file, &amp;quot;.//dcterms:isPartOf&amp;quot;) %&amp;gt;% xml_text()

    # Only keep the newspapers written in French
    if(!(newspaper %in% c(&amp;quot;L&amp;#39;UNION.&amp;quot;,
                          &amp;quot;L&amp;#39;indépendance luxembourgeoise&amp;quot;,
                          &amp;quot;COURRIER DU GRAND-DUCHÉ DE LUXEMBOURG.&amp;quot;,
                          &amp;quot;JOURNAL DE LUXEMBOURG.&amp;quot;,
                          &amp;quot;L&amp;#39;AVENIR&amp;quot;,
                          &amp;quot;L’Arlequin&amp;quot;,
                          &amp;quot;La Gazette du Grand-Duché de Luxembourg&amp;quot;,
                          &amp;quot;L&amp;#39;AVENIR DE LUXEMBOURG&amp;quot;,
                          &amp;quot;L&amp;#39;AVENIR DU GRAND-DUCHE DE LUXEMBOURG.&amp;quot;,
                          &amp;quot;L&amp;#39;AVENIR DU GRAND-DUCHÉ DE LUXEMBOURG.&amp;quot;,
                          &amp;quot;Le gratis luxembourgeois&amp;quot;,
                          &amp;quot;Luxemburger Zeitung – Journal de Luxembourg&amp;quot;,
                          &amp;quot;Recueil des mémoires et des travaux publiés par la Société de Botanique du Grand-Duché de Luxembourg&amp;quot;))){
        return(NULL)
    } else {
        # Get the type of the content. Can be article, advert, issue, section or other
        type &amp;lt;- xml_find_all(file, &amp;quot;.//dc:type&amp;quot;) %&amp;gt;% xml_text()

        type &amp;lt;- case_when(type == &amp;quot;ARTICLE&amp;quot; ~ &amp;quot;1&amp;quot;,
                          type == &amp;quot;ADVERTISEMENT&amp;quot; ~ &amp;quot;2&amp;quot;,
                          type == &amp;quot;ISSUE&amp;quot; ~ &amp;quot;3&amp;quot;,
                          type == &amp;quot;SECTION&amp;quot; ~ &amp;quot;4&amp;quot;,
                          TRUE ~ &amp;quot;5&amp;quot;
        )

        # Get the content itself. Only keep alphanumeric characters, and remove any line returns or 
        # carriage returns
        description &amp;lt;- xml_find_all(file, &amp;quot;.//dc:description&amp;quot;) %&amp;gt;%
            xml_text() %&amp;gt;%
            str_replace_all(pattern = &amp;quot;[^[:alnum:][:space:]]&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
            str_to_lower() %&amp;gt;%
            str_replace_all(&amp;quot;\r?\n|\r|\n&amp;quot;, &amp;quot; &amp;quot;)

        # Return the final object: one line that looks like this
        # 1 | bla bla
        paste(type, &amp;quot;|&amp;quot;, description)
    }

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now run this code to parse all the files, and I do so in parallel, thanks to the &lt;code&gt;{furrr}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plan(multiprocess, workers = 12)

text_fr &amp;lt;- files %&amp;gt;%
    future_map(to_vw)

text_fr &amp;lt;- text_fr %&amp;gt;%
    discard(is.null)

write_lines(text_fr, &amp;quot;text_fr.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-install-vowpal-wabbit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: Install Vowpal Wabbit&lt;/h2&gt;
&lt;p&gt;To easiest way to install VW must be using Anaconda, and more specifically the conda package manager.
Anaconda is a Python (and R) distribution for scientific computing and it comes with a package manager
called conda which makes installing Python (or R) packages very easy. While VW is a standalone
piece of software, it can also be installed by conda or pip. Instead of installing the full Anaconda distribution,
you can install Miniconda, which only comes with the bare minimum: a Python executable and the
conda package manager. You can find Miniconda &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;here&lt;/a&gt;
and once it’s installed, you can install VW with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c gwerbin vowpal-wabbit &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to install VW with pip, as detailed &lt;a href=&#34;https://pypi.org/project/vowpalwabbit/&#34;&gt;here&lt;/a&gt;,
but in my experience, managing Python packages with pip is not super. It is better to manage your
Python distribution through conda, because it creates environments in your home folder which are
independent of the system’s Python installation, which is often out-of-date.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-building-a-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: Building &lt;em&gt;a&lt;/em&gt; model&lt;/h2&gt;
&lt;p&gt;Vowpal Wabbit can be used from the command line, but there are interfaces for Python and since a
few weeks, for R. The R interface is quite crude for now, as it’s still in very early stages. I’m
sure it will evolve, and perhaps a Vowpal Wabbit engine will be added to &lt;code&gt;{parsnip}&lt;/code&gt;, which would
make modeling with VW really easy.&lt;/p&gt;
&lt;p&gt;For now, let’s only use 10000 lines for prototyping purposes before running the model on the whole file. Because
the data is quite large, I do not want to import it into R. So I use command line tools to manipulate
this data directly from my hard drive:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Prepare data
system2(&amp;quot;shuf&amp;quot;, args = &amp;quot;-n 10000 text_fr.txt &amp;gt; small.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;shuf&lt;/code&gt; is a Unix command, and as such the above code should work on GNU/Linux systems, and most
likely macOS too. &lt;code&gt;shuf&lt;/code&gt; generates random permutations of a given file to standard output. I use &lt;code&gt;&amp;gt;&lt;/code&gt;
to direct this output to another file, which I called &lt;code&gt;small.txt&lt;/code&gt;. The &lt;code&gt;-n 10000&lt;/code&gt; options simply
means that I want 10000 lines.&lt;/p&gt;
&lt;p&gt;I then split this small file into a training and a testing set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Adapted from http://bitsearch.blogspot.com/2009/03/bash-script-to-split-train-and-test.html

# The command below counts the lines in small.txt. This is not really needed, since I know that the 
# file only has 10000 lines, but I kept it here for future reference
# notice the stdout = TRUE option. This is needed because the output simply gets shown in R&amp;#39;s
# command line and does get saved into a variable.
nb_lines &amp;lt;- system2(&amp;quot;cat&amp;quot;, args = &amp;quot;small.txt | wc -l&amp;quot;, stdout = TRUE)

system2(&amp;quot;split&amp;quot;, args = paste0(&amp;quot;-l&amp;quot;, as.numeric(nb_lines)*0.99, &amp;quot; small.txt data_split/&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;split&lt;/code&gt; is the Unix command that does the splitting. I keep 99% of the lines in the training set and
1% in the test set. This creates two files, &lt;code&gt;aa&lt;/code&gt; and &lt;code&gt;ab&lt;/code&gt;. I rename them using the &lt;code&gt;mv&lt;/code&gt; Unix command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;system2(&amp;quot;mv&amp;quot;, args = &amp;quot;data_split/aa data_split/small_train.txt&amp;quot;)
system2(&amp;quot;mv&amp;quot;, args = &amp;quot;data_split/ab data_split/small_test.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, now let’s run a model using the VW command line utility from R, using &lt;code&gt;system2()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;oaa_fit &amp;lt;- system2(&amp;quot;~/miniconda3/bin/vw&amp;quot;, args = &amp;quot;--oaa 5 -d data_split/small_train.txt -f small_oaa.model&amp;quot;, stderr = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I need to point &lt;code&gt;system2()&lt;/code&gt; to the &lt;code&gt;vw&lt;/code&gt; executable, and then add some options. &lt;code&gt;--oaa&lt;/code&gt; stands for
&lt;em&gt;one against all&lt;/em&gt; and is a way of doing multiclass classification; first, one class gets classified
by a logistic classifier against all the others, then the other class against all the others, then
the other…. The &lt;code&gt;5&lt;/code&gt; in the option means that there are 5 classes.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-d data_split/train.txt&lt;/code&gt; specifies the path to the training data. &lt;code&gt;-f&lt;/code&gt; means “final regressor”
and specifies where you want to save the trained model.&lt;/p&gt;
&lt;p&gt;This is the output that get’s captured and saved into &lt;code&gt;oaa_fit&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [1] &amp;quot;final_regressor = oaa.model&amp;quot;                                             
 [2] &amp;quot;Num weight bits = 18&amp;quot;                                                    
 [3] &amp;quot;learning rate = 0.5&amp;quot;                                                     
 [4] &amp;quot;initial_t = 0&amp;quot;                                                           
 [5] &amp;quot;power_t = 0.5&amp;quot;                                                           
 [6] &amp;quot;using no cache&amp;quot;                                                          
 [7] &amp;quot;Reading datafile = data_split/train.txt&amp;quot;                                 
 [8] &amp;quot;num sources = 1&amp;quot;                                                         
 [9] &amp;quot;average  since         example        example  current  current  current&amp;quot;
[10] &amp;quot;loss     last          counter         weight    label  predict features&amp;quot;
[11] &amp;quot;1.000000 1.000000            1            1.0        3        1       87&amp;quot;
[12] &amp;quot;1.000000 1.000000            2            2.0        1        3     2951&amp;quot;
[13] &amp;quot;1.000000 1.000000            4            4.0        1        3      506&amp;quot;
[14] &amp;quot;0.625000 0.250000            8            8.0        1        1      262&amp;quot;
[15] &amp;quot;0.625000 0.625000           16           16.0        1        2      926&amp;quot;
[16] &amp;quot;0.500000 0.375000           32           32.0        4        1        3&amp;quot;
[17] &amp;quot;0.375000 0.250000           64           64.0        1        1      436&amp;quot;
[18] &amp;quot;0.296875 0.218750          128          128.0        2        2      277&amp;quot;
[19] &amp;quot;0.238281 0.179688          256          256.0        2        2      118&amp;quot;
[20] &amp;quot;0.158203 0.078125          512          512.0        2        2       61&amp;quot;
[21] &amp;quot;0.125000 0.091797         1024         1024.0        2        2      258&amp;quot;
[22] &amp;quot;0.096191 0.067383         2048         2048.0        1        1       45&amp;quot;
[23] &amp;quot;0.085205 0.074219         4096         4096.0        1        1      318&amp;quot;
[24] &amp;quot;0.076172 0.067139         8192         8192.0        2        1      523&amp;quot;
[25] &amp;quot;&amp;quot;                                                                        
[26] &amp;quot;finished run&amp;quot;                                                            
[27] &amp;quot;number of examples = 9900&amp;quot;                                               
[28] &amp;quot;weighted example sum = 9900.000000&amp;quot;                                      
[29] &amp;quot;weighted label sum = 0.000000&amp;quot;                                           
[30] &amp;quot;average loss = 0.073434&amp;quot;                                                 
[31] &amp;quot;total feature number = 4456798&amp;quot;  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, when I try to run the same model using &lt;code&gt;RVowpalWabbit::vw()&lt;/code&gt; I get the following error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;oaa_class &amp;lt;- c(&amp;quot;--oaa&amp;quot;, &amp;quot;5&amp;quot;,
               &amp;quot;-d&amp;quot;, &amp;quot;data_split/small_train.txt&amp;quot;,
               &amp;quot;-f&amp;quot;, &amp;quot;vw_models/small_oaa.model&amp;quot;)

result &amp;lt;- vw(oaa_class)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in Rvw(args) : unrecognised option &amp;#39;--oaa&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think the problem might be because I installed Vowpal Wabbit using conda, and the package
cannot find the executable. I’ll open an issue with reproducible code and we’ll see.&lt;/p&gt;
&lt;p&gt;In any case, that’s it for now! In the next blog post, we’ll see how to get the accuracy of this
very simple model, and see how to improve it!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Manipulating strings with the {stringr} package</title>
      <link>https://www.brodrigues.co/blog/2019-02-10-stringr_package/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-02-10-stringr_package/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://b-rodrigues.github.io/modern_R/descriptive-statistics-and-data-manipulation.html#manipulate-strings-with-stringr&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/string.jpg&#34; title = &#34;Click here to go the ebook&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This blog post is an excerpt of my ebook Modern R with the tidyverse that you can read for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;. This is taken from Chapter 4,
in which I introduce the &lt;code&gt;{stringr}&lt;/code&gt; package.&lt;/p&gt;
&lt;div id=&#34;manipulate-strings-with-stringr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Manipulate strings with &lt;code&gt;{stringr}&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;{stringr}&lt;/code&gt; contains functions to manipulate strings. In Chapter 10, I will teach you about regular
expressions, but the functions contained in &lt;code&gt;{stringr}&lt;/code&gt; allow you to already do a lot of work on
strings, without needing to be a regular expression expert.&lt;/p&gt;
&lt;p&gt;I will discuss the most common string operations: detecting, locating, matching, searching and
replacing, and exctracting/removing strings.&lt;/p&gt;
&lt;p&gt;To introduce these operations, let us use an ALTO file of an issue of &lt;em&gt;The Winchester News&lt;/em&gt; from
October 31, 1910, which you can find on this
&lt;a href=&#34;https://gist.githubusercontent.com/b-rodrigues/5139560e7d0f2ecebe5da1df3629e015/raw/e3031d894ffb97217ddbad1ade1b307c9937d2c8/gistfile1.txt&#34;&gt;link&lt;/a&gt; (to see
how the newspaper looked like,
&lt;a href=&#34;https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/&#34;&gt;click here&lt;/a&gt;). I re-hosted
the file on a public gist for archiving purposes. While working on the book, the original site went
down several times…&lt;/p&gt;
&lt;p&gt;ALTO is an XML schema for the description of text OCR and layout information of pages for digitzed
material, such as newspapers (source: &lt;a href=&#34;https://en.wikipedia.org/wiki/ALTO_(XML)&#34;&gt;ALTO Wikipedia page&lt;/a&gt;).
For more details, you can read my
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/&#34;&gt;blogpost&lt;/a&gt;
on the matter, but for our current purposes, it is enough to know that the file contains the text
of newspaper articles. The file looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;TextLine HEIGHT=&amp;quot;138.0&amp;quot; WIDTH=&amp;quot;2434.0&amp;quot; HPOS=&amp;quot;4056.0&amp;quot; VPOS=&amp;quot;5814.0&amp;quot;&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;108.0&amp;quot; WIDTH=&amp;quot;393.0&amp;quot; HPOS=&amp;quot;4056.0&amp;quot; VPOS=&amp;quot;5838.0&amp;quot; CONTENT=&amp;quot;timore&amp;quot; WC=&amp;quot;0.82539684&amp;quot;&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;timole&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;tlnldre&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;timor&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;insole&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;landed&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;/String&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;74.0&amp;quot; HPOS=&amp;quot;4449.0&amp;quot; VPOS=&amp;quot;5838.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;105.0&amp;quot; WIDTH=&amp;quot;432.0&amp;quot; HPOS=&amp;quot;4524.0&amp;quot; VPOS=&amp;quot;5847.0&amp;quot; CONTENT=&amp;quot;market&amp;quot; WC=&amp;quot;0.95238096&amp;quot;/&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;116.0&amp;quot; HPOS=&amp;quot;4956.0&amp;quot; VPOS=&amp;quot;5847.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;69.0&amp;quot; WIDTH=&amp;quot;138.0&amp;quot; HPOS=&amp;quot;5073.0&amp;quot; VPOS=&amp;quot;5883.0&amp;quot; CONTENT=&amp;quot;as&amp;quot; WC=&amp;quot;0.96825397&amp;quot;/&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;74.0&amp;quot; HPOS=&amp;quot;5211.0&amp;quot; VPOS=&amp;quot;5883.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;69.0&amp;quot; WIDTH=&amp;quot;285.0&amp;quot; HPOS=&amp;quot;5286.0&amp;quot; VPOS=&amp;quot;5877.0&amp;quot; CONTENT=&amp;quot;were&amp;quot; WC=&amp;quot;1.0&amp;quot;&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;verc&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;veer&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;/String&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;68.0&amp;quot; HPOS=&amp;quot;5571.0&amp;quot; VPOS=&amp;quot;5877.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;111.0&amp;quot; WIDTH=&amp;quot;147.0&amp;quot; HPOS=&amp;quot;5640.0&amp;quot; VPOS=&amp;quot;5838.0&amp;quot; CONTENT=&amp;quot;all&amp;quot; WC=&amp;quot;1.0&amp;quot;/&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;83.0&amp;quot; HPOS=&amp;quot;5787.0&amp;quot; VPOS=&amp;quot;5838.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID7&amp;quot; HEIGHT=&amp;quot;111.0&amp;quot; WIDTH=&amp;quot;183.0&amp;quot; HPOS=&amp;quot;5871.0&amp;quot; VPOS=&amp;quot;5835.0&amp;quot; CONTENT=&amp;quot;the&amp;quot; WC=&amp;quot;0.95238096&amp;quot;&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;tll&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;Cu&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;ALTERNATIVE&amp;gt;tall&amp;lt;/ALTERNATIVE&amp;gt;
&amp;lt;/String&amp;gt;
&amp;lt;SP WIDTH=&amp;quot;75.0&amp;quot; HPOS=&amp;quot;6054.0&amp;quot; VPOS=&amp;quot;5835.0&amp;quot;/&amp;gt;
&amp;lt;String STYLEREFS=&amp;quot;ID3&amp;quot; HEIGHT=&amp;quot;132.0&amp;quot; WIDTH=&amp;quot;351.0&amp;quot; HPOS=&amp;quot;6129.0&amp;quot; VPOS=&amp;quot;5814.0&amp;quot; CONTENT=&amp;quot;cattle&amp;quot; WC=&amp;quot;0.95238096&amp;quot;/&amp;gt;
&amp;lt;/TextLine&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are interested in the strings after &lt;code&gt;CONTENT=&lt;/code&gt;. We are going to use functions from the &lt;code&gt;{stringr}&lt;/code&gt;
package to get the strings after &lt;code&gt;CONTENT=&lt;/code&gt;. In Chapter 10, we are going to explore this file
again, but using complex regular expressions to get all the content in one go.&lt;/p&gt;
&lt;div id=&#34;getting-text-data-into-rstudio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting text data into Rstudio&lt;/h3&gt;
&lt;p&gt;First of all, let us read in the file:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester &amp;lt;- read_lines(&amp;quot;https://gist.githubusercontent.com/b-rodrigues/5139560e7d0f2ecebe5da1df3629e015/raw/e3031d894ffb97217ddbad1ade1b307c9937d2c8/gistfile1.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though the file is an XML file, I still read it in using &lt;code&gt;read_lines()&lt;/code&gt; and not &lt;code&gt;read_xml()&lt;/code&gt;
from the &lt;code&gt;{xml2}&lt;/code&gt; package. This is for the purposes of the current exercise, and also because I
always have trouble with XML files, and prefer to treat them as simple text files, and use regular
expressions to get what I need.&lt;/p&gt;
&lt;p&gt;Now that the ALTO file is read in and saved in the &lt;code&gt;winchester&lt;/code&gt; variable, you might want to print
the whole thing in the console. Before that, take a look at the structure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(winchester)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  chr [1:43] &amp;quot;&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the &lt;code&gt;winchester&lt;/code&gt; variable is a character atomic vector with 43 elements. So first, we need to
understand what these elements are. Let’s start with the first one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so it seems like the first element is part of the header of the file. What about the second one?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;&amp;lt;meta http-equiv=\&amp;quot;Content-Type\&amp;quot; content=\&amp;quot;text/html; charset=UTF-8\&amp;quot;&amp;gt;&amp;lt;base href=\&amp;quot;https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\&amp;quot;&amp;gt;&amp;lt;style&amp;gt;body{margin-left:0;margin-right:0;margin-top:0}#bN015htcoyT__google-cache-hdr{background:#f5f5f5;font:13px arial,sans-serif;text-align:left;color:#202020;border:0;margin:0;border-bottom:1px solid #cecece;line-height:16px;padding:16px 28px 24px 28px}#bN015htcoyT__google-cache-hdr *{display:inline;font:inherit;text-align:inherit;color:inherit;line-height:inherit;background:none;border:0;margin:0;padding:0;letter-spacing:0}#bN015htcoyT__google-cache-hdr a{text-decoration:none;color:#1a0dab}#bN015htcoyT__google-cache-hdr a:hover{text-decoration:underline}#bN015htcoyT__google-cache-hdr a:visited{color:#609}#bN015htcoyT__google-cache-hdr div{display:block;margin-top:4px}#bN015htcoyT__google-cache-hdr b{font-weight:bold;display:inline-block;direction:ltr}&amp;lt;/style&amp;gt;&amp;lt;div id=\&amp;quot;bN015htcoyT__google-cache-hdr\&amp;quot;&amp;gt;&amp;lt;div&amp;gt;&amp;lt;span&amp;gt;This is Google&amp;#39;s cache of &amp;lt;a href=\&amp;quot;https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\&amp;quot;&amp;gt;https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml&amp;lt;/a&amp;gt;.&amp;lt;/span&amp;gt;&amp;amp;nbsp;&amp;lt;span&amp;gt;It is a snapshot of the page as it appeared on 21 Jan 2019 05:18:18 GMT.&amp;lt;/span&amp;gt;&amp;amp;nbsp;&amp;lt;span&amp;gt;The &amp;lt;a href=\&amp;quot;https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml\&amp;quot;&amp;gt;current page&amp;lt;/a&amp;gt; could have changed in the meantime.&amp;lt;/span&amp;gt;&amp;amp;nbsp;&amp;lt;a href=\&amp;quot;http://support.google.com/websearch/bin/answer.py?hl=en&amp;amp;amp;p=cached&amp;amp;amp;answer=1687222\&amp;quot;&amp;gt;&amp;lt;span&amp;gt;Learn more&amp;lt;/span&amp;gt;.&amp;lt;/a&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;div&amp;gt;&amp;lt;span style=\&amp;quot;display:inline-block;margin-top:8px;margin-right:104px;white-space:nowrap\&amp;quot;&amp;gt;&amp;lt;span style=\&amp;quot;margin-right:28px\&amp;quot;&amp;gt;&amp;lt;span style=\&amp;quot;font-weight:bold\&amp;quot;&amp;gt;Full version&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span style=\&amp;quot;margin-right:28px\&amp;quot;&amp;gt;&amp;lt;a href=\&amp;quot;http://webcache.googleusercontent.com/search?q=cache:2BVPV8QGj3oJ:https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml&amp;amp;amp;hl=en&amp;amp;amp;gl=lu&amp;amp;amp;strip=1&amp;amp;amp;vwsrc=0\&amp;quot;&amp;gt;&amp;lt;span&amp;gt;Text-only version&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;span style=\&amp;quot;margin-right:28px\&amp;quot;&amp;gt;&amp;lt;a href=\&amp;quot;http://webcache.googleusercontent.com/search?q=cache:2BVPV8QGj3oJ:https://chroniclingamerica.loc.gov/lccn/sn86069133/1910-10-31/ed-1/seq-1/ocr.xml&amp;amp;amp;hl=en&amp;amp;amp;gl=lu&amp;amp;amp;strip=0&amp;amp;amp;vwsrc=1\&amp;quot;&amp;gt;&amp;lt;span&amp;gt;View source&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;span style=\&amp;quot;display:inline-block;margin-top:8px;color:#717171\&amp;quot;&amp;gt;&amp;lt;span&amp;gt;Tip: To quickly find your search term on this page, press &amp;lt;b&amp;gt;Ctrl+F&amp;lt;/b&amp;gt; or &amp;lt;b&amp;gt;⌘-F&amp;lt;/b&amp;gt; (Mac) and use the find bar.&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;div style=\&amp;quot;position:relative;\&amp;quot;&amp;gt;&amp;lt;?xml version=\&amp;quot;1.0\&amp;quot; encoding=\&amp;quot;UTF-8\&amp;quot;?&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Same. So where is the content? The file is very large, so if you print it in the console, it will
take quite some time to print, and you will not really be able to make out anything. The best
way would be to try to detect the string &lt;code&gt;CONTENT&lt;/code&gt; and work from there.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;detecting-getting-the-position-and-locating-strings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Detecting, getting the position and locating strings&lt;/h3&gt;
&lt;p&gt;When confronted to an atomic vector of strings, you might want to know inside which elements you
can find certain strings. For example, to know which elements of &lt;code&gt;winchester&lt;/code&gt; contain the string
&lt;code&gt;CONTENT&lt;/code&gt;, use &lt;code&gt;str_detect()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester %&amp;gt;%
  str_detect(&amp;quot;CONTENT&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [23] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
## [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This returns a boolean atomic vector of the same length as &lt;code&gt;winchester&lt;/code&gt;. If the string &lt;code&gt;CONTENT&lt;/code&gt; is
nowhere to be found, the result will equal &lt;code&gt;FALSE&lt;/code&gt;, if not it will equal &lt;code&gt;TRUE&lt;/code&gt;. Here it is easy to
see that the last element contains the string &lt;code&gt;CONTENT&lt;/code&gt;. But what if instead of having 43 elements,
the vector had 24192 elements? And hundreds would contain the string &lt;code&gt;CONTENT&lt;/code&gt;? It would be easier
to instead have the indices of the vector where one can find the word &lt;code&gt;CONTENT&lt;/code&gt;. This is possible
with &lt;code&gt;str_which()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester %&amp;gt;%
  str_which(&amp;quot;CONTENT&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, the result is 43, meaning that the 43rd element of &lt;code&gt;winchester&lt;/code&gt; contains the string &lt;code&gt;CONTENT&lt;/code&gt;
somewhere. If we need more precision, we can use &lt;code&gt;str_locate()&lt;/code&gt; and &lt;code&gt;str_locate_all()&lt;/code&gt;. To explain
how both these functions work, let’s create a very small example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers &amp;lt;- c(&amp;quot;aristotle&amp;quot;, &amp;quot;plato&amp;quot;, &amp;quot;epictetus&amp;quot;, &amp;quot;seneca the younger&amp;quot;, &amp;quot;epicurus&amp;quot;, &amp;quot;marcus aurelius&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now suppose I am interested in philosophers whose name ends in &lt;code&gt;us&lt;/code&gt;. Let us use &lt;code&gt;str_locate()&lt;/code&gt; first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_locate(&amp;quot;us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      start end
## [1,]    NA  NA
## [2,]    NA  NA
## [3,]     8   9
## [4,]    NA  NA
## [5,]     7   8
## [6,]     5   6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can interpret the result as follows: in the rows, the index of the vector where the
string &lt;code&gt;us&lt;/code&gt; is found. So the 3rd, 5th and 6th philosopher have &lt;code&gt;us&lt;/code&gt; somewhere in their name.
The result also has two columns: &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;end&lt;/code&gt;. These give the position of the string. So the
string &lt;code&gt;us&lt;/code&gt; can be found starting at position 8 of the 3rd element of the vector, and ends at position
9. Same goes for the other philisophers. However, consider Marcus Aurelius. He has two names, both
ending with &lt;code&gt;us&lt;/code&gt;. However, &lt;code&gt;str_locate()&lt;/code&gt; only shows the position of the &lt;code&gt;us&lt;/code&gt; in &lt;code&gt;Marcus&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To get both &lt;code&gt;us&lt;/code&gt; strings, you need to use &lt;code&gt;str_locate_all()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_locate_all(&amp;quot;us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##      start end
## 
## [[2]]
##      start end
## 
## [[3]]
##      start end
## [1,]     8   9
## 
## [[4]]
##      start end
## 
## [[5]]
##      start end
## [1,]     7   8
## 
## [[6]]
##      start end
## [1,]     5   6
## [2,]    14  15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we get the position of the two &lt;code&gt;us&lt;/code&gt; in Marcus Aurelius. Doing this on the &lt;code&gt;winchester&lt;/code&gt; vector
will give use the position of the &lt;code&gt;CONTENT&lt;/code&gt; string, but this is not really important right now. What
matters is that you know how &lt;code&gt;str_locate()&lt;/code&gt; and &lt;code&gt;str_locate_all()&lt;/code&gt; work.&lt;/p&gt;
&lt;p&gt;So now that we know what interests us in the 43nd element of &lt;code&gt;winchester&lt;/code&gt;, let’s take a closer
look at it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester[43]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, it’s a mess:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;TextLine HEIGHT=\&amp;quot;126.0\&amp;quot; WIDTH=\&amp;quot;1731.0\&amp;quot; HPOS=\&amp;quot;17160.0\&amp;quot; VPOS=\&amp;quot;21252.0\&amp;quot;&amp;gt;&amp;lt;String HEIGHT=\&amp;quot;114.0\&amp;quot; WIDTH=\&amp;quot;354.0\&amp;quot; HPOS=\&amp;quot;17160.0\&amp;quot; VPOS=\&amp;quot;21264.0\&amp;quot; CONTENT=\&amp;quot;0tV\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;131.0\&amp;quot; HPOS=\&amp;quot;17514.0\&amp;quot; VPOS=\&amp;quot;21264.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;111.0\&amp;quot; WIDTH=\&amp;quot;474.0\&amp;quot; HPOS=\&amp;quot;17646.0\&amp;quot; VPOS=\&amp;quot;21258.0\&amp;quot; CONTENT=\&amp;quot;BATES\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;140.0\&amp;quot; HPOS=\&amp;quot;18120.0\&amp;quot; VPOS=\&amp;quot;21258.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;114.0\&amp;quot; WIDTH=\&amp;quot;630.0\&amp;quot; HPOS=\&amp;quot;18261.0\&amp;quot; VPOS=\&amp;quot;21252.0\&amp;quot; CONTENT=\&amp;quot;President\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;Prcideht&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;Pride&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;/String&amp;gt;&amp;lt;/TextLine&amp;gt;&amp;lt;TextLine HEIGHT=\&amp;quot;153.0\&amp;quot; WIDTH=\&amp;quot;1689.0\&amp;quot; HPOS=\&amp;quot;17145.0\&amp;quot; VPOS=\&amp;quot;21417.0\&amp;quot;&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;105.0\&amp;quot; WIDTH=\&amp;quot;258.0\&amp;quot; HPOS=\&amp;quot;17145.0\&amp;quot; VPOS=\&amp;quot;21439.0\&amp;quot; CONTENT=\&amp;quot;WM\&amp;quot; WC=\&amp;quot;0.82539684\&amp;quot;&amp;gt;&amp;lt;TextLine HEIGHT=\&amp;quot;120.0\&amp;quot; WIDTH=\&amp;quot;2211.0\&amp;quot; HPOS=\&amp;quot;16788.0\&amp;quot; VPOS=\&amp;quot;21870.0\&amp;quot;&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;96.0\&amp;quot; WIDTH=\&amp;quot;102.0\&amp;quot; HPOS=\&amp;quot;16788.0\&amp;quot; VPOS=\&amp;quot;21894.0\&amp;quot; CONTENT=\&amp;quot;It\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;72.0\&amp;quot; HPOS=\&amp;quot;16890.0\&amp;quot; VPOS=\&amp;quot;21894.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;96.0\&amp;quot; WIDTH=\&amp;quot;93.0\&amp;quot; HPOS=\&amp;quot;16962.0\&amp;quot; VPOS=\&amp;quot;21885.0\&amp;quot; CONTENT=\&amp;quot;is\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;80.0\&amp;quot; HPOS=\&amp;quot;17055.0\&amp;quot; VPOS=\&amp;quot;21885.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;102.0\&amp;quot; WIDTH=\&amp;quot;417.0\&amp;quot; HPOS=\&amp;quot;17136.0\&amp;quot; VPOS=\&amp;quot;21879.0\&amp;quot; CONTENT=\&amp;quot;seldom\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;80.0\&amp;quot; HPOS=\&amp;quot;17553.0\&amp;quot; VPOS=\&amp;quot;21879.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;96.0\&amp;quot; WIDTH=\&amp;quot;267.0\&amp;quot; HPOS=\&amp;quot;17634.0\&amp;quot; VPOS=\&amp;quot;21873.0\&amp;quot; CONTENT=\&amp;quot;hard\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;81.0\&amp;quot; HPOS=\&amp;quot;17901.0\&amp;quot; VPOS=\&amp;quot;21873.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;87.0\&amp;quot; WIDTH=\&amp;quot;111.0\&amp;quot; HPOS=\&amp;quot;17982.0\&amp;quot; VPOS=\&amp;quot;21879.0\&amp;quot; CONTENT=\&amp;quot;to\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;81.0\&amp;quot; HPOS=\&amp;quot;18093.0\&amp;quot; VPOS=\&amp;quot;21879.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;96.0\&amp;quot; WIDTH=\&amp;quot;219.0\&amp;quot; HPOS=\&amp;quot;18174.0\&amp;quot; VPOS=\&amp;quot;21870.0\&amp;quot; CONTENT=\&amp;quot;find\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;77.0\&amp;quot; HPOS=\&amp;quot;18393.0\&amp;quot; VPOS=\&amp;quot;21870.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;69.0\&amp;quot; WIDTH=\&amp;quot;66.0\&amp;quot; HPOS=\&amp;quot;18471.0\&amp;quot; VPOS=\&amp;quot;21894.0\&amp;quot; CONTENT=\&amp;quot;a\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;77.0\&amp;quot; HPOS=\&amp;quot;18537.0\&amp;quot; VPOS=\&amp;quot;21894.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;78.0\&amp;quot; WIDTH=\&amp;quot;384.0\&amp;quot; HPOS=\&amp;quot;18615.0\&amp;quot; VPOS=\&amp;quot;21888.0\&amp;quot; CONTENT=\&amp;quot;succes\&amp;quot; WC=\&amp;quot;0.82539684\&amp;quot;&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;success&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;/String&amp;gt;&amp;lt;/TextLine&amp;gt;&amp;lt;TextLine HEIGHT=\&amp;quot;126.0\&amp;quot; WIDTH=\&amp;quot;2316.0\&amp;quot; HPOS=\&amp;quot;16662.0\&amp;quot; VPOS=\&amp;quot;22008.0\&amp;quot;&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;75.0\&amp;quot; WIDTH=\&amp;quot;183.0\&amp;quot; HPOS=\&amp;quot;16662.0\&amp;quot; VPOS=\&amp;quot;22059.0\&amp;quot; CONTENT=\&amp;quot;sor\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;soar&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;/String&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;72.0\&amp;quot; HPOS=\&amp;quot;16845.0\&amp;quot; VPOS=\&amp;quot;22059.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;90.0\&amp;quot; WIDTH=\&amp;quot;168.0\&amp;quot; HPOS=\&amp;quot;16917.0\&amp;quot; VPOS=\&amp;quot;22035.0\&amp;quot; CONTENT=\&amp;quot;for\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;72.0\&amp;quot; HPOS=\&amp;quot;17085.0\&amp;quot; VPOS=\&amp;quot;22035.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;69.0\&amp;quot; WIDTH=\&amp;quot;267.0\&amp;quot; HPOS=\&amp;quot;17157.0\&amp;quot; VPOS=\&amp;quot;22050.0\&amp;quot; CONTENT=\&amp;quot;even\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;cen&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;ALTERNATIVE&amp;gt;cent&amp;lt;/ALTERNATIVE&amp;gt;&amp;lt;/String&amp;gt;&amp;lt;SP WIDTH=\&amp;quot;77.0\&amp;quot; HPOS=\&amp;quot;17434.0\&amp;quot; VPOS=\&amp;quot;22050.0\&amp;quot;/&amp;gt;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;66.0\&amp;quot; WIDTH=\&amp;quot;63.0\&amp;quot; HPOS=\&amp;quot;17502.0\&amp;quot; VPOS=\&amp;quot;22044.0\&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The file was imported without any newlines. So we need to insert them ourselves, by splitting the
string in a clever way.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;splitting-strings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Splitting strings&lt;/h3&gt;
&lt;p&gt;There are two functions included in &lt;code&gt;{stringr}&lt;/code&gt; to split strings, &lt;code&gt;str_split()&lt;/code&gt; and &lt;code&gt;str_split_fixed()&lt;/code&gt;.
Let’s go back to our ancient philosophers. Two of them, Seneca the Younger and Marcus Aurelius have
something else in common than both being Roman Stoic philosophers. Their names are composed of several
words. If we want to split their names at the space character, we can use &lt;code&gt;str_split()&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_split(&amp;quot; &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;aristotle&amp;quot;
## 
## [[2]]
## [1] &amp;quot;plato&amp;quot;
## 
## [[3]]
## [1] &amp;quot;epictetus&amp;quot;
## 
## [[4]]
## [1] &amp;quot;seneca&amp;quot;  &amp;quot;the&amp;quot;     &amp;quot;younger&amp;quot;
## 
## [[5]]
## [1] &amp;quot;epicurus&amp;quot;
## 
## [[6]]
## [1] &amp;quot;marcus&amp;quot;   &amp;quot;aurelius&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;str_split()&lt;/code&gt; also has a &lt;code&gt;simplify = TRUE&lt;/code&gt; option:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_split(&amp;quot; &amp;quot;, simplify = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]        [,2]       [,3]     
## [1,] &amp;quot;aristotle&amp;quot; &amp;quot;&amp;quot;         &amp;quot;&amp;quot;       
## [2,] &amp;quot;plato&amp;quot;     &amp;quot;&amp;quot;         &amp;quot;&amp;quot;       
## [3,] &amp;quot;epictetus&amp;quot; &amp;quot;&amp;quot;         &amp;quot;&amp;quot;       
## [4,] &amp;quot;seneca&amp;quot;    &amp;quot;the&amp;quot;      &amp;quot;younger&amp;quot;
## [5,] &amp;quot;epicurus&amp;quot;  &amp;quot;&amp;quot;         &amp;quot;&amp;quot;       
## [6,] &amp;quot;marcus&amp;quot;    &amp;quot;aurelius&amp;quot; &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time, the returned object is a matrix.&lt;/p&gt;
&lt;p&gt;What about &lt;code&gt;str_split_fixed()&lt;/code&gt;? The difference is that here you can specify the number of pieces
to return. For example, you could consider the name “Aurelius” to be the middle name of Marcus Aurelius,
and the “the younger” to be the middle name of Seneca the younger. This means that you would want
to split the name only at the first space character, and not at all of them. This is easily achieved
with &lt;code&gt;str_split_fixed()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_split_fixed(&amp;quot; &amp;quot;, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]        [,2]         
## [1,] &amp;quot;aristotle&amp;quot; &amp;quot;&amp;quot;           
## [2,] &amp;quot;plato&amp;quot;     &amp;quot;&amp;quot;           
## [3,] &amp;quot;epictetus&amp;quot; &amp;quot;&amp;quot;           
## [4,] &amp;quot;seneca&amp;quot;    &amp;quot;the younger&amp;quot;
## [5,] &amp;quot;epicurus&amp;quot;  &amp;quot;&amp;quot;           
## [6,] &amp;quot;marcus&amp;quot;    &amp;quot;aurelius&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gives the expected result.&lt;/p&gt;
&lt;p&gt;So how does this help in our case? Well, if you look at how the ALTO file looks like, at the beginning
of this section, you will notice that every line ends with the “&amp;gt;” character. So let’s split at
that character!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_text &amp;lt;- winchester[43] %&amp;gt;%
  str_split(&amp;quot;&amp;gt;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a closer look at &lt;code&gt;winchester_text&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(winchester_text)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 1
##  $ : chr [1:19706] &amp;quot;&amp;lt;/processingStepSettings&amp;quot; &amp;quot;&amp;lt;processingSoftware&amp;quot; &amp;quot;&amp;lt;softwareCreator&amp;quot; &amp;quot;iArchives&amp;lt;/softwareCreator&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So this is a list of length one, and the first, and only, element of that list is an atomic vector
with 19706 elements. Since this is a list of only one element, we can simplify it by saving the
atomic vector in a variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_text &amp;lt;- winchester_text[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now look at some lines:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_text[1232:1245]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;&amp;lt;SP WIDTH=\&amp;quot;66.0\&amp;quot; HPOS=\&amp;quot;5763.0\&amp;quot; VPOS=\&amp;quot;9696.0\&amp;quot;/&amp;quot;                                                                         
##  [2] &amp;quot;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;108.0\&amp;quot; WIDTH=\&amp;quot;612.0\&amp;quot; HPOS=\&amp;quot;5829.0\&amp;quot; VPOS=\&amp;quot;9693.0\&amp;quot; CONTENT=\&amp;quot;Louisville\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;&amp;quot;
##  [3] &amp;quot;&amp;lt;ALTERNATIVE&amp;quot;                                                                                                                
##  [4] &amp;quot;Loniile&amp;lt;/ALTERNATIVE&amp;quot;                                                                                                        
##  [5] &amp;quot;&amp;lt;ALTERNATIVE&amp;quot;                                                                                                                
##  [6] &amp;quot;Lenities&amp;lt;/ALTERNATIVE&amp;quot;                                                                                                       
##  [7] &amp;quot;&amp;lt;/String&amp;quot;                                                                                                                    
##  [8] &amp;quot;&amp;lt;/TextLine&amp;quot;                                                                                                                  
##  [9] &amp;quot;&amp;lt;TextLine HEIGHT=\&amp;quot;150.0\&amp;quot; WIDTH=\&amp;quot;2520.0\&amp;quot; HPOS=\&amp;quot;4032.0\&amp;quot; VPOS=\&amp;quot;9849.0\&amp;quot;&amp;quot;                                                 
## [10] &amp;quot;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;108.0\&amp;quot; WIDTH=\&amp;quot;510.0\&amp;quot; HPOS=\&amp;quot;4032.0\&amp;quot; VPOS=\&amp;quot;9861.0\&amp;quot; CONTENT=\&amp;quot;Tobacco\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;/&amp;quot;  
## [11] &amp;quot;&amp;lt;SP WIDTH=\&amp;quot;113.0\&amp;quot; HPOS=\&amp;quot;4542.0\&amp;quot; VPOS=\&amp;quot;9861.0\&amp;quot;/&amp;quot;                                                                        
## [12] &amp;quot;&amp;lt;String STYLEREFS=\&amp;quot;ID7\&amp;quot; HEIGHT=\&amp;quot;105.0\&amp;quot; WIDTH=\&amp;quot;696.0\&amp;quot; HPOS=\&amp;quot;4656.0\&amp;quot; VPOS=\&amp;quot;9861.0\&amp;quot; CONTENT=\&amp;quot;Warehouse\&amp;quot; WC=\&amp;quot;1.0\&amp;quot;&amp;quot; 
## [13] &amp;quot;&amp;lt;ALTERNATIVE&amp;quot;                                                                                                                
## [14] &amp;quot;WHrchons&amp;lt;/ALTERNATIVE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This now looks easier to handle. We can narrow it down to the lines that only contain the string
we are interested in, “CONTENT”. First, let’s get the indices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;content_winchester_index &amp;lt;- winchester_text %&amp;gt;%
  str_which(&amp;quot;CONTENT&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How many lines contain the string “CONTENT”?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(content_winchester_index)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4462&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this reduces the amount of data we have to work with. Let us save this is a new
variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;content_winchester &amp;lt;- winchester_text[content_winchester_index]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matching-strings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Matching strings&lt;/h3&gt;
&lt;p&gt;Matching strings is useful, but only in combination with regular expressions. As stated at the
beginning of this section, we are going to learn about regular expressions in Chapter 10, but in
order to make this section useful, we are going to learn the easiest, but perhaps the most useful
regular expression: &lt;code&gt;.*&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s go back to our ancient philosophers, and use &lt;code&gt;str_match()&lt;/code&gt; and see what happens. Let’s match
the “us” string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match(&amp;quot;us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,] NA  
## [2,] NA  
## [3,] &amp;quot;us&amp;quot;
## [4,] NA  
## [5,] &amp;quot;us&amp;quot;
## [6,] &amp;quot;us&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not very useful, but what about the regular expression &lt;code&gt;.*&lt;/code&gt;? How could it help?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match(&amp;quot;.*us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]             
## [1,] NA               
## [2,] NA               
## [3,] &amp;quot;epictetus&amp;quot;      
## [4,] NA               
## [5,] &amp;quot;epicurus&amp;quot;       
## [6,] &amp;quot;marcus aurelius&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s already very interesting! So how does &lt;code&gt;.*&lt;/code&gt; work? To understand, let’s first start by using
&lt;code&gt;.&lt;/code&gt; alone:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match(&amp;quot;.us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] 
## [1,] NA   
## [2,] NA   
## [3,] &amp;quot;tus&amp;quot;
## [4,] NA   
## [5,] &amp;quot;rus&amp;quot;
## [6,] &amp;quot;cus&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This also matched whatever symbol comes just before the “u” from “us”. What if we use two &lt;code&gt;.&lt;/code&gt; instead?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match(&amp;quot;..us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]  
## [1,] NA    
## [2,] NA    
## [3,] &amp;quot;etus&amp;quot;
## [4,] NA    
## [5,] &amp;quot;urus&amp;quot;
## [6,] &amp;quot;rcus&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time, we get the two symbols that immediately precede “us”. Instead of continuing like this
we now use the &lt;code&gt;*&lt;/code&gt;, which matches zero or more of &lt;code&gt;.&lt;/code&gt;. So by combining &lt;code&gt;*&lt;/code&gt; and &lt;code&gt;.&lt;/code&gt;, we can match
any symbol repeatedly, until there is nothing more to match. Note that there is also &lt;code&gt;+&lt;/code&gt;, which works
similarly to &lt;code&gt;*&lt;/code&gt;, but it matches one or more symbols.&lt;/p&gt;
&lt;p&gt;There is also a &lt;code&gt;str_match_all()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match_all(&amp;quot;.*us&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##      [,1]
## 
## [[2]]
##      [,1]
## 
## [[3]]
##      [,1]       
## [1,] &amp;quot;epictetus&amp;quot;
## 
## [[4]]
##      [,1]
## 
## [[5]]
##      [,1]      
## [1,] &amp;quot;epicurus&amp;quot;
## 
## [[6]]
##      [,1]             
## [1,] &amp;quot;marcus aurelius&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this particular case it does not change the end result, but keep it in mind for cases like this one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(&amp;quot;haha&amp;quot;, &amp;quot;huhu&amp;quot;) %&amp;gt;%
  str_match(&amp;quot;ha&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,] &amp;quot;ha&amp;quot;
## [2,] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(&amp;quot;haha&amp;quot;, &amp;quot;huhu&amp;quot;) %&amp;gt;%
  str_match_all(&amp;quot;ha&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##      [,1]
## [1,] &amp;quot;ha&amp;quot;
## [2,] &amp;quot;ha&amp;quot;
## 
## [[2]]
##      [,1]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What if we want to match names containing the letter “t”? Easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ancient_philosophers %&amp;gt;%
  str_match(&amp;quot;.*t.*&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]                
## [1,] &amp;quot;aristotle&amp;quot;         
## [2,] &amp;quot;plato&amp;quot;             
## [3,] &amp;quot;epictetus&amp;quot;         
## [4,] &amp;quot;seneca the younger&amp;quot;
## [5,] NA                  
## [6,] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how does this help us with our historical newspaper? Let’s try to get the strings that come
after “CONTENT”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_text %&amp;gt;%
  str_match(&amp;quot;CONTENT.*&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s use our faithful &lt;code&gt;str()&lt;/code&gt; function to take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content %&amp;gt;%
  str&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  chr [1:19706, 1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hum, there’s a lot of &lt;code&gt;NA&lt;/code&gt; values! This is because a lot of the lines from the file did not have the
string “CONTENT”, so there is no match possible. Let’s us remove all these &lt;code&gt;NA&lt;/code&gt;s. Because the
result is a matrix, we cannot use the &lt;code&gt;filter()&lt;/code&gt; function from &lt;code&gt;{dplyr}&lt;/code&gt;. So we need to convert it
to a tibble first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;%
  as.tibble() %&amp;gt;%
  filter(!is.na(V1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `as.tibble()` is deprecated, use `as_tibble()` (but mind the new semantics).
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because matrix columns do not have names, when a matrix gets converted into a tibble, the firt column
gets automatically called &lt;code&gt;V1&lt;/code&gt;. This is why I filter on this column. Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   V1                                  
##   &amp;lt;chr&amp;gt;                               
## 1 &amp;quot;CONTENT=\&amp;quot;J\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;   
## 2 &amp;quot;CONTENT=\&amp;quot;a\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;   
## 3 &amp;quot;CONTENT=\&amp;quot;Ira\&amp;quot; WC=\&amp;quot;0.95238096\&amp;quot;/&amp;quot;
## 4 &amp;quot;CONTENT=\&amp;quot;mj\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;  
## 5 &amp;quot;CONTENT=\&amp;quot;iI\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;  
## 6 &amp;quot;CONTENT=\&amp;quot;tE1r\&amp;quot; WC=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;searching-and-replacing-strings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Searching and replacing strings&lt;/h3&gt;
&lt;p&gt;We are getting close to the final result. We still need to do some cleaning however. Since our data
is inside a nice tibble, we might as well stick with it. So let’s first rename the column and
change all the strings to lowercase:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = tolower(V1)) %&amp;gt;% 
  select(-V1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content                             
##   &amp;lt;chr&amp;gt;                               
## 1 &amp;quot;content=\&amp;quot;j\&amp;quot; wc=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;   
## 2 &amp;quot;content=\&amp;quot;a\&amp;quot; wc=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;   
## 3 &amp;quot;content=\&amp;quot;ira\&amp;quot; wc=\&amp;quot;0.95238096\&amp;quot;/&amp;quot;
## 4 &amp;quot;content=\&amp;quot;mj\&amp;quot; wc=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;  
## 5 &amp;quot;content=\&amp;quot;ii\&amp;quot; wc=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;  
## 6 &amp;quot;content=\&amp;quot;te1r\&amp;quot; wc=\&amp;quot;0.8095238\&amp;quot;/&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second part of the string, “wc=….” is not really interesting. Let’s search and replace this
with an empty string, using &lt;code&gt;str_replace()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = str_replace(content, &amp;quot;wc.*&amp;quot;, &amp;quot;&amp;quot;))

head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content            
##   &amp;lt;chr&amp;gt;              
## 1 &amp;quot;content=\&amp;quot;j\&amp;quot; &amp;quot;   
## 2 &amp;quot;content=\&amp;quot;a\&amp;quot; &amp;quot;   
## 3 &amp;quot;content=\&amp;quot;ira\&amp;quot; &amp;quot; 
## 4 &amp;quot;content=\&amp;quot;mj\&amp;quot; &amp;quot;  
## 5 &amp;quot;content=\&amp;quot;ii\&amp;quot; &amp;quot;  
## 6 &amp;quot;content=\&amp;quot;te1r\&amp;quot; &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to use the regular expression from before to replace “wc” and every character that follows.
The same can be use to remove “content=”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = str_replace(content, &amp;quot;content=&amp;quot;, &amp;quot;&amp;quot;))

head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content    
##   &amp;lt;chr&amp;gt;      
## 1 &amp;quot;\&amp;quot;j\&amp;quot; &amp;quot;   
## 2 &amp;quot;\&amp;quot;a\&amp;quot; &amp;quot;   
## 3 &amp;quot;\&amp;quot;ira\&amp;quot; &amp;quot; 
## 4 &amp;quot;\&amp;quot;mj\&amp;quot; &amp;quot;  
## 5 &amp;quot;\&amp;quot;ii\&amp;quot; &amp;quot;  
## 6 &amp;quot;\&amp;quot;te1r\&amp;quot; &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are almost done, but some cleaning is still necessary:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exctracting-or-removing-strings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exctracting or removing strings&lt;/h3&gt;
&lt;p&gt;Now, because I now the ALTO spec, I know how to find words that are split between two sentences:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content %&amp;gt;% 
  filter(str_detect(content, &amp;quot;hyppart&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 1
##    content                                                               
##    &amp;lt;chr&amp;gt;                                                                 
##  1 &amp;quot;\&amp;quot;aver\&amp;quot; subs_type=\&amp;quot;hyppart1\&amp;quot; subs_content=\&amp;quot;average\&amp;quot; &amp;quot;           
##  2 &amp;quot;\&amp;quot;age\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;average\&amp;quot; &amp;quot;            
##  3 &amp;quot;\&amp;quot;considera\&amp;quot; subs_type=\&amp;quot;hyppart1\&amp;quot; subs_content=\&amp;quot;consideration\&amp;quot; &amp;quot;
##  4 &amp;quot;\&amp;quot;tion\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;consideration\&amp;quot; &amp;quot;     
##  5 &amp;quot;\&amp;quot;re\&amp;quot; subs_type=\&amp;quot;hyppart1\&amp;quot; subs_content=\&amp;quot;resigned\&amp;quot; &amp;quot;            
##  6 &amp;quot;\&amp;quot;signed\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;resigned\&amp;quot; &amp;quot;        
##  7 &amp;quot;\&amp;quot;install\&amp;quot; subs_type=\&amp;quot;hyppart1\&amp;quot; subs_content=\&amp;quot;installed\&amp;quot; &amp;quot;      
##  8 &amp;quot;\&amp;quot;ed\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;installed\&amp;quot; &amp;quot;           
##  9 &amp;quot;\&amp;quot;be\&amp;quot; subs_type=\&amp;quot;hyppart1\&amp;quot; subs_content=\&amp;quot;before\&amp;quot; &amp;quot;              
## 10 &amp;quot;\&amp;quot;fore\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;before\&amp;quot; &amp;quot;            
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, the word “average” was split over two lines, the first part of the word, “aver” on the
first line, and the second part of the word, “age”, on the second line. We want to keep what comes
after “subs_content”. Let’s extract the word “average” using &lt;code&gt;str_extract()&lt;/code&gt;. However, because only
some words were split between two lines, we first need to detect where the string “hyppart1” is
located, and only then can we extract what comes after “subs_content”. Thus, we need to combine
&lt;code&gt;str_detect()&lt;/code&gt; to first detect the string, and then &lt;code&gt;str_extract()&lt;/code&gt; to extract what comes after
“subs_content”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = if_else(str_detect(content, &amp;quot;hyppart1&amp;quot;), 
                           str_extract_all(content, &amp;quot;content=.*&amp;quot;, simplify = TRUE), 
                           content))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content %&amp;gt;% 
  filter(str_detect(content, &amp;quot;content&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 1
##    content                                                          
##    &amp;lt;chr&amp;gt;                                                            
##  1 &amp;quot;content=\&amp;quot;average\&amp;quot; &amp;quot;                                           
##  2 &amp;quot;\&amp;quot;age\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;average\&amp;quot; &amp;quot;       
##  3 &amp;quot;content=\&amp;quot;consideration\&amp;quot; &amp;quot;                                     
##  4 &amp;quot;\&amp;quot;tion\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;consideration\&amp;quot; &amp;quot;
##  5 &amp;quot;content=\&amp;quot;resigned\&amp;quot; &amp;quot;                                          
##  6 &amp;quot;\&amp;quot;signed\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;resigned\&amp;quot; &amp;quot;   
##  7 &amp;quot;content=\&amp;quot;installed\&amp;quot; &amp;quot;                                         
##  8 &amp;quot;\&amp;quot;ed\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;installed\&amp;quot; &amp;quot;      
##  9 &amp;quot;content=\&amp;quot;before\&amp;quot; &amp;quot;                                            
## 10 &amp;quot;\&amp;quot;fore\&amp;quot; subs_type=\&amp;quot;hyppart2\&amp;quot; subs_content=\&amp;quot;before\&amp;quot; &amp;quot;       
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We still need to get rid of the string “content=” and then of all the strings that contain “hyppart2”,
which are not needed now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = str_replace(content, &amp;quot;content=&amp;quot;, &amp;quot;&amp;quot;)) %&amp;gt;% 
  mutate(content = if_else(str_detect(content, &amp;quot;hyppart2&amp;quot;), NA_character_, content))

head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content    
##   &amp;lt;chr&amp;gt;      
## 1 &amp;quot;\&amp;quot;j\&amp;quot; &amp;quot;   
## 2 &amp;quot;\&amp;quot;a\&amp;quot; &amp;quot;   
## 3 &amp;quot;\&amp;quot;ira\&amp;quot; &amp;quot; 
## 4 &amp;quot;\&amp;quot;mj\&amp;quot; &amp;quot;  
## 5 &amp;quot;\&amp;quot;ii\&amp;quot; &amp;quot;  
## 6 &amp;quot;\&amp;quot;te1r\&amp;quot; &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Almost done! We only need to remove the &lt;code&gt;&#34;&lt;/code&gt; characters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = str_replace_all(content, &amp;quot;\&amp;quot;&amp;quot;, &amp;quot;&amp;quot;)) 

head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content
##   &amp;lt;chr&amp;gt;  
## 1 &amp;quot;j &amp;quot;   
## 2 &amp;quot;a &amp;quot;   
## 3 &amp;quot;ira &amp;quot; 
## 4 &amp;quot;mj &amp;quot;  
## 5 &amp;quot;ii &amp;quot;  
## 6 &amp;quot;te1r &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s remove space characters with &lt;code&gt;str_trim()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  mutate(content = str_trim(content)) 

head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content
##   &amp;lt;chr&amp;gt;  
## 1 j      
## 2 a      
## 3 ira    
## 4 mj     
## 5 ii     
## 6 te1r&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To finish off this section, let’s remove stop words (words that do not add any meaning to a sentence,
such as “as”, “and”…) and words that are composed of less than 3 characters. You can find a dataset
with stopwords inside the &lt;code&gt;{stopwords}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stopwords)

data(data_stopwords_stopwordsiso)

eng_stopwords &amp;lt;- tibble(&amp;quot;content&amp;quot; = data_stopwords_stopwordsiso$en)

winchester_content &amp;lt;- winchester_content %&amp;gt;% 
  anti_join(eng_stopwords) %&amp;gt;% 
  filter(nchar(content) &amp;gt; 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;content&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(winchester_content)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   content   
##   &amp;lt;chr&amp;gt;     
## 1 te1r      
## 2 jilas     
## 3 edition   
## 4 winchester
## 5 news      
## 6 injuries&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it for this section! You now know how to work with strings, but in Chapter 10 we are going
one step further by learning about regular expressions, which offer much more power.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building a shiny app to explore historical newspapers: a step-by-step guide</title>
      <link>https://www.brodrigues.co/blog/2019-02-04-newspapers_shiny_app_tutorial/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-02-04-newspapers_shiny_app_tutorial/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://brodriguesco.shinyapps.io/newspapers_app/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/tf_idf.png&#34; title = &#34;Click here to go the app&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I started off this year by exploring a world that was unknown to me, the world of historical newspapers.
I did not know that historical newspapers data was a thing, and have been thoroughly enjoying myself
exploring the different datasets published by the National Library of Luxembourg. You can find
the data &lt;a href=&#34;https://data.bnl.lu/data/historical-newspapers/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers/&#34;&gt;first blog post&lt;/a&gt;, I analyzed data from
&lt;em&gt;L’indépendence Luxembourgeoise&lt;/em&gt;. I focused on the ads, which were for the most part in the 4th and
last page of the newspaper. I did so by extracting the data from the ALTO files. ALTO files contain
the content of the newspapers, (basically, the words that make up the article). For this first
exercise, I disregarded the METS files, for two reasons. First, I simply wanted to have something
quick, and get used to the data. And second, I did not know about ALTO and METS files enough to
truly make something out of them. The problem of disregarding the METS file is that I only had a big
dump of words, and did not know which words came from which article, or ad in this case.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/&#34;&gt;second blog post&lt;/a&gt;), I extracted
data from the &lt;em&gt;L’Union&lt;/em&gt; newspaper, this time by using the metadata from the METS files too. By
combining the data from the ALTO files with the metadata from the METS files, I know which
words came from which article, which would make further analysis much more interesting.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-31-newspapers_shiny_app/&#34;&gt;third blog post&lt;/a&gt; of this series,
I built a Shiny app which makes it easy to explore the 10 years of publications of &lt;em&gt;L’Union&lt;/em&gt;. In this
blog post, I will explain in great detail how I created this app.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-1-getting-the-data-ready-for-the-shiny-app&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1: Getting the data ready for the Shiny app&lt;/h2&gt;
&lt;div id=&#34;step-1-extracting-the-needed-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 1: Extracting the needed data&lt;/h3&gt;
&lt;p&gt;If you want to follow along with a dataset from a single publication, you can download the following archive on
&lt;a href=&#34;https://www.dropbox.com/s/56ttqetz4cirsja/1533660_newspaper_lunion_1860-11-14.zip?dl=0&#34;&gt;dropbox&lt;/a&gt;.
Extract this archive, and you will find the data exactly as you would get it from the the big
archive you can download from the website of the National Library of Luxembourg. However, to keep
the size of the archive small, I removed the .pdf and .jpeg scans.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/&#34;&gt;second blog post&lt;/a&gt;) I wrote
some functions that made extracting the needed data from the files easy. However, after I wrote the
article, I noticed that in some cases these functions were not working exactly as intended. I
rewrote them a little bit to overcome these issues. You can find the code I used right below. I won’t
explain it too much, because you can read the details in the previous blog post. However, should
something be unclear, just drop me an email or a tweet!&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This functions will be used within the next functions to extract the relevant pieces

extractor &amp;lt;- function(string, regex, all = FALSE){
    if(all) {
        string %&amp;gt;%
            str_extract_all(regex) %&amp;gt;%
            flatten_chr() %&amp;gt;%
            str_remove_all(&amp;quot;=|\\\&amp;quot;&amp;quot;) %&amp;gt;%
            #str_extract_all(&amp;quot;[:alnum:]+|.|,|\\?|!&amp;quot;, simplify = FALSE) %&amp;gt;%
            map(paste, collapse = &amp;quot;&amp;quot;) %&amp;gt;%
            flatten_chr()
    } else {
        string %&amp;gt;%
            str_extract(regex) %&amp;gt;%
            str_remove_all(&amp;quot;=|\\\&amp;quot;&amp;quot;) %&amp;gt;%
            #str_extract_all(&amp;quot;[:alnum:]+|.|,|\\?|!&amp;quot;, simplify = TRUE) %&amp;gt;%
            paste(collapse = &amp;quot; &amp;quot;) %&amp;gt;%
            tolower()
    }
}

# This function extracts the data from the METS files, and returns a tibble:

extract_mets &amp;lt;- function(article){
    id &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=ID)(.*?)(?=LABEL)&amp;quot;)

    label &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=LABEL)(.*?)(?=TYPE)&amp;quot;)

    type &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=TYPE)(.*?)(?=&amp;gt;)&amp;quot;)

    begins &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=BEGIN)(.*?)(?=BETYPE)&amp;quot;, all = TRUE)

    tibble::tribble(~label, ~type, ~begins, ~id,
                    label, type, begins, id) %&amp;gt;%
        unnest()
}

# This function extracts the data from the ALTO files, and also returns a tibble:

extract_alto &amp;lt;- function(article){
    begins &amp;lt;- article[1] %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=^ID)(.*?)(?=HPOS)&amp;quot;, all = TRUE)

    content &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=CONTENT)(.*?)(?=WC)&amp;quot;, all = TRUE)

    tibble::tribble(~begins, ~content,
                    begins, content) %&amp;gt;%
        unnest()
}

# This function takes the path to a page as an argument, and extracts the data from 
# each article using the function defined above. It then writes a flat CSV to disk.

alto_csv &amp;lt;- function(page_path){

    page &amp;lt;- read_file(page_path)

    doc_name &amp;lt;- str_extract(page_path, &amp;quot;(?&amp;lt;=/text/).*&amp;quot;)

    alto_articles &amp;lt;- page %&amp;gt;%
        str_split(&amp;quot;TextBlock &amp;quot;) %&amp;gt;%
        flatten_chr()

    alto_df &amp;lt;- map_df(alto_articles, extract_alto)

    alto_df &amp;lt;- alto_df %&amp;gt;%
        mutate(document = doc_name)

    write_csv(alto_df, paste0(page_path, &amp;quot;.csv&amp;quot;))
}

# Same as above, but for the METS file:

mets_csv &amp;lt;- function(page_path){

    page &amp;lt;- read_file(page_path)

    doc_name &amp;lt;- str_extract(page_path, &amp;quot;(?&amp;lt;=/).*&amp;quot;)

    mets_articles &amp;lt;- page %&amp;gt;%
        str_split(&amp;quot;DMDID&amp;quot;) %&amp;gt;%
        flatten_chr()

    mets_df &amp;lt;- map_df(mets_articles, extract_mets)

    mets_df &amp;lt;- mets_df %&amp;gt;%
        mutate(document = doc_name)

    write_csv(mets_df, paste0(page_path, &amp;quot;.csv&amp;quot;))
}

# Time to use the above defined functions. First, let&amp;#39;s save the path of all the ALTO files
# into a list:

pages_alto &amp;lt;- str_match(list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE), &amp;quot;.*/text/.*.xml&amp;quot;) %&amp;gt;%
    discard(is.na)

# I use the {furrr} library to do the extraction in parallel, using 8 cores:

library(furrr)

plan(multiprocess, workers = 8)

tic &amp;lt;- Sys.time()
future_map(pages_alto, alto_csv)
toc &amp;lt;- Sys.time()

toc - tic

#Time difference of 18.64776 mins


# Same for the METS files:

pages_mets &amp;lt;- str_match(list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE), &amp;quot;.*mets.xml&amp;quot;) %&amp;gt;%
    discard(is.na)


library(furrr)

plan(multiprocess, workers = 8)

tic &amp;lt;- Sys.time()
future_map(pages_mets, mets_csv)
toc &amp;lt;- Sys.time()

toc - tic

#Time difference of 18.64776 mins&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;If you want to try the above code for one ALTO and METS files, you can use the following lines
(use the download link in the beginning of the blog post to get the required data):&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mets &amp;lt;- read_file(&amp;quot;1533660_newspaper_lunion_1860-11-14/1533660_newspaper_lunion_1860-11-14-mets.xml&amp;quot;)

mets_articles2 &amp;lt;- mets %&amp;gt;%
    str_split(&amp;quot;DMDID&amp;quot;) %&amp;gt;%
    flatten_chr()


alto &amp;lt;- read_file(&amp;quot;1533660_newspaper_lunion_1860-11-14/text/1860-11-14_01-00001.xml&amp;quot;)

alto_articles &amp;lt;- alto %&amp;gt;%
    str_split(&amp;quot;TextBlock &amp;quot;) %&amp;gt;%
    flatten_chr()

mets_df2 &amp;lt;- mets_articles2 %&amp;gt;%
    map_df(extract_mets)

# Same exercice for ALTO

alto_df &amp;lt;- alto_articles %&amp;gt;%
    map_df(extract_alto)&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-joining-the-data-and-the-metadata&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 2: Joining the data and the metadata&lt;/h3&gt;
&lt;p&gt;Now that I extracted the data from the ALTO files, and the metadata from the METS files, I still
need to join both data sets and do some cleaning. What is the goal of joining these two sources?
Remember, by doing this I will know which words come from which article, which will make things
much easier later on. I explain how the code works as comments in the code block below:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(udpipe)
library(textrank)
library(tidytext)

# First, I need the path to each folder that contains the ALTO and METS files. Each newspaper
# data is inside its own folder, one folder per publication. Inside, there&amp;#39;s `text` folder that
# contains the ALTO and METS files. This is also where I saved the .csv files from before.

pathdirs &amp;lt;- list.dirs(recursive = FALSE) %&amp;gt;%
    str_match(&amp;quot;.*lunion.*&amp;quot;) %&amp;gt;%
    discard(is.na)

# The following function imports the METS and the ALTO csv files, joins them, and does some 
# basic cleaning. I used a trick to detect German articles (even though L&amp;#39;Union is a French publication
# some articles are in German) and then remove them.

tidy_papers &amp;lt;- function(path){
    mets_path &amp;lt;- paste0(path, &amp;quot;/&amp;quot;, list.files(path, &amp;quot;.*.xml.csv&amp;quot;))
    mets_csv &amp;lt;- data.table::fread(mets_path)

    alto_path &amp;lt;- paste0(path, &amp;quot;/text/&amp;quot;, list.files(paste0(path, &amp;quot;/text/&amp;quot;), &amp;quot;.*.csv&amp;quot;))
    alto_csv &amp;lt;- map_dfr(alto_path, data.table::fread)

    final &amp;lt;- full_join(alto_csv, mets_csv, by = &amp;quot;begins&amp;quot;) %&amp;gt;%
        mutate(content = tolower(content)) %&amp;gt;%
        mutate(content = if_else(str_detect(content, &amp;quot;hyppart1&amp;quot;), str_extract_all(content, &amp;quot;(?&amp;lt;=CONTENT_).*&amp;quot;, simplify = TRUE), content)) %&amp;gt;%
        mutate(content = if_else(str_detect(content, &amp;quot;hyppart2&amp;quot;), NA_character_, content)) %&amp;gt;%
        # When words are separated by a hyphen and split over two lines, it looks like this in the data.
        # ex SUBS_TYPEHypPart1 SUBS_CONTENTexceptée
        # ceptée SUBS_TYPEHypPart2 SUBS_CONTENTexceptée
        # Here, the word `exceptée` is split over two lines, so using a regular expression, I keep
        # the string `exceptée`, which comes after the string `CONTENT`,  from the first line and 
        # replace the second line by an NA_character_
        mutate(content = if_else(str_detect(content, &amp;quot;superscript&amp;quot;), NA_character_, content)) %&amp;gt;%
        mutate(content = if_else(str_detect(content, &amp;quot;subscript&amp;quot;), NA_character_, content)) %&amp;gt;%
        filter(!is.na(content)) %&amp;gt;%
        filter(type == &amp;quot;article&amp;quot;) %&amp;gt;%
        group_by(id) %&amp;gt;%
        nest %&amp;gt;%
        # Below I create a list column with all the content of the article in a single string.
        mutate(article_text = map(data, ~paste(.$content, collapse = &amp;quot; &amp;quot;))) %&amp;gt;%
        mutate(article_text = as.character(article_text)) %&amp;gt;%
        # Detecting and removing german articles
        mutate(german = str_detect(article_text, &amp;quot;wenn|wird|und&amp;quot;)) %&amp;gt;%
        filter(german == FALSE) %&amp;gt;%
        select(-german) %&amp;gt;%
        # Finally, creating the label of the article (the title), and removing things that are 
        # not articles, such as the daily feuilleton.
        mutate(label = map(data, ~`[`(.$label, 1))) %&amp;gt;%
        filter(!str_detect(label, &amp;quot;embranchement|ligne|bourse|abonnés|feuilleton&amp;quot;)) %&amp;gt;%
        filter(label != &amp;quot;na&amp;quot;)

    # Save the data in the rds format, as it is not a flat file
    saveRDS(final, paste0(path, &amp;quot;/&amp;quot;, str_sub(path, 11, -1), &amp;quot;.rds&amp;quot;))
}

# Here again, I do this in parallel

library(furrr)

plan(multiprocess, workers = 8)

future_map(pathdirs, tidy_papers)&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;This is how one of these files looks like, after passing through this function:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/articles_rds.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;One line is one article. The first column is the id of the article, the second column contains
a data frame, the text of the article and finally the title of the article.
Let’s take a look at the content of the first element of the &lt;em&gt;data&lt;/em&gt; column:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/merged_alto_mets.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This is the result of the merger of the METS and ALTO csv files. The first column is the id of the
article, the second column contains each individual word of the article, the &lt;em&gt;label&lt;/em&gt; column the
label, or title of the article.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-part-of-speech-annotation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 3: Part-of-speech annotation&lt;/h3&gt;
&lt;p&gt;Part-of-speech annotation is a technique with the aim of assigning to each word its part of speech.
Basically, Pos annotation tells us whether a word is a verb, a noun, an adjective… This will
be quite useful for the analysis. To perform Pos annotation, you need to install the &lt;code&gt;{udpipe}&lt;/code&gt;
package, and download the pre-trained model for the language you want to annotate, in my case French:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Only run this once. This downloads the model for French
udpipe_download_model(language = &amp;quot;french&amp;quot;)

# Load the model
udmodel_french &amp;lt;- udpipe_load_model(file = &amp;#39;french-gsd-ud-2.3-181115.udpipe&amp;#39;)

# Save the path of the files to annotate in a list:
pathrds &amp;lt;- list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE) %&amp;gt;% 
  str_match(&amp;quot;.*.rds&amp;quot;) %&amp;gt;%
  discard(is.na)

annotate_rds &amp;lt;- function(path, udmodel){

    newspaper &amp;lt;- readRDS(path)

    s &amp;lt;- udpipe_annotate(udmodel, newspaper$article_text, doc_id = newspaper$label)
    x &amp;lt;- data.frame(s)

    saveRDS(x, str_replace(path, &amp;quot;.rds&amp;quot;, &amp;quot;_annotated.rds&amp;quot;))
}

library(furrr)
plan(multiprocess, workers = 8)
tic &amp;lt;- Sys.time()
future_map(pathrds, annotate_rds, udmodel = udmodel_french)
toc &amp;lt;- Sys.time()
toc - tic&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;And here is the result:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/pos_article.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;upos&lt;/em&gt; column contains the tags. Now I know which words are nouns, verbs, adjectives, stopwords…
Meaning that I can easily focus on the type of words that interest me. Plus, as an added benefit, I
can focus on the lemma of the words. For example, the word &lt;em&gt;viennent&lt;/em&gt;, is the
&lt;a href=&#34;https://en.wikipedia.org/wiki/French_conjugation&#34;&gt;conjugated&lt;/a&gt; form of the verb &lt;em&gt;venir&lt;/em&gt;. &lt;em&gt;venir&lt;/em&gt; is
thus the lemma of &lt;em&gt;viennent&lt;/em&gt;. This means that I can focus my analysis on lemmata. This is useful,
because if I compute the frequency of words, &lt;em&gt;viennent&lt;/em&gt; would be different from &lt;em&gt;venir&lt;/em&gt;, which is
not really what we want.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4-tf-idf&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 4: tf-idf&lt;/h3&gt;
&lt;p&gt;Just like what I did in my &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers/&#34;&gt;first blog post&lt;/a&gt;,
I compute the tf-idf of words. The difference, is that here the “document” is the article. This means
that I will get the most frequent words inside each article, but who are at the same time rare
in the other articles. Doing this ensures that I will only get very relevant words for each article.&lt;/p&gt;
&lt;p&gt;In the lines below, I prepare the data to then make the plots. The files that are created using
the code below are available in the following &lt;a href=&#34;https://github.com/b-rodrigues/newspapers_shinyapp/tree/master/tf_idf_data&#34;&gt;Github link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the Shiny app, I read the data directly from the repo. This way, I can keep the app small in size.&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_annotatedrds &amp;lt;- list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE) %&amp;gt;% str_match(&amp;quot;.*_annotated.rds&amp;quot;) %&amp;gt;%
    discard(is.na)

prepare_tf_idf &amp;lt;- function(path){

    annotated_newspaper &amp;lt;- readRDS(path)

    tf_idf_data &amp;lt;- annotated_newspaper %&amp;gt;%
        filter(upos %in% c(&amp;quot;NOUN&amp;quot;, &amp;quot;VERB&amp;quot;, &amp;quot;ADJ&amp;quot;, &amp;quot;PROPN&amp;quot;)) %&amp;gt;%
        filter(nchar(lemma) &amp;gt; 3) %&amp;gt;%
        count(doc_id, lemma) %&amp;gt;%
        bind_tf_idf(lemma, doc_id, n) %&amp;gt;%
        arrange(desc(tf_idf)) %&amp;gt;%
        group_by(doc_id)

    name_tf_idf_data &amp;lt;- str_split(path, &amp;quot;/&amp;quot;, simplify = 1)[1] %&amp;gt;%
        paste0(&amp;quot;_tf_idf_data.rds&amp;quot;)  %&amp;gt;%
        str_sub(start = 9, -1)

    saveRDS(tf_idf_data, paste0(&amp;quot;tf_idf_data/&amp;quot;, name_tf_idf_data))
}

library(furrr)
plan(multiprocess, workers = 8)

future_map(path_annotatedrds, prepare_tf_idf)&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;div id=&#34;step-5-summarizing-articles-by-extracting-the-most-relevant-sentences-using-textrank&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Step 5: Summarizing articles by extracting the most relevant sentences, using &lt;code&gt;{textrank}&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The last step in data preparation is to extract the most relevant sentences of each articles, using
the &lt;code&gt;{textrank}&lt;/code&gt; package. This packages implements the &lt;em&gt;PageRank&lt;/em&gt; algorithm developed by Larry Page
and Sergey Brin in 1995. This algorithm ranks pages by the number of links that point to the pages;
the most popular and important pages are also the ones with more links to them. A similar approach
is used by the implementation of &lt;code&gt;{textrank}&lt;/code&gt;. The algorithm is explained in detail in the following
&lt;a href=&#34;https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, I cannot simply apply &lt;code&gt;{textrank}&lt;/code&gt; to the annotated data frame as it is. Because I have
several articles, I have to run the &lt;code&gt;textrank_sentences()&lt;/code&gt; function, which extracts the relevant
sentences, article by article. For this I still need to transform the data set and also need to
prepare the data in a way that makes it digestible by the function. I will not explain the code
below line by line, since the documentation of the package is quite straightforward. However,
keep in mind that I have to run the &lt;code&gt;textrank_sentences()&lt;/code&gt; function for each article, which explains
that as some point I use the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group_by(doc_id) %&amp;gt;%
    nest() %&amp;gt;%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which then makes it easy to work by article (&lt;em&gt;doc_id&lt;/em&gt; is the id of the articles). This part is
definitely the most complex, so if you’re interested in the methodology described here, really
take your time to understand this function. Let me know if I can clarify things!&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(textrank)
library(brotools)

path_annotatedrds &amp;lt;- list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE) %&amp;gt;% str_match(&amp;quot;.*_annotated.rds&amp;quot;) %&amp;gt;%
    discard(is.na)

prepare_textrank &amp;lt;- function(path){

    annotated_newspaper &amp;lt;- readRDS(path)

    # sentences summary
    x_text_rank &amp;lt;- annotated_newspaper %&amp;gt;%
        group_by(doc_id) %&amp;gt;%
        nest() %&amp;gt;%
        mutate(textrank_id = map(data, ~unique_identifier(., c(&amp;quot;paragraph_id&amp;quot;, &amp;quot;sentence_id&amp;quot;)))) %&amp;gt;%
        mutate(cleaned = map2(.x = data, .y = textrank_id, ~cbind(.x, &amp;quot;textrank_id&amp;quot; = .y))) %&amp;gt;%
        select(doc_id, cleaned)

    x_text_rank2 &amp;lt;- x_text_rank %&amp;gt;%
        mutate(sentences = map(cleaned, ~select(., textrank_id, sentence))) %&amp;gt;%
        # one_row() is a function from my own package, which eliminates duplicates rows
        # from a data frame
        mutate(sentences = map(sentences, ~one_row(., c(&amp;quot;textrank_id&amp;quot;, &amp;quot;sentence&amp;quot;))))

    x_terminology &amp;lt;- x_text_rank %&amp;gt;%
        mutate(terminology = map(cleaned, ~filter(., upos %in% c(&amp;quot;NOUN&amp;quot;, &amp;quot;ADJ&amp;quot;)))) %&amp;gt;%
        mutate(terminology = map(terminology, ~select(., textrank_id, &amp;quot;lemma&amp;quot;))) %&amp;gt;%
        select(terminology)

    x_final &amp;lt;- bind_cols(x_text_rank2, x_terminology)

    possibly_textrank_sentences &amp;lt;- possibly(textrank_sentences, otherwise = NULL)

    x_final &amp;lt;- x_final %&amp;gt;%
        mutate(summary = map2(sentences, terminology, possibly_textrank_sentences)) %&amp;gt;%
        select(doc_id, summary)

    name_textrank_data &amp;lt;- str_split(path, &amp;quot;/&amp;quot;, simplify = 1)[1] %&amp;gt;%
        paste0(&amp;quot;_textrank_data.rds&amp;quot;) %&amp;gt;%
        str_sub(start = 9, -1)

    saveRDS(x_final, paste0(&amp;quot;textrank_data/&amp;quot;, name_textrank_data))
}

library(furrr)
plan(multiprocess, workers = 8)

future_map(path_annotatedrds, prepare_textrank)&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;You can download the annotated data sets from the following
&lt;a href=&#34;https://github.com/b-rodrigues/newspapers_shinyapp/tree/master/textrank_data&#34;&gt;link&lt;/a&gt;. This is how
the data looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/textrank_df.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;summary()&lt;/code&gt; function on an element of the &lt;em&gt;summary&lt;/em&gt; column returns the 5 most relevant
sentences as extracted by &lt;code&gt;{textrank}&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-building-the-shiny-app&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2: Building the shiny app&lt;/h2&gt;
&lt;p&gt;The most difficult parts are behind us! Building a dashboard is quite easy thanks to the &lt;code&gt;{flexdashboard}&lt;/code&gt;
package. You need to know Markdown and some Shiny, but it’s way easier than building a complete
Shiny app. First of all, install the &lt;code&gt;{fleshdashboard}&lt;/code&gt; package, and start from a template, or
from &lt;a href=&#34;https://rmarkdown.rstudio.com/flexdashboard/layouts.html&#34;&gt;this list of layouts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I think that the only trick worth mentioning is that I put the data in a Github repo, and read it
directly from the Shiny app. Users choose a date, which I save in a reactive variable. I then
build the right url that points towards the right data set, and read it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_tf_idf &amp;lt;- reactive({
    paste0(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/newspapers_shinyapp/master/tf_idf_data/newspaper_lunion_&amp;quot;, as.character(input$date2), &amp;quot;_tf_idf_data.rds&amp;quot;)
})

dfInput &amp;lt;- reactive({
        read_rds(url(path_tf_idf())) %&amp;gt;%
        top_n(as.numeric(input$tf_df_words), tf_idf) %&amp;gt;%
        mutate(word = reorder(lemma, tf_idf)) 
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because I did all the computations beforehand, the app simply reads the data and creates the bar
plots for the tf-idf data, or prints the sentences for the textrank data. To print the sentences
correcly, I had to use some html tags, using the &lt;code&gt;{htmltools}&lt;/code&gt; package. Below you can find the
source code of the app:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the code&lt;/summary&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: &amp;quot;Exploring 10 years of daily publications of the Luxembourguish newspaper, *L&amp;#39;Union*&amp;quot;
output: 
  flexdashboard::flex_dashboard:
    theme: yeti
    orientation: columns
    vertical_layout: fill
runtime: shiny
---

`` `{r setup, include=FALSE}
library(flexdashboard)
library(shiny)
library(tidyverse)
library(textrank)
library(tidytext)
library(udpipe)
library(plotly)
library(ggthemes)
`` `

Sidebar {.sidebar}
=====================================

`` `{r}
dateInput(&amp;#39;date2&amp;#39;,
      label = paste(&amp;#39;Select date&amp;#39;),
      value = as.character(as.Date(&amp;quot;1860-11-14&amp;quot;)),
      min = as.Date(&amp;quot;1860-11-12&amp;quot;), max = as.Date(&amp;quot;1869-12-31&amp;quot;),
      format = &amp;quot;yyyy/mm/dd&amp;quot;,
      startview = &amp;#39;year&amp;#39;, language = &amp;#39;en-GB&amp;#39;, weekstart = 1
    )
selectInput(inputId = &amp;quot;tf_df_words&amp;quot;, 
            label = &amp;quot;Select number of unique words for tf-idf&amp;quot;, 
            choices = seq(1:10),
            selected = 5)
selectInput(inputId = &amp;quot;textrank_n_sentences&amp;quot;, 
            label = &amp;quot;Select the number of sentences for the summary of the article&amp;quot;, 
            choices = seq(1:20), 
            selected = 5)
`` `

*The BnL has digitised over 800.000 pages of Luxembourg newspapers. From those, more than 700.000 
pages have rich metadata using international XML standards such as METS and ALTO. 
Multiple datasets are available for download. Each one is of different size and contains different
newspapers. All the digitised material can also be found on our search platform a-z.lu 
(Make sure to filter by “eluxemburgensia”). All datasets contain XML (METS + ALTO), PDF, original 
TIFF and PNG files for every newspaper issue.* 
Source: https://data.bnl.lu/data/historical-newspapers/

This Shiny app allows you to get summaries of the 10 years of daily issues of the &amp;quot;L&amp;#39;Union&amp;quot; newspaper.
In the first tab, a simple word frequency per article is shown, using the tf-idf method. In the 
second tab, summary sentences have been extracted using the `{textrank}` package.


Word frequency per article
===================================== 
Row
-----------------------------------------------------------------------

### Note: there might be days without any publication. In case of an error, select another date.
    
`` `{r}
path_tf_idf &amp;lt;- reactive({
    paste0(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/newspapers_shinyapp/master/tf_idf_data/newspaper_lunion_&amp;quot;, as.character(input$date2), &amp;quot;_tf_idf_data.rds&amp;quot;)
})
dfInput &amp;lt;- reactive({
        read_rds(url(path_tf_idf())) %&amp;gt;%
        top_n(as.numeric(input$tf_df_words), tf_idf) %&amp;gt;%
        mutate(word = reorder(lemma, tf_idf)) 
})
renderPlotly({
    df_tf_idf &amp;lt;- dfInput()
    p1 &amp;lt;- ggplot(df_tf_idf,
                 aes(word, tf_idf)) +
                 geom_col(show.legend = FALSE, fill = &amp;quot;#82518c&amp;quot;) +
                 labs(x = NULL, y = &amp;quot;tf-doc_idf&amp;quot;) +
                 facet_wrap(~doc_id, ncol = 2, scales = &amp;quot;free&amp;quot;) +
                 coord_flip() +
                 theme_dark()
    ggplotly(p1)
})
`` `

Summary of articles {data-orientation=rows}
===================================== 
Row 
-----------------------------------------------------------------------

### The sentence in bold is the title of the article. You can show more sentences in the summary by using the input in the sidebar.
    
`` `{r}
print_summary_textrank &amp;lt;- function(doc_id, summary, n_sentences){
    htmltools::HTML(paste0(&amp;quot;&amp;lt;b&amp;gt;&amp;quot;, doc_id, &amp;quot;&amp;lt;/b&amp;gt;&amp;quot;), paste(&amp;quot;&amp;lt;p&amp;gt;&amp;quot;, summary(summary, n_sentences), sep = &amp;quot;&amp;quot;, collapse = &amp;quot;&amp;lt;br/&amp;gt;&amp;quot;), &amp;quot;&amp;lt;/p&amp;gt;&amp;quot;)
}
path_textrank &amp;lt;- reactive({
    paste0(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/newspapers_shinyapp/master/textrank_data/newspaper_lunion_&amp;quot;, as.character(input$date2), &amp;quot;_textrank_data.rds&amp;quot;)
})
dfInput2 &amp;lt;- reactive({
        read_rds(url(path_textrank()))
})
renderUI({
    df_textrank &amp;lt;- dfInput2()
    
df_textrank &amp;lt;- df_textrank %&amp;gt;% 
    mutate(to_print = map2(doc_id, summary, print_summary_textrank, n_sentences = as.numeric(input$textrank_n_sentences)))
df_textrank$to_print
})
`` `
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;I host the app on Shinyapps.io, which is really easy to do from within Rstudio.&lt;/p&gt;
&lt;p&gt;That was quite long, I’m not sure that anyone will read this blog post completely, but oh well.
Better to put the code online, might help someone one day, that leave it to rot on my hard drive.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using Data Science to read 10 years of Luxembourguish newspapers from the 19th century</title>
      <link>https://www.brodrigues.co/blog/2019-01-31-newspapers_shiny_app/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-01-31-newspapers_shiny_app/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://brodriguesco.shinyapps.io/newspapers_app/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/tf_idf.png&#34; title = &#34;Click here to go the app&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have been playing around with historical newspaper data (see
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers/&#34;&gt;here&lt;/a&gt; and
&lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/&#34;&gt;here&lt;/a&gt;). I have extracted the
data from the largest archive available, as described in the previous blog post, and now created
a shiny dashboard where it is possible to visualize the most common words per article, as well as
read a summary of each article.
The summary was made using a method called &lt;em&gt;textrank&lt;/em&gt;, using the &lt;code&gt;{textrank}&lt;/code&gt; package, which extracts
relevant sentences using the Pagerank (developed by Google) algorithm. You can read the scientific
paper &lt;a href=&#34;https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf&#34;&gt;here&lt;/a&gt; for more info.&lt;/p&gt;
&lt;p&gt;You can play around with the app by clicking &lt;a href=&#34;https://brodriguesco.shinyapps.io/newspapers_app/&#34;&gt;here&lt;/a&gt;.
In the next blog post, I will explain how I created the app, step by step. It’s going to be a long blog post!&lt;/p&gt;
&lt;p&gt;Using the app, I noticed that some war happened around November 1860 in China, which turned out to
be the &lt;a href=&#34;https://en.wikipedia.org/wiki/Second_Opium_War&#34;&gt;Second Opium War&lt;/a&gt;. The war actually ended
in October 1860, but apparently the news took several months to travel to Europe.&lt;/p&gt;
&lt;p&gt;I also learned that already in the 1861, there was public transportation between some Luxembourguish villages,
and French villages that were by the border (see the publication from the 17th of December 1861).&lt;/p&gt;
&lt;p&gt;Let me know if you find about historical events using my app!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making sense of the METS and ALTO XML standards</title>
      <link>https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-01-13-newspapers_mets_alto/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=V1qpvpH26fo&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/union.png&#34; title = &#34;The 19th century was a tough place&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Last week I wrote a &lt;a href=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers/&#34;&gt;blog post&lt;/a&gt; where I analyzed
one year of newspapers ads from 19th century newspapers. The data is made available by the
&lt;a href=&#34;https://data.bnl.lu/data/historical-newspapers/&#34;&gt;national library of Luxembourg&lt;/a&gt;.
In this blog post, which is part 1 of a 2 part series, I extract data from the 257gb archive, which
contains 10 years of publications of the &lt;em&gt;L’Union&lt;/em&gt;, another 19th century Luxembourguish newspaper
written in French. As I explained in the previous post, to make life easier to data scientists,
the national library also included ALTO and METS files (which are a XML files used to
describe the layout and contents of physical text sources, such as pages of a book or newspaper)
which can be easily parsed by R.&lt;/p&gt;
&lt;p&gt;This is how a ALTO file looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/alto.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Each page of the newspaper of a given day has one ALTO file.
This is how a METS file looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/mets.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;For each daily issue of the newspaper, there is a METS file. So 1 METS file for 4 ALTO files.&lt;/p&gt;
&lt;p&gt;In my last blog post, I only extracted the words from the ALTO file (red rectangles of the first
screenshot) and did not touch the METS file.
The problem of doing this is that I get all the words for each page, without knowing which
come from the same article. If I want to know which words come from the same article, I need to use
the info from the METS file. From the METS file I have the ID of the article, and some other
metadata, such as the title of the article and the type of the article (which can be &lt;em&gt;article&lt;/em&gt;,
&lt;em&gt;advertisement&lt;/em&gt;, etc). The information highlighted with the green rectangles in the METS file
can be linked to the green rectangles from the ALTO files. My goal is to get the following data
frame from the METS file:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/mets_df.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;and this data frame from the ALTO files:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/alto_df.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;As you can see, by combining both data frames I can know which words come from the same article,
which will be helpful for further analysis.
&lt;a href=&#34;https://en.wikipedia.org/wiki/1860s&#34;&gt;A lot of things happened in the 1860s.&lt;/a&gt;
I am really curious to see if and how these events where reported in a Luxembourguish newspaper.
I am particularly curious about how long it took to report certain news from far away, such as the
assassination of Abraham Lincoln. But before that I need to extract the data!&lt;/p&gt;
&lt;p&gt;I will only focus on the METS file. The logic for the ALTO file is the same. All the source code
will be in the appendix of this blog post.&lt;/p&gt;
&lt;p&gt;First, let’s take a look at a METS file:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
mets &amp;lt;- read_file(&amp;quot;1533660_newspaper_lunion_1860-11-14/1533660_newspaper_lunion_1860-11-14-mets.xml&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is how it looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;&amp;lt;?xml version=&amp;#39;1.0&amp;#39; encoding=&amp;#39;utf-8&amp;#39;?&amp;gt;\r\n&amp;lt;mets xmlns=\&amp;quot;http://www.loc.gov/METS/\&amp;quot; xmlns:mix=\&amp;quot;http://www.loc.gov/mix/v20\&amp;quot; xmlns:mods=\&amp;quot;http://www.loc.gov/mods/v3\&amp;quot; xmlns:xlink=\&amp;quot;http://www.w3.org/1999/xlink\&amp;quot; xmlns:xsi=\&amp;quot;http://www.w3.org/2001/XMLSchema-instance\&amp;quot; LABEL=\&amp;quot;L&amp;#39;UNION. 1860-11-14_01\&amp;quot; OBJID=\&amp;quot;https://persist.lu/ark:/70795/m62fcm\&amp;quot; TYPE=\&amp;quot;Newspaper\&amp;quot; xsi:schemaLocation=\&amp;quot;http://www.loc.gov/METS/ http://www.loc.gov/standards/mets/mets.xsd http://www.loc.gov/mods/v3 http://www.loc.gov/standards/mods/v3/mods-3-6.xsd http://www.loc.gov/mix/v20 http://www.loc.gov/standards/mix/mix.xsd\&amp;quot;&amp;gt;\r\n  &amp;lt;metsHdr CREATEDATE=\&amp;quot;2010-12-03T20:35:05\&amp;quot; LASTMODDATE=\&amp;quot;2018-05-09T05:35:51Z\&amp;quot;&amp;gt;\r\n    &amp;lt;agent OTHERTYPE=\&amp;quot;SOFTWARE\&amp;quot; ROLE=\&amp;quot;CREATOR\&amp;quot; TYPE=\&amp;quot;OTHER\&amp;quot;&amp;gt;\r\n      &amp;lt;name&amp;gt;CCS docWORKS/METAe Version 6.4-3&amp;lt;/name&amp;gt;\r\n      &amp;lt;note&amp;gt;docWORKS-ID: 101636&amp;lt;/note&amp;gt;\r\n    &amp;lt;/agent&amp;gt;\r\n  &amp;lt;/metsHdr&amp;gt;\r\n  &amp;lt;dmdSec ID=\&amp;quot;MODSMD_COLLECTION\&amp;quot;&amp;gt;\r\n    &amp;lt;mdWrap LABEL=\&amp;quot;Bibliographic meta-data of the collection\&amp;quot; MDTYPE=\&amp;quot;MODS\&amp;quot; MIMETYPE=\&amp;quot;text/xml\&amp;quot;&amp;gt;\r\n      &amp;lt;xmlData&amp;gt;\r\n        &amp;lt;mods:mods&amp;gt;\r\n          &amp;lt;mods:identifier type=\&amp;quot;local\&amp;quot;&amp;gt;lunion&amp;lt;/mods:identifier&amp;gt;\r\n          &amp;lt;mods:titleInfo ID=\&amp;quot;MODSMD_COLLECTION_TI1\&amp;quot; xml:lang=\&amp;quot;fr\&amp;quot;&amp;gt;\r\n            &amp;lt;mods:title&amp;gt;L&amp;#39;UNION.&amp;lt;/mods:title&amp;gt;\r\n          &amp;lt;/mods:titleInfo&amp;gt;\r\n        &amp;lt;/mods:mods&amp;gt;\r\n      &amp;lt;/xmlData&amp;gt;\r\n    &amp;lt;/mdWrap&amp;gt;\r\n  &amp;lt;/dmdSec&amp;gt;\r\n  &amp;lt;dmdSec ID=\&amp;quot;MODSMD_SECTION1\&amp;quot;&amp;gt;\r\n    &amp;lt;mdWrap MDTYPE=\&amp;quot;MODS\&amp;quot; MIMETYPE=\&amp;quot;text/xml\&amp;quot;&amp;gt;\r\n      &amp;lt;xmlData&amp;gt;\r\n        &amp;lt;mods:mods&amp;gt;\r\n          &amp;lt;mods:titleInfo ID=\&amp;quot;MODSMD_SECTION1_TI1\&amp;quot; xml:lang=\&amp;quot;fr\&amp;quot;&amp;gt;\r\n            &amp;lt;mods:title&amp;gt;Chemins de fer. — Service d&amp;#39;hiver.&amp;lt;/mods:title&amp;gt;\r\n          &amp;lt;/mods:titleInfo&amp;gt;\r\n          &amp;lt;mods:language&amp;gt;\r\n            &amp;lt;mods:languageTerm authority=\&amp;quot;rfc3066\&amp;quot; type=\&amp;quot;code\&amp;quot;&amp;gt;fr&amp;lt;/mods:languageTerm&amp;gt;\r\n ....&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As usual when you import text files like this, it’s always a good idea to split the file. I will
split at the &lt;code&gt;&#34;DMDID&#34;&lt;/code&gt; character. Take a look back at the second screenshot. The very first tag,
first row, first word after &lt;code&gt;div&lt;/code&gt; is &lt;code&gt;&#34;DMDID&#34;&lt;/code&gt;. By splitting at this level, I will get back a list,
where each element is the content of this &lt;code&gt;div DMDID&lt;/code&gt; block. This is exactly what I need, since
this block contains the information from the green rectangles.
So let’s split the &lt;code&gt;mets&lt;/code&gt; variable at this level:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mets_articles &amp;lt;- mets %&amp;gt;%
    str_split(&amp;quot;DMDID&amp;quot;) %&amp;gt;%
    flatten_chr()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;mets_articles&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(mets_articles)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; chr [1:25] &amp;quot;&amp;lt;?xml version=&amp;#39;1.0&amp;#39; encoding=&amp;#39;utf-8&amp;#39;?&amp;gt;\r\n&amp;lt;mets xmlns=\&amp;quot;http://www.loc.gov/METS/\&amp;quot; xmlns:mix=\&amp;quot;http://www.loc.g&amp;quot;| __truncated__ ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doesn’t seem to be very helpful, but actually it is. We can see that &lt;code&gt;mets_articles&lt;/code&gt; is a now a list
of 25 elements.&lt;/p&gt;
&lt;p&gt;This means that for each element of &lt;code&gt;mets_articles&lt;/code&gt;, I need to get the identifier, the label, the type
(the red rectangles from the screenshot), but also the information from the &lt;code&gt;&#34;BEGIN&#34;&lt;/code&gt; element (the green
rectangle).&lt;/p&gt;
&lt;p&gt;To do this, I’ll be using regular expressions. In general, I start by experimenting in the console,
and then when things start looking good, I write a function. Here is this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extractor &amp;lt;- function(string, regex, all = FALSE){
    if(all) {
        string %&amp;gt;%
            str_extract_all(regex) %&amp;gt;%
            flatten_chr() %&amp;gt;%
            str_extract_all(&amp;quot;[:alnum:]+&amp;quot;, simplify = FALSE) %&amp;gt;%
            map(paste, collapse = &amp;quot;_&amp;quot;) %&amp;gt;%
            flatten_chr()
    } else {
        string %&amp;gt;%
            str_extract(regex) %&amp;gt;%
            str_extract_all(&amp;quot;[:alnum:]+&amp;quot;, simplify = TRUE) %&amp;gt;%
            paste(collapse = &amp;quot; &amp;quot;) %&amp;gt;%
            tolower()
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function may seem complicated, but it simply encapsulates some pretty standard steps to get
the data I need. I had to consider two cases. The first case is when I need to extract all the
elements with &lt;code&gt;str_extract_all()&lt;/code&gt;, or only the first occurrence, with &lt;code&gt;str_extract()&lt;/code&gt;.
Let’s test it on the first article of the &lt;code&gt;mets_articles&lt;/code&gt; list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mets_articles_1 &amp;lt;- mets_articles[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extractor(mets_articles_1, &amp;quot;ID&amp;quot;, all = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;id&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what happens with &lt;code&gt;all = TRUE&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extractor(mets_articles_1, &amp;quot;ID&amp;quot;, all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   [1] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [15] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [29] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [43] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [57] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [71] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [85] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
##  [99] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
## [113] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;
## [127] &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;ID&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems to work as intended. Since I need to call this function several times, I’ll be writing
another function that extracts all I need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_mets &amp;lt;- function(article){

    id &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=ID)(.*?)(?=LABEL)&amp;quot;)

    label &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=LABEL)(.*?)(?=TYPE)&amp;quot;)

    type &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=TYPE)(.*?)(?=&amp;gt;)&amp;quot;)

    begins &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=BEGIN)(.*?)(?=BETYPE)&amp;quot;, all = TRUE)

    tibble::tribble(~label, ~type, ~begins, ~id,
                    label, type, begins, id) %&amp;gt;%
        unnest()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function uses complex regular expressions to extract the strings I need, and then puts
the result into a data frame, with the &lt;code&gt;tibble()&lt;/code&gt; function. I then use &lt;code&gt;unnest()&lt;/code&gt;, because &lt;code&gt;label&lt;/code&gt;,
&lt;code&gt;type&lt;/code&gt;, &lt;code&gt;begins&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt; are not the same length. &lt;code&gt;label&lt;/code&gt;, &lt;code&gt;type&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt; are of length 1, while
&lt;code&gt;begins&lt;/code&gt; is longer. This means that when I put them into a data frame it looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tribble(~a, ~b,
&amp;quot;a&amp;quot;, rep(&amp;quot;b&amp;quot;, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   a     b        
##   &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt;   
## 1 a     &amp;lt;chr [4]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;unnest()&lt;/code&gt;, I get a nice data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tribble(~a, ~b,
&amp;quot;a&amp;quot;, rep(&amp;quot;b&amp;quot;, 4)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   a     b    
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 a     b    
## 2 a     b    
## 3 a     b    
## 4 a     b&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I simply need to map this function to all the files and that’s it! For this, I will write yet
another helper function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mets_csv &amp;lt;- function(page_path){
    
    page &amp;lt;- read_file(page_path)
    
    doc_name &amp;lt;- str_extract(page_path, &amp;quot;(?&amp;lt;=/).*&amp;quot;)
    
    mets_articles &amp;lt;- page %&amp;gt;%
        str_split(&amp;quot;DMDID&amp;quot;) %&amp;gt;%
        flatten_chr()
    
    mets_df &amp;lt;- map_df(mets_articles, extract_mets)
    
    mets_df &amp;lt;- mets_df %&amp;gt;%
        mutate(document = doc_name)
    
    write_csv(mets_df, paste0(page_path, &amp;quot;.csv&amp;quot;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes the path to a METS file as input, and processes it using the steps I explained
above. The only difference is that I add a column containing the name of the file that was processed,
and write the resulting data frame directly to disk as a data frame. Finally, I can map this function to all the METS
files:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract content from METS files

pages_mets &amp;lt;- str_match(list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE), &amp;quot;.*mets.xml&amp;quot;) %&amp;gt;%
    discard(is.na)

library(furrr)

plan(multiprocess, workers = 8)

tic &amp;lt;- Sys.time()
future_map(pages_mets, mets_csv)
toc &amp;lt;- Sys.time()

toc - tic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I use &lt;code&gt;{furrr}&lt;/code&gt; to extract the data from all the files in parallel, by putting 8 cores of my CPU to
work. This took around 3 minutes and 20 seconds to finish.&lt;/p&gt;
&lt;p&gt;That’s it for now, stay tuned for part 2 where I will analyze this fresh data!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_alto &amp;lt;- function(article){
    begins &amp;lt;- article[1] %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=^ID)(.*?)(?=HPOS)&amp;quot;, all = TRUE)

    content &amp;lt;- article %&amp;gt;%
        extractor(&amp;quot;(?&amp;lt;=CONTENT)(.*?)(?=WC)&amp;quot;, all = TRUE)

    tibble::tribble(~begins, ~content,
                    begins, content) %&amp;gt;%
        unnest()
}

alto_csv &amp;lt;- function(page_path){

    page &amp;lt;- read_file(page_path)

    doc_name &amp;lt;- str_extract(page_path, &amp;quot;(?&amp;lt;=/text/).*&amp;quot;)

    alto_articles &amp;lt;- page %&amp;gt;%
        str_split(&amp;quot;TextBlock &amp;quot;) %&amp;gt;%
        flatten_chr()

    alto_df &amp;lt;- map_df(alto_articles, extract_alto)

    alto_df &amp;lt;- alto_df %&amp;gt;%
        mutate(document = doc_name)

    write_csv(alto_df, paste0(page_path, &amp;quot;.csv&amp;quot;))
}


alto &amp;lt;- read_file(&amp;quot;1533660_newspaper_lunion_1860-11-14/text/1860-11-14_01-00001.xml&amp;quot;)


# Extract content from alto files

pages_alto &amp;lt;- str_match(list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE), &amp;quot;.*/text/.*.xml&amp;quot;) %&amp;gt;%
    discard(is.na)


library(furrr)

plan(multiprocess, workers = 8)

tic &amp;lt;- Sys.time()
future_map(pages_alto, alto_csv)
toc &amp;lt;- Sys.time()

toc - tic

#Time difference of 18.64776 mins&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Looking into 19th century ads from a Luxembourguish newspaper with R</title>
      <link>https://www.brodrigues.co/blog/2019-01-04-newspapers/</link>
      <pubDate>Fri, 04 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2019-01-04-newspapers/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0xzN6FM5x_E&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/Wales.jpg&#34; title = &#34;Sometimes ads are better than this. Especially if it&#39;s Flex Tape ® ads.&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;a href=&#34;https://data.bnl.lu/data/historical-newspapers/&#34;&gt;national library of Luxembourg&lt;/a&gt; published
some very interesting data sets; scans of historical newspapers! There are several data sets that
you can download, from 250mb up to 257gb. I decided to take a look at the 32gb “ML Starter Pack”.
It contains high quality scans of one year of the &lt;em&gt;L’indépendence Luxembourgeoise&lt;/em&gt; (Luxembourguish
independence) from the year 1877. To make life easier to data scientists, the national library
also included ALTO and METS files (which is a XML schema that is used to describe the layout and
contents of physical text sources, such as pages of a book or newspaper) which can be easily parsed
by R.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;L’indépendence Luxembourgeoise&lt;/em&gt; is quite interesting in that it is a Luxembourguish newspaper written
in French. Luxembourg always had 3 languages that were used in different situations, French, German
and Luxembourguish. Luxembourguish is the language people used (and still use) for day to day life
and to speak to their baker.
Historically however, it was not used for the press or in politics. Instead it was German that
was used for the press (or so I thought) and French in politics (only in
&lt;a href=&#34;http://legilux.public.lu/eli/etat/leg/loi/1984/02/24/n1/jo&#34;&gt;1984&lt;/a&gt; was Luxembourguish made
an official Language of Luxembourg).
It turns out however that &lt;em&gt;L’indépendence Luxembourgeoise&lt;/em&gt;, a daily newspaper that does not exist
anymore, was in French. This piqued my interest, and it also made analysis easier, for 2 reasons:
I first started with the &lt;em&gt;Luxemburger Wort&lt;/em&gt; (Luxembourg’s Word I guess would be a translation), which
still exists today, but which is in German. And at that time, German was written using the Fraktur
font, which makes it barely readable. Look at the alphabet in Fraktur:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;𝕬 𝕭 𝕮 𝕯 𝕰 𝕱 𝕲 𝕳 𝕴 𝕵 𝕶 𝕷 𝕸 𝕹 𝕺 𝕻 𝕼 𝕽 𝕾 𝕿 𝖀 𝖁 𝖂 𝖃 𝖄 𝖅
𝖆 𝖇 𝖈 𝖉 𝖊 𝖋 𝖌 𝖍 𝖎 𝖏 𝖐 𝖑 𝖒 𝖓 𝖔 𝖕 𝖖 𝖗 𝖘 𝖙 𝖚 𝖛 𝖜 𝖝 𝖞 𝖟&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s not like German is already hard enough, they had to invent the least readable font ever to write
German in, to make extra sure it would be hell to decipher.&lt;/p&gt;
&lt;p&gt;So basically I couldn’t be bothered to try to read a German newspaper in Fraktur. That’s when I noticed
the &lt;em&gt;L’indépendence Luxembourgeoise&lt;/em&gt;… A Luxembourguish newspaper? Written in French? Sounds
interesting.&lt;/p&gt;
&lt;p&gt;And oh boy. Interesting it was.&lt;/p&gt;
&lt;p&gt;19th century newspapers articles were something else. There’s this article for instance:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/pray%20for%20senators.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;For those of you that do not read French, this article relates that in France, the ministry of
justice required priests to include prayers on the Sunday that follows the start of the new season
of parliamentary discussions, in order for God to provide senators his help.&lt;/p&gt;
&lt;p&gt;There this gem too:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/tallest_soldier.jpg&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This article presents the tallest soldier of the German army, called Emhke, and nominated by the
German Emperor himself to accompany him during his visit to Palestine. Emhke was 2.08 meters tall
and weighted 236 pounds (apparently at the time Luxembourg was not fully sold on the metric system).&lt;/p&gt;
&lt;p&gt;Anyway, I decided to take a look at ads. The last paper of this 4 page newspaper always contained
ads and other announcements. For example, there’s this ad for a pharmacy:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/pharmacy.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;that sells tea, and mineral water. Yes, tea and mineral water. In a pharmacy. Or this one:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/upside_down.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;which is literally upside down in the newspaper (the one from the 10th of April 1877). I don’t
know if it’s a mistake or if it’s a marketing ploy, but it did catch my attention, 140 years later,
so &lt;em&gt;bravo&lt;/em&gt;. This is an announcement made by a shop owner that wants to sell all his merchandise
for cheap, perhaps to make space for new stuff coming in?&lt;/p&gt;
&lt;p&gt;So I decided brush up on my natural language processing skills with R and do topic modeling on these ads.
The challenge here is that a single document, the 4th page of the newspaper, contains a lot of ads.
So it will probably be difficult to clearly isolate topics. But let’s try nonetheless.
First of all, let’s load all the &lt;code&gt;.xml&lt;/code&gt; files that contain the data. These files look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;TextLine ID=&amp;quot;LINE6&amp;quot; STYLEREFS=&amp;quot;TS11&amp;quot; HEIGHT=&amp;quot;42&amp;quot; WIDTH=&amp;quot;449&amp;quot; HPOS=&amp;quot;165&amp;quot; VPOS=&amp;quot;493&amp;quot;&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S16&amp;quot; CONTENT=&amp;quot;l’après-midi,&amp;quot; WC=&amp;quot;0.638&amp;quot; CC=&amp;quot;0803367024653&amp;quot; HEIGHT=&amp;quot;42&amp;quot; WIDTH=&amp;quot;208&amp;quot; HPOS=&amp;quot;165&amp;quot; VPOS=&amp;quot;493&amp;quot;/&amp;gt;
                                    &amp;lt;SP ID=&amp;quot;SP11&amp;quot; WIDTH=&amp;quot;24&amp;quot; HPOS=&amp;quot;373&amp;quot; VPOS=&amp;quot;493&amp;quot;/&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S17&amp;quot; CONTENT=&amp;quot;le&amp;quot; WC=&amp;quot;0.8&amp;quot; CC=&amp;quot;40&amp;quot; HEIGHT=&amp;quot;30&amp;quot; WIDTH=&amp;quot;29&amp;quot; HPOS=&amp;quot;397&amp;quot; VPOS=&amp;quot;497&amp;quot;/&amp;gt;
                                    &amp;lt;SP ID=&amp;quot;SP12&amp;quot; WIDTH=&amp;quot;14&amp;quot; HPOS=&amp;quot;426&amp;quot; VPOS=&amp;quot;497&amp;quot;/&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S18&amp;quot; CONTENT=&amp;quot;Gouverne&amp;quot; WC=&amp;quot;0.638&amp;quot; CC=&amp;quot;72370460&amp;quot; HEIGHT=&amp;quot;31&amp;quot; WIDTH=&amp;quot;161&amp;quot; HPOS=&amp;quot;440&amp;quot; VPOS=&amp;quot;496&amp;quot; SUBS_TYPE=&amp;quot;HypPart1&amp;quot; SUBS_CONTENT=&amp;quot;Gouvernement&amp;quot;/&amp;gt;
                                    &amp;lt;HYP CONTENT=&amp;quot;-&amp;quot; WIDTH=&amp;quot;11&amp;quot; HPOS=&amp;quot;603&amp;quot; VPOS=&amp;quot;514&amp;quot;/&amp;gt;
                                  &amp;lt;/TextLine&amp;gt;
                        &amp;lt;TextLine ID=&amp;quot;LINE7&amp;quot; STYLEREFS=&amp;quot;TS11&amp;quot; HEIGHT=&amp;quot;41&amp;quot; WIDTH=&amp;quot;449&amp;quot; HPOS=&amp;quot;166&amp;quot; VPOS=&amp;quot;541&amp;quot;&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S19&amp;quot; CONTENT=&amp;quot;ment&amp;quot; WC=&amp;quot;0.725&amp;quot; CC=&amp;quot;0074&amp;quot; HEIGHT=&amp;quot;26&amp;quot; WIDTH=&amp;quot;81&amp;quot; HPOS=&amp;quot;166&amp;quot; VPOS=&amp;quot;545&amp;quot; SUBS_TYPE=&amp;quot;HypPart2&amp;quot; SUBS_CONTENT=&amp;quot;Gouvernement&amp;quot;/&amp;gt;
                                    &amp;lt;SP ID=&amp;quot;SP13&amp;quot; WIDTH=&amp;quot;24&amp;quot; HPOS=&amp;quot;247&amp;quot; VPOS=&amp;quot;545&amp;quot;/&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S20&amp;quot; CONTENT=&amp;quot;Royal&amp;quot; WC=&amp;quot;0.62&amp;quot; CC=&amp;quot;74503&amp;quot; HEIGHT=&amp;quot;41&amp;quot; WIDTH=&amp;quot;100&amp;quot; HPOS=&amp;quot;271&amp;quot; VPOS=&amp;quot;541&amp;quot;/&amp;gt;
                                    &amp;lt;SP ID=&amp;quot;SP14&amp;quot; WIDTH=&amp;quot;26&amp;quot; HPOS=&amp;quot;371&amp;quot; VPOS=&amp;quot;541&amp;quot;/&amp;gt;
                                    &amp;lt;String ID=&amp;quot;S21&amp;quot; CONTENT=&amp;quot;Grand-Ducal&amp;quot; WC=&amp;quot;0.682&amp;quot; CC=&amp;quot;75260334005&amp;quot; HEIGHT=&amp;quot;32&amp;quot; WIDTH=&amp;quot;218&amp;quot; HPOS=&amp;quot;397&amp;quot; VPOS=&amp;quot;541&amp;quot;/&amp;gt;
                                  &amp;lt;/TextLine&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m interested in the “CONTENT” tag, which contains the words. Let’s first get that into R.&lt;/p&gt;
&lt;p&gt;Load the packages, and the files:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidytext)
library(topicmodels)
library(brotools)

ad_pages &amp;lt;- str_match(list.files(path = &amp;quot;./&amp;quot;, all.files = TRUE, recursive = TRUE), &amp;quot;.*4-alto.xml&amp;quot;) %&amp;gt;%
    discard(is.na)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I save the path of all the pages at once into the &lt;code&gt;ad_pages&lt;/code&gt; variables. To understand how and why
this works, you must take a look at the hierarchy of the folder:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/layout.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Inside each of these folder, there is a &lt;code&gt;text&lt;/code&gt; folder, and inside this folder there are the &lt;code&gt;.xml&lt;/code&gt;
files. Because this structure is bit complex, I use the &lt;code&gt;list.files()&lt;/code&gt; function with the
&lt;code&gt;all.files&lt;/code&gt; and &lt;code&gt;recursive&lt;/code&gt; argument set to &lt;code&gt;TRUE&lt;/code&gt; which allow me to dig deep into the folder
structure and list every single file. I am only interested into the 4th page though, so that’s why
I use &lt;code&gt;str_match()&lt;/code&gt; to only keep the 4th page using the &lt;code&gt;&#34;.*4-alto.xml&#34;&lt;/code&gt; regular expression. This
is the right regular expression, because the files are named like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1877-12-29_01-00004-alto.xml&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So in the end, &lt;code&gt;ad_pages&lt;/code&gt; is a list of all the paths to these files. I then write a function
to extract the contents of the “CONTENT” tag. Here is the function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_words &amp;lt;- function(page_path){
    
    page &amp;lt;- read_file(page_path)
    
    page_name &amp;lt;- str_extract(page_path, &amp;quot;1.*(?=-0000)&amp;quot;) 
    
    page %&amp;gt;%  
        str_split(&amp;quot;\n&amp;quot;, simplify = TRUE) %&amp;gt;% 
        keep(str_detect(., &amp;quot;CONTENT&amp;quot;)) %&amp;gt;% 
        str_extract(&amp;quot;(?&amp;lt;=CONTENT)(.*?)(?=WC)&amp;quot;) %&amp;gt;% 
        discard(is.na) %&amp;gt;% 
        str_extract(&amp;quot;[:alpha:]+&amp;quot;) %&amp;gt;% 
        tolower %&amp;gt;% 
        as_tibble %&amp;gt;% 
        rename(tokens = value) %&amp;gt;% 
        mutate(page = page_name)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes the path to a page as argument, and returns a tibble with the two columns: one
containing the words, which I called &lt;code&gt;tokens&lt;/code&gt; and the second the name of the document this word
was found. I uploaded on &lt;code&gt;.xml&lt;/code&gt; file
&lt;a href=&#34;https://gist.github.com/b-rodrigues/a22d2aa63dff01d88acc2916c003489d&#34;&gt;here&lt;/a&gt;
so that you can try the function yourself. The difficult part is &lt;code&gt;str_extract(&#34;(?&amp;lt;=CONTENT)(.*?)(?=WC)&#34;)&lt;/code&gt;
which is were the words inside the “CONTENT” tag get extracted.&lt;/p&gt;
&lt;p&gt;I then map this function to all the pages, and get a nice tibble with all the words:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ad_words &amp;lt;- map_dfr(ad_pages, get_words)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ad_words&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,114,662 x 2
##    tokens     page                            
##    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                           
##  1 afin       1877-01-05_01/text/1877-01-05_01
##  2 de         1877-01-05_01/text/1877-01-05_01
##  3 mettre     1877-01-05_01/text/1877-01-05_01
##  4 mes        1877-01-05_01/text/1877-01-05_01
##  5 honorables 1877-01-05_01/text/1877-01-05_01
##  6 clients    1877-01-05_01/text/1877-01-05_01
##  7 à          1877-01-05_01/text/1877-01-05_01
##  8 même       1877-01-05_01/text/1877-01-05_01
##  9 d          1877-01-05_01/text/1877-01-05_01
## 10 avantages  1877-01-05_01/text/1877-01-05_01
## # … with 1,114,652 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then do some further cleaning, removing stop words (French and German, because there are some
ads in German) and a bunch of garbage characters and words, which are probably when the OCR failed.
I also remove some German words from the few German ads that are in the paper, because they have
a very high tf-idf (I’ll explain below what that is).
I also remove very common words in ads that were just like stopwords. Every ad of a shop mentioned their
clients with &lt;em&gt;honorable clientèle&lt;/em&gt;, or used the word &lt;em&gt;vente&lt;/em&gt;, and so on. This is what you see below
in the very long calls to &lt;code&gt;str_remove_all&lt;/code&gt;. I also compute the &lt;code&gt;tf_idf&lt;/code&gt; and I am grateful to
ThinkR blog post on that, which you can read &lt;a href=&#34;https://thinkr.fr/text-mining-et-topic-modeling-avec-r/&#34;&gt;here&lt;/a&gt;.
It’s in French though, but the idea of the blog post is to present topic modeling with Wikipedia
articles. You can also read the section on tf-idf from the Text Mining with R ebook, &lt;a href=&#34;https://www.tidytextmining.com/tfidf.html&#34;&gt;here&lt;/a&gt;.
tf-idf gives a measure of how common words are. Very common words, like stopwords, have a tf-idf
of 0. So I use this to further remove very common words, by only keeping words with a tf-idf
greater than 0.01. This is why I manually remove garbage words and German words below, because they
are so uncommon that they have a very high tf-idf and mess up the rest of the analysis. To find these words
I had to go back and forth between the tibble of cleaned words and my code, and manually add all
these exceptions. It took some time, but definitely made the results of the next steps better.&lt;br /&gt;
I then use &lt;code&gt;cast_dtm&lt;/code&gt; to cast the tibble into a DocumentTermMatrix object, which
is needed for the &lt;code&gt;LDA()&lt;/code&gt; function that does the topic modeling:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stopwords_fr &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/stopwords-iso/stopwords-fr/master/stopwords-fr.txt&amp;quot;,
                         col_names = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   X1 = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stopwords_de &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/stopwords-iso/stopwords-de/master/stopwords-de.txt&amp;quot;,
                         col_names = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   X1 = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 1 parsing failure.
## row col  expected    actual                                                                                   file
## 157  -- 1 columns 2 columns &amp;#39;https://raw.githubusercontent.com/stopwords-iso/stopwords-de/master/stopwords-de.txt&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ad_words2 &amp;lt;- ad_words %&amp;gt;% 
    filter(!is.na(tokens)) %&amp;gt;% 
    mutate(tokens = str_remove_all(tokens, 
                                   &amp;#39;[|\\|!|&amp;quot;|#|$|%|&amp;amp;|\\*|+|,|-|.|/|:|;|&amp;lt;|=|&amp;gt;|?|@|^|_|`|’|\&amp;#39;|‘|(|)|\\||~|=|]|°|&amp;lt;|&amp;gt;|«|»|\\d{1,100}|©|®|•|—|„|“|-|¦\\\\|”&amp;#39;)) %&amp;gt;%
    mutate(tokens = str_remove_all(tokens,
                                   &amp;quot;j&amp;#39;|j’|m’|m&amp;#39;|n’|n&amp;#39;|c’|c&amp;#39;|qu’|qu&amp;#39;|s’|s&amp;#39;|t’|t&amp;#39;|l’|l&amp;#39;|d’|d&amp;#39;|luxembourg|honneur|rue|prix|maison|frs|ber|adresser|unb|mois|vente|informer|sann|neben|rbudj|artringen|salz|eingetragen|ort|ftofjenb|groifdjen|ort|boch|chem|jahrgang|uoa|genannt|neuwahl|wechsel|sittroe|yerlorenkost|beichsmark|tttr|slpril|ofto|rbudj|felben|acferftücf|etr|eft|sbege|incl|estce|bes|franzosengrund|qne|nne|mme|qni|faire|id|kil&amp;quot;)) %&amp;gt;%
    anti_join(stopwords_de, by = c(&amp;quot;tokens&amp;quot; = &amp;quot;X1&amp;quot;)) %&amp;gt;% 
    filter(!str_detect(tokens, &amp;quot;§&amp;quot;)) %&amp;gt;% 
    mutate(tokens = ifelse(tokens == &amp;quot;inédite&amp;quot;, &amp;quot;inédit&amp;quot;, tokens)) %&amp;gt;% 
    filter(tokens != &amp;quot;&amp;quot;) %&amp;gt;% 
    anti_join(stopwords_fr, by = c(&amp;quot;tokens&amp;quot; = &amp;quot;X1&amp;quot;)) %&amp;gt;% 
    count(page, tokens) %&amp;gt;% 
    bind_tf_idf(tokens, page, n) %&amp;gt;% 
    arrange(desc(tf_idf))

dtm_long &amp;lt;- ad_words2 %&amp;gt;% 
    filter(tf_idf &amp;gt; 0.01) %&amp;gt;% 
    cast_dtm(page, tokens, n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To read more details on this, I suggest you take a look at the following section of the
Text Mining with R ebook: &lt;a href=&#34;https://www.tidytextmining.com/topicmodeling.html#latent-dirichlet-allocation&#34;&gt;Latent Dirichlet Allocation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I choose to model 10 topics (&lt;code&gt;k = 10&lt;/code&gt;), and set the &lt;code&gt;alpha&lt;/code&gt; parameter to 5. This hyperparamater controls how
many topics are present in one document. Since my ads are all in one page (one document), I
increased it. Let’s fit the model, and plot the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lda_model_long &amp;lt;- LDA(dtm_long, k = 10, control = list(alpha = 5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I plot the per-topic-per-word probabilities, the “beta” from the model and plot the 5 words that
contribute the most to each topic:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- tidy(lda_model_long, &amp;quot;beta&amp;quot;)

result %&amp;gt;%
    group_by(topic) %&amp;gt;%
    top_n(5, beta) %&amp;gt;%
    ungroup() %&amp;gt;%
    arrange(topic, -beta) %&amp;gt;% 
    mutate(term = reorder(term, beta)) %&amp;gt;%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = &amp;quot;free&amp;quot;) +
    coord_flip() +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2019-01-04-newspapers_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So some topics seem clear to me, other not at all. For example topic 4 seems to be about shoes made
out of leather. The word &lt;code&gt;semelle&lt;/code&gt;, sole, also appears.
Then there’s a lot of topics that reference either music, bals, or instruments.
I guess these are ads for local music festivals, or similar events. There’s also an ad for what
seems to be bundles of sticks, topic 3: &lt;code&gt;chêne&lt;/code&gt; is oak, &lt;code&gt;copeaux&lt;/code&gt; is shavings and you know
what &lt;code&gt;fagots&lt;/code&gt; is. The first word &lt;code&gt;stère&lt;/code&gt; which I did not know is a unit of volume equal to one
cubic meter (see &lt;a href=&#34;https://en.wikipedia.org/wiki/Stere&#34;&gt;Wikipedia&lt;/a&gt;). So they were likely selling
bundle of oak sticks by the cubic meter. For the other topics, I either
lack context or perhaps I just need to adjust &lt;code&gt;k&lt;/code&gt;, the number of topics to model, and &lt;code&gt;alpha&lt;/code&gt; to get better
results. In the meantime, topic 1 is about shoes (&lt;code&gt;chaussures&lt;/code&gt;), theatre, fuel (&lt;code&gt;combustible&lt;/code&gt;)
and farts (&lt;code&gt;pet&lt;/code&gt;). Really wonder what they were selling in that shop.&lt;/p&gt;
&lt;p&gt;In any case, this was quite an interesting project. I learned a lot about topic modeling
and historical newspapers of my country! I do not know if I will continue exploring it myself,
but I am really curious to see what others will do with it!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R or Python? Why not both? Using Anaconda Python within R with {reticulate}</title>
      <link>https://www.brodrigues.co/blog/2018-12-30-reticulate/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-30-reticulate/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/I8vaCrVIR-Q?t=1h2m26s&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/why not both.png&#34; title = &#34;This literally starts playing when you run both R and Python in the same session&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This short blog post illustrates how easy it is to use R and Python in the same R Notebook thanks to the
&lt;code&gt;{reticulate}&lt;/code&gt; package. For this to work, you might need to upgrade RStudio to the &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/preview/&#34;&gt;current preview version&lt;/a&gt;.
Let’s start by importing &lt;code&gt;{reticulate}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{reticulate}&lt;/code&gt; is an RStudio package that provides “&lt;em&gt;a comprehensive set of tools for interoperability
between Python and R&lt;/em&gt;”. With it, it is possible to call Python and use Python libraries within
an R session, or define Python chunks in R markdown. I think that using R Notebooks is the best way
to work with Python and R; when you want to use Python, you simply use a Python chunk:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{python}
your python code here
```&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s even autocompletion for Python object methods:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/autocompletion.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Fantastic!&lt;/p&gt;
&lt;p&gt;However, if you wish to use Python interactively within your R session, you must start the Python
REPL with the &lt;code&gt;repl_python()&lt;/code&gt; function, which starts a Python REPL. You can then do whatever you
want, even access objects from your R session, and then when you exit the REPL, any object you
created in Python remains accessible in R. I think that using Python this way is a bit more involved
and would advise using R Notebooks if you need to use both languages.&lt;/p&gt;
&lt;p&gt;I installed the Anaconda Python distribution to have Python on my system. To use it with &lt;code&gt;{reticulate}&lt;/code&gt;
I must first use the &lt;code&gt;use_python()&lt;/code&gt; function that allows me to set which version of Python I want
to use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This is an R chunk
use_python(&amp;quot;~/miniconda3/bin/python&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now load a dataset, still using R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This is an R chunk
data(mtcars)
head(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now, to access the &lt;code&gt;mtcars&lt;/code&gt; data frame, I simply use the &lt;code&gt;r&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# This is a Python chunk
print(r.mtcars.describe())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              mpg        cyl        disp   ...            am       gear     carb
## count  32.000000  32.000000   32.000000   ...     32.000000  32.000000  32.0000
## mean   20.090625   6.187500  230.721875   ...      0.406250   3.687500   2.8125
## std     6.026948   1.785922  123.938694   ...      0.498991   0.737804   1.6152
## min    10.400000   4.000000   71.100000   ...      0.000000   3.000000   1.0000
## 25%    15.425000   4.000000  120.825000   ...      0.000000   3.000000   2.0000
## 50%    19.200000   6.000000  196.300000   ...      0.000000   4.000000   2.0000
## 75%    22.800000   8.000000  326.000000   ...      1.000000   4.000000   4.0000
## max    33.900000   8.000000  472.000000   ...      1.000000   5.000000   8.0000
## 
## [8 rows x 11 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;.describe()&lt;/code&gt; is a Python Pandas DataFrame method to get summary statistics of our data. This means that
&lt;code&gt;mtcars&lt;/code&gt; was automatically converted from a &lt;code&gt;tibble&lt;/code&gt; object to a Pandas DataFrame! Let’s check its type:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# This is a Python chunk
print(type(r.mtcars))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s save the summary statistics in a variable:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# This is a Python chunk
summary_mtcars = r.mtcars.describe()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s access this from R, by using the &lt;code&gt;py&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This is an R chunk
class(py$summary_mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try something more complex. Let’s first fit a linear model in Python, and see how R sees it:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# This is a Python chunk
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
model = smf.ols(&amp;#39;mpg ~ hp&amp;#39;, data = r.mtcars).fit()
print(model.summary())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                             OLS Regression Results                            
## ==============================================================================
## Dep. Variable:                    mpg   R-squared:                       0.602
## Model:                            OLS   Adj. R-squared:                  0.589
## Method:                 Least Squares   F-statistic:                     45.46
## Date:                Sun, 10 Feb 2019   Prob (F-statistic):           1.79e-07
## Time:                        00:25:51   Log-Likelihood:                -87.619
## No. Observations:                  32   AIC:                             179.2
## Df Residuals:                      30   BIC:                             182.2
## Df Model:                           1                                         
## Covariance Type:            nonrobust                                         
## ==============================================================================
##                  coef    std err          t      P&amp;gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## Intercept     30.0989      1.634     18.421      0.000      26.762      33.436
## hp            -0.0682      0.010     -6.742      0.000      -0.089      -0.048
## ==============================================================================
## Omnibus:                        3.692   Durbin-Watson:                   1.134
## Prob(Omnibus):                  0.158   Jarque-Bera (JB):                2.984
## Skew:                           0.747   Prob(JB):                        0.225
## Kurtosis:                       2.935   Cond. No.                         386.
## ==============================================================================
## 
## Warnings:
## [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just for fun, I ran the linear regression with the Scikit-learn library too:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# This is a Python chunk
import numpy as np
from sklearn.linear_model import LinearRegression  
regressor = LinearRegression()  
x = r.mtcars[[&amp;quot;hp&amp;quot;]]
y = r.mtcars[[&amp;quot;mpg&amp;quot;]]
model_scikit = regressor.fit(x, y)
print(model_scikit.intercept_)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [30.09886054]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(model_scikit.coef_)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[-0.06822828]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s access the &lt;code&gt;model&lt;/code&gt; variable in R and see what type of object it is in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This is an R chunk
model_r &amp;lt;- py$model
class(model_r)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;statsmodels.regression.linear_model.RegressionResultsWrapper&amp;quot;
## [2] &amp;quot;statsmodels.base.wrapper.ResultsWrapper&amp;quot;                     
## [3] &amp;quot;python.builtin.object&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So because this is a custom Python object, it does not get converted into the equivalent R object.
This is described &lt;a href=&#34;https://rstudio.github.io/reticulate/index.html&#34;&gt;here&lt;/a&gt;. However, you can still
use Python methods from within an R chunk!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This is an R chunk
model_r$aic&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 179.2386&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_r$params&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Intercept          hp 
## 30.09886054 -0.06822828&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I must say that I am very impressed with the &lt;code&gt;{reticulate}&lt;/code&gt; package. I think that even if you are
primarily a Python user, this is still very interesting to know in case you need a specific function
from an R package. Just write all your script inside a Python Markdown chunk and then use the R
function you need from an R chunk! Of course there is also a way to use R from Python, a Python library
called &lt;code&gt;rpy2&lt;/code&gt; but I am not very familiar with it. From what I read, it seems to be also quite
simple to use.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some fun with {gganimate}</title>
      <link>https://www.brodrigues.co/blog/2018-12-27-fun_gganimate/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-27-fun_gganimate/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;video width=&#34;864&#34; height=&#34;480&#34; controls&gt;
&lt;source src=&#34;https://www.brodrigues.co/img/wiid_gganimate.webm&#34; type=&#34;video/webm&#34;&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;In this short blog post I show you how you can use the &lt;code&gt;{gganimate}&lt;/code&gt; package to create animations
from &lt;code&gt;{ggplot2}&lt;/code&gt; graphs with data from UNU-WIDER.&lt;/p&gt;
&lt;div id=&#34;wiid-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;WIID data&lt;/h2&gt;
&lt;p&gt;Just before Christmas, UNU-WIDER released a new edition of their World Income Inequality Database:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;*NEW &lt;a href=&#34;https://twitter.com/hashtag/DATA?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DATA&lt;/a&gt;*&lt;br&gt;We’ve just released a new version of the World Income Inequality Database.&lt;br&gt;WIID4 includes &lt;a href=&#34;https://twitter.com/hashtag/data?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#data&lt;/a&gt; from 7 new countries, now totalling 189, and reaches the year 2017. All data is freely available for download on our website: &lt;a href=&#34;https://t.co/XFxuLvyKTC&#34;&gt;https://t.co/XFxuLvyKTC&lt;/a&gt; &lt;a href=&#34;https://t.co/rCf9eXN8D5&#34;&gt;pic.twitter.com/rCf9eXN8D5&lt;/a&gt;&lt;/p&gt;&amp;mdash; UNU-WIDER (@UNUWIDER) &lt;a href=&#34;https://twitter.com/UNUWIDER/status/1076001879556005888?ref_src=twsrc%5Etfw&#34;&gt;December 21, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;The data is available in Excel and STATA formats, and I thought it was a great opportunity to
release it as an R package. You can install it with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/wiid4&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here a short description of the data, taken from UNU-WIDER’s website:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&#34;The World Income Inequality Database (WIID) presents information on income inequality for
developed, developing, and transition countries. It provides the most comprehensive set of income
inequality statistics available and can be downloaded for free.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;WIID4, released in December 2018, covers 189 countries (including historical entities), with over
11,000 data points in total. With the current version, the latest observations now reach the year 2017.&#34;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It was also a good opportunity to play around with the &lt;code&gt;{gganimate}&lt;/code&gt; package. This package
makes it possible to create animations and is an extension to &lt;code&gt;{ggplot2}&lt;/code&gt;. Read more about it
&lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparing the data&lt;/h2&gt;
&lt;p&gt;To create a smooth animation, I need to have a cylindrical panel data set; meaning that for each
country in the data set, there are no missing years. I also chose to focus on certain variables
only; net income, all the population of the country (instead of just focusing on the economically
active for instance) as well as all the country itself (and not just the rural areas).
On &lt;a href=&#34;https://www.wider.unu.edu/sites/default/files/WIID/PDF/WIID4%20User%20Guide.pdf&#34;&gt;this link&lt;/a&gt; you
can find a codebook (pdf warning), so you can understand the filters I defined below better.&lt;/p&gt;
&lt;p&gt;Let’s first load the packages, data and perform the necessary transformations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wiid4)
library(tidyverse)
library(ggrepel)
library(gganimate)
library(brotools)

small_wiid4 &amp;lt;- wiid4 %&amp;gt;%
    mutate(eu = as.character(eu)) %&amp;gt;%
    mutate(eu = case_when(eu == &amp;quot;1&amp;quot; ~ &amp;quot;EU member state&amp;quot;,
                          eu == &amp;quot;0&amp;quot; ~ &amp;quot;Non-EU member state&amp;quot;)) %&amp;gt;%
    filter(resource == 1, popcovr == 1, areacovr == 1, scale == 2) %&amp;gt;%
    group_by(country) %&amp;gt;%
    group_by(country, year) %&amp;gt;%
    filter(quality_score == max(quality_score)) %&amp;gt;%
    filter(source == min(source)) %&amp;gt;%
    filter(!is.na(bottom5)) %&amp;gt;%
    group_by(country) %&amp;gt;%
    mutate(flag = ifelse(all(seq(2004, 2016) %in% year), 1, 0)) %&amp;gt;%
    filter(flag == 1, year &amp;gt; 2003) %&amp;gt;%
    mutate(year = lubridate::ymd(paste0(year, &amp;quot;-01-01&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For some country and some years, there are several sources of data with varying quality. I only
keep the highest quality sources with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    group_by(country, year) %&amp;gt;%
    filter(quality_score == max(quality_score)) %&amp;gt;%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If there are different sources of equal quality, I give priority to the sources that are the most
comparable across country (Luxembourg Income Study, LIS data) to less comparable sources with
(at least that’s my understanding of the &lt;code&gt;source&lt;/code&gt; variable):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    filter(source == min(source)) %&amp;gt;%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then remove missing data with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    filter(!is.na(bottom5)) %&amp;gt;%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;bottom5&lt;/code&gt; and &lt;code&gt;top5&lt;/code&gt; give the share of income that is controlled by the bottom 5% and top 5%
respectively. These are the variables that I want to plot.&lt;/p&gt;
&lt;p&gt;Finally I keep the years 2004 to 2016, without any interruption with the following line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    mutate(flag = ifelse(all(seq(2004, 2016) %in% year), 1, 0)) %&amp;gt;%
    filter(flag == 1, year &amp;gt; 2003) %&amp;gt;%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ifelse(all(seq(2004, 2016) %in% year), 1, 0))&lt;/code&gt; creates a flag that equals &lt;code&gt;1&lt;/code&gt; only if the years
2004 to 2016 are present in the data without any interruption. Then I only keep the data from 2004
on and only where the flag variable equals 1.&lt;/p&gt;
&lt;p&gt;In the end, I ended up only with European countries. It would have been interesting to have countries
from other continents, but apparently only European countries provide data in an annual basis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-animation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the animation&lt;/h2&gt;
&lt;p&gt;To create the animation I first started by creating a static ggplot showing what I wanted;
a scatter plot of the income by bottom and top 5%. The size of the bubbles should be proportional
to the GDP of the country (another variable provided in the data). Once the plot looked how I wanted
I added the lines that are specific to &lt;code&gt;{gganimate}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    labs(title = &amp;#39;Year: {frame_time}&amp;#39;, x = &amp;#39;Top 5&amp;#39;, y = &amp;#39;Bottom 5&amp;#39;) +
    transition_time(year) +
    ease_aes(&amp;#39;linear&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I took this from &lt;code&gt;{gganimate}&lt;/code&gt;’s README.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animation &amp;lt;- ggplot(small_wiid4) +
    geom_point(aes(y = bottom5, x = top5, colour = eu, size = log(gdp_ppp_pc_usd2011))) +
    xlim(c(10, 20)) +
    geom_label_repel(aes(y = bottom5, x = top5, label = country), hjust = 1, nudge_x = 20) +
    theme(legend.position = &amp;quot;bottom&amp;quot;) +
    theme_blog() +
    scale_color_blog() +
    labs(title = &amp;#39;Year: {frame_time}&amp;#39;, x = &amp;#39;Top 5&amp;#39;, y = &amp;#39;Bottom 5&amp;#39;) +
    transition_time(year) +
    ease_aes(&amp;#39;linear&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I use &lt;code&gt;geom_label_repel&lt;/code&gt; to place the countries’ labels on the right of the plot. If I don’t do
this, the labels of the countries would be floating around and the animation would be unreadable.&lt;/p&gt;
&lt;p&gt;I then spent some time trying to render a nice webm instead of a gif. It took some trial and error
and I am still not entirely satisfied with the result, but here is the code to render the animation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animate(animation, renderer = ffmpeg_renderer(options = list(s = &amp;quot;864x480&amp;quot;, 
                                                             vcodec = &amp;quot;libvpx-vp9&amp;quot;,
                                                             crf = &amp;quot;15&amp;quot;,
                                                             b = &amp;quot;1600k&amp;quot;, 
                                                             vf = &amp;quot;setpts=5*PTS&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The option &lt;code&gt;vf = &#34;setpts=5*PTS&#34;&lt;/code&gt; is important because it slows the video down, so we can actually
see something. &lt;code&gt;crf = &#34;15&#34;&lt;/code&gt; is the quality of the video (lower is better), &lt;code&gt;b = &#34;1600k&#34;&lt;/code&gt; is the
bitrate, and &lt;code&gt;vcodec = &#34;libvpx-vp9&#34;&lt;/code&gt; is the codec I use. The video you saw at the top of this
post is the result. You can also find the video &lt;a href=&#34;https://raw.githubusercontent.com/rbind/b-rodrigues.github.com/master/static/img/wiid_gganimate.webm&#34;&gt;here&lt;/a&gt;,
and here’s a gif if all else fails:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3zXx0ReqOOI&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wiid_gganimate_gif.gif&#34; title = &#34;Click to listen to OST of this gif&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I would have preferred if the video was smoother, which should be possible by creating more frames.
I did not find such an option in &lt;code&gt;{gganimate}&lt;/code&gt;, and perhaps there is none, at least for now.&lt;/p&gt;
&lt;p&gt;In any case &lt;code&gt;{gganimate}&lt;/code&gt; is pretty nice to play with, and I’ll definitely use it more!&lt;/p&gt;
&lt;div id=&#34;update&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Update&lt;/h3&gt;
&lt;p&gt;Silly me! It turns out thate the &lt;code&gt;animate()&lt;/code&gt; function has arguments that can control the number of frames
and the duration, without needing to pass options to the renderer. I was looking at options for the
renderer only, without having read the documentation of the &lt;code&gt;animate()&lt;/code&gt; function. It turns out that
you can pass several arguments to the &lt;code&gt;animate()&lt;/code&gt; function; for example, here is how you
can make a GIF that lasts for 20 seconds running and 20 frames per second, pausing for 5
frames at the end and then restarting:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animate(animation, nframes = 400, duration = 20, fps = 20, end_pause = 5, rewind = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I guess that you should only pass options to the renderer if you really need fine-grained control.&lt;/p&gt;
&lt;p&gt;This took around 2 minutes to finish. You can use the same options with the ffmpeg renderer too.
Here is what the gif looks like:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3zXx0ReqOOI&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/wiid_gganimate_gif_smooth.gif&#34; title = &#34;Click to listen to OST of this gif&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Much, much smoother!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Objects types and some useful R functions for beginners</title>
      <link>https://www.brodrigues.co/blog/2018-12-24-modern_objects/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-24-modern_objects/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=M-1nTwiHxic&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/santa_sanders.jpg&#34; title = &#34;The frydiest time of the year&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;p&gt;This blog post is an excerpt of my ebook &lt;em&gt;Modern R with the tidyverse&lt;/em&gt; that you can read for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;. This is taken from Chapter 2, which explains
the different R objects you can manipulate as well as some functions to get you started.&lt;/p&gt;
&lt;div id=&#34;objects-types-and-useful-r-functions-to-get-started&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Objects, types and useful R functions to get started&lt;/h2&gt;
&lt;p&gt;All objects in R have a given &lt;em&gt;type&lt;/em&gt;. You already know most of them, as these types are also used
in mathematics. Integers, floating point numbers, or floats, matrices, etc, are all objects you
are already familiar with. But R has other, maybe lesser known data types (that you can find in a
lot of other programming languages) that you need to become familiar with. But first, we need to
learn how to assign a value to a variable. This can be done in two ways:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a = 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in very practical terms, there is no difference between the two. I prefer using &lt;code&gt;&amp;lt;-&lt;/code&gt; for assigning
values to variables and reserve &lt;code&gt;=&lt;/code&gt; for passing arguments to functions, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spam &amp;lt;- mean(x = c(1,2,3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this is less confusing than:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spam = mean(x = c(1,2,3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but as I explained above you can use whatever you feel most comfortable with.&lt;/p&gt;
&lt;div id=&#34;the-numeric-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;numeric&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;To define single numbers, you can do the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;class()&lt;/code&gt; function allows you to check the class of an object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Decimals are defined with the character &lt;code&gt;.&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 3.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R also supports integers. If you find yourself in a situation where you explicitly need an integer
and not a floating point number, you can use the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a  &amp;lt;- as.integer(3)
class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;as.integer()&lt;/code&gt; function is very useful, because it converts its argument into an integer. There
is a whole family of &lt;code&gt;as.*()&lt;/code&gt; functions. To convert &lt;code&gt;a&lt;/code&gt; into a floating point number again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as.numeric(a))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is also &lt;code&gt;is.numeric()&lt;/code&gt; which tests whether a number is of the &lt;code&gt;numeric&lt;/code&gt; class:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;is.numeric(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These functions are very useful, there is one for any of the supported types in R. Later, we are going
to learn about the &lt;code&gt;{purrr}&lt;/code&gt; package, which is a very powerful package for functional programming. This
package includes further such functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-character-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;character&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;Use &lt;code&gt;&#34; &#34;&lt;/code&gt; to define characters (called strings in other programming languages):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- &amp;quot;this is a string&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To convert something to a character you can use the &lt;code&gt;as.character()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 4.392

class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as.character(a))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to convert a character to a numeric:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- &amp;quot;4.392&amp;quot;

class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as.numeric(a))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this only works if it makes sense:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- &amp;quot;this won&amp;#39;t work, chief&amp;quot;

class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A very nice package to work with characters is &lt;code&gt;{stringr}&lt;/code&gt;, which is also part of the &lt;code&gt;{tidyverse}&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-factor-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;factor&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;Factors look like characters, but are very different. They are the representation of categorical
variables. A &lt;code&gt;{tidyverse}&lt;/code&gt; package to work with factors is &lt;code&gt;{forcats}&lt;/code&gt;. You would rarely use
factor variables outside of datasets, so for now, it is enough to know that this class exists.
We are going to learn more about factor variables in Chapter 4, by using the &lt;code&gt;{forcats}&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-date-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;Date&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;Dates also look like characters, but are very different too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.Date(&amp;quot;2019/03/19&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2019-03-19&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as.Date(&amp;quot;2019/03/19&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Manipulating dates and time can be tricky, but thankfully there’s a &lt;code&gt;{tidyverse}&lt;/code&gt; package for that,
called &lt;code&gt;{lubridate}&lt;/code&gt;. We are going to go over this package in Chapter 4.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-logical-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;logical&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;This class is the result of logical comparisons, for example, if you type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;4 &amp;gt; 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R returns &lt;code&gt;TRUE&lt;/code&gt;, which is an object of class &lt;code&gt;logical&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- 4 &amp;gt; 3
class(k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;logical&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other programming languages, &lt;code&gt;logical&lt;/code&gt;s are often called &lt;code&gt;bool&lt;/code&gt;s. A &lt;code&gt;logical&lt;/code&gt; variable can only have
two values, either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;. You can test the truthiness of a variable with &lt;code&gt;isTRUE()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- 4 &amp;gt; 3
isTRUE(k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How can you test if a variable is false? There is not a &lt;code&gt;isFALSE()&lt;/code&gt; function (at least not without having
to load a package containing this function), but there is way to do it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;k &amp;lt;- 4 &amp;gt; 3
!isTRUE(k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;!&lt;/code&gt; operator indicates negation, so the above expression could be translated as &lt;em&gt;is k not TRUE?&lt;/em&gt;.
There are other such operators, namely &lt;code&gt;&amp;amp;, &amp;amp;&amp;amp;, |, ||&lt;/code&gt;. &lt;code&gt;&amp;amp;&lt;/code&gt; means &lt;em&gt;and&lt;/em&gt; and &lt;code&gt;|&lt;/code&gt; stands for &lt;em&gt;or&lt;/em&gt;.
You might be wondering what the difference between &lt;code&gt;&amp;amp;&lt;/code&gt; and &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; is? Or between &lt;code&gt;|&lt;/code&gt; and &lt;code&gt;||&lt;/code&gt;? &lt;code&gt;&amp;amp;&lt;/code&gt; and
&lt;code&gt;|&lt;/code&gt; work on vectors, doing pairwise comparisons:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one &amp;lt;- c(TRUE, FALSE, TRUE, FALSE)
two &amp;lt;- c(FALSE, TRUE, TRUE, TRUE)
one &amp;amp; two&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE FALSE  TRUE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare this to the &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; operator:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one &amp;lt;- c(TRUE, FALSE, TRUE, FALSE)
two &amp;lt;- c(FALSE, TRUE, TRUE, TRUE)
one &amp;amp;&amp;amp; two&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; and &lt;code&gt;||&lt;/code&gt; operators only compare the first element of the vectors and stop as soon as a the return
value can be safely determined. This is called short-circuiting. Consider the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one &amp;lt;- c(TRUE, FALSE, TRUE, FALSE)
two &amp;lt;- c(FALSE, TRUE, TRUE, TRUE)
three &amp;lt;- c(TRUE, TRUE, FALSE, FALSE)
one &amp;amp;&amp;amp; two &amp;amp;&amp;amp; three&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one || two || three&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;||&lt;/code&gt; operator stops as soon it evaluates to &lt;code&gt;TRUE&lt;/code&gt; whereas the &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; stops as soon as it evaluates to &lt;code&gt;FALSE&lt;/code&gt;.
Personally, I rarely use &lt;code&gt;||&lt;/code&gt; or &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; because I get confused. I find using &lt;code&gt;|&lt;/code&gt; or &lt;code&gt;&amp;amp;&lt;/code&gt; in combination with the
&lt;code&gt;all()&lt;/code&gt; or &lt;code&gt;any()&lt;/code&gt; functions much more useful:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one &amp;lt;- c(TRUE, FALSE, TRUE, FALSE)
two &amp;lt;- c(FALSE, TRUE, TRUE, TRUE)
any(one &amp;amp; two)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all(one &amp;amp; two)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;any()&lt;/code&gt; checks whether any of the vector’s elements are &lt;code&gt;TRUE&lt;/code&gt; and &lt;code&gt;all()&lt;/code&gt; checks if all elements of the vector are
&lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As a final note, you should know that is possible to use &lt;code&gt;T&lt;/code&gt; for &lt;code&gt;TRUE&lt;/code&gt; and &lt;code&gt;F&lt;/code&gt; for &lt;code&gt;FALSE&lt;/code&gt; but I would advise against
doing this, because it is not very explicit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vectors-and-matrices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vectors and matrices&lt;/h3&gt;
&lt;p&gt;You can create a vector in different ways. But first of all, it is important to understand that a
vector in most programming languages is nothing more than a list of things. These things can be
numbers (either integers or floats), strings, or even other vectors. A vector in R can only contain elements of one
single type. This is not the case for a list, which is much more flexible. We will talk about lists shortly, but
let’s first focus on vectors and matrices.&lt;/p&gt;
&lt;div id=&#34;the-c-function&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The &lt;code&gt;c()&lt;/code&gt; function&lt;/h4&gt;
&lt;p&gt;A very important function that allows you to build a vector is &lt;code&gt;c()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- c(1,2,3,4,5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a vector with elements 1, 2, 3, 4, 5. If you check its class:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can be confusing: you where probably expecting a to be of class &lt;em&gt;vector&lt;/em&gt; or
something similar. This is not the case if you use &lt;code&gt;c()&lt;/code&gt; to create the vector, because &lt;code&gt;c()&lt;/code&gt;
doesn’t build a vector in the mathematical sense, but a so-called atomic vector.
Checking its dimension:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;returns &lt;code&gt;NULL&lt;/code&gt; because an atomic vector doesn’t have a dimension.
If you want to create a true vector, you need to use &lt;code&gt;cbind()&lt;/code&gt; or &lt;code&gt;rbind()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But before continuing, be aware that atomic vectors can only contain elements of the same type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(1, 2, &amp;quot;3&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;because “3” is a character, all the other values get implicitly converted to characters. You have
to be very careful about this, and if you use atomic vectors in your programming, you have to make
absolutely sure that no characters or logicals or whatever else are going to convert your atomic
vector to something you were not expecting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cbind-and-rbind&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;code&gt;cbind()&lt;/code&gt; and &lt;code&gt;rbind()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;You can create a &lt;em&gt;true&lt;/em&gt; vector with &lt;code&gt;cbind()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- cbind(1, 2, 3, 4, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check its class now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;matrix&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is exactly what we expected. Let’s check its dimension:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This returns the dimension of &lt;code&gt;a&lt;/code&gt; using the LICO notation (number of LInes first, the number of COlumns).&lt;/p&gt;
&lt;p&gt;It is also possible to bind vectors together to create a matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b &amp;lt;- cbind(6,7,8,9,10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s put vector &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; into a matrix called &lt;code&gt;matrix_c&lt;/code&gt; using &lt;code&gt;rbind()&lt;/code&gt;.
&lt;code&gt;rbind()&lt;/code&gt; functions the same way as &lt;code&gt;cbind()&lt;/code&gt; but glues the vectors together by rows and not by columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_c &amp;lt;- rbind(a,b)
print(matrix_c)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    2    3    4    5
## [2,]    6    7    8    9   10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-matrix-class&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The &lt;code&gt;matrix&lt;/code&gt; class&lt;/h4&gt;
&lt;p&gt;R also has support for matrices. For example, you can create a matrix of dimension (5,5) filled
with 0’s with the &lt;code&gt;matrix()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_a &amp;lt;- matrix(0, nrow = 5, ncol = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to create the following matrix:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
B = \left(
\begin{array}{ccc}
 2 &amp;amp; 4 &amp;amp; 3 \\
 1 &amp;amp; 5 &amp;amp; 7
\end{array} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;you would do it like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- matrix(c(2, 4, 3, 1, 5, 7), nrow = 2, byrow = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The option &lt;code&gt;byrow = TRUE&lt;/code&gt; means that the rows of the matrix will be filled first.&lt;/p&gt;
&lt;p&gt;You can access individual elements of &lt;code&gt;matrix_a&lt;/code&gt; like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_a[2, 3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and R returns its value, 0. We can assign a new value to this element if we want. Try:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix_a[2, 3] &amp;lt;- 7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now take a look at &lt;code&gt;matrix_a&lt;/code&gt; again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(matrix_a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4] [,5]
## [1,]    0    0    0    0    0
## [2,]    0    0    7    0    0
## [3,]    0    0    0    0    0
## [4,]    0    0    0    0    0
## [5,]    0    0    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Recall our vector &lt;code&gt;b&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b &amp;lt;- cbind(6,7,8,9,10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To access its third element, you can simply write:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b[3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have heard many people praising R for being a matrix based language. Matrices are indeed useful,
and statisticians are used to working with them. However, I very rarely use matrices in my
day to day work, and prefer an approach based on data frames (which will be discussed below). This
is because working with data frames makes it easier to use R’s advanced functional programming
language capabilities, and this is where R really shines in my opinion. Working with matrices
almost automatically implies using loops and all the iterative programming techniques, &lt;em&gt;à la Fortran&lt;/em&gt;,
which I personally believe are ill-suited for interactive statistical programming (as discussed in
the introduction).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-list-class&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;list&lt;/code&gt; class&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;list&lt;/code&gt; class is a very flexible class, and thus, very useful. You can put anything inside a list,
such as numbers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list1 &amp;lt;- list(3, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or other lists constructed with &lt;code&gt;c()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list2 &amp;lt;- list(c(1, 2), c(3, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you can also put objects of different classes in the same list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list3 &amp;lt;- list(3, c(1, 2), &amp;quot;lists are amazing!&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and of course create list of lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_lists &amp;lt;- list(list1, list2, list3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check the contents of a list, you can use the structure function &lt;code&gt;str()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(my_lists)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 3
##  $ :List of 2
##   ..$ : num 3
##   ..$ : num 2
##  $ :List of 2
##   ..$ : num [1:2] 1 2
##   ..$ : num [1:2] 3 4
##  $ :List of 3
##   ..$ : num 3
##   ..$ : num [1:2] 1 2
##   ..$ : chr &amp;quot;lists are amazing!&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or you can use RStudio’s &lt;em&gt;Environment&lt;/em&gt; pane:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/rstudio_environment_list.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;You can also create named lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list4 &amp;lt;- list(&amp;quot;a&amp;quot; = 2, &amp;quot;b&amp;quot; = 8, &amp;quot;c&amp;quot; = &amp;quot;this is a named list&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you can access the elements in two ways:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list4[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or, for named lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list4$c&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;this is a named list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lists are used extensively because they are so flexible. You can build lists of datasets and apply
functions to all the datasets at once, build lists of models, lists of plots, etc… In the later
chapters we are going to learn all about them. Lists are central objects in a functional programming
workflow for interactive statistical analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data.frame-and-tibble-classes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;data.frame&lt;/code&gt; and &lt;code&gt;tibble&lt;/code&gt; classes&lt;/h3&gt;
&lt;p&gt;In the next chapter we are going to learn how to import datasets into R. Once you import data, the
resulting object is either a &lt;code&gt;data.frame&lt;/code&gt; or a &lt;code&gt;tibble&lt;/code&gt; depending on which package you used to
import the data. &lt;code&gt;tibble&lt;/code&gt;s extend &lt;code&gt;data.frame&lt;/code&gt;s so if you know about &lt;code&gt;data.frame&lt;/code&gt; objects already,
working with &lt;code&gt;tibble&lt;/code&gt;s will be very easy. &lt;code&gt;tibble&lt;/code&gt;s have a better &lt;code&gt;print()&lt;/code&gt; method, and some other
niceties.&lt;/p&gt;
&lt;p&gt;However, I want to stress that these objects are central to R and are thus very important; they are
actually special cases of lists, discussed above. There are different ways to print a &lt;code&gt;data.frame&lt;/code&gt; or
a &lt;code&gt;tibble&lt;/code&gt; if you wish to inspect it. You can use &lt;code&gt;View(my_data)&lt;/code&gt; to show the &lt;code&gt;my_data&lt;/code&gt; &lt;code&gt;data.frame&lt;/code&gt;
in the &lt;em&gt;View&lt;/em&gt; pane of RStudio:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/rstudio_view_data.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;You can also use the &lt;code&gt;str()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(my_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And if you need to access an individual column, you can use the &lt;code&gt;$&lt;/code&gt; sign, same as for a list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_data$col1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;formulas&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Formulas&lt;/h3&gt;
&lt;p&gt;We will learn more about formulas later, but because it is an important object, it is useful if you
already know about them early on. A formula is defined in the following way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_formula &amp;lt;- ~x

class(my_formula)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;formula&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Formula objects are defined using the &lt;code&gt;~&lt;/code&gt; symbol. Formulas are useful to define statistical models,
for example for a linear regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(y ~ x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or also to define anonymous functions, but more on this later.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Models&lt;/h2&gt;
&lt;p&gt;A statistical model is an object like any other in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)

my_model &amp;lt;- lm(mpg ~ hp, mtcars)

class(my_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;lm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;my_model&lt;/code&gt; is an object of class &lt;code&gt;lm&lt;/code&gt;. You can apply different functions to a model object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(my_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = mpg ~ hp, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.7121 -2.1122 -0.8854  1.5819  8.2360 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 30.09886    1.63392  18.421  &amp;lt; 2e-16 ***
## hp          -0.06823    0.01012  -6.742 1.79e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 3.863 on 30 degrees of freedom
## Multiple R-squared:  0.6024, Adjusted R-squared:  0.5892 
## F-statistic: 45.46 on 1 and 30 DF,  p-value: 1.788e-07&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This class will be explored in later chapters.&lt;/p&gt;
&lt;div id=&#34;null-na-and-nan&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;NULL, NA and NaN&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;NULL&lt;/code&gt;, &lt;code&gt;NA&lt;/code&gt; and &lt;code&gt;NaN&lt;/code&gt; classes are pretty special. &lt;code&gt;NULL&lt;/code&gt; is returned when the result of function is undetermined.
For example, consider &lt;code&gt;list4&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 2
## 
## $b
## [1] 8
## 
## $c
## [1] &amp;quot;this is a named list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;if you try to access an element that does not exist, such as &lt;code&gt;d&lt;/code&gt;, you will get &lt;code&gt;NULL&lt;/code&gt; back:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list4$d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;NaN&lt;/code&gt; means “Not a Number” and is returned when a function return something that is not a number:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in sqrt(-1): NaNs produced&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NaN&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;0/0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NaN&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Basically, numbers that cannot be represented as floating point numbers are &lt;code&gt;NaN&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, there’s &lt;code&gt;NA&lt;/code&gt; which is closely related to &lt;code&gt;NaN&lt;/code&gt; but is used for missing values. &lt;code&gt;NA&lt;/code&gt; stands for &lt;code&gt;Not Available&lt;/code&gt;. There are
several types of &lt;code&gt;NA&lt;/code&gt;s:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NA_integer_&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NA_real_&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NA_complex_&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NA_character_&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;but these are in principle only used when you need to program your own functions and need to explicitly test for the missingness of, say,
a character value.&lt;/p&gt;
&lt;p&gt;To test whether a value is &lt;code&gt;NA&lt;/code&gt;, use the &lt;code&gt;is.na()&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;useful-functions-to-get-you-started&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Useful functions to get you started&lt;/h3&gt;
&lt;p&gt;This section will list several basic R functions that are very useful and should be part of your toolbox.&lt;/p&gt;
&lt;div id=&#34;sequences&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Sequences&lt;/h4&gt;
&lt;p&gt;There are several functions that create sequences, &lt;code&gt;seq()&lt;/code&gt;, &lt;code&gt;seq_along()&lt;/code&gt; and &lt;code&gt;rep()&lt;/code&gt;. &lt;code&gt;rep()&lt;/code&gt; is easy enough:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rep(1, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1 1 1 1 1 1 1 1 1 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simply repeats &lt;code&gt;1&lt;/code&gt; 10 times. You can repeat other objects too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rep(&amp;quot;HAHA&amp;quot;, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot; &amp;quot;HAHA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To create a sequence, things are not as straightforward. There is &lt;code&gt;seq()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(70, 80)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 70 71 72 73 74 75 76 77 78 79 80&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to provide a &lt;code&gt;by&lt;/code&gt; argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 10, by = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 3 5 7 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;seq_along()&lt;/code&gt; behaves similarly, but returns the length of the object passed to it. So if you pass &lt;code&gt;list4&lt;/code&gt; to
&lt;code&gt;seq_along()&lt;/code&gt;, it will return a sequence from 1 to 3:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq_along(list4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is also true for &lt;code&gt;seq()&lt;/code&gt; actually:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(list4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but these two functions behave differently for arguments of length equal to 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq_along(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So be quite careful about that. I would advise you do not use &lt;code&gt;seq()&lt;/code&gt;, but only &lt;code&gt;seq_along()&lt;/code&gt; and &lt;code&gt;seq_len()&lt;/code&gt;. &lt;code&gt;seq_len()&lt;/code&gt;
only takes arguments of length 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq_len(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq_along(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem with &lt;code&gt;seq()&lt;/code&gt; is that it is unpredictable; depending on its input, the output will either be an integer or a sequence.
When programming, it is better to have function that are stricter and fail when confronted to special cases, instead of returning
some result. This is a bit of a recurrent issue with R, and the functions from the &lt;code&gt;{tidyverse}&lt;/code&gt; mitigate this issue by being
stricter than their base R counterparts. For example, consider the &lt;code&gt;ifelse()&lt;/code&gt; function from base R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ifelse(3 &amp;gt; 5, 1, &amp;quot;this is false&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;this is false&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and compare it to &lt;code&gt;{dplyr}&lt;/code&gt;’s implementation, &lt;code&gt;if_else()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if_else(3 &amp;gt; 5, 1, &amp;quot;this is false&amp;quot;)
Error: `false` must be type double, not character
Call `rlang::last_error()` to see a backtrace&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;if_else()&lt;/code&gt; fails because the return value when &lt;code&gt;FALSE&lt;/code&gt; is not a double (a real number) but a character. This might seem unnecessarily
strict, but at least it is predictable. This makes debugging easier when used inside functions. In Chapter 8 we are going to learn how
to write our own functions, and being strict makes programming easier.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-string-manipulation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Basic string manipulation&lt;/h4&gt;
&lt;p&gt;For now, we have not closely studied &lt;code&gt;character&lt;/code&gt; objects, we only learned how to define them. Later, in Chapter 5 we will learn about the
&lt;code&gt;{stringr}&lt;/code&gt; package which provides useful function to work with strings. However, there are several base R functions that are very
useful that you might want to know nonetheless, such as &lt;code&gt;paste()&lt;/code&gt; and &lt;code&gt;paste0()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste(&amp;quot;Hello&amp;quot;, &amp;quot;amigo&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Hello amigo&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but you can also change the separator if needed:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste(&amp;quot;Hello&amp;quot;, &amp;quot;amigo&amp;quot;, sep = &amp;quot;--&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Hello--amigo&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;paste0()&lt;/code&gt; is the same as &lt;code&gt;paste()&lt;/code&gt; but does not have any &lt;code&gt;sep&lt;/code&gt; argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste0(&amp;quot;Hello&amp;quot;, &amp;quot;amigo&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Helloamigo&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you provide a vector of characters, you can also use the &lt;code&gt;collapse&lt;/code&gt; argument, which places whatever you provide for &lt;code&gt;collapse&lt;/code&gt; between the
characters of the vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste0(c(&amp;quot;Joseph&amp;quot;, &amp;quot;Mary&amp;quot;, &amp;quot;Jesus&amp;quot;), collapse = &amp;quot;, and &amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Joseph, and Mary, and Jesus&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To change the case of characters, you can use &lt;code&gt;toupper()&lt;/code&gt; and &lt;code&gt;tolower()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tolower(&amp;quot;HAHAHAHAH&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;hahahahah&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;toupper(&amp;quot;hueuehuehuheuhe&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;HUEUEHUEHUHEUHE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mathematical-functions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Mathematical functions&lt;/h4&gt;
&lt;p&gt;Finally, there are the classical mathematical functions that you know and love:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sqrt()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exp()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;abs()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sin()&lt;/code&gt;, &lt;code&gt;cos()&lt;/code&gt;, &lt;code&gt;tan()&lt;/code&gt;, and others&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;cumsum()&lt;/code&gt;, &lt;code&gt;prod()&lt;/code&gt;, &lt;code&gt;cumprod()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max()&lt;/code&gt;, &lt;code&gt;min()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and many others…&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using the tidyverse for more than data manipulation: estimating pi with Monte Carlo methods</title>
      <link>https://www.brodrigues.co/blog/2018-12-21-tidyverse_pi/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-21-tidyverse_pi/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kZJY15dyMig&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/casino.jpg&#34; title = &#34;Audentes Fortuna Iuvat&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;p&gt;This blog post is an excerpt of my ebook &lt;em&gt;Modern R with the tidyverse&lt;/em&gt; that you can read for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;. This is taken from Chapter 5, which presents
the &lt;code&gt;{tidyverse}&lt;/code&gt; packages and how to use them to compute descriptive statistics and manipulate data.
In the text below, I show how you can use the &lt;code&gt;{tidyverse}&lt;/code&gt; functions and principles for the
estimation of &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; using Monte Carlo simulation.&lt;/p&gt;
&lt;div id=&#34;going-beyond-descriptive-statistics-and-data-manipulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Going beyond descriptive statistics and data manipulation&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;{tidyverse}&lt;/code&gt; collection of packages can do much more than simply data manipulation and
descriptive statisics. You can use the principles we have covered and the functions you now know
to do much more. For instance, you can use a few &lt;code&gt;{tidyverse}&lt;/code&gt; functions to do Monte Carlo simulations,
for example to estimate &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Draw the unit circle inside the unit square, the ratio of the area of the circle to the area of the
square will be &lt;span class=&#34;math inline&#34;&gt;\(\pi/4\)&lt;/span&gt;. Then shot K arrows at the square; roughly &lt;span class=&#34;math inline&#34;&gt;\(K*\pi/4\)&lt;/span&gt; should have fallen
inside the circle. So if now you shoot N arrows at the square, and M fall inside the circle, you have
the following relationship &lt;span class=&#34;math inline&#34;&gt;\(M = N*\pi/4\)&lt;/span&gt;. You can thus compute &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; like so: &lt;span class=&#34;math inline&#34;&gt;\(\pi = 4*M/N\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The more arrows N you throw at the square, the better approximation of &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; you’ll have. Let’s
try to do this with a tidy Monte Carlo simulation. First, let’s randomly pick some points inside
the unit square:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 5000

set.seed(2019)
points &amp;lt;- tibble(&amp;quot;x&amp;quot; = runif(n), &amp;quot;y&amp;quot; = runif(n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, to know if a point is inside the unit circle, we need to check wether &lt;span class=&#34;math inline&#34;&gt;\(x^2 + y^2 &amp;lt; 1\)&lt;/span&gt;. Let’s
add a new column to the &lt;code&gt;points&lt;/code&gt; tibble, called &lt;code&gt;inside&lt;/code&gt; equal to 1 if the point is inside the
unit circle and 0 if not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points &amp;lt;- points %&amp;gt;% 
    mutate(inside = map2_dbl(.x = x, .y = y, ~ifelse(.x**2 + .y**2 &amp;lt; 1, 1, 0))) %&amp;gt;% 
    rowid_to_column(&amp;quot;N&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;points&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5,000 x 4
##        N       x      y inside
##    &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1     1 0.770   0.984       0
##  2     2 0.713   0.0107      1
##  3     3 0.303   0.133       1
##  4     4 0.618   0.0378      1
##  5     5 0.0505  0.677       1
##  6     6 0.0432  0.0846      1
##  7     7 0.820   0.727       0
##  8     8 0.00961 0.0758      1
##  9     9 0.102   0.373       1
## 10    10 0.609   0.676       1
## # … with 4,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;rowid_to_column()&lt;/code&gt; function, from the &lt;code&gt;{tibble}&lt;/code&gt; package, adds a new column to the data frame
with an id, going from 1 to the number of rows in the data frame. Now, I can compute the estimation
of &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; at each row, by computing the cumulative sum of the 1’s in the &lt;code&gt;inside&lt;/code&gt; column and dividing
that by the current value of &lt;code&gt;N&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points &amp;lt;- points %&amp;gt;% 
    mutate(estimate = 4*cumsum(inside)/N)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;cumsum(inside)&lt;/code&gt; is the &lt;code&gt;M&lt;/code&gt; from the formula. Now, we can finish by plotting the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(points) + 
    geom_line(aes(y = estimate, x = N), colour = &amp;quot;#82518c&amp;quot;) + 
    geom_hline(yintercept = pi) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-12-21-tidyverse_pi_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In Chapter 6, we are going to learn all about &lt;code&gt;{ggplot2}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As the number of tries grows, the estimation of &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; gets better.&lt;/p&gt;
&lt;p&gt;Using a data frame as a structure to hold our simulated points and the results makes it very easy
to avoid loops, and thus write code that is more concise and easier to follow.
If you studied a quantitative field in u8niversity, you might have done a similar exercise at the
time, very likely by defining a matrix to hold your points, and an empty vector to hold whether a
particular point was inside the unit circle. Then you wrote a loop to compute whether
a point was inside the unit circle, save this result in the before-defined empty vector and then
compute the estimation of &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt;. Again, I take this opportunity here to stress that there is nothing
wrong with this approach per se, but R, with the &lt;code&gt;{tidyverse}&lt;/code&gt; is better suited for a workflow
where lists or data frames are the central objects and where the analyst operates over them
with functional programming techniques.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Manipulate dates easily with {lubridate}</title>
      <link>https://www.brodrigues.co/blog/2018-12-15-lubridate_africa/</link>
      <pubDate>Sat, 15 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-15-lubridate_africa/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FTQbiNvZqaY&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/africa.jpg&#34; title = &#34;One of my favourite songs&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;p&gt;This blog post is an excerpt of my ebook &lt;em&gt;Modern R with the tidyverse&lt;/em&gt; that you can read for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;. This is taken from Chapter 5, which presents
the &lt;code&gt;{tidyverse}&lt;/code&gt; packages and how to use them to compute descriptive statistics and manipulate data.
In the text below, I scrape a table from Wikipedia, which shows when African countries gained
independence from other countries. Then, using &lt;code&gt;{lubridate}&lt;/code&gt; functions I show you how you can
answers questions such as &lt;em&gt;Which countries gained independence before 1960?&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;set-up-scraping-some-data-from-wikipedia&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set-up: scraping some data from Wikipedia&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;{lubridate}&lt;/code&gt; is yet another tidyverse package, that makes dealing with dates or duration data
(and intervals) as painless as possible. I do not use every function contained in the package
daily, and as such will only focus on some of the functions. However, if you have to deal with
dates often, you might want to explore the package thoroughly.&lt;/p&gt;
&lt;p&gt;Let’s get some data from a Wikipedia table:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;page &amp;lt;- read_html(&amp;quot;https://en.wikipedia.org/wiki/Decolonisation_of_Africa&amp;quot;)

independence &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;.wikitable&amp;quot;) %&amp;gt;%
    html_table(fill = TRUE)

independence &amp;lt;- independence %&amp;gt;%
    select(-Rank) %&amp;gt;%
    map_df(~str_remove_all(., &amp;quot;\\[.*\\]&amp;quot;)) %&amp;gt;%
    rename(country = `Country[a]`,
           colonial_name = `Colonial name`,
           colonial_power = `Colonial power[b]`,
           independence_date = `Independence date[c]`,
           first_head_of_state = `First head of state[d]`,
           independence_won_through = `Independence won through`)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This dataset was scraped from the following Wikipedia &lt;a href=&#34;https://en.wikipedia.org/wiki/Decolonisation_of_Africa#Timeline&#34;&gt;table&lt;/a&gt;.
It shows when African countries gained independence from which colonial powers. In Chapter 11, I
will show you how to scrape Wikipedia pages using R. For now, let’s take a look at the contents
of the dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 54 x 6
##    country colonial_name colonial_power independence_da… first_head_of_s…
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;           
##  1 Liberia Liberia       United States  26 July 1847     Joseph Jenkins …
##  2 South … Cape Colony … United Kingdom 31 May 1910      Louis Botha     
##  3 Egypt   Sultanate of… United Kingdom 28 February 1922 Fuad I          
##  4 Eritrea Italian Erit… Italy          10 February 1947 Haile Selassie  
##  5 Libya   British Mili… United Kingdo… 24 December 1951 Idris           
##  6 Sudan   Anglo-Egypti… United Kingdo… 1 January 1956   Ismail al-Azhari
##  7 Tunisia French Prote… France         20 March 1956    Muhammad VIII a…
##  8 Morocco French Prote… France Spain   2 March 19567 A… Mohammed V      
##  9 Ghana   Gold Coast    United Kingdom 6 March 1957     Kwame Nkrumah   
## 10 Guinea  French West … France         2 October 1958   Ahmed Sékou Tou…
## # … with 44 more rows, and 1 more variable: independence_won_through &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as you can see, the date of independence is in a format that might make it difficult to answer questions
such as &lt;em&gt;Which African countries gained independence before 1960 ?&lt;/em&gt; for two reasons. First of all,
the date uses the name of the month instead of the number of the month (well, this is not such a
big deal, but still), and second of all the type of
the independence day column is &lt;em&gt;character&lt;/em&gt; and not “date”. So our first task is to correctly define the column
as being of type date, while making sure that R understands that &lt;em&gt;January&lt;/em&gt; is supposed to be “01”, and so
on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-lubridate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;{lubridate}&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;There are several helpful functions included in &lt;code&gt;{lubridate}&lt;/code&gt; to convert columns to dates. For instance
if the column you want to convert is of the form “2012-11-21”, then you would use the function &lt;code&gt;ymd()&lt;/code&gt;,
for “year-month-day”. If, however the column is “2012-21-11”, then you would use &lt;code&gt;ydm()&lt;/code&gt;. There’s
a few of these helper functions, and they can handle a lot of different formats for dates. In our case,
having the name of the month instead of the number might seem quite problematic, but it turns out
that this is a case that &lt;code&gt;{lubridate}&lt;/code&gt; handles painfully:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;lubridate&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:base&amp;#39;:
## 
##     date&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence &amp;lt;- independence %&amp;gt;%
  mutate(independence_date = dmy(independence_date))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 5 failed to parse.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some dates failed to parse, for instance for Morocco. This is because these countries have several
independence dates; this means that the string to convert looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;2 March 1956
7 April 1956
10 April 1958
4 January 1969&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which obviously cannot be converted by &lt;code&gt;{lubridate}&lt;/code&gt; without further manipulation. I ignore these cases for
simplicity’s sake.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the data now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 54 x 6
##    country colonial_name colonial_power independence_da… first_head_of_s…
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;          &amp;lt;date&amp;gt;           &amp;lt;chr&amp;gt;           
##  1 Liberia Liberia       United States  1847-07-26       Joseph Jenkins …
##  2 South … Cape Colony … United Kingdom 1910-05-31       Louis Botha     
##  3 Egypt   Sultanate of… United Kingdom 1922-02-28       Fuad I          
##  4 Eritrea Italian Erit… Italy          1947-02-10       Haile Selassie  
##  5 Libya   British Mili… United Kingdo… 1951-12-24       Idris           
##  6 Sudan   Anglo-Egypti… United Kingdo… 1956-01-01       Ismail al-Azhari
##  7 Tunisia French Prote… France         1956-03-20       Muhammad VIII a…
##  8 Morocco French Prote… France Spain   NA               Mohammed V      
##  9 Ghana   Gold Coast    United Kingdom 1957-03-06       Kwame Nkrumah   
## 10 Guinea  French West … France         1958-10-02       Ahmed Sékou Tou…
## # … with 44 more rows, and 1 more variable: independence_won_through &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we now have a date column in the right format. We can now answer questions such as
&lt;em&gt;Which countries gained independence before 1960?&lt;/em&gt; quite easily, by using the functions &lt;code&gt;year()&lt;/code&gt;,
&lt;code&gt;month()&lt;/code&gt; and &lt;code&gt;day()&lt;/code&gt;. Let’s see which countries gained independence before 1960:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence %&amp;gt;%
  filter(year(independence_date) &amp;lt;= 1960) %&amp;gt;%
  pull(country)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Liberia&amp;quot;                          &amp;quot;South Africa&amp;quot;                    
##  [3] &amp;quot;Egypt&amp;quot;                            &amp;quot;Eritrea&amp;quot;                         
##  [5] &amp;quot;Libya&amp;quot;                            &amp;quot;Sudan&amp;quot;                           
##  [7] &amp;quot;Tunisia&amp;quot;                          &amp;quot;Ghana&amp;quot;                           
##  [9] &amp;quot;Guinea&amp;quot;                           &amp;quot;Cameroon&amp;quot;                        
## [11] &amp;quot;Togo&amp;quot;                             &amp;quot;Mali&amp;quot;                            
## [13] &amp;quot;Madagascar&amp;quot;                       &amp;quot;Democratic Republic of the Congo&amp;quot;
## [15] &amp;quot;Benin&amp;quot;                            &amp;quot;Niger&amp;quot;                           
## [17] &amp;quot;Burkina Faso&amp;quot;                     &amp;quot;Ivory Coast&amp;quot;                     
## [19] &amp;quot;Chad&amp;quot;                             &amp;quot;Central African Republic&amp;quot;        
## [21] &amp;quot;Republic of the Congo&amp;quot;            &amp;quot;Gabon&amp;quot;                           
## [23] &amp;quot;Mauritania&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You guessed it, &lt;code&gt;year()&lt;/code&gt; extracts the year of the date column and converts it as a &lt;em&gt;numeric&lt;/em&gt; so that we can work
on it. This is the same for &lt;code&gt;month()&lt;/code&gt; or &lt;code&gt;day()&lt;/code&gt;. Let’s try to see if countries gained their independence on
Christmas Eve:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence %&amp;gt;%
  filter(month(independence_date) == 12,
         day(independence_date) == 24) %&amp;gt;%
  pull(country)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Libya&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seems like Libya was the only one! You can also operate on dates. For instance, let’s compute the difference between
two dates, using the &lt;code&gt;interval()&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence %&amp;gt;%
  mutate(today = lubridate::today()) %&amp;gt;%
  mutate(independent_since = interval(independence_date, today)) %&amp;gt;%
  select(country, independent_since)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 54 x 2
##    country      independent_since             
##    &amp;lt;chr&amp;gt;        &amp;lt;S4: Interval&amp;gt;                
##  1 Liberia      1847-07-26 UTC--2019-02-10 UTC
##  2 South Africa 1910-05-31 UTC--2019-02-10 UTC
##  3 Egypt        1922-02-28 UTC--2019-02-10 UTC
##  4 Eritrea      1947-02-10 UTC--2019-02-10 UTC
##  5 Libya        1951-12-24 UTC--2019-02-10 UTC
##  6 Sudan        1956-01-01 UTC--2019-02-10 UTC
##  7 Tunisia      1956-03-20 UTC--2019-02-10 UTC
##  8 Morocco      NA--NA                        
##  9 Ghana        1957-03-06 UTC--2019-02-10 UTC
## 10 Guinea       1958-10-02 UTC--2019-02-10 UTC
## # … with 44 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;independent_since&lt;/code&gt; column now contains an &lt;em&gt;interval&lt;/em&gt; object that we can convert to years:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence %&amp;gt;%
  mutate(today = lubridate::today()) %&amp;gt;%
  mutate(independent_since = interval(independence_date, today)) %&amp;gt;%
  select(country, independent_since) %&amp;gt;%
  mutate(years_independent = as.numeric(independent_since, &amp;quot;years&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 54 x 3
##    country      independent_since              years_independent
##    &amp;lt;chr&amp;gt;        &amp;lt;S4: Interval&amp;gt;                             &amp;lt;dbl&amp;gt;
##  1 Liberia      1847-07-26 UTC--2019-02-10 UTC             172. 
##  2 South Africa 1910-05-31 UTC--2019-02-10 UTC             109. 
##  3 Egypt        1922-02-28 UTC--2019-02-10 UTC              97.0
##  4 Eritrea      1947-02-10 UTC--2019-02-10 UTC              72  
##  5 Libya        1951-12-24 UTC--2019-02-10 UTC              67.1
##  6 Sudan        1956-01-01 UTC--2019-02-10 UTC              63.1
##  7 Tunisia      1956-03-20 UTC--2019-02-10 UTC              62.9
##  8 Morocco      NA--NA                                      NA  
##  9 Ghana        1957-03-06 UTC--2019-02-10 UTC              61.9
## 10 Guinea       1958-10-02 UTC--2019-02-10 UTC              60.4
## # … with 44 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now see for how long the last country to gain independence has been independent.
Because the data is not tidy (in some cases, an African country was colonized by two powers,
see Libya), I will only focus on 4 European colonial powers: Belgium, France, Portugal and the United Kingdom:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;independence %&amp;gt;%
  filter(colonial_power %in% c(&amp;quot;Belgium&amp;quot;, &amp;quot;France&amp;quot;, &amp;quot;Portugal&amp;quot;, &amp;quot;United Kingdom&amp;quot;)) %&amp;gt;%
  mutate(today = lubridate::today()) %&amp;gt;%
  mutate(independent_since = interval(independence_date, today)) %&amp;gt;%
  mutate(years_independent = as.numeric(independent_since, &amp;quot;years&amp;quot;)) %&amp;gt;%
  group_by(colonial_power) %&amp;gt;%
  summarise(last_colony_independent_for = min(years_independent, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   colonial_power last_colony_independent_for
##   &amp;lt;chr&amp;gt;                                &amp;lt;dbl&amp;gt;
## 1 Belgium                               56.6
## 2 France                                41.6
## 3 Portugal                              43.2
## 4 United Kingdom                        42.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{lubridate}&lt;/code&gt; contains many more functions. If you often work with dates, duration or interval data, &lt;code&gt;{lubridate}&lt;/code&gt;
is a package that you have to master.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What hyper-parameters are, and what to do with them; an illustration with ridge regression</title>
      <link>https://www.brodrigues.co/blog/2018-12-02-hyper-parameters/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-12-02-hyper-parameters/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=13Gd5kpLzsw&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/ridge.jpg&#34; title = &#34;Gameboy ridge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;
&lt;p&gt;This blog post is an excerpt of my ebook &lt;em&gt;Modern R with the tidyverse&lt;/em&gt; that you can read for
free &lt;a href=&#34;https://b-rodrigues.github.io/modern_R/&#34;&gt;here&lt;/a&gt;. This is taken from Chapter 7, which deals
with statistical models. In the text below, I explain what hyper-parameters are, and as an example
I run a ridge regression using the &lt;code&gt;{glmnet}&lt;/code&gt; package. The book is still being written, so
comments are more than welcome!&lt;/p&gt;
&lt;div id=&#34;hyper-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hyper-parameters&lt;/h2&gt;
&lt;p&gt;Hyper-parameters are parameters of the model that cannot be directly learned from the data.
A linear regression does not have any hyper-parameters, but a random forest for instance has several.
You might have heard of ridge regression, lasso and elasticnet. These are
extensions to linear models that avoid over-fitting by penalizing &lt;em&gt;large&lt;/em&gt; models. These
extensions of the linear regression have hyper-parameters that the practitioner has to tune. There
are several ways one can tune these parameters, for example, by doing a grid-search, or a random
search over the grid or using more elaborate methods. To introduce hyper-parameters, let’s get
to know ridge regression, also called Tikhonov regularization.&lt;/p&gt;
&lt;div id=&#34;ridge-regression&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ridge regression&lt;/h3&gt;
&lt;p&gt;Ridge regression is used when the data you are working with has a lot of explanatory variables,
or when there is a risk that a simple linear regression might overfit to the training data, because,
for example, your explanatory variables are collinear.
If you are training a linear model and then you notice that it generalizes very badly to new,
unseen data, it is very likely that the linear model you trained overfits the data.
In this case, ridge regression might prove useful. The way ridge regression works might seem
counter-intuititive; it boils down to fitting a &lt;em&gt;worse&lt;/em&gt; model to the training data, but in return,
this worse model will generalize better to new data.&lt;/p&gt;
&lt;p&gt;The closed form solution of the ordinary least squares estimator is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\widehat{\beta} = (X&amp;#39;X)^{-1}X&amp;#39;Y
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the design matrix (the matrix made up of the explanatory variables) and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is the
dependent variable. For ridge regression, this closed form solution changes a little bit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\widehat{\beta} = (X&amp;#39;X + \lambda I_p)^{-1}X&amp;#39;Y
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\lambda \in \mathbb{R}\)&lt;/span&gt; is an hyper-parameter and &lt;span class=&#34;math inline&#34;&gt;\(I_p\)&lt;/span&gt; is the identity matrix of dimension &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;
(&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of explanatory variables).
This formula above is the closed form solution to the following optimisation program:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sum_{i=1}^n \left(y_i - \sum_{j=1}^px_{ij}\beta_j\right)^2 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sum_{j=1}^p(\beta_j)^2 &amp;lt; c
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for any strictly positive &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;glmnet()&lt;/code&gt; function from the &lt;code&gt;{glmnet}&lt;/code&gt; package can be used for ridge regression, by setting
the &lt;code&gt;alpha&lt;/code&gt; argument to 0 (setting it to 1 would do LASSO, and setting it to a number between
0 and 1 would do elasticnet). But in order to compare linear regression and ridge regression,
let me first divide the data into a training set and a testing set. I will be using the &lt;code&gt;Housing&lt;/code&gt;
data from the &lt;code&gt;{Ecdat}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(Ecdat)
library(glmnet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;index &amp;lt;- 1:nrow(Housing)

set.seed(12345)
train_index &amp;lt;- sample(index, round(0.90*nrow(Housing)), replace = FALSE)

test_index &amp;lt;- setdiff(index, train_index)

train_x &amp;lt;- Housing[train_index, ] %&amp;gt;% 
    select(-price)

train_y &amp;lt;- Housing[train_index, ] %&amp;gt;% 
    pull(price)

test_x &amp;lt;- Housing[test_index, ] %&amp;gt;% 
    select(-price)

test_y &amp;lt;- Housing[test_index, ] %&amp;gt;% 
    pull(price)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I do the train/test split this way, because &lt;code&gt;glmnet()&lt;/code&gt; requires a design matrix as input, and not
a formula. Design matrices can be created using the &lt;code&gt;model.matrix()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_matrix &amp;lt;- model.matrix(train_y ~ ., data = train_x)

test_matrix &amp;lt;- model.matrix(test_y ~ ., data = test_x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To run an unpenalized linear regression, we can set the penalty to 0:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_lm_ridge &amp;lt;- glmnet(y = train_y, x = train_matrix, alpha = 0, lambda = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model above provides the same result as a linear regression. Let’s compare the coefficients between the two:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(model_lm_ridge)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 13 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
##                       s0
## (Intercept) -3247.030393
## (Intercept)     .       
## lotsize         3.520283
## bedrooms     1745.211187
## bathrms     14337.551325
## stories      6736.679470
## drivewayyes  5687.132236
## recroomyes   5701.831289
## fullbaseyes  5708.978557
## gashwyes    12508.524241
## aircoyes    12592.435621
## garagepl     4438.918373
## prefareayes  9085.172469&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now the coefficients of the linear regression (because I provide a design matrix, I have to use
&lt;code&gt;lm.fit()&lt;/code&gt; instead of &lt;code&gt;lm()&lt;/code&gt; which requires a formula, not a matrix.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(lm.fit(x = train_matrix, y = train_y))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  (Intercept)      lotsize     bedrooms      bathrms      stories 
## -3245.146665     3.520357  1744.983863 14336.336858  6737.000410 
##  drivewayyes   recroomyes  fullbaseyes     gashwyes     aircoyes 
##  5686.394123  5700.210775  5709.493884 12509.005265 12592.367268 
##     garagepl  prefareayes 
##  4439.029607  9085.409155&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;as you can see, the coefficients are the same. Let’s compute the RMSE for the unpenalized linear
regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;preds_lm &amp;lt;- predict(model_lm_ridge, test_matrix)

rmse_lm &amp;lt;- sqrt(mean((preds_lm - test_y)^2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The RMSE for the linear unpenalized regression is equal to 14463.08.&lt;/p&gt;
&lt;p&gt;Let’s now run a ridge regression, with &lt;code&gt;lambda&lt;/code&gt; equal to 100, and see if the RMSE is smaller:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_ridge &amp;lt;- glmnet(y = train_y, x = train_matrix, alpha = 0, lambda = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and let’s compute the RMSE again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;preds &amp;lt;- predict(model_ridge, test_matrix)

rmse &amp;lt;- sqrt(mean((preds - test_y)^2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The RMSE for the linear penalized regression is equal to 14460.71, which is smaller than before.
But which value of &lt;code&gt;lambda&lt;/code&gt; gives smallest RMSE? To find out, one must run model over a grid of
&lt;code&gt;lambda&lt;/code&gt; values and pick the model with lowest RMSE. This procedure is available in the &lt;code&gt;cv.glmnet()&lt;/code&gt;
function, which picks the best value for &lt;code&gt;lambda&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model &amp;lt;- cv.glmnet(train_matrix, train_y)
# lambda that minimises the MSE
best_model$lambda.min&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 66.07936&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to &lt;code&gt;cv.glmnet()&lt;/code&gt; the best value for &lt;code&gt;lambda&lt;/code&gt; is 66.0793576.
In the next section, we will implement cross validation ourselves, in order to find the hyper-parameters
of a random forest.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt; or &lt;a href=&#34;https://www.paypal.me/brodriguesco&#34;&gt;paypal.me&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A tutorial on tidy cross-validation with R</title>
      <link>https://www.brodrigues.co/blog/2018-11-25-tidy_cv/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-25-tidy_cv/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=7T6pgZdFLP0&#34;&gt;
&lt;image width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/cross_validation.gif&#34; title = &#34;Visual representation of cross⁻validation inside your computer *click for virtual weed*&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This blog posts will use several packages from the
&lt;a href=&#34;https://github.com/tidymodels&#34;&gt;&lt;code&gt;{tidymodels}&lt;/code&gt;&lt;/a&gt; collection of packages, namely
&lt;a href=&#34;https://tidymodels.github.io/recipes/&#34;&gt;&lt;code&gt;{recipes}&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&#34;https://tidymodels.github.io/rsample/&#34;&gt;&lt;code&gt;{rsample}&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&#34;https://tidymodels.github.io/parsnip/&#34;&gt;&lt;code&gt;{parsnip}&lt;/code&gt;&lt;/a&gt; to train a random forest the tidy way. I will
also use &lt;a href=&#34;http://mlrmbo.mlr-org.com/&#34;&gt;&lt;code&gt;{mlrMBO}&lt;/code&gt;&lt;/a&gt; to tune the hyper-parameters of the random forest.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;set-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set up&lt;/h2&gt;
&lt;p&gt;Let’s load the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;tidymodels&amp;quot;)
library(&amp;quot;parsnip&amp;quot;)
library(&amp;quot;brotools&amp;quot;)
library(&amp;quot;mlbench&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Load the data, included in the &lt;code&gt;{mlrbench}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;BostonHousing2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will train a random forest to predict the housing price, which is the &lt;code&gt;cmedv&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(BostonHousing2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         town tract      lon     lat medv cmedv    crim zn indus chas   nox
## 1     Nahant  2011 -70.9550 42.2550 24.0  24.0 0.00632 18  2.31    0 0.538
## 2 Swampscott  2021 -70.9500 42.2875 21.6  21.6 0.02731  0  7.07    0 0.469
## 3 Swampscott  2022 -70.9360 42.2830 34.7  34.7 0.02729  0  7.07    0 0.469
## 4 Marblehead  2031 -70.9280 42.2930 33.4  33.4 0.03237  0  2.18    0 0.458
## 5 Marblehead  2032 -70.9220 42.2980 36.2  36.2 0.06905  0  2.18    0 0.458
## 6 Marblehead  2033 -70.9165 42.3040 28.7  28.7 0.02985  0  2.18    0 0.458
##      rm  age    dis rad tax ptratio      b lstat
## 1 6.575 65.2 4.0900   1 296    15.3 396.90  4.98
## 2 6.421 78.9 4.9671   2 242    17.8 396.90  9.14
## 3 7.185 61.1 4.9671   2 242    17.8 392.83  4.03
## 4 6.998 45.8 6.0622   3 222    18.7 394.63  2.94
## 5 7.147 54.2 6.0622   3 222    18.7 396.90  5.33
## 6 6.430 58.7 6.0622   3 222    18.7 394.12  5.21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Only keep relevant columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boston &amp;lt;- BostonHousing2 %&amp;gt;% 
    select(-medv, -town, -lon, -lat) %&amp;gt;% 
    rename(price = cmedv)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I remove &lt;code&gt;town&lt;/code&gt;, &lt;code&gt;lat&lt;/code&gt; and &lt;code&gt;lon&lt;/code&gt; because the information contained in the column &lt;code&gt;tract&lt;/code&gt; is enough.&lt;/p&gt;
&lt;p&gt;To train and evaluate the model’s performance, I split the data in two.
One data set, which I call the training set, will be further split into two down below. I won’t
touch the second data set, the test set, until the very end.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_test_split &amp;lt;- initial_split(boston, prop = 0.9)

housing_train &amp;lt;- training(train_test_split)

housing_test &amp;lt;- testing(train_test_split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I want to train a random forest to predict price of houses, but random forests have so-called
hyperparameters, which are parameters that cannot be estimated, or learned, from the data. Instead,
these parameters have to be chosen by the analyst. In order to choose them, you can
use values from the literature that seemed to have worked well (like is done in Macro-econometrics)
or you can further split the train set into two, create a grid of hyperparameter, train the model
on one part of the data for all values of the grid, and compare the predictions of the models on the
second part of the data. You then stick with the model that performed the best, for example, the
model with lowest RMSE. The thing is, you can’t estimate the true value of the RMSE with only
one value. It’s like if you wanted to estimate the height of the population by drawing one single
observation from the population. You need a bit more observations. To approach the true value of the
RMSE for a give set of hyperparameters, instead of doing one split, I’ll do 30. I then
compute the average RMSE, which implies training 30 models for each combination of the values of the
hyperparameters I am interested in.&lt;/p&gt;
&lt;p&gt;First, let’s split the training data again, using the &lt;code&gt;mc_cv()&lt;/code&gt; function from &lt;code&gt;{rsample}&lt;/code&gt; package.
This function implements Monte Carlo cross-validation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;validation_data &amp;lt;- mc_cv(housing_train, prop = 0.9, times = 30)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What does &lt;code&gt;validation_data&lt;/code&gt; look like?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;validation_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # # Monte Carlo cross-validation (0.9/0.1) with 30 resamples  
## # A tibble: 30 x 2
##    splits           id        
##    &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;     
##  1 &amp;lt;split [411/45]&amp;gt; Resample01
##  2 &amp;lt;split [411/45]&amp;gt; Resample02
##  3 &amp;lt;split [411/45]&amp;gt; Resample03
##  4 &amp;lt;split [411/45]&amp;gt; Resample04
##  5 &amp;lt;split [411/45]&amp;gt; Resample05
##  6 &amp;lt;split [411/45]&amp;gt; Resample06
##  7 &amp;lt;split [411/45]&amp;gt; Resample07
##  8 &amp;lt;split [411/45]&amp;gt; Resample08
##  9 &amp;lt;split [411/45]&amp;gt; Resample09
## 10 &amp;lt;split [411/45]&amp;gt; Resample10
## # … with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look further down:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;validation_data$splits[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;411/45/456&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first value is the number of rows of the first set, the second value of the second, and the third
was the original amount of values in the training data, before splitting again.&lt;/p&gt;
&lt;p&gt;How should we call these two new data sets? The author of &lt;code&gt;{rsample}&lt;/code&gt;, Max Kuhn, talks about
the &lt;em&gt;analysis&lt;/em&gt; and the &lt;em&gt;assessment&lt;/em&gt; sets:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;rsample convention for now but I intend on using it everywhere. Reusing training and testing is insane.&lt;/p&gt;&amp;mdash; Max Kuhn (@topepos) &lt;a href=&#34;https://twitter.com/topepos/status/1066131042615140353?ref_src=twsrc%5Etfw&#34;&gt;November 24, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Now, in order to continue I need pre-process the data. I will do this in three steps.
The first and the second step are used to center and scale the numeric variables and the third step
converts character and factor variables to dummy variables. This is needed because I will train a
random forest, which cannot handle factor variables directly. Let’s define a recipe to do that,
and start by pre-processing the testing set. I write a wrapper function around the recipe,
because I will need to apply this recipe to various data sets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simple_recipe &amp;lt;- function(dataset){
    recipe(price ~ ., data = dataset) %&amp;gt;%
        step_center(all_numeric()) %&amp;gt;%
        step_scale(all_numeric()) %&amp;gt;%
        step_dummy(all_nominal())
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the recipe is defined, I can use the &lt;code&gt;prep()&lt;/code&gt; function, which estimates the parameters from
the data which are needed to process the data. For example, for centering, &lt;code&gt;prep()&lt;/code&gt; estimates
the mean which will then be subtracted from the variables. With &lt;code&gt;bake()&lt;/code&gt; the estimates are then
applied on the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testing_rec &amp;lt;- prep(simple_recipe(housing_test), testing = housing_test)

test_data &amp;lt;- bake(testing_rec, newdata = housing_test)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Please use `new_data` instead of `newdata` with `bake`. 
## In recipes versions &amp;gt;= 0.1.4, this will cause an error.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to split the data before using &lt;code&gt;prep()&lt;/code&gt; and &lt;code&gt;bake()&lt;/code&gt;, because if not, you will
use observations from the test set in the &lt;code&gt;prep()&lt;/code&gt; step, and thus introduce knowledge from the test
set into the training data. This is called data leakage, and must be avoided. This is why it is
necessary to first split the training data into an analysis and an assessment set, and then also
pre-process these sets separately. However, the &lt;code&gt;validation_data&lt;/code&gt; object cannot now be used with
&lt;code&gt;recipe()&lt;/code&gt;, because it is not a dataframe. No worries, I simply need to write a function that extracts
the analysis and assessment sets from the &lt;code&gt;validation_data&lt;/code&gt; object, applies the pre-processing, trains
the model, and returns the RMSE. This will be a big function, at the center of the analysis.&lt;/p&gt;
&lt;p&gt;But before that, let’s run a simple linear regression, as a benchmark. For the linear regression, I will
not use any CV, so let’s pre-process the training set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trainlm_rec &amp;lt;- prep(simple_recipe(housing_train), testing = housing_train)

trainlm_data &amp;lt;- bake(trainlm_rec, newdata = housing_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Please use `new_data` instead of `newdata` with `bake`. 
## In recipes versions &amp;gt;= 0.1.4, this will cause an error.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linreg_model &amp;lt;- lm(price ~ ., data = trainlm_data)

broom::augment(linreg_model, newdata = test_data) %&amp;gt;% 
    rmse(price, .fitted)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard       0.438&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;broom::augment()&lt;/code&gt; adds the predictions to the &lt;code&gt;test_data&lt;/code&gt; in a new column, &lt;code&gt;.fitted&lt;/code&gt;. I won’t
use this trick with the random forest, because there is no &lt;code&gt;augment()&lt;/code&gt; method for random forests
from the &lt;code&gt;{ranger}&lt;/code&gt; which I’ll use. I’ll add the predictions to the data myself.&lt;/p&gt;
&lt;p&gt;Ok, now let’s go back to the random forest and write the big function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_rf &amp;lt;- function(mtry, trees, split, id){
    
    analysis_set &amp;lt;- analysis(split)
    
    analysis_prep &amp;lt;- prep(simple_recipe(analysis_set), training = analysis_set)
    
    analysis_processed &amp;lt;- bake(analysis_prep, newdata = analysis_set)
    
    model &amp;lt;- rand_forest(mtry = mtry, trees = trees) %&amp;gt;%
        set_engine(&amp;quot;ranger&amp;quot;, importance = &amp;#39;impurity&amp;#39;) %&amp;gt;%
        fit(price ~ ., data = analysis_processed)

    assessment_set &amp;lt;- assessment(split)
    
    assessment_prep &amp;lt;- prep(simple_recipe(assessment_set), testing = assessment_set)
    
    assessment_processed &amp;lt;- bake(assessment_prep, newdata = assessment_set)

    tibble::tibble(&amp;quot;id&amp;quot; = id,
        &amp;quot;truth&amp;quot; = assessment_processed$price,
        &amp;quot;prediction&amp;quot; = unlist(predict(model, new_data = assessment_processed)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;rand_forest()&lt;/code&gt; function is available from the &lt;code&gt;{parsnip}&lt;/code&gt; package. This package provides an
unified interface to a lot of other machine learning packages. This means that instead of having to
learn the syntax of &lt;code&gt;range()&lt;/code&gt; and &lt;code&gt;randomForest()&lt;/code&gt; and, and… you can simply use the &lt;code&gt;rand_forest()&lt;/code&gt;
function and change the &lt;code&gt;engine&lt;/code&gt; argument to the one you want (&lt;code&gt;ranger&lt;/code&gt;, &lt;code&gt;randomForest&lt;/code&gt;, etc).&lt;/p&gt;
&lt;p&gt;Let’s try this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_example &amp;lt;- map2_df(.x = validation_data$splits,
                           .y = validation_data$id,
                           ~my_rf(mtry = 3, trees = 200, split = .x, id = .y))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(results_example)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   id           truth prediction
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1 Resample01  0.0235    -0.104 
## 2 Resample01 -0.135     -0.0906
## 3 Resample01 -0.378     -0.158 
## 4 Resample01 -0.232      0.0623
## 5 Resample01 -0.0859     0.0173
## 6 Resample01  0.169      0.303&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now compute the RMSE when &lt;code&gt;mtry&lt;/code&gt; = 3 and &lt;code&gt;trees&lt;/code&gt; = 200:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results_example %&amp;gt;%
    group_by(id) %&amp;gt;%
    rmse(truth, prediction) %&amp;gt;%
    summarise(mean_rmse = mean(.estimate)) %&amp;gt;%
    pull&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4319164&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The random forest has already lower RMSE than the linear regression. The goal now is to lower this
RMSE by tuning the &lt;code&gt;mtry&lt;/code&gt; and &lt;code&gt;trees&lt;/code&gt; hyperparameters. For this, I will use Bayesian Optimization
methods implemented in the &lt;code&gt;{mlrMBO}&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-hyperparameter-optimization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian hyperparameter optimization&lt;/h2&gt;
&lt;p&gt;I will re-use the code from above, and define a function that does everything from pre-processing
to returning the metric I want to minimize by tuning the hyperparameters, the RMSE:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tuning &amp;lt;- function(param, validation_data){

    mtry &amp;lt;- param[1]
    trees &amp;lt;- param[2]

    results &amp;lt;- purrr::map2_df(.x = validation_data$splits,
                       .y = validation_data$id,
                       ~my_rf(mtry = mtry, trees = trees, split = .x, id = .y))

    results %&amp;gt;%
        group_by(id) %&amp;gt;%
        rmse(truth, prediction) %&amp;gt;%
        summarise(mean_rmse = mean(.estimate)) %&amp;gt;%
        pull
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is exactly the code from before, but it now returns the RMSE. Let’s try the function
with the values from before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tuning(c(3, 200), validation_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4330951&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s also plot the value of RMSE for &lt;code&gt;mtry = 3&lt;/code&gt; and &lt;code&gt;trees&lt;/code&gt; from 200 to 300. This takes some
time, because I need to evaluate this costly function 100 times. If evaluating the function was
cheap, I could have made a 3D plot by varying values of &lt;code&gt;mtry&lt;/code&gt; too, but then again if evaluating
the function was cheap, I would run an exhaustive grid search to find the hyperparameters instead of
using Bayesian optimization.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_points &amp;lt;- crossing(&amp;quot;mtry&amp;quot; = 3, &amp;quot;trees&amp;quot; = seq(200, 300))

plot_data &amp;lt;- plot_points %&amp;gt;% 
    mutate(value = map_dbl(seq(200, 300), ~tuning(c(3, .), validation_data)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_data %&amp;gt;% 
    ggplot(aes(y = value, x = trees)) + 
    geom_line(colour = &amp;quot;#82518c&amp;quot;) + 
    theme_blog() +
    ggtitle(&amp;quot;RMSE for mtry = 3&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-25-tidy_cv_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;mtry = 3&lt;/code&gt; the minimum seems to lie around 255. The function to minimize is not smooth at all.&lt;/p&gt;
&lt;p&gt;I now follow the code that can be found in the &lt;a href=&#34;https://arxiv.org/abs/1703.03373&#34;&gt;arxiv&lt;/a&gt; paper to
run the optimization. I think I got the gist of the paper, but I did not understand everything yet.
For now, I am still experimenting with the library at the moment, but from what I understand, a
simpler model, called the surrogate model, is used to look for promising points and to evaluate the
value of the function at these points. This seems somewhat similar (in spirit) to the
&lt;em&gt;Indirect Inference&lt;/em&gt; method as described in &lt;a href=&#34;https://www.jstor.org/stable/2285076&#34;&gt;Gourieroux, Monfort, Renault&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s first load the package and create the function to optimize:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;mlrMBO&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fn &amp;lt;- makeSingleObjectiveFunction(name = &amp;quot;tuning&amp;quot;,
                                 fn = tuning,
                                 par.set = makeParamSet(makeIntegerParam(&amp;quot;x1&amp;quot;, lower = 3, upper = 8),
                                                        makeIntegerParam(&amp;quot;x2&amp;quot;, lower = 50, upper = 500)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function is based on the function I defined before. The parameters to optimize are also
defined as are their bounds. I will look for &lt;code&gt;mtry&lt;/code&gt; between the values of 3 and 8, and &lt;code&gt;trees&lt;/code&gt;
between 50 and 500.&lt;/p&gt;
&lt;p&gt;Now comes the part I didn’t quite get.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create initial random Latin Hypercube Design of 10 points
library(lhs)# for randomLHS
des &amp;lt;- generateDesign(n = 5L * 2L, getParamSet(fn), fun = randomLHS)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this means that these 10 points are the points used to start the whole process. I did not
understand why they have to be sampled from a hypercube, but ok. Then I choose the surrogate model,
a random forest too, and predict the standard error. Here also, I did not quite get why the
standard error can be an option.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Specify kriging model with standard error estimation
surrogate &amp;lt;- makeLearner(&amp;quot;regr.ranger&amp;quot;, predict.type = &amp;quot;se&amp;quot;, keep.inbag = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here I define some options:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set general controls
ctrl &amp;lt;- makeMBOControl()
ctrl &amp;lt;- setMBOControlTermination(ctrl, iters = 10L)
ctrl &amp;lt;- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And this is the optimization part:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Start optimization
result &amp;lt;- mbo(fn, des, surrogate, ctrl, more.args = list(&amp;quot;validation_data&amp;quot; = validation_data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Recommended parameters:
## x1=6; x2=381
## Objective: y = 0.393
## 
## Optimization path
## 10 + 10 entries in total, displaying last 10 (or less):
##    x1  x2         y dob eol error.message exec.time            ei
## 11  6 370 0.3943479   1  NA          &amp;lt;NA&amp;gt;     8.913 -3.134568e-05
## 12  6 362 0.3950402   2  NA          &amp;lt;NA&amp;gt;     8.844 -2.987934e-05
## 13  6 373 0.3939587   3  NA          &amp;lt;NA&amp;gt;     8.939 -2.259674e-05
## 14  6 394 0.3962875   4  NA          &amp;lt;NA&amp;gt;     9.342 -7.427682e-06
## 15  6 368 0.3944954   5  NA          &amp;lt;NA&amp;gt;     8.760 -4.121337e-06
## 16  6 378 0.3938796   6  NA          &amp;lt;NA&amp;gt;     8.949 -4.503591e-07
## 17  6 381 0.3934176   7  NA          &amp;lt;NA&amp;gt;     9.109 -1.141853e-06
## 18  6 380 0.3948077   8  NA          &amp;lt;NA&amp;gt;     9.026 -4.718394e-08
## 19  6 381 0.3932636   9  NA          &amp;lt;NA&amp;gt;     9.022 -9.801395e-08
## 20  6 383 0.3953004  10  NA          &amp;lt;NA&amp;gt;     9.184 -1.579619e-09
##    error.model train.time prop.type propose.time           se      mean
## 11        &amp;lt;NA&amp;gt;      0.014 infill_ei        0.449 0.0010924600 0.3955131
## 12        &amp;lt;NA&amp;gt;      0.012 infill_ei        0.458 0.0007415920 0.3948705
## 13        &amp;lt;NA&amp;gt;      0.012 infill_ei        0.460 0.0006116756 0.3947185
## 14        &amp;lt;NA&amp;gt;      0.012 infill_ei        0.729 0.0003104694 0.3943572
## 15        &amp;lt;NA&amp;gt;      0.023 infill_ei        0.444 0.0003446061 0.3945085
## 16        &amp;lt;NA&amp;gt;      0.013 infill_ei        0.458 0.0002381887 0.3944642
## 17        &amp;lt;NA&amp;gt;      0.013 infill_ei        0.492 0.0002106454 0.3943200
## 18        &amp;lt;NA&amp;gt;      0.013 infill_ei        0.516 0.0002093524 0.3940764
## 19        &amp;lt;NA&amp;gt;      0.014 infill_ei        0.756 0.0002481260 0.3941597
## 20        &amp;lt;NA&amp;gt;      0.013 infill_ei        0.483 0.0001687982 0.3939285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the recommended parameters are 6 for &lt;code&gt;mtry&lt;/code&gt; and 381 for &lt;code&gt;trees&lt;/code&gt;. The value of the RMSE is lower
than before, and equals 0.393.
Let’s now train the random forest on the training data with this values. First, I pre-process the
training data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;training_rec &amp;lt;- prep(simple_recipe(housing_train), testing = housing_train)

train_data &amp;lt;- bake(training_rec, newdata = housing_train)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Please use `new_data` instead of `newdata` with `bake`. 
## In recipes versions &amp;gt;= 0.1.4, this will cause an error.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now train our final model and predict the prices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_model &amp;lt;- rand_forest(mtry = 6, trees = 381) %&amp;gt;%
        set_engine(&amp;quot;ranger&amp;quot;, importance = &amp;#39;impurity&amp;#39;) %&amp;gt;%
        fit(price ~ ., data = train_data)

price_predict &amp;lt;- predict(final_model, new_data = select(test_data, -price))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s transform the data back and compare the predicted prices to the true ones visually:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cbind(price_predict * sd(housing_train$price) + mean(housing_train$price), 
      housing_test$price)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        .pred housing_test$price
## 1  34.811111               34.7
## 2  20.591304               22.9
## 3  19.463920               18.9
## 4  20.321990               21.7
## 5  19.063132               17.5
## 6  15.969125               14.5
## 7  18.203023               15.6
## 8  17.139943               13.9
## 9  21.393329               24.2
## 10 27.508482               25.0
## 11 24.030162               24.1
## 12 21.222857               21.2
## 13 23.052677               22.2
## 14 20.303233               19.3
## 15 21.134554               21.7
## 16 22.913097               18.5
## 17 20.029506               18.8
## 18 18.045923               16.2
## 19 17.321006               13.3
## 20 18.201785               13.4
## 21 29.928316               32.5
## 22 24.339983               26.4
## 23 45.518316               42.3
## 24 29.551251               26.7
## 25 26.513473               30.1
## 26 42.984738               46.7
## 27 43.513001               48.3
## 28 25.436146               23.3
## 29 21.766247               24.3
## 30 36.328740               36.0
## 31 32.830061               31.0
## 32 38.736098               35.2
## 33 31.573311               32.0
## 34 19.847848               19.4
## 35 23.401032               23.1
## 36 22.000914               19.4
## 37 20.155696               18.7
## 38 21.342003               22.6
## 39 20.846330               19.9
## 40 13.752108               13.8
## 41 12.499064               13.1
## 42 15.019987               16.3
## 43  8.489851                7.2
## 44  7.803981               10.4
## 45 18.629488               20.8
## 46 14.645669               14.3
## 47 15.094423               15.2
## 48 20.470057               17.7
## 49 15.147170               13.3
## 50 15.880035               13.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now compute the RMSE:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble::tibble(&amp;quot;truth&amp;quot; = test_data$price,
        &amp;quot;prediction&amp;quot; = unlist(price_predict)) %&amp;gt;% 
    rmse(truth, prediction)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 rmse    standard       0.327&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Very nice.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The best way to visit Luxembourguish castles is doing data science &#43; combinatorial optimization</title>
      <link>https://www.brodrigues.co/blog/2018-11-21-lux_castle/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-21-lux_castle/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=XQDm6I3mbMU&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/harold_kumar.jpg&#34; title = &#34;Only 00&#39;s kids will get the reference&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Inspired by David Schoch’s blog post,
&lt;a href=&#34;http://blog.schochastics.net/post/traveling-beerdrinker-problem/&#34;&gt;Traveling Beerdrinker Problem&lt;/a&gt;.
Check out his blog, he has some amazing posts!&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Luxembourg, as any proper European country, is full of castles. According to Wikipedia,&lt;/p&gt;
&lt;p&gt;“By some optimistic estimates, there are as many as 130 castles in Luxembourg but more realistically
there are probably just over a hundred, although many of these could be considered large residences
or manor houses rather than castles”.&lt;/p&gt;
&lt;p&gt;I see the editors are probably German or French, calling our castles &lt;em&gt;manor houses&lt;/em&gt;! They only say
that because Luxembourg is small, so our castles must be small too, right?&lt;/p&gt;
&lt;p&gt;Banter aside, with that many castles, what is the best way to visit them all? And by best way I mean
shortest way. This is a classical &lt;strong&gt;Travelling salesman problem&lt;/strong&gt;. To solve this, I need the following elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A list of castles to visit, with their coordinates&lt;/li&gt;
&lt;li&gt;The distances between these castles to each other&lt;/li&gt;
&lt;li&gt;A program to solve the TSP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s start by loading some packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(magrittr)
library(rvest)
library(curl)
library(brotools)
library(RJSONIO)
library(TSP)
library(ggimage)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First step; scrape the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scraping-the-data-thats-the-data-science-part&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scraping the data (that’s the data science part)&lt;/h2&gt;
&lt;p&gt;Let’s start by having a list of castles. For this, I go to the French Wikipedia page of
&lt;a href=&#34;https://fr.wikipedia.org/wiki/Liste_de_ch%C3%A2teaux_luxembourgeois&#34;&gt;Luxembourguish castles&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Luxembourguish page is more &lt;a href=&#34;https://lb.wikipedia.org/wiki/L%C3%ABscht_vun_de_L%C3%ABtzebuerger_Buergen_a_Schl%C3%A4sser&#34;&gt;exhaustive&lt;/a&gt;,
but the names are in Luxembourguish, and I doubt that
OpenStreetMap, which I’ll use to get the coordinates, understands Luxembourguish.&lt;/p&gt;
&lt;p&gt;This list has around 50 castles, a reasonable amount of castles. Scraping the table is quite easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;page &amp;lt;- read_html(&amp;quot;https://fr.wikipedia.org/wiki/Liste_de_ch%C3%A2teaux_luxembourgeois&amp;quot;)

castles &amp;lt;- page %&amp;gt;%
    html_node(&amp;quot;.wikitable&amp;quot;) %&amp;gt;%
    html_table(fill = TRUE) %&amp;gt;%
    select(Nom, Localité) %&amp;gt;%
    mutate(query = paste0(Nom, &amp;quot;, &amp;quot;, Localité))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also add a &lt;code&gt;query&lt;/code&gt; column which concatenates the name of the castle (“Nom”) to where it is found
(“Localité”). The query should be a better choice that simply the castle name to get the coordinates.&lt;/p&gt;
&lt;p&gt;Now, I need to add the coordinates to this data frame. For this, I use a function I found online
that gets the coordinates from OpenStreetMap:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## geocoding function using OSM Nominatim API
## details: http://wiki.openstreetmap.org/wiki/Nominatim
## made by: D.Kisler

#https://datascienceplus.com/osm-nominatim-with-r-getting-locations-geo-coordinates-by-its-address/

nominatim_osm &amp;lt;- function(address = NULL){
    if(suppressWarnings(is.null(address)))
        return(data.frame())
    tryCatch(
        d &amp;lt;- jsonlite::fromJSON(
            gsub(&amp;#39;\\@addr\\@&amp;#39;, gsub(&amp;#39;\\s+&amp;#39;, &amp;#39;\\%20&amp;#39;, address),
                 &amp;#39;http://nominatim.openstreetmap.org/search/@addr@?format=json&amp;amp;addressdetails=0&amp;amp;limit=1&amp;#39;)
        ), error = function(c) return(data.frame())
    )
    if(length(d) == 0) return(data.frame())
    return(data.frame(lon = as.numeric(d$lon), lat = as.numeric(d$lat)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now easily add the coordinates by mapping the &lt;code&gt;nominatim_osm()&lt;/code&gt; function to the
&lt;code&gt;query&lt;/code&gt; column I built before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;castles_osm &amp;lt;- castles %&amp;gt;%
    mutate(geolocation = map(query, nominatim_osm))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;castles_osm&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(castles_osm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            Nom    Localité
## 1         Château d&amp;#39;Ansembourg  Ansembourg
## 2 Nouveau Château d&amp;#39;Ansembourg  Ansembourg
## 3             Château d&amp;#39;Aspelt      Aspelt
## 4          Château de Beaufort    Beaufort
## 5            Château de Beggen Dommeldange
## 6       Château de Colmar-Berg Colmar-Berg
##                                      query         geolocation
## 1         Château d&amp;#39;Ansembourg, Ansembourg 6.046748, 49.700693
## 2 Nouveau Château d&amp;#39;Ansembourg, Ansembourg   6.04760, 49.70085
## 3                 Château d&amp;#39;Aspelt, Aspelt 6.222653, 49.524822
## 4            Château de Beaufort, Beaufort 2.757293, 43.297466
## 5           Château de Beggen, Dommeldange 6.137765, 49.643383
## 6      Château de Colmar-Berg, Colmar-Berg 6.087944, 49.814687&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now clean the data. There were several mistakes or castles that were not found, which I added
manually. I did not notice these mistakes immediately, but when I computed the distances matrix I
notices several inconsistencies; 0’s in positions other than the diagonal, as well as NAs. So I went
back to the raw data and corrected what was wrong, this time by looking at Google Maps. Thankfully
there were not that many mistakes. Below the whole workflow:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Little helper function to clean the lon and lat columns
extract_numbers &amp;lt;- function(string){
    str_extract_all(string, &amp;quot;\\d+&amp;quot;, simplify = TRUE) %&amp;gt;%
        paste0(collapse = &amp;quot;.&amp;quot;)
}

castles &amp;lt;- castles_osm %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Wintrange&amp;quot;, &amp;quot;6.3517223, 49.5021975&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Septfontaines, Rollingergrund&amp;quot;, &amp;quot;6.1028634, 49.6257147&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Septfontaines&amp;quot;, &amp;quot;5.9617443, 49.7006292&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Senningen&amp;quot;, &amp;quot;6.2342581, 49.6464632&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Schauwenburg&amp;quot;, &amp;quot;6.0478341, 49.6110245&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Schuttbourg&amp;quot;, &amp;quot;5.8980951, 49.7878706&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Meysembourg&amp;quot;, &amp;quot;6.1864882, 49.7704348&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Mamer&amp;quot;, &amp;quot;6.0232432, 49.6262397&amp;quot;, geolocation)) %&amp;gt;%
    mutate(geolocation = 
               ifelse(Nom == &amp;quot;Château de Born&amp;quot;, &amp;quot;6.5125214, 49.7611168&amp;quot;, geolocation)) %&amp;gt;%
    # Found chateau de Betzdorf in Germany, not Luxembourg:
    mutate(geolocation = ifelse(Nom == &amp;quot;Château Betzdorf&amp;quot;, &amp;quot;6.330278, 49.694167&amp;quot;, geolocation)) %&amp;gt;%
    # Found château de Clemency in France, not Luxembourg:
    mutate(geolocation = ifelse(Nom == &amp;quot;Château de Clemency&amp;quot;, &amp;quot;5.874167, 49.598056&amp;quot;, geolocation)) %&amp;gt;%
    separate(geolocation, into = c(&amp;quot;lon&amp;quot;, &amp;quot;lat&amp;quot;), sep = &amp;quot;,&amp;quot;) %&amp;gt;%
    filter(!is.na(lat)) %&amp;gt;%
    mutate(lon = map(lon, extract_numbers)) %&amp;gt;%
    mutate(lat = map(lat, extract_numbers)) %&amp;gt;%
    # Château de Beaufort found is in southern France, not the one in lux
    # Château de Dudelange is wrong (same as Bettembourg)
    # Château de Pétange is wrong (same as Differdange)
    # Château d&amp;#39;Urspelt is wrong (same as Clervaux)
    # Château d&amp;#39;Hesperange is wrong (same as Palais Grand-Ducal)
    mutate(lon = ifelse(Nom == &amp;quot;Château de Beaufort&amp;quot;, &amp;quot;6.2865176&amp;quot;, lon),
           lat = ifelse(Nom == &amp;quot;Château de Beaufort&amp;quot;, &amp;quot;49.8335306&amp;quot;, lat)) %&amp;gt;%
    mutate(lon = ifelse(Nom == &amp;quot;Château Dudelange&amp;quot;, &amp;quot;6.0578438&amp;quot;, lon),
           lat = ifelse(Nom == &amp;quot;Château Dudelange&amp;quot;, &amp;quot;49.4905049&amp;quot;, lat)) %&amp;gt;%
    mutate(lon = ifelse(Nom == &amp;quot;Château de Pétange&amp;quot;, &amp;quot;6.105703&amp;quot;, lon),
           lat = ifelse(Nom == &amp;quot;Château de Pétange&amp;quot;, &amp;quot;49.7704746&amp;quot;, lat)) %&amp;gt;%
    mutate(lon = ifelse(Nom == &amp;quot;Château d&amp;#39; Urspelt&amp;quot;, &amp;quot;6.043375&amp;quot;, lon),
           lat = ifelse(Nom == &amp;quot;Château d&amp;#39; Urspelt&amp;quot;, &amp;quot;50.075342&amp;quot;, lat)) %&amp;gt;%
    mutate(lon = ifelse(Nom == &amp;quot;Château d&amp;#39;Hesperange&amp;quot;, &amp;quot;6.1524302&amp;quot;, lon),
           lat = ifelse(Nom == &amp;quot;Château d&amp;#39;Hesperange&amp;quot;, &amp;quot;49.573071&amp;quot;, lat)) %&amp;gt;%
    mutate(latlon = paste0(lat, &amp;quot;,&amp;quot;, lon)) %&amp;gt;%
    mutate(lon = as.numeric(lon), lat = as.numeric(lat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the end, I have 48 castles, 2 of them were not found neither by OpenStreetMap nor
Google Maps.&lt;/p&gt;
&lt;p&gt;Now I can get the distances matrix. For this, I opened an account at &lt;a href=&#34;https://www.graphhopper.com/&#34;&gt;Graphhopper&lt;/a&gt;
and used their &lt;a href=&#34;https://graphhopper.com/api/1/docs/matrix/#matrix-api&#34;&gt;Matrix API&lt;/a&gt;. When you open
a free account, you get a standard account for free for two weeks, which was perfect for this little
exercise.&lt;/p&gt;
&lt;p&gt;To use the Matrix API you can make a call with curl from your terminal, like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl &amp;quot;https://graphhopper.com/api/1/matrix?point=49.932707,11.588051&amp;amp;point=50.241935,10.747375&amp;amp;point=50.118817,11.983337&amp;amp;type=json&amp;amp;vehicle=car&amp;amp;debug=true&amp;amp;out_array=weights&amp;amp;out_array=times&amp;amp;out_array=distances&amp;amp;key=[YOUR_KEY]&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To use this from R, I use the &lt;code&gt;{curl}&lt;/code&gt; package and the &lt;code&gt;curl_download()&lt;/code&gt; function to download and
write the output to disk.&lt;/p&gt;
&lt;p&gt;I built the url like this. First, the “points” part:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points &amp;lt;- paste(castles$latlon, collapse = &amp;quot;&amp;amp;point=&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the “points” string&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;49.70069265,6.04674779400653&amp;amp;point=49.7008533,6.04759957386294&amp;amp;point=49.5248216,6.2226525964455&amp;amp;point=49.8335306,6.2865176&amp;amp;point=49.64338295,6.1377647435619&amp;amp;point=49.8146867,6.08794389490417&amp;amp;point=49.5749356,5.9841033&amp;amp;point=49.5173197,6.09641390513718&amp;amp;point=49.8760687,6.22027097982788&amp;amp;point=49.694167,6.330278&amp;amp;point=49.7611168,6.5125214&amp;amp;point=49.70256665,6.21740997690437&amp;amp;point=49.905581,6.07950107769784&amp;amp;point=49.9127745,6.13764166375989&amp;amp;point=49.598056,5.874167&amp;amp;point=50.0544533,6.03028463135369&amp;amp;point=49.75943095,5.82586812555896&amp;amp;point=49.52132545,5.88917535225117&amp;amp;point=49.6345518,6.1386377&amp;amp;point=49.4905049,6.0578438&amp;amp;point=49.8600716,6.11163732377525&amp;amp;point=49.9110418,5.93440053120085&amp;amp;point=49.7475976,6.18681116161273&amp;amp;point=49.61092115,6.13288873913352&amp;amp;point=49.573071,6.1524302&amp;amp;point=49.71207855,6.05156617599082&amp;amp;point=49.6694157,5.9496767&amp;amp;point=49.7704143,6.18888954785334&amp;amp;point=49.6262397,6.0232432&amp;amp;point=49.7478579,6.10315847283333&amp;amp;point=49.7704348,6.1864882&amp;amp;point=49.6328906,6.25941956000154&amp;amp;point=49.7704746,6.105703&amp;amp;point=49.54325715,5.9262570638974&amp;amp;point=49.470114,6.3658507&amp;amp;point=49.719675,6.09334070925783&amp;amp;point=49.7878706,5.8980951&amp;amp;point=49.6110245,6.0478341&amp;amp;point=49.6464632,6.2342581&amp;amp;point=49.7006292,5.9617443&amp;amp;point=49.6257147,6.1028634&amp;amp;point=49.556964,6.380786&amp;amp;point=50.075342,6.043375&amp;amp;point=49.7682266,5.9803414&amp;amp;point=49.9348908,6.20279648757301&amp;amp;point=49.6604088,6.1337864&amp;amp;point=49.9664662,5.93854270968922&amp;amp;point=49.5021975,6.3517223&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Then, I added my key, and pasted these elements together to form the correct url:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_key &amp;lt;- &amp;quot;my_key_was_here&amp;quot;

url &amp;lt;- paste0(&amp;quot;https://graphhopper.com/api/1/matrix?point=&amp;quot;, points, &amp;quot;&amp;amp;type=json&amp;amp;vehicle=car&amp;amp;debug=true&amp;amp;out_array=weights&amp;amp;out_array=times&amp;amp;out_array=distances&amp;amp;key=&amp;quot;, my_key)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I get the matrix like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;castles_dist &amp;lt;- &amp;quot;distances_graphhopper.json&amp;quot;
curl_download(url, castles_dist)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distances &amp;lt;- castles_dist$distances&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the distance object&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distances&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##  [1]     0    48 46364 38416 16619 20387 19617 31990 31423 46587 60894
## [12] 19171 36961 30701 25734 52929 22843 42618 18138 40015 24860 39395
## [23] 17163 18938 28107  2570 10882 16888 12302  9350 16599 32025 14369
## [34] 40780 56004  6069 17602 16112 31552  8180 14523 49431 53199 13354
## [45] 43769 15868 46237 53617
## 
## [[2]]
##  [1]    48     0 46412 38464 16667 20435 19665 32038 31471 46635 60942
## [12] 19219 37009 30749 25781 52977 22890 42665 18186 40063 24908 39443
## [23] 17211 18986 28155  2618 10930 16936 12350  9398 16647 32073 14417
## [34] 40828 56052  6116 17650 16160 31599  8228 14571 49478 53247 13402
## [45] 43817 15916 46285 53665
## 
## [[3]]
##  [1] 46900 46947     0 48698 30281 45548 30424 17056 56584 31187 52215
## [12] 28799 62122 55862 39130 78090 66375 33585 23961 21009 50021 64556
## [23] 35740 25853 10852 49283 43218 43052 37317 36283 42763 17250 39530
## [34] 31748 14513 33919 60798 31885 22872 44629 37023 14605 78360 44602
## [45] 68930 26320 71398 12126
## 
## [[4]]
##  [1] 38214 38261 48754     0 34949 23582 55661 48848 11274 29579 26880
## [12] 25631 32853 20633 67818 46577 47882 65319 33355 58499 26540 40460
## [23] 24359 38061 43577 37674 61661 21704 55760 29822 25030 36698 27956
## [34] 63482 72862 32945 42596 50328 34302 42495 38740 46782 46847 35141
## [45] 20752 33520 47302 56789
## 
## [[5]]
##  [1] 16494 16541 25311 35192     0 25375 19477 16687 36411 20939 42124
## [12] 13107 41949 35689 27116 57917 44116 30670  1432 26337 29848 44383
## [23] 18673  5767 11224 18877 20958 23922 15058 16110 23633 13255 19357
## [34] 28833 40700 15310 30392 12024 12782 20050  7178 30661 58187 24429
## [45] 48757  2511 51225 33346
## 
## [[6]]
##  [1] 18468 18516 43459 23632 29633     0 33496 43553 15352 45965 60272
## [12] 23583 20890 14630 39612 36858 27623 60024 28268 53203  8789 21614
## [23] 17217 32765 38282 17929 29164 13853 27119  8892 15798 31403  7026
## [34] 58187 67567 13199 22337 27919 30929 22750 26330 48809 37128 14882
## [45] 27698 21128 28456 51494
## 
## [[7]]
##  [1] 19645 19693 30022 55860 21434 35353     0 17740 46389 45070 59377
## [12] 35962 51927 45668 10941 67895 36650 11975 16038 16675 39826 49570
## [23] 42902 13747 19018 22029 13093 32857  7837 24321 32568 30508 29335
## [34]  8659 39662 20998 33544  9053 30034 17958 19337 40306 68165 29296
## [45] 58736 20683 59099 37275
## 
## [[8]]
##  [1] 33194 33242 17113 48244 16576 45094 16196     0 56130 37454 51761
## [12] 28345 61668 55408 26667 77635 52670 21122 15199  8546 49567 64102
## [23] 35286 12148 11167 35578 29512 42597 23612 35829 42308 22891 39076
## [34] 19285 26753 30159 47093 12671 22418 30923 23317 27397 77906 44148
## [45] 68476 25866 70944 24366
## 
## [[9]]
##  [1] 34049 34097 59040 11039 45215 18025 49077 59134     0 35131 34289
## [12] 25588 18148  8956 55193 34944 47717 75605 43849 68785 11835 33390
## [23] 19644 48347 53863 33510 44745 17010 42701 26274 22029 46984 22791
## [34] 73768 83148 28780 42477 43501 46511 38331 41912 64390 35215 29033
## [45] 11504 36710 37265 67075
## 
## [[10]]
##  [1] 40768 40815 31200 29561 26887 47108 44877 38064 35204     0 24550
## [12] 11501 46805 40546 57034 62773 59493 54535 25521 47714 51581 66116
## [23] 18215 27276 32792 40228 50876 23464 44975 37844 23175 16279 41090
## [34] 52698 33741 35479 54253 39544 10472 52287 30906 22876 63043 46162
## [45] 44908 19378 72959 30101
## 
## [[11]]
##  [1] 54812 54860 52014 26837 40931 61152 58921 52108 34149 24114     0
## [12] 30135 56417 42752 71078 69452 73537 68579 39565 61758 65626 80160
## [23] 33264 41320 46836 54272 64920 34961 59020 51888 38287 30323 55134
## [34] 66742 46672 49523 68297 53588 33981 66331 44951 37998 69722 60206
## [45] 39488 41924 87003 44227
## 
## [[12]]
##  [1] 19189 19237 28715 23758 13122 25545 35622 28809 25568 11495 27547
## [12]     0 42119 35859 47779 58087 37930 45280 12217 38459 30018 44553
## [23]  8427 18021 23537 18649 41621 13676 35721 16280 13387 16659 19527
## [34] 43443 52822 13901 32690 30289 10679 28544 17602 34064 58357 24599
## [45] 34791 11692 51395 36749
## 
## [[13]]
##  [1] 36813 36860 61804 32740 47978 20788 51841 61898 18594 46628 54032
## [12] 41927     0 11355 57957 25913 31393 78369 46612 71548 10254 18035
## [23] 33039 51110 56626 36273 47508 29674 45464 29037 31619 49747 26873
## [34] 76531 85911 31544 28499 46264 49274 41094 44675 67153 26183 28043
## [45] 22973 39473 21910 69838
## 
## [[14]]
##  [1] 30553 30601 55544 20685 41718 14528 45581 55638  9008 40368 42945
## [12] 35668 11355     0 51697 26249 44221 72109 40353 65288  8339 26597
## [23] 26779 44850 50367 30014 41249 23415 39204 22778 25360 43488 20613
## [34] 70272 79652 25284 38981 40004 43014 34835 38415 60894 26519 25537
## [45] 13328 33213 30473 63579
## 
## [[15]]
##  [1] 25606 25654 38728 67712 27136 41314 10938 26445 52350 56922 71229
## [12] 37346 57888 51628     0 73856 27918 10658 28655 25381 45787 55480
## [23] 42912 31851 30870 27990 14521 38818 16023 30282 38529 42360 35296
## [34]  9692 48367 26996 35203 18968 41886 19386 25040 49012 74126 25555
## [45] 64696 26385 63610 45980
## 
## [[16]]
##  [1]  52597  52644  77588  46234  63762  36572  67625  77681  34889  62412
## [11]  69484  57711  25729  26142  73741      0  51707  94153  62396  87332
## [21]  30382  29845  48823  66894  72410  52057  63292  45458  61248  44821
## [31]  47403  65531  42657  92315 101695  47328  48813  62048  65058  56878
## [41]  60459  82937   3927  48357  26809  55257  16900  85622
## 
## [[17]]
##  [1] 22742 22790 66383 47823 44393 27506 36726 52009 45012 59978 74285
## [12] 37595 31384 44290 27751 49817     0 38346 45912 60034 38449 23624
## [23] 32592 49107 48126 21474 20735 31486 33280 24718 31198 45415 24781
## [34] 37380 76023 27212  9559 36224 44942 16608 42297 71343 51639 13101
## [45] 57358 43642 33153 73636
## 
## [[18]]
##  [1] 43466 43513 32742 64592 35685 61442 12026 20459 72478 53802 68109
## [12] 44693 78016 71756 10711 93983 38600     0 31781 19395 65915 80450
## [23] 51634 28730 27749 45849 20641 58945 19674 52177 58656 39239 55424
## [34]  6452 42381 40430 45885 20422 38766 25506 33588 43026 94253 53116
## [45] 84824 34934 87292 39994
## 
## [[19]]
##  [1] 17092 17140 23308 33262  1432 30429 15982 15299 41465 25814 40121
## [12] 12039 47003 40743 27715 62970 44714 29283     0 24950 34902 49437
## [23] 17605  4379  9837 19476 21557 22854 15656 21164 22565 11252 24411
## [34] 27446 39313 18800 37574 12622 10778 20648  5791 28657 63241 29483
## [45] 53811  3497 56279 31342
## 
## [[20]]
##  [1] 40369 40417 21028 58519 26851 55368 16853  5415 66404 47729 62035
## [12] 38620 71942 65683 25560 87910 59845 20015 25473     0 59842 74376
## [23] 45561 22423 21442 42753 36687 52872 30786 46104 52583 33166 49351
## [34] 18178 30668 37333 54268 25355 32693 38098 30492 31312 88180 50019
## [45] 78751 31837 81219 28281
## 
## [[21]]
##  [1] 25435 25483 50426 23657 36601  9410 40463 50520  9511 52933 67240
## [12] 30550 10254  8470 46579 30697 31384 66991 35235 60171     0 22368
## [23] 19572 39732 45249 24896 36131 16208 34087 17660 18153 38370 15495
## [34] 65154 74534 20166 26099 34887 37897 29717 33298 55776 30967 18643
## [45] 21538 28096 29210 58461
## 
## [[22]]
##  [1] 39601 39649 64592 40786 50767 21730 50009 64686 34013 67099 81406
## [12] 44716 18356 26775 55533 27246 27163 81157 49401 74337 22735     0
## [23] 35431 53898 59415 39062 38903 32067 42694 31826 34012 52536 26191
## [34] 79320 88700 34332 24269 49053 52063 31939 47464 69942 29069 20615
## [45] 35072 42262 10583 72627
## 
## [[23]]
##  [1] 17968 18016 35386 24320 18687 19877 42293 35480 19624 18209 33230
## [12]  8427 33133 26873 42921 49101 32654 51951 17782 45130 21032 35141
## [23]     0 21756 30208 17139 28664  5714 26043  8833  5426 23330 10461
## [34] 50114 59493 12123 27413 26843 20737 23268 23168 40735 49371 19323
## [45] 29874 17258 41983 43420
## 
## [[24]]
##  [1] 17512 17560 15422 36059  4428 33226 13943 13260 44262 27280 41587
## [12] 14836 49800 43540 24703 65768 41703 27243  3050 22910 37699 52234
## [23] 20402     0  7797 19895 18546 25651 12645 23961 25362 12718 27208
## [34] 25406 37273 16329 31410  8506 12244 19956  6213 26147 66038 32280
## [45] 56608  6317 59076 34886
## 
## [[25]]
##  [1] 27872 27920 10877 44424 10352 41273 18191 11042 52309 33634 47940
## [12] 24525 57847 51588 30348 73815 47348 27849  8975 20692 45747 60281
## [23] 31466  5924     0 30256 24190 38777 18290 32009 38488 19071 35255
## [34] 26012 35056 24837 41771 12858 18598 25601 17995 21917 74085 40327
## [45] 64656 19340 67124 21432
## 
## [[26]]
##  [1]  2570  2618 48748 37876 19003 19847 22001 34374 30884 46048 60355
## [12] 18632 36421 30162 28117 52389 21574 45001 28350 42399 24321 32360
## [23] 17165 21322 30491     0 13266 16059 14686  8521 15770 31485 13830
## [34] 43164 58387  5529 16334 18496 31012 10564 16906 48891 52659 12086
## [45] 43230 18252 45698 56000
## 
## [[27]]
##  [1] 10882 10930 43104 61689 21113 31083 13102 28730 42119 50899 65206
## [12] 31324 47657 41397 14188 63624 20735 20742 22632 36755 35556 38436
## [23] 27859 25828 24847 13266     0 27584 10000 20046 27295 36337 25065
## [34] 19286 52743 16764 22410 12945 35863  6736 19017 48063 63894 18161
## [45] 54465 20362 47965 50356
## 
## [[28]]
##  [1] 16863 16910 42857 21661 23936 13872 32894 42951 16990 23458 34927
## [12] 13676 29769 23509 39010 45736 31548 59422 23031 52601 17668 31777
## [23]  5714 27005 37680 16033 27558     0 26517  7728   640 30801  9331
## [34] 57585 66965 12597 26308 27318 25985 22162 25728 48207 46006 18217
## [45] 26509 22507 38619 50892
## 
## [[29]]
##  [1] 12254 12302 36928 55514 14937 28982  7761 22554 40018 44724 59031
## [12] 25148 45556 39296 16297 61524 33297 19546 16457 30579 33455 42179
## [23] 25758 19652 18671 14638 10140 26486     0 17950 26197 30161 22964
## [34] 16230 46568 14086 26153  3631 29688 11548 12841 41888 61794 21904
## [45] 52364 14186 51708 44180
## 
## [[30]]
##  [1]  9350  9398 36159 28322 22333 12073 24364 36253 23110 38665 52972
## [12] 16282 28647 22388 30480 44615 24850 52724 20968 45903 16547 31081
## [23]  8859 25465 30981  8521 20046  7753 17987     0  7465 24103  5802
## [34] 50887 60266  4067 19610 18787 23629 17344 17198 41508 44885 11519
## [45] 35456 13828 37924 44193
## 
## [[31]]
##  [1] 16574 16622 42568 24986 23647 18483 32605 42662 21985 23169 38253
## [12] 13387 31714 25454 38721 47681 31259 59133 22742 52312 19613 33722
## [23]  5426 26716 37391 15744 27269   640 26229  7439     0 30512  9042
## [34] 57296 66676 12308 26019 27029 25696 21873 25440 47918 47951 17928
## [45] 28454 22218 40564 50603
## 
## [[32]]
##  [1] 26503 26551 16931 35994 12622 32844 30612 23800 43880 15938 30245
## [12] 16095 49418 43158 42770 65386 45229 40271 11257 33450 37317 51852
## [23] 23036 13012 18528 25964 36612 30348 30711 23579 30059     0 26826
## [34] 38433 28491 21215 39989 25280  5038 38023 16642 16486 65656 31898
## [45] 56226 13616 58694 22401
## 
## [[33]]
##  [1] 14182 14230 39173 27991 25347  7318 29210 39267 22746 41679 55986
## [12] 19297 27681 21422 35326 43649 24862 55738 23982 48917 15581 26003
## [23] 10461 28479 33996 13643 24878  9331 22833  5790  9042 27117     0
## [34] 53901 63281  8913 19576 23633 26643 18464 22044 44523 43919 12121
## [45] 29215 16842 35531 47208
## 
## [[34]]
##  [1] 28166 28214 31292 63142 34235 59992  8710 19009 71028 52352 66659
## [12] 43243 76566 70306  9382 92533 36885  6378 30331 17945 64465 64447
## [23] 50184 27280 26299 30550 18965 57495 16357 50727 57206 37789 53974
## [34]     0 40931 38980 44170 17105 37316 23829 32138 41576 92803 34921
## [45] 83374 33484 85842 38544
## 
## [[35]]
##  [1]  56656  56703  14836  71705  40037  68555  40180  26812  79591  33969
## [11]  46710  51806  85129  78869  48886 101097  76131  43341  38660  30765
## [21]  73028  87563  58747  35609  34628  59039  52974  66059  47073  59291
## [31]  65770  28534  62537  41504      0  53620  70554  41641  45879  54384
## [41]  46778  10804 101367  67609  91937  49327  94405   4470
## 
## [[36]]
##  [1]  6069  6116 38793 33128 15430 15099 20926 29765 26135 41299 55606
## [12] 13883 31673 25413 27213 47641 27484 40392 23602 37789 19572 34107
## [23] 11875 28099 33615  5529 16764 12602 14123  4067 12314 26737  9081
## [34] 38555 53778     0 22244 14923 26263 14062 13334 44142 47911 14153
## [45] 38481 11296 40949 46827
## 
## [[37]]
##  [1] 17599 17647 60259 42618 30514 22302 33512 45885 39869 54835 69142
## [12] 32452 28491 39147 35036 46923  9559 56513 37137 53910 33306 20731
## [23] 27449 41635 42002 16331 22406 26343 26197 19575 26054 40272 19576
## [34] 54675 69899 22068     0 30007 39799 15442 28418 57678 48746  7897
## [45] 52215 29998 30260 67512
## 
## [[38]]
##  [1] 16015 16063 31108 49694 12129 29728  8933 12719 40764 38904 53211
## [12] 29795 46302 40042 19294 62270 36294 27361 13648 24759 34201 48736
## [23] 26504  8314 12851 18398 13137 27231  3723 18696 26943 24341 23710
## [34] 17000 40748 14832 29913     0 23868 14545 10032 36068 62540 25665
## [45] 53110 11378 55578 38360
## 
## [[39]]
##  [1] 25665 25713 22868 35156 11784 32006 29774 22961 43042 10466 34023
## [12] 15257 48580 42320 41932 64548 44391 39433 10419 32612 36479 51014
## [23] 22198 12174 17690 25126 35774 29510 29873 22741 29221  5081 25988
## [34] 37595 46975 20377 39151 24442     0 37185 15804 21298 64818 31060
## [45] 55388 12778 57856 30902
## 
## [[40]]
##  [1]  8180  8228 44691 42719 20175 24690 17967 30317 35726 52486 66793
## [12] 28309 41264 35005 19052 57232 16608 25606 21695 38341 29164 31472
## [23] 23306 27415 26433 10564  6736 22201 11607 17344 21912 37924 18672
## [34] 24151 54330 14062 15446 14551 37450     0 18079 49650 57502 11198
## [45] 48073 19424 41001 51943
## 
## [[41]]
##  [1] 14500 14548 37450 38853  8571 28213 17483 23076 39249 31405 45712
## [12] 17630 44787 38527 25122 60755 42122 33703  5844 31101 32686 47221
## [23] 23196  6938 19193 16883 18965 25716 13064 17181 25428 16842 22195
## [34] 31866 47090 13317 28398 10030 16369 18056     0 34248 61025 24150
## [45] 51595  7820 54063 44703
## 
## [[42]]
##  [1] 44607 44655 14655 46763 30726 50948 40494 27126 61984 22848 38359
## [12] 34199 67522 61262 49200 83489 76445 43655 29360 31079 55421 69956
## [23] 41140 24844 22014 44067 53288 48451 47387 41683 48162 16486 44930
## [34] 41818 10865 39319 58092 41955 21254 54699 47093     0 83759 50002
## [45] 74330 31720 76798  7225
## 
## [[43]]
##  [1]  53049  53096  78040  46686  64214  37024  68076  78133  35341  62864
## [11]  69936  58163  26181  26593  74193   3927  51887  94604  62848  87784
## [21]  30834  37251  49275  67346  72862  52509  63744  45910  61700  45273
## [31]  47855  65983  43109  92767 102147  47780  48993  62500  65510  57330
## [41]  60911  83389      0  48032  27261  55709  18722  86074
## 
## [[44]]
##  [1] 13481 13529 44241 35163 30415 14847 29395 44335 31781 46747 61054
## [12] 24364 28035 31060 30271 46467 13182 52395 29050 49792 25219 20275
## [23] 19361 33547 39063 12213 18288 18256 22079 11488 17967 32185 12121
## [34] 50557 68348 13981  7897 25889 31711 11325 24300 49590 53557     0
## [45] 44128 21910 29803 52275
## 
## [[45]]
##  [1] 40446 40494 65437 20517 51611 24421 55474 65531 11556 44883 39488
## [12] 34762 24423 13328 61590 26917 54113 82002 50246 75181 18231 34751
## [23] 29845 54743 60259 39906 51142 26480 49097 32670 28426 53381 29188
## [34] 80164 89544 35177 48873 49897 52907 44727 48308 70786 27187 35430
## [45]     0 43106 33848 73471
## 
## [[46]]
##  [1] 15720 15767 25996 33807  2532 23092 18703 24296 34128 19554 42809
## [12] 11722 39666 33406 26342 55633 43342 34923  4080 32321 27565 42100
## [23] 17288  7632 20818 18103 20185 22537 14284 13827 22248 13940 17074
## [34] 33086 48309 11317 30237 11250 11347 19276  7865 31345 55903 22146
## [45] 46474     0 48942 34030
## 
## [[47]]
##  [1] 48326 48373 73317 53314 59491 30454 61401 73410 39547 75823 76564
## [12] 53440 23890 33221 63609 16972 35356 74204 58125 83061 30123 12418
## [23] 44155 62623 68139 47786 50295 40791 54086 40550 42736 61260 37582
## [34] 73238 97424 43057 32463 57777 60787 43331 56188 78666 18794 32007
## [45] 33889 50986     0 81351
## 
## [[48]]
##  [1] 53987 54035 12168 56733 37369 53583 37512 24144 64619 31546 44287
## [12] 36834 70157 63897 46218 86125 73463 40673 35992 28097 58056 72591
## [23] 43775 32941 31960 56371 50305 51087 44405 44319 50798 22413 47565
## [34] 38836  4459 50952 67886 38973 30907 51716 44110  7225 86395 52637
## [45] 76965 34355 79433     0&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;&lt;code&gt;distances&lt;/code&gt; is a list where the first element is the distances from the first castle to all the others.
Let’s make it a matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distances_matrix &amp;lt;- distances %&amp;gt;%
    reduce(rbind)&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the distance matrix&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;distances_matrix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
## out     0    48 46364 38416 16619 20387 19617 31990 31423 46587 60894
##        48     0 46412 38464 16667 20435 19665 32038 31471 46635 60942
##     46900 46947     0 48698 30281 45548 30424 17056 56584 31187 52215
##     38214 38261 48754     0 34949 23582 55661 48848 11274 29579 26880
##     16494 16541 25311 35192     0 25375 19477 16687 36411 20939 42124
##     18468 18516 43459 23632 29633     0 33496 43553 15352 45965 60272
##     19645 19693 30022 55860 21434 35353     0 17740 46389 45070 59377
##     33194 33242 17113 48244 16576 45094 16196     0 56130 37454 51761
##     34049 34097 59040 11039 45215 18025 49077 59134     0 35131 34289
##     40768 40815 31200 29561 26887 47108 44877 38064 35204     0 24550
##     54812 54860 52014 26837 40931 61152 58921 52108 34149 24114     0
##     19189 19237 28715 23758 13122 25545 35622 28809 25568 11495 27547
##     36813 36860 61804 32740 47978 20788 51841 61898 18594 46628 54032
##     30553 30601 55544 20685 41718 14528 45581 55638  9008 40368 42945
##     25606 25654 38728 67712 27136 41314 10938 26445 52350 56922 71229
##     52597 52644 77588 46234 63762 36572 67625 77681 34889 62412 69484
##     22742 22790 66383 47823 44393 27506 36726 52009 45012 59978 74285
##     43466 43513 32742 64592 35685 61442 12026 20459 72478 53802 68109
##     17092 17140 23308 33262  1432 30429 15982 15299 41465 25814 40121
##     40369 40417 21028 58519 26851 55368 16853  5415 66404 47729 62035
##     25435 25483 50426 23657 36601  9410 40463 50520  9511 52933 67240
##     39601 39649 64592 40786 50767 21730 50009 64686 34013 67099 81406
##     17968 18016 35386 24320 18687 19877 42293 35480 19624 18209 33230
##     17512 17560 15422 36059  4428 33226 13943 13260 44262 27280 41587
##     27872 27920 10877 44424 10352 41273 18191 11042 52309 33634 47940
##      2570  2618 48748 37876 19003 19847 22001 34374 30884 46048 60355
##     10882 10930 43104 61689 21113 31083 13102 28730 42119 50899 65206
##     16863 16910 42857 21661 23936 13872 32894 42951 16990 23458 34927
##     12254 12302 36928 55514 14937 28982  7761 22554 40018 44724 59031
##      9350  9398 36159 28322 22333 12073 24364 36253 23110 38665 52972
##     16574 16622 42568 24986 23647 18483 32605 42662 21985 23169 38253
##     26503 26551 16931 35994 12622 32844 30612 23800 43880 15938 30245
##     14182 14230 39173 27991 25347  7318 29210 39267 22746 41679 55986
##     28166 28214 31292 63142 34235 59992  8710 19009 71028 52352 66659
##     56656 56703 14836 71705 40037 68555 40180 26812 79591 33969 46710
##      6069  6116 38793 33128 15430 15099 20926 29765 26135 41299 55606
##     17599 17647 60259 42618 30514 22302 33512 45885 39869 54835 69142
##     16015 16063 31108 49694 12129 29728  8933 12719 40764 38904 53211
##     25665 25713 22868 35156 11784 32006 29774 22961 43042 10466 34023
##      8180  8228 44691 42719 20175 24690 17967 30317 35726 52486 66793
##     14500 14548 37450 38853  8571 28213 17483 23076 39249 31405 45712
##     44607 44655 14655 46763 30726 50948 40494 27126 61984 22848 38359
##     53049 53096 78040 46686 64214 37024 68076 78133 35341 62864 69936
##     13481 13529 44241 35163 30415 14847 29395 44335 31781 46747 61054
##     40446 40494 65437 20517 51611 24421 55474 65531 11556 44883 39488
##     15720 15767 25996 33807  2532 23092 18703 24296 34128 19554 42809
##     48326 48373 73317 53314 59491 30454 61401 73410 39547 75823 76564
##     53987 54035 12168 56733 37369 53583 37512 24144 64619 31546 44287
##     [,12] [,13] [,14] [,15]  [,16] [,17] [,18] [,19] [,20] [,21] [,22]
## out 19171 36961 30701 25734  52929 22843 42618 18138 40015 24860 39395
##     19219 37009 30749 25781  52977 22890 42665 18186 40063 24908 39443
##     28799 62122 55862 39130  78090 66375 33585 23961 21009 50021 64556
##     25631 32853 20633 67818  46577 47882 65319 33355 58499 26540 40460
##     13107 41949 35689 27116  57917 44116 30670  1432 26337 29848 44383
##     23583 20890 14630 39612  36858 27623 60024 28268 53203  8789 21614
##     35962 51927 45668 10941  67895 36650 11975 16038 16675 39826 49570
##     28345 61668 55408 26667  77635 52670 21122 15199  8546 49567 64102
##     25588 18148  8956 55193  34944 47717 75605 43849 68785 11835 33390
##     11501 46805 40546 57034  62773 59493 54535 25521 47714 51581 66116
##     30135 56417 42752 71078  69452 73537 68579 39565 61758 65626 80160
##         0 42119 35859 47779  58087 37930 45280 12217 38459 30018 44553
##     41927     0 11355 57957  25913 31393 78369 46612 71548 10254 18035
##     35668 11355     0 51697  26249 44221 72109 40353 65288  8339 26597
##     37346 57888 51628     0  73856 27918 10658 28655 25381 45787 55480
##     57711 25729 26142 73741      0 51707 94153 62396 87332 30382 29845
##     37595 31384 44290 27751  49817     0 38346 45912 60034 38449 23624
##     44693 78016 71756 10711  93983 38600     0 31781 19395 65915 80450
##     12039 47003 40743 27715  62970 44714 29283     0 24950 34902 49437
##     38620 71942 65683 25560  87910 59845 20015 25473     0 59842 74376
##     30550 10254  8470 46579  30697 31384 66991 35235 60171     0 22368
##     44716 18356 26775 55533  27246 27163 81157 49401 74337 22735     0
##      8427 33133 26873 42921  49101 32654 51951 17782 45130 21032 35141
##     14836 49800 43540 24703  65768 41703 27243  3050 22910 37699 52234
##     24525 57847 51588 30348  73815 47348 27849  8975 20692 45747 60281
##     18632 36421 30162 28117  52389 21574 45001 28350 42399 24321 32360
##     31324 47657 41397 14188  63624 20735 20742 22632 36755 35556 38436
##     13676 29769 23509 39010  45736 31548 59422 23031 52601 17668 31777
##     25148 45556 39296 16297  61524 33297 19546 16457 30579 33455 42179
##     16282 28647 22388 30480  44615 24850 52724 20968 45903 16547 31081
##     13387 31714 25454 38721  47681 31259 59133 22742 52312 19613 33722
##     16095 49418 43158 42770  65386 45229 40271 11257 33450 37317 51852
##     19297 27681 21422 35326  43649 24862 55738 23982 48917 15581 26003
##     43243 76566 70306  9382  92533 36885  6378 30331 17945 64465 64447
##     51806 85129 78869 48886 101097 76131 43341 38660 30765 73028 87563
##     13883 31673 25413 27213  47641 27484 40392 23602 37789 19572 34107
##     32452 28491 39147 35036  46923  9559 56513 37137 53910 33306 20731
##     29795 46302 40042 19294  62270 36294 27361 13648 24759 34201 48736
##     15257 48580 42320 41932  64548 44391 39433 10419 32612 36479 51014
##     28309 41264 35005 19052  57232 16608 25606 21695 38341 29164 31472
##     17630 44787 38527 25122  60755 42122 33703  5844 31101 32686 47221
##     34199 67522 61262 49200  83489 76445 43655 29360 31079 55421 69956
##     58163 26181 26593 74193   3927 51887 94604 62848 87784 30834 37251
##     24364 28035 31060 30271  46467 13182 52395 29050 49792 25219 20275
##     34762 24423 13328 61590  26917 54113 82002 50246 75181 18231 34751
##     11722 39666 33406 26342  55633 43342 34923  4080 32321 27565 42100
##     53440 23890 33221 63609  16972 35356 74204 58125 83061 30123 12418
##     36834 70157 63897 46218  86125 73463 40673 35992 28097 58056 72591
##     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33]
## out 17163 18938 28107  2570 10882 16888 12302  9350 16599 32025 14369
##     17211 18986 28155  2618 10930 16936 12350  9398 16647 32073 14417
##     35740 25853 10852 49283 43218 43052 37317 36283 42763 17250 39530
##     24359 38061 43577 37674 61661 21704 55760 29822 25030 36698 27956
##     18673  5767 11224 18877 20958 23922 15058 16110 23633 13255 19357
##     17217 32765 38282 17929 29164 13853 27119  8892 15798 31403  7026
##     42902 13747 19018 22029 13093 32857  7837 24321 32568 30508 29335
##     35286 12148 11167 35578 29512 42597 23612 35829 42308 22891 39076
##     19644 48347 53863 33510 44745 17010 42701 26274 22029 46984 22791
##     18215 27276 32792 40228 50876 23464 44975 37844 23175 16279 41090
##     33264 41320 46836 54272 64920 34961 59020 51888 38287 30323 55134
##      8427 18021 23537 18649 41621 13676 35721 16280 13387 16659 19527
##     33039 51110 56626 36273 47508 29674 45464 29037 31619 49747 26873
##     26779 44850 50367 30014 41249 23415 39204 22778 25360 43488 20613
##     42912 31851 30870 27990 14521 38818 16023 30282 38529 42360 35296
##     48823 66894 72410 52057 63292 45458 61248 44821 47403 65531 42657
##     32592 49107 48126 21474 20735 31486 33280 24718 31198 45415 24781
##     51634 28730 27749 45849 20641 58945 19674 52177 58656 39239 55424
##     17605  4379  9837 19476 21557 22854 15656 21164 22565 11252 24411
##     45561 22423 21442 42753 36687 52872 30786 46104 52583 33166 49351
##     19572 39732 45249 24896 36131 16208 34087 17660 18153 38370 15495
##     35431 53898 59415 39062 38903 32067 42694 31826 34012 52536 26191
##         0 21756 30208 17139 28664  5714 26043  8833  5426 23330 10461
##     20402     0  7797 19895 18546 25651 12645 23961 25362 12718 27208
##     31466  5924     0 30256 24190 38777 18290 32009 38488 19071 35255
##     17165 21322 30491     0 13266 16059 14686  8521 15770 31485 13830
##     27859 25828 24847 13266     0 27584 10000 20046 27295 36337 25065
##      5714 27005 37680 16033 27558     0 26517  7728   640 30801  9331
##     25758 19652 18671 14638 10140 26486     0 17950 26197 30161 22964
##      8859 25465 30981  8521 20046  7753 17987     0  7465 24103  5802
##      5426 26716 37391 15744 27269   640 26229  7439     0 30512  9042
##     23036 13012 18528 25964 36612 30348 30711 23579 30059     0 26826
##     10461 28479 33996 13643 24878  9331 22833  5790  9042 27117     0
##     50184 27280 26299 30550 18965 57495 16357 50727 57206 37789 53974
##     58747 35609 34628 59039 52974 66059 47073 59291 65770 28534 62537
##     11875 28099 33615  5529 16764 12602 14123  4067 12314 26737  9081
##     27449 41635 42002 16331 22406 26343 26197 19575 26054 40272 19576
##     26504  8314 12851 18398 13137 27231  3723 18696 26943 24341 23710
##     22198 12174 17690 25126 35774 29510 29873 22741 29221  5081 25988
##     23306 27415 26433 10564  6736 22201 11607 17344 21912 37924 18672
##     23196  6938 19193 16883 18965 25716 13064 17181 25428 16842 22195
##     41140 24844 22014 44067 53288 48451 47387 41683 48162 16486 44930
##     49275 67346 72862 52509 63744 45910 61700 45273 47855 65983 43109
##     19361 33547 39063 12213 18288 18256 22079 11488 17967 32185 12121
##     29845 54743 60259 39906 51142 26480 49097 32670 28426 53381 29188
##     17288  7632 20818 18103 20185 22537 14284 13827 22248 13940 17074
##     44155 62623 68139 47786 50295 40791 54086 40550 42736 61260 37582
##     43775 32941 31960 56371 50305 51087 44405 44319 50798 22413 47565
##     [,34]  [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42]  [,43] [,44]
## out 40780  56004  6069 17602 16112 31552  8180 14523 49431  53199 13354
##     40828  56052  6116 17650 16160 31599  8228 14571 49478  53247 13402
##     31748  14513 33919 60798 31885 22872 44629 37023 14605  78360 44602
##     63482  72862 32945 42596 50328 34302 42495 38740 46782  46847 35141
##     28833  40700 15310 30392 12024 12782 20050  7178 30661  58187 24429
##     58187  67567 13199 22337 27919 30929 22750 26330 48809  37128 14882
##      8659  39662 20998 33544  9053 30034 17958 19337 40306  68165 29296
##     19285  26753 30159 47093 12671 22418 30923 23317 27397  77906 44148
##     73768  83148 28780 42477 43501 46511 38331 41912 64390  35215 29033
##     52698  33741 35479 54253 39544 10472 52287 30906 22876  63043 46162
##     66742  46672 49523 68297 53588 33981 66331 44951 37998  69722 60206
##     43443  52822 13901 32690 30289 10679 28544 17602 34064  58357 24599
##     76531  85911 31544 28499 46264 49274 41094 44675 67153  26183 28043
##     70272  79652 25284 38981 40004 43014 34835 38415 60894  26519 25537
##      9692  48367 26996 35203 18968 41886 19386 25040 49012  74126 25555
##     92315 101695 47328 48813 62048 65058 56878 60459 82937   3927 48357
##     37380  76023 27212  9559 36224 44942 16608 42297 71343  51639 13101
##      6452  42381 40430 45885 20422 38766 25506 33588 43026  94253 53116
##     27446  39313 18800 37574 12622 10778 20648  5791 28657  63241 29483
##     18178  30668 37333 54268 25355 32693 38098 30492 31312  88180 50019
##     65154  74534 20166 26099 34887 37897 29717 33298 55776  30967 18643
##     79320  88700 34332 24269 49053 52063 31939 47464 69942  29069 20615
##     50114  59493 12123 27413 26843 20737 23268 23168 40735  49371 19323
##     25406  37273 16329 31410  8506 12244 19956  6213 26147  66038 32280
##     26012  35056 24837 41771 12858 18598 25601 17995 21917  74085 40327
##     43164  58387  5529 16334 18496 31012 10564 16906 48891  52659 12086
##     19286  52743 16764 22410 12945 35863  6736 19017 48063  63894 18161
##     57585  66965 12597 26308 27318 25985 22162 25728 48207  46006 18217
##     16230  46568 14086 26153  3631 29688 11548 12841 41888  61794 21904
##     50887  60266  4067 19610 18787 23629 17344 17198 41508  44885 11519
##     57296  66676 12308 26019 27029 25696 21873 25440 47918  47951 17928
##     38433  28491 21215 39989 25280  5038 38023 16642 16486  65656 31898
##     53901  63281  8913 19576 23633 26643 18464 22044 44523  43919 12121
##         0  40931 38980 44170 17105 37316 23829 32138 41576  92803 34921
##     41504      0 53620 70554 41641 45879 54384 46778 10804 101367 67609
##     38555  53778     0 22244 14923 26263 14062 13334 44142  47911 14153
##     54675  69899 22068     0 30007 39799 15442 28418 57678  48746  7897
##     17000  40748 14832 29913     0 23868 14545 10032 36068  62540 25665
##     37595  46975 20377 39151 24442     0 37185 15804 21298  64818 31060
##     24151  54330 14062 15446 14551 37450     0 18079 49650  57502 11198
##     31866  47090 13317 28398 10030 16369 18056     0 34248  61025 24150
##     41818  10865 39319 58092 41955 21254 54699 47093     0  83759 50002
##     92767 102147 47780 48993 62500 65510 57330 60911 83389      0 48032
##     50557  68348 13981  7897 25889 31711 11325 24300 49590  53557     0
##     80164  89544 35177 48873 49897 52907 44727 48308 70786  27187 35430
##     33086  48309 11317 30237 11250 11347 19276  7865 31345  55903 22146
##     73238  97424 43057 32463 57777 60787 43331 56188 78666  18794 32007
##     38836   4459 50952 67886 38973 30907 51716 44110  7225  86395 52637
##     [,45] [,46] [,47] [,48]
## out 43769 15868 46237 53617
##     43817 15916 46285 53665
##     68930 26320 71398 12126
##     20752 33520 47302 56789
##     48757  2511 51225 33346
##     27698 21128 28456 51494
##     58736 20683 59099 37275
##     68476 25866 70944 24366
##     11504 36710 37265 67075
##     44908 19378 72959 30101
##     39488 41924 87003 44227
##     34791 11692 51395 36749
##     22973 39473 21910 69838
##     13328 33213 30473 63579
##     64696 26385 63610 45980
##     26809 55257 16900 85622
##     57358 43642 33153 73636
##     84824 34934 87292 39994
##     53811  3497 56279 31342
##     78751 31837 81219 28281
##     21538 28096 29210 58461
##     35072 42262 10583 72627
##     29874 17258 41983 43420
##     56608  6317 59076 34886
##     64656 19340 67124 21432
##     43230 18252 45698 56000
##     54465 20362 47965 50356
##     26509 22507 38619 50892
##     52364 14186 51708 44180
##     35456 13828 37924 44193
##     28454 22218 40564 50603
##     56226 13616 58694 22401
##     29215 16842 35531 47208
##     83374 33484 85842 38544
##     91937 49327 94405  4470
##     38481 11296 40949 46827
##     52215 29998 30260 67512
##     53110 11378 55578 38360
##     55388 12778 57856 30902
##     48073 19424 41001 51943
##     51595  7820 54063 44703
##     74330 31720 76798  7225
##     27261 55709 18722 86074
##     44128 21910 29803 52275
##         0 43106 33848 73471
##     46474     0 48942 34030
##     33889 50986     0 81351
##     76965 34355 79433     0&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Let’s baptize the rows and columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(distances_matrix) &amp;lt;- castles$Nom

rownames(distances_matrix) &amp;lt;- castles$Nom&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data, we can solve the TSP.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;solving-the-travelling-salesman-problem-thats-the-combinatorial-optimization-part&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Solving the Travelling salesman problem (that’s the combinatorial optimization part)&lt;/h2&gt;
&lt;p&gt;Let’s first coerce the &lt;code&gt;distances_matrix&lt;/code&gt; to an &lt;code&gt;ATSP&lt;/code&gt; object, which is needed for the solver.
&lt;code&gt;ATSP&lt;/code&gt; stands for asymmetrical TSP. Asymmetrical because the &lt;code&gt;distances_matrix&lt;/code&gt; is not symmetric,
meaning that going from Castle A to Castle B is longer than going from Castle B to Castle A (for
example).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;atsp_castles &amp;lt;- ATSP(distances_matrix)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then define a list of all the available methods:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;methods &amp;lt;- c(&amp;quot;identity&amp;quot;, &amp;quot;random&amp;quot;, &amp;quot;nearest_insertion&amp;quot;,
             &amp;quot;cheapest_insertion&amp;quot;, &amp;quot;farthest_insertion&amp;quot;, &amp;quot;arbitrary_insertion&amp;quot;,
             &amp;quot;nn&amp;quot;, &amp;quot;repetitive_nn&amp;quot;, &amp;quot;two_opt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And solve the problem with all the methods:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solutions &amp;lt;- map(methods, ~solve_TSP(x = atsp_castles, method = ., two_opt = TRUE, rep = 10,  two_opt_repetitions = 10)) %&amp;gt;%
    set_names(methods)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: executing %dopar% sequentially: no parallel backend registered&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I do this because the results vary depending on the methods, and I want to be exhaustive (solving
this problem is quite fast, so there’s no reason not to do it):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solutions_df &amp;lt;- solutions %&amp;gt;%
    map_df(as.numeric)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;solutions_df&lt;/code&gt; is a data frame with the order of the castles to visit in rows and the method used
in columns.&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click if you want to see the solutions&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solutions_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 48 x 9
##    identity random nearest_inserti… cheapest_insert… farthest_insert…
##       &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
##  1        1     10               37               44               15
##  2        2     11               17               37               27
##  3       36      4               22               17               29
##  4       33      9               47               40               38
##  5        6     45               16               27               41
##  6       44     43               43               15               19
##  7       37     16               13               18                5
##  8       17     47               21               34               46
##  9       22     22               14                7               12
## 10       47     13               45               20               23
## # … with 38 more rows, and 4 more variables: arbitrary_insertion &amp;lt;dbl&amp;gt;,
## #   nn &amp;lt;dbl&amp;gt;, repetitive_nn &amp;lt;dbl&amp;gt;, two_opt &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Now, let’s extract the tour lengths, see which one is the minimum, then plot it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tour_lengths &amp;lt;- solutions %&amp;gt;%
    map_dbl(tour_length)

which.min(tour_lengths)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## arbitrary_insertion 
##                   6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The total length of the tour is 474 kilometers
(that’s 295 miles). Before plotting the data, let’s
re-order it according to the solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;castles_to_visit &amp;lt;- castles[pull(solutions_df, names(which.min(tour_lengths))), ]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-solution&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the solution&lt;/h2&gt;
&lt;p&gt;To plot the solution, I first use a data frame I created with the longitude and latitude of
Luxembourguish communes, from the &lt;code&gt;geojson&lt;/code&gt; file available on the
&lt;a href=&#34;https://data.public.lu/en/datasets/limites-administratives-du-grand-duche-de-luxembourg/#resource-39af91a6-9ce4-4c18-8271-313b3ad7c7f5&#34;&gt;OpenData Portal&lt;/a&gt;.
I converted it to a data frame because it is easier to manipulate this way. The code to do that is
in the appendix of this blog post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes_df &amp;lt;- read_csv(&amp;quot;communes_df.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   lon = col_double(),
##   lat = col_double(),
##   commune = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can use &lt;code&gt;{ggplot2}&lt;/code&gt; to create the map with the tour. I use &lt;code&gt;geom_polygon()&lt;/code&gt; to build the map,
&lt;code&gt;geom_point()&lt;/code&gt; to add the castles, &lt;code&gt;geom_path()&lt;/code&gt; to connect the points according to the solution I
found and &lt;code&gt;geom_point()&lt;/code&gt; again to highlight the starting castle:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
    geom_polygon(data = communes_df, aes(x = lon, y = lat, group = commune), colour = &amp;quot;grey&amp;quot;, fill = NA) +
    geom_point(data = castles, aes(x = lon, y = lat), colour = &amp;quot;#82518c&amp;quot;, size = 3) +
    geom_path(data = castles_to_visit, aes(x = lon, y = lat), colour = &amp;quot;#647e0e&amp;quot;) +
    geom_point(data = (slice(castles_to_visit, 1)), aes(x = lon, y = lat), colour = &amp;quot;white&amp;quot;, size = 5) +
    theme_void() +
    ggtitle(&amp;quot;The shortest tour to visit 48 Luxembourguish castles&amp;quot;) +
    theme(legend.position = &amp;quot;bottom&amp;quot;,
          legend.title = element_blank(),
          legend.text = element_text(colour = &amp;quot;white&amp;quot;),
          plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
          plot.title = element_text(colour = &amp;quot;white&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-21-lux_castle_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The white point is the starting point of the tour. As a bonus, let’s do the same plot without
points, but castles emojis instead (using the &lt;code&gt;{ggimage}&lt;/code&gt; package):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
    geom_polygon(data = communes_df, aes(x = lon, y = lat, group = commune), colour = &amp;quot;grey&amp;quot;, fill = NA) +
    geom_emoji(data = castles, aes(x = lon, y = lat, image = &amp;quot;1f3f0&amp;quot;)) + # &amp;lt;- this is the hex code for the &amp;quot;european castle&amp;quot; emoji
    geom_path(data = castles_to_visit, aes(x = lon, y = lat), colour = &amp;quot;#647e0e&amp;quot;) +
    theme_void() +
    ggtitle(&amp;quot;The shortest tour to visit 48 Luxembourguish castles&amp;quot;) +
    theme(legend.position = &amp;quot;bottom&amp;quot;,
          legend.title = element_blank(),
          legend.text = element_text(colour = &amp;quot;white&amp;quot;),
          plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
          plot.title = element_text(colour = &amp;quot;white&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown parameters: image_colour&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-21-lux_castle_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s horrible.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates and
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;p&gt;The code below converts the &lt;code&gt;geojson&lt;/code&gt; that can be downloaded from the
&lt;a href=&#34;https://data.public.lu/en/datasets/limites-administratives-du-grand-duche-de-luxembourg/#resource-39af91a6-9ce4-4c18-8271-313b3ad7c7f5&#34;&gt;OpenData Portal&lt;/a&gt;
to &lt;code&gt;csv&lt;/code&gt;. A &lt;code&gt;csv&lt;/code&gt; file is easier to handle. I only focus on the communes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;limadmin &amp;lt;- RJSONIO::fromJSON(&amp;quot;limadmin.geojson&amp;quot;)

communes &amp;lt;- limadmin$communes

extract_communes &amp;lt;- function(features){

    res &amp;lt;- features$geometry$coordinates %&amp;gt;%
        map(lift(rbind)) %&amp;gt;%
        as.data.frame() %&amp;gt;%
        rename(lon = X1,
               lat = X2)

    res %&amp;gt;%
        mutate(commune = features$properties[1])
}

communes_df &amp;lt;- map(limadmin$communes$features, extract_communes)

## Steinfort and Waldbredimus special treatment:

steinfort &amp;lt;- limadmin$communes$features[[5]]$geometry$coordinates[[1]] %&amp;gt;%
    map(lift(rbind)) %&amp;gt;%
    as.data.frame() %&amp;gt;%
    rename(lon = X1,
           lat = X2) %&amp;gt;%
    mutate(commune = &amp;quot;Steinfort&amp;quot;)

waldbredimus &amp;lt;- limadmin$communes$features[[44]]$geometry$coordinates[[1]] %&amp;gt;%
    map(lift(rbind)) %&amp;gt;%
    as.data.frame() %&amp;gt;%
    rename(lon = X1,
           lat = X2) %&amp;gt;%
    mutate(commune = &amp;quot;Waldbredimus&amp;quot;)

communes_df[[5]] &amp;lt;- NULL
communes_df[[43]] &amp;lt;- NULL


communes_df &amp;lt;- bind_rows(communes_df, list(steinfort, waldbredimus))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using a genetic algorithm for the hyperparameter optimization of a SARIMA model</title>
      <link>https://www.brodrigues.co/blog/2018-11-16-rgenoud_arima/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-16-rgenoud_arima/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://keiwan.itch.io/evolution&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/tap-walker.gif&#34; title = &#34;Nietzsche&#39;s Übermensch&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this blog post, I’ll use the data that I cleaned in a previous
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport/&#34;&gt;blog post&lt;/a&gt;, which you can download
&lt;a href=&#34;https://github.com/b-rodrigues/avia_par_lu/tree/master&#34;&gt;here&lt;/a&gt;. If you want to follow along,
download the monthly data. In my &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-15-tidy_gridsearch/&#34;&gt;last blog post&lt;/a&gt;
I showed how to perform a grid search the “tidy” way. As an example, I looked for the right
hyperparameters of a SARIMA model. However, the goal of the post was not hyperparameter optimization
per se, so I did not bother with tuning the hyperparameters on a validation set, and used the test
set for both validation of the hyperparameters and testing the forecast. Of course, this is not great
because doing this might lead to overfitting the hyperparameters to the test set. So in this blog post
I split my data into trainig, validation and testing sets and use a genetic algorithm to look
for the hyperparameters. Again, this is not the most optimal way to go about this problem, since
the &lt;code&gt;{forecast}&lt;/code&gt; package contains the very useful &lt;code&gt;auto.arima()&lt;/code&gt; function. I just wanted to see
what kind of solution a genetic algorithm would return, and also try different cost functions.
If you’re interested, read on!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;p&gt;Let’s first load some libraries and define some helper functions (the helper functions were explained
in the previous blog posts):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forecast)
library(rgenoud)
library(parallel)
library(lubridate)
library(furrr)
library(tsibble)
library(brotools)

ihs &amp;lt;- function(x){
    log(x + sqrt(x**2 + 1))
}

to_tibble &amp;lt;- function(forecast_object){
    point_estimate &amp;lt;- forecast_object$mean %&amp;gt;%
        as_tsibble() %&amp;gt;%
        rename(point_estimate = value,
               date = index)

    upper &amp;lt;- forecast_object$upper %&amp;gt;%
        as_tsibble() %&amp;gt;%
        spread(key, value) %&amp;gt;%
        rename(date = index,
               upper80 = `80%`,
               upper95 = `95%`)

    lower &amp;lt;- forecast_object$lower %&amp;gt;%
        as_tsibble() %&amp;gt;%
        spread(key, value) %&amp;gt;%
        rename(date = index,
               lower80 = `80%`,
               lower95 = `95%`)

    reduce(list(point_estimate, upper, lower), full_join)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/avia_par_lu/master/avia_clean_monthy.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   destination = col_character(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   passengers = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s split the data into a train set, a validation set and a test set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_train &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(year(date) &amp;lt; 2013) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2005, 1))

avia_clean_validation &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(between(year(date), 2013, 2016)) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2013, 1))

avia_clean_test &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(year(date) &amp;gt;= 2016) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2016, 1))

logged_test_data &amp;lt;- ihs(avia_clean_test)

logged_validation_data &amp;lt;- ihs(avia_clean_validation)

logged_train_data &amp;lt;- ihs(avia_clean_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will train the models on data from 2005 to 2012, look for the hyperparameters on data from 2013
to 2016 and test the accuracy on data from 2016 to March 2018. For this kind of exercise, the ideal
situation would be to perform cross-validation. Doing this with time-series data is not obvious
because of the autocorrelation between observations, which would be broken by sampling independently
which is required by CV. Also, if for example you do leave-one-out CV,
you would end up trying to predict a point in, say, 2017, with data
from 2018, which does not make sense. So you should be careful about that. &lt;code&gt;{forecast}&lt;/code&gt; is able
to perform &lt;a href=&#34;https://robjhyndman.com/hyndsight/tscv/&#34;&gt;CV for time series&lt;/a&gt; and &lt;code&gt;scikit-learn&lt;/code&gt;, the
Python package, is able to perform
&lt;a href=&#34;https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split&#34;&gt;cross-validation of time series data&lt;/a&gt;
too. I will not do it in this blog post and simply focus on the genetic algorithm part.&lt;/p&gt;
&lt;p&gt;Let’s start by defining the cost function to minimize. I’ll try several, in the first one I will
minimize the RMSE:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_rmse &amp;lt;- function(param, train_data, validation_data, forecast_periods){
    order &amp;lt;- param[1:3]
    season &amp;lt;- c(param[4:6], 12)
    model &amp;lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, order = order, 
                                                      seasonal = season,
                                                      method = &amp;quot;ML&amp;quot;)
    if(is.null(model)){
        return(9999999)
    } else {
      forecast_model &amp;lt;- forecast::forecast(model, h = forecast_periods)
      point_forecast &amp;lt;- forecast_model$mean
      sqrt(mean(point_forecast - validation_data) ** 2)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If &lt;code&gt;arima()&lt;/code&gt; is not able to estimate a model for the given parameters, I force it to return &lt;code&gt;NULL&lt;/code&gt;,
and in that case force the cost function to return a very high cost. If a model was successfully estimated,
then I compute the RMSE.&lt;/p&gt;
&lt;p&gt;Let’s also take a look at what &lt;code&gt;auto.arima()&lt;/code&gt; says:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starting_model &amp;lt;- auto.arima(logged_train_data)
summary(starting_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Series: logged_train_data 
## ARIMA(3,0,0)(0,1,1)[12] with drift 
## 
## Coefficients:
##          ar1     ar2     ar3     sma1   drift
##       0.2318  0.2292  0.3661  -0.8498  0.0029
## s.e.  0.1016  0.1026  0.1031   0.2101  0.0010
## 
## sigma^2 estimated as 0.004009:  log likelihood=107.98
## AIC=-203.97   AICc=-202.88   BIC=-189.38
## 
## Training set error measures:
##                        ME       RMSE        MAE         MPE      MAPE
## Training set 0.0009924108 0.05743719 0.03577996 0.006323241 0.3080978
##                   MASE        ACF1
## Training set 0.4078581 -0.02707016&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compute the cost at this vector of parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_rmse(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1731473&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, now let’s start with optimizing the hyperparameters. Let’s help the genetic algorithm a little
bit by defining where it should perform the search:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;domains &amp;lt;- matrix(c(0, 3, 0, 2, 0, 3, 0, 3, 0, 2, 0, 3), byrow = TRUE, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This matrix constraints the first parameter to lie between 0 and 3, the second one between 0 and 2,
and so on.&lt;/p&gt;
&lt;p&gt;Let’s call the &lt;code&gt;genoud()&lt;/code&gt; function from the &lt;code&gt;{rgenoud}&lt;/code&gt; package, and use 8 cores:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cl &amp;lt;- makePSOCKcluster(8)
clusterExport(cl, c(&amp;#39;logged_train_data&amp;#39;, &amp;#39;logged_validation_data&amp;#39;))

tic &amp;lt;- Sys.time()

auto_arima_rmse &amp;lt;- genoud(cost_function_rmse,
                     nvars = 6,
                     data.type.int = TRUE,
                     starting.values = c(1, 0, 2, 2, 1, 0), # &amp;lt;- from auto.arima
                     Domains = domains,
                     cluster = cl,
                     train_data = logged_train_data,
                     validation_data = logged_validation_data,
                     forecast_periods = length(logged_validation_data),
                     hard.generation.limit = TRUE)
toc_rmse &amp;lt;- Sys.time() - tic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;makePSOCKcluster()&lt;/code&gt; is a function from the &lt;code&gt;{parallel}&lt;/code&gt; package. I must also &lt;em&gt;export&lt;/em&gt; the global
variables &lt;code&gt;logged_train_data&lt;/code&gt; or &lt;code&gt;logged_validation_data&lt;/code&gt;. If I don’t do that, the workers called
by &lt;code&gt;genoud()&lt;/code&gt; will not &lt;em&gt;know&lt;/em&gt; about these variables and an error will be returned. The option
&lt;code&gt;data.type.int = TRUE&lt;/code&gt; force the algorithm to look only for integers, and &lt;code&gt;hard.generation.limit = TRUE&lt;/code&gt;
forces the algorithm to stop after 100 generations.&lt;/p&gt;
&lt;p&gt;The process took 7 minutes, which is faster than doing the grid search.
What was the solution found?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auto_arima_rmse&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $value
## [1] 0.0001863039
## 
## $par
## [1] 3 2 1 1 2 1
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 11
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s train the model using the &lt;code&gt;arima()&lt;/code&gt; function at these parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_rmse &amp;lt;- arima(logged_train_data, order = auto_arima_rmse$par[1:3], 
                         season = list(order = auto_arima_rmse$par[4:6], period = 12),
                         method = &amp;quot;ML&amp;quot;)

summary(best_model_rmse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## arima(x = logged_train_data, order = auto_arima_rmse$par[1:3], seasonal = list(order = auto_arima_rmse$par[4:6], 
##     period = 12), method = &amp;quot;ML&amp;quot;)
## 
## Coefficients:
##           ar1      ar2      ar3      ma1     sar1     sma1
##       -0.6999  -0.4541  -0.0476  -0.9454  -0.4996  -0.9846
## s.e.   0.1421   0.1612   0.1405   0.1554   0.1140   0.2193
## 
## sigma^2 estimated as 0.006247:  log likelihood = 57.34,  aic = -100.67
## 
## Training set error measures:
##                         ME       RMSE        MAE          MPE      MAPE
## Training set -0.0006142355 0.06759545 0.04198561 -0.005408262 0.3600483
##                   MASE         ACF1
## Training set 0.4386693 -0.008298546&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s extract the forecasts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_rmse_forecast &amp;lt;- forecast::forecast(best_model_rmse, h = 65)

best_model_rmse_forecast &amp;lt;- to_tibble(best_model_rmse_forecast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;date&amp;quot;
## Joining, by = &amp;quot;date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;starting_model_forecast &amp;lt;- forecast(starting_model, h = 65)

starting_model_forecast &amp;lt;- to_tibble(starting_model_forecast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;date&amp;quot;
## Joining, by = &amp;quot;date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and plot the forecast to see how it looks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Minimization of RMSE&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) +
    geom_ribbon(data = best_model_rmse_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#666018&amp;quot;, alpha = 0.2) +
    geom_line(data = best_model_rmse_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#8e9d98&amp;quot;) +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#98431e&amp;quot;, alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#a53031&amp;quot;) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-16-rgenoud_arima_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The yellowish line and confidence intervals come from minimizing the genetic algorithm, and the
redish from &lt;code&gt;auto.arima()&lt;/code&gt;. Interesting; the point estimate is very precise, but the confidence
intervals are very wide. Low bias, high variance.&lt;/p&gt;
&lt;p&gt;Now, let’s try with another cost function, where I minimize the BIC, similar to the &lt;code&gt;auto.arima()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_bic &amp;lt;- function(param, train_data, validation_data, forecast_periods){
    order &amp;lt;- param[1:3]
    season &amp;lt;- c(param[4:6], 12)
    model &amp;lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, order = order, 
                                                      seasonal = season,
                                                      method = &amp;quot;ML&amp;quot;)
    if(is.null(model)){
        return(9999999)
    } else {
        BIC(model)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the cost at the parameter values returned by &lt;code&gt;auto.arima()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_bic(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -184.6397&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let the genetic algorithm run again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cl &amp;lt;- makePSOCKcluster(8)
clusterExport(cl, c(&amp;#39;logged_train_data&amp;#39;, &amp;#39;logged_validation_data&amp;#39;))

tic &amp;lt;- Sys.time()

auto_arima_bic &amp;lt;- genoud(cost_function_bic,
                     nvars = 6,
                     data.type.int = TRUE,
                     starting.values = c(1, 0, 2, 2, 1, 0), # &amp;lt;- from auto.arima
                     Domains = domains,
                     cluster = cl,
                     train_data = logged_train_data,
                     validation_data = logged_validation_data,
                     forecast_periods = length(logged_validation_data),
                     hard.generation.limit = TRUE)
toc_bic &amp;lt;- Sys.time() - tic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This time, it took 6 minutes, a bit slower than before. Let’s take a look at the solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auto_arima_bic&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $value
## [1] -201.0656
## 
## $par
## [1] 0 1 1 1 0 1
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 12
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s train the model at these parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_bic &amp;lt;- arima(logged_train_data, order = auto_arima_bic$par[1:3], 
                        season = list(order = auto_arima_bic$par[4:6], period = 12),
                        method = &amp;quot;ML&amp;quot;)

summary(best_model_bic)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## arima(x = logged_train_data, order = auto_arima_bic$par[1:3], seasonal = list(order = auto_arima_bic$par[4:6], 
##     period = 12), method = &amp;quot;ML&amp;quot;)
## 
## Coefficients:
##           ma1    sar1    sma1
##       -0.6225  0.9968  -0.832
## s.e.   0.0835  0.0075   0.187
## 
## sigma^2 estimated as 0.004145:  log likelihood = 109.64,  aic = -211.28
## 
## Training set error measures:
##                       ME       RMSE        MAE        MPE      MAPE
## Training set 0.003710982 0.06405303 0.04358164 0.02873561 0.3753513
##                   MASE        ACF1
## Training set 0.4553447 -0.03450603&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let’s plot the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_bic_forecast &amp;lt;- forecast::forecast(best_model_bic, h = 65)

best_model_bic_forecast &amp;lt;- to_tibble(best_model_bic_forecast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;date&amp;quot;
## Joining, by = &amp;quot;date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Minimization of BIC&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) +
    geom_ribbon(data = best_model_bic_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#5160a0&amp;quot;, alpha = 0.2) +
    geom_line(data = best_model_bic_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#208480&amp;quot;) +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#98431e&amp;quot;, alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#a53031&amp;quot;) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-16-rgenoud_arima_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The solutions are very close, both in terms of point estimates and confidence intervals. Bias
increased, but variance lowered… This gives me an idea! What if I minimize the RMSE, while
keeping the number of parameters low, as a kind of regularization? This is somewhat what minimising
BIC does, but let’s try to do it a more “naive” approach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_rmse_low_k &amp;lt;- function(param, train_data, validation_data, forecast_periods, max.order){
    order &amp;lt;- param[1:3]
    season &amp;lt;- c(param[4:6], 12)
    if(param[1] + param[3] + param[4] + param[6] &amp;gt; max.order){
        return(9999999)
    } else {
        model &amp;lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, 
                                                          order = order, 
                                                          seasonal = season,
                                                          method = &amp;quot;ML&amp;quot;)
    }
    if(is.null(model)){
        return(9999999)
    } else {
        forecast_model &amp;lt;- forecast::forecast(model, h = forecast_periods)
        point_forecast &amp;lt;- forecast_model$mean
        sqrt(mean(point_forecast - validation_data) ** 2)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is also similar to what &lt;code&gt;auto.arima()&lt;/code&gt; does; by default, the &lt;code&gt;max.order&lt;/code&gt; argument in &lt;code&gt;auto.arima()&lt;/code&gt;
is set to 5, and is the sum of &lt;code&gt;p + q + P + Q&lt;/code&gt;. So I’ll try something similar.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the cost at the parameter values returned by &lt;code&gt;auto.arima()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cost_function_rmse_low_k(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65,
              max.order = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1731473&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what will happen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cl &amp;lt;- makePSOCKcluster(8)
clusterExport(cl, c(&amp;#39;logged_train_data&amp;#39;, &amp;#39;logged_validation_data&amp;#39;))

tic &amp;lt;- Sys.time()

auto_arima_rmse_low_k &amp;lt;- genoud(cost_function_rmse_low_k,
                         nvars = 6,
                         data.type.int = TRUE,
                         starting.values = c(1, 0, 2, 2, 1, 0), # &amp;lt;- from auto.arima
                         max.order = 5,
                         Domains = domains,
                         cluster = cl,
                         train_data = logged_train_data,
                         validation_data = logged_validation_data,
                         forecast_periods = length(logged_validation_data),
                         hard.generation.limit = TRUE)
toc_rmse_low_k &amp;lt;- Sys.time() - tic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It took 1 minute to train this one, quite fast! Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auto_arima_rmse_low_k&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $value
## [1] 0.002503478
## 
## $par
## [1] 1 2 0 3 1 0
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 11
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let’s plot it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_rmse_low_k &amp;lt;- arima(logged_train_data, order = auto_arima_rmse_low_k$par[1:3], 
                               season = list(order = auto_arima_rmse_low_k$par[4:6], period = 12),
                               method = &amp;quot;ML&amp;quot;)

summary(best_model_rmse_low_k)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## arima(x = logged_train_data, order = auto_arima_rmse_low_k$par[1:3], seasonal = list(order = auto_arima_rmse_low_k$par[4:6], 
##     period = 12), method = &amp;quot;ML&amp;quot;)
## 
## Coefficients:
##           ar1     sar1     sar2     sar3
##       -0.6468  -0.7478  -0.5263  -0.1143
## s.e.   0.0846   0.1171   0.1473   0.1446
## 
## sigma^2 estimated as 0.01186:  log likelihood = 57.88,  aic = -105.76
## 
## Training set error measures:
##                        ME      RMSE        MAE         MPE      MAPE
## Training set 0.0005953302 0.1006917 0.06165919 0.003720452 0.5291736
##                   MASE       ACF1
## Training set 0.6442205 -0.3706693&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model_rmse_low_k_forecast &amp;lt;- forecast::forecast(best_model_rmse_low_k, h = 65)

best_model_rmse_low_k_forecast &amp;lt;- to_tibble(best_model_rmse_low_k_forecast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;date&amp;quot;
## Joining, by = &amp;quot;date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Minimization of RMSE + low k&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) +
    geom_ribbon(data = best_model_rmse_low_k_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#5160a0&amp;quot;, alpha = 0.2) +
    geom_line(data = best_model_rmse_low_k_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#208480&amp;quot;) +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = &amp;quot;#98431e&amp;quot;, alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = &amp;quot;#a53031&amp;quot;) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-16-rgenoud_arima_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like this was not the right strategy. There might be a better cost function than what I have
tried, but looks like minimizing the BIC is the way to go.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Searching for the optimal hyper-parameters of an ARIMA model in parallel: the tidy gridsearch approach</title>
      <link>https://www.brodrigues.co/blog/2018-11-15-tidy_gridsearch/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-15-tidy_gridsearch/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://youtu.be/3NxM-AL18lU?t=33s&#34;&gt;
&lt;img width = &#34;400&#34; src=&#34;https://www.brodrigues.co/img/dank_memes.jpg&#34; title = &#34;What a time to be alive&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this blog post, I’ll use the data that I cleaned in a previous
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport/&#34;&gt;blog post&lt;/a&gt;, which you can download
&lt;a href=&#34;https://github.com/b-rodrigues/avia_par_lu/tree/master&#34;&gt;here&lt;/a&gt;. If you want to follow along,
download the monthly data.&lt;/p&gt;
&lt;p&gt;In the previous blog post, I used the &lt;code&gt;auto.arima()&lt;/code&gt; function to very quickly get a “good-enough”
model to predict future monthly total passengers flying from LuxAirport. “Good-enough” models can
be all you need in a lot of situations, but perhaps you’d like to have a better model. I will show
here how you can get a better model by searching through a grid of hyper-parameters.&lt;/p&gt;
&lt;p&gt;This blog post was partially inspired by: &lt;a href=&#34;https://drsimonj.svbtle.com/grid-search-in-the-tidyverse&#34; class=&#34;uri&#34;&gt;https://drsimonj.svbtle.com/grid-search-in-the-tidyverse&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;SARIMA models have a lot of hyper-parameters, 7 in total! Three trend hyper-parameters, &lt;em&gt;p, d, q&lt;/em&gt;,
same as for an ARIMA model, and four seasonal hyper-parameters, &lt;em&gt;P, D, Q, S&lt;/em&gt;. The traditional way t
o search for these hyper-parameters is the so-called Box-Jenkins method. You can read about it
&lt;a href=&#34;https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc44a.htm&#34;&gt;here&lt;/a&gt;. This method was described
in a 1970 book, &lt;em&gt;Time series analysis: Forecasting and control&lt;/em&gt; by Box and Jenkins. The method
requires that you first prepare the data by logging it and differencing it, in order to make the
time series stationary. You then need to analyze ACF and PACF plots, in order to determine the
right amount of lags… It take some time, but this method made sense in a time were computing
power was very expensive. Today, we can simply let our computer search through thousands of models,
check memes on the internet, and come back to the best fit. This blog post is for you, the busy
data scientist meme connoisseurs who cannot waste time with theory and other such useless time drains,
when there are literally thousands of new memes being created and shared every day. Every second counts.
To determine what model is best, I will do pseudo out-of-sample forecasting and compute the RMSE
for each model. I will then choose the model that has the lowest RMSE.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;p&gt;Let’s first load some libraries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forecast)
library(lubridate)
library(furrr)
library(tsibble)
library(brotools)

ihs &amp;lt;- function(x){
    log(x + sqrt(x**2 + 1))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/b-rodrigues/avia_par_lu/master/avia_clean_monthy.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   destination = col_character(),
##   date = col_date(format = &amp;quot;&amp;quot;),
##   passengers = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s split the data into a training set and into a testing set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_train &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(year(date) &amp;lt; 2015) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2005, 1))

avia_clean_test &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(year(date) &amp;gt;= 2015) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2015, 1))

logged_train_data &amp;lt;- ihs(avia_clean_train)

logged_test_data &amp;lt;- ihs(avia_clean_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also define a helper function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_tibble &amp;lt;- function(forecast_object){
    point_estimate &amp;lt;- forecast_object$mean %&amp;gt;%
        as_tsibble() %&amp;gt;%
        rename(point_estimate = value,
               date = index)

    upper &amp;lt;- forecast_object$upper %&amp;gt;%
        as_tsibble() %&amp;gt;%
        spread(key, value) %&amp;gt;%
        rename(date = index,
               upper80 = `80%`,
               upper95 = `95%`)

    lower &amp;lt;- forecast_object$lower %&amp;gt;%
        as_tsibble() %&amp;gt;%
        spread(key, value) %&amp;gt;%
        rename(date = index,
               lower80 = `80%`,
               lower95 = `95%`)

    reduce(list(point_estimate, upper, lower), full_join)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes a &lt;code&gt;forecast&lt;/code&gt; object as argument, and returns a nice tibble. This will be useful
later, and is based on the code I already used in my previous
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport/&#34;&gt;blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s take a closer look at the &lt;code&gt;arima()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ARIMA Modelling of Time Series

Description

Fit an ARIMA model to a univariate time series.

Usage

arima(x, order = c(0L, 0L, 0L),
      seasonal = list(order = c(0L, 0L, 0L), period = NA),
      xreg = NULL, include.mean = TRUE,
      transform.pars = TRUE,
      fixed = NULL, init = NULL,
      method = c(&amp;quot;CSS-ML&amp;quot;, &amp;quot;ML&amp;quot;, &amp;quot;CSS&amp;quot;), n.cond,
      SSinit = c(&amp;quot;Gardner1980&amp;quot;, &amp;quot;Rossignol2011&amp;quot;),
      optim.method = &amp;quot;BFGS&amp;quot;,
      optim.control = list(), kappa = 1e6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The user is supposed to enter the hyper-parameters as two lists, one called &lt;code&gt;order&lt;/code&gt; for &lt;em&gt;p, d, q&lt;/em&gt;
and one called &lt;code&gt;seasonal&lt;/code&gt; for &lt;em&gt;P, D, Q, S&lt;/em&gt;. So what we need is to define these lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;order_list &amp;lt;- list(&amp;quot;p&amp;quot; = seq(0, 3),
                   &amp;quot;d&amp;quot; = seq(0, 2),
                   &amp;quot;q&amp;quot; = seq(0, 3)) %&amp;gt;%
    cross() %&amp;gt;%
    map(lift(c))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I first start with &lt;code&gt;order_list&lt;/code&gt;. This list has 3 elements, “p”, “d” and “q”. Each element is a
sequence from 0 to 3 (2 in the case of “d”). When I pass this list to &lt;code&gt;purrr::cross()&lt;/code&gt; I get the
product set of the starting list, so in this case a list of 4*3*4 = 48 elements. However, this
list looks pretty bad:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list(&amp;quot;p&amp;quot; = seq(0, 3),
     &amp;quot;d&amp;quot; = seq(0, 2),
     &amp;quot;q&amp;quot; = seq(0, 3)) %&amp;gt;%
    cross() %&amp;gt;%
    head(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]]$p
## [1] 0
## 
## [[1]]$d
## [1] 0
## 
## [[1]]$q
## [1] 0
## 
## 
## [[2]]
## [[2]]$p
## [1] 1
## 
## [[2]]$d
## [1] 0
## 
## [[2]]$q
## [1] 0
## 
## 
## [[3]]
## [[3]]$p
## [1] 2
## 
## [[3]]$d
## [1] 0
## 
## [[3]]$q
## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I would like to have something like this instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[[1]]
p d q 
0 0 0 

[[2]]
p d q 
1 0 0 

[[3]]
p d q 
2 0 0 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is possible with the last line, &lt;code&gt;map(lift(c))&lt;/code&gt;. There’s a lot going on in this very small
line of code. First of all, there’s &lt;code&gt;map()&lt;/code&gt;. &lt;code&gt;map()&lt;/code&gt; iterates over lists, and applies a function,
in this case &lt;code&gt;lift(c)&lt;/code&gt;. &lt;code&gt;purrr::lift()&lt;/code&gt; is a very interesting function that lifts the domain of
definition of a function from one type of input to another. The function whose input I am lifting
is &lt;code&gt;c()&lt;/code&gt;. So now, &lt;code&gt;c()&lt;/code&gt; can take a list instead of a vector. Compare the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The usual

c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Nothing happens
c(list(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;a&amp;quot;
## 
## [[2]]
## [1] &amp;quot;b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Magic happens
lift(c)(list(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So &lt;code&gt;order_list&lt;/code&gt; is exactly what I wanted:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(order_list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## p d q 
## 0 0 0 
## 
## [[2]]
## p d q 
## 1 0 0 
## 
## [[3]]
## p d q 
## 2 0 0 
## 
## [[4]]
## p d q 
## 3 0 0 
## 
## [[5]]
## p d q 
## 0 1 0 
## 
## [[6]]
## p d q 
## 1 1 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I do the same for &lt;code&gt;season_list&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;season_list &amp;lt;- list(&amp;quot;P&amp;quot; = seq(0, 3),
                    &amp;quot;D&amp;quot; = seq(0, 2),
                    &amp;quot;Q&amp;quot; = seq(0, 3),
                    &amp;quot;period&amp;quot; = 12)  %&amp;gt;%
    cross() %&amp;gt;%
    map(lift(c))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now coerce these two lists of vectors to tibbles:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;orderdf &amp;lt;- tibble(&amp;quot;order&amp;quot; = order_list)

seasondf &amp;lt;- tibble(&amp;quot;season&amp;quot; = season_list)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And I can now finally create the grid of hyper-parameters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hyper_parameters_df &amp;lt;- crossing(orderdf, seasondf)

nrows &amp;lt;- nrow(hyper_parameters_df)

head(hyper_parameters_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   order     season   
##   &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;   
## 1 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;
## 2 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;
## 3 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;
## 4 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;
## 5 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;
## 6 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;hyper_parameters_df&lt;/code&gt; data frame has 2304 rows, meaning, I will now estimate 2304
models, and will do so in parallel. Let’s just take a quick look at the internals of &lt;code&gt;hyper_parameters_df&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(hyper_parameters_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 2,304
## Variables: 2
## $ order  &amp;lt;list&amp;gt; [&amp;lt;0, 0, 0&amp;gt;, &amp;lt;0, 0, 0&amp;gt;, &amp;lt;0, 0, 0&amp;gt;, &amp;lt;0, 0, 0&amp;gt;, &amp;lt;0, 0, 0&amp;gt;, …
## $ season &amp;lt;list&amp;gt; [&amp;lt;0, 0, 0, 12&amp;gt;, &amp;lt;1, 0, 0, 12&amp;gt;, &amp;lt;2, 0, 0, 12&amp;gt;, &amp;lt;3, 0, 0, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So in the &lt;code&gt;order&lt;/code&gt; column, the vector &lt;code&gt;0, 0, 0&lt;/code&gt; is repeated as many times as there are combinations
of &lt;em&gt;P, D, Q, S&lt;/em&gt; for &lt;code&gt;season&lt;/code&gt;. Same for all the other vectors of the &lt;code&gt;order&lt;/code&gt; column.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;training-the-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Training the models&lt;/h2&gt;
&lt;p&gt;Because training these models might take some time, I will use the fantastic &lt;code&gt;{furrr}&lt;/code&gt; package
by &lt;a href=&#34;https://twitter.com/dvaughan32&#34;&gt;Davis Vaughan&lt;/a&gt; to train the &lt;code&gt;arima()&lt;/code&gt; function in parallel.
For this, I first define 8 workers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plan(multiprocess, workers = 8)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then I run the code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic &amp;lt;- Sys.time()
models_df &amp;lt;- hyper_parameters_df %&amp;gt;%
    mutate(models = future_map2(.x = order,
                         .y = season,
                         ~possibly(arima, otherwise = NULL)(x = logged_train_data,
                                                                           order = .x, seasonal = .y)))
running_time &amp;lt;- Sys.time() - tic&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I use &lt;code&gt;future_map2()&lt;/code&gt;, which is just like &lt;code&gt;map2()&lt;/code&gt; but running in parallel.
I add a new column to the data called &lt;code&gt;models&lt;/code&gt;, which will contain the models trained over all the
different combinations of &lt;code&gt;order&lt;/code&gt; and &lt;code&gt;season&lt;/code&gt;. The models are trained on the &lt;code&gt;logged_train_data&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Training the 2304 models took 18 minutes, which is
plenty of time to browse the latest memes, but still quick enough that it justifies the whole approach.
Let’s take a look at the &lt;code&gt;models_df&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(models_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   order     season    models 
##   &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt; 
## 1 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;
## 2 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;
## 3 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;
## 4 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;
## 5 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;
## 6 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the &lt;code&gt;models&lt;/code&gt; column contains all the trained models. The model on the first row,
was trained with the hyperparameters of row 1, and so on. But, our work is not over! We now need
to find the best model. First, I add a new column to the tibble, which contains the forecast. From
the forecast, I extract the point estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models_df %&amp;gt;%
    mutate(forecast = map(models, ~possibly(forecast, otherwise = NULL)(., h = 39))) %&amp;gt;%
    mutate(point_forecast = map(forecast, ~.$`mean`)) %&amp;gt;%
    ....&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You have to be familiar with a &lt;code&gt;forecast&lt;/code&gt; object to understand the last line: a &lt;code&gt;forecast&lt;/code&gt; object
is a list with certain elements, the point estimates, the confidence intervals, and so on. To get
the point estimates, I have to extract the “mean” element from the list. Hence the weird &lt;code&gt;~.$mean&lt;/code&gt;.
Then I need to add a new list-column, where each element is the vector of true values, meaning the data
from 2015 to 2018. Because I have to add it as a list of size 2304, I do that with &lt;code&gt;purrr::rerun()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rerun(5, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;
## 
## [[2]]
## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;
## 
## [[3]]
## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;
## 
## [[4]]
## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;
## 
## [[5]]
## [1] &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is then easy to compute the RMSE, which I add as a column to the original data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;... %&amp;gt;%
    mutate(true_value = rerun(nrows, logged_test_data)) %&amp;gt;%
    mutate(rmse = map2_dbl(point_forecast, true_value,
                           ~sqrt(mean((.x - .y) ** 2))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The whole workflow is here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models_df &amp;lt;- models_df %&amp;gt;%
    mutate(forecast = map(models, ~possibly(forecast, otherwise = NULL)(., h = 39))) %&amp;gt;%
    mutate(point_forecast = map(forecast, ~.$`mean`)) %&amp;gt;%
    mutate(true_value = rerun(nrows, logged_test_data)) %&amp;gt;%
    mutate(rmse = map2_dbl(point_forecast, true_value,
                           ~sqrt(mean((.x - .y) ** 2))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is how &lt;code&gt;models_df&lt;/code&gt; looks now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(models_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   order     season    models  forecast   point_forecast true_value  rmse
##   &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;    &amp;lt;list&amp;gt;  &amp;lt;list&amp;gt;     &amp;lt;list&amp;gt;         &amp;lt;list&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.525
## 2 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.236
## 3 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.235
## 4 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.217
## 5 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.190
## 6 &amp;lt;int [3]&amp;gt; &amp;lt;dbl [4]&amp;gt; &amp;lt;Arima&amp;gt; &amp;lt;forecast&amp;gt; &amp;lt;ts&amp;gt;           &amp;lt;ts&amp;gt;       0.174&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I can finally select the best performing model. I select the model with minimum RMSE:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;best_model &amp;lt;- models_df %&amp;gt;%
    filter(rmse == min(rmse, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And save the forecast into a new variable, as a &lt;code&gt;tibble&lt;/code&gt;, using my &lt;code&gt;to_tibble()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(best_model_forecast &amp;lt;- to_tibble(best_model$forecast[[1]]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;date&amp;quot;
## Joining, by = &amp;quot;date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tsibble: 39 x 6 [1M]
##        date point_estimate upper80 upper95 lower80 lower95
##       &amp;lt;mth&amp;gt;          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 2015 Jan           11.9    12.1    12.1    11.8    11.7
##  2 2015 Feb           11.9    12.0    12.1    11.7    11.6
##  3 2015 Mar           12.1    12.3    12.3    11.9    11.9
##  4 2015 Apr           12.2    12.3    12.4    12.0    11.9
##  5 2015 May           12.2    12.4    12.5    12.1    12.0
##  6 2015 Jun           12.3    12.4    12.5    12.1    12.0
##  7 2015 Jul           12.2    12.3    12.4    12.0    11.9
##  8 2015 Aug           12.3    12.5    12.6    12.2    12.1
##  9 2015 Sep           12.3    12.5    12.6    12.2    12.1
## 10 2015 Oct           12.2    12.4    12.5    12.1    12.0
## # … with 29 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, I can plot it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Logged data&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) +
    geom_ribbon(data = best_model_forecast, aes(x = date, ymin = lower95, ymax = upper95), 
                fill = &amp;quot;#666018&amp;quot;, alpha = 0.2) +
    geom_line(data = best_model_forecast, aes(x = date, y = point_estimate), linetype = 2, colour = &amp;quot;#8e9d98&amp;quot;) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-15-tidy_gridsearch_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Compared to the previous &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport/&#34;&gt;blog post&lt;/a&gt;, the
dotted line now seems to follow the true line even better! However, this is not suprising, as I
am using the test set as a validation set, which might lead to overfitting the hyperparameters
to the test set. Also, I am not saying that you should always do a gridsearch whenever you have a
problem like this one. In the case of univariate time series, I am still doubtful that a gridsearch like this is really necessary. The goal of this blog post was not to teach you how to look for
hyperparameters per se, but more to show you how to do a grid search the tidy way. I’ll be writing
about &lt;em&gt;proper&lt;/em&gt; hyperparameter optimization in a future blog post.
Also, the other thing I wanted to show was the power of &lt;code&gt;{furrr}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Easy time-series prediction with R: a tutorial with air traffic data from Lux Airport</title>
      <link>https://www.brodrigues.co/blog/2018-11-14-luxairport/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-14-luxairport/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GIQn8pab8Vc&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/lx_aie.jpg&#34; title = &#34;Luxembourg&#39;s largest aircraft landing&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this blog post, I will show you how you can quickly and easily forecast a univariate time series.
I am going to use data from the EU Open Data Portal on air passenger transport. You can find the
data &lt;a href=&#34;https://data.europa.eu/euodp/en/data/dataset/2EwfWXj5d94BUOzfoABKSQ&#34;&gt;here&lt;/a&gt;. I downloaded
the data in the TSV format for Luxembourg Airport, but you could repeat the analysis for any airport.&lt;/p&gt;
&lt;p&gt;Once you have the data, load some of the package we are going to need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(forecast)
library(tsibble)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and define the following function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ihs &amp;lt;- function(x){
    log(x + sqrt(x**2 + 1))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function, the inverse hyperbolic sine, is useful to transform data in a manner that is very
close to logging it, but that allows for 0’s. The data from Eurostat is not complete for some reason,
so there are some 0 sometimes. To avoid having to log 0, which in R yields &lt;code&gt;-Inf&lt;/code&gt;, I use this
transformation.&lt;/p&gt;
&lt;p&gt;Now, let’s load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia &amp;lt;- read_tsv(&amp;quot;avia_par_lu.tsv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   .default = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## See spec(...) for full column specifications.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(avia)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 238
##   `unit,tra_meas,… `2018Q1` `2018M03` `2018M02` `2018M01` `2017Q4` `2017Q3`
##   &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;   
## 1 FLIGHT,CAF_PAS,… 511      172       161       178       502      475     
## 2 FLIGHT,CAF_PAS,… :        :         :         :         :        :       
## 3 FLIGHT,CAF_PAS,… :        :         :         :         399      306     
## 4 FLIGHT,CAF_PAS,… 485      167       151       167       493      497     
## 5 FLIGHT,CAF_PAS,… 834      293       267       274       790      728     
## 6 FLIGHT,CAF_PAS,… :        :         :         :         :        :       
## # … with 231 more variables: `2017Q2` &amp;lt;chr&amp;gt;, `2017Q1` &amp;lt;chr&amp;gt;,
## #   `2017M12` &amp;lt;chr&amp;gt;, `2017M11` &amp;lt;chr&amp;gt;, `2017M10` &amp;lt;chr&amp;gt;, `2017M09` &amp;lt;chr&amp;gt;,
## #   `2017M08` &amp;lt;chr&amp;gt;, `2017M07` &amp;lt;chr&amp;gt;, `2017M06` &amp;lt;chr&amp;gt;, `2017M05` &amp;lt;chr&amp;gt;,
## #   `2017M04` &amp;lt;chr&amp;gt;, `2017M03` &amp;lt;chr&amp;gt;, `2017M02` &amp;lt;chr&amp;gt;, `2017M01` &amp;lt;chr&amp;gt;,
## #   `2017` &amp;lt;chr&amp;gt;, `2016Q4` &amp;lt;chr&amp;gt;, `2016Q3` &amp;lt;chr&amp;gt;, `2016Q2` &amp;lt;chr&amp;gt;,
## #   `2016Q1` &amp;lt;chr&amp;gt;, `2016M12` &amp;lt;chr&amp;gt;, `2016M11` &amp;lt;chr&amp;gt;, `2016M10` &amp;lt;chr&amp;gt;,
## #   `2016M09` &amp;lt;chr&amp;gt;, `2016M08` &amp;lt;chr&amp;gt;, `2016M07` &amp;lt;chr&amp;gt;, `2016M06` &amp;lt;chr&amp;gt;,
## #   `2016M05` &amp;lt;chr&amp;gt;, `2016M04` &amp;lt;chr&amp;gt;, `2016M03` &amp;lt;chr&amp;gt;, `2016M02` &amp;lt;chr&amp;gt;,
## #   `2016M01` &amp;lt;chr&amp;gt;, `2016` &amp;lt;chr&amp;gt;, `2015Q4` &amp;lt;chr&amp;gt;, `2015Q3` &amp;lt;chr&amp;gt;,
## #   `2015Q2` &amp;lt;chr&amp;gt;, `2015Q1` &amp;lt;chr&amp;gt;, `2015M12` &amp;lt;chr&amp;gt;, `2015M11` &amp;lt;chr&amp;gt;,
## #   `2015M10` &amp;lt;chr&amp;gt;, `2015M09` &amp;lt;chr&amp;gt;, `2015M08` &amp;lt;chr&amp;gt;, `2015M07` &amp;lt;chr&amp;gt;,
## #   `2015M06` &amp;lt;chr&amp;gt;, `2015M05` &amp;lt;chr&amp;gt;, `2015M04` &amp;lt;chr&amp;gt;, `2015M03` &amp;lt;chr&amp;gt;,
## #   `2015M02` &amp;lt;chr&amp;gt;, `2015M01` &amp;lt;chr&amp;gt;, `2015` &amp;lt;chr&amp;gt;, `2014Q4` &amp;lt;chr&amp;gt;,
## #   `2014Q3` &amp;lt;chr&amp;gt;, `2014Q2` &amp;lt;chr&amp;gt;, `2014Q1` &amp;lt;chr&amp;gt;, `2014M12` &amp;lt;chr&amp;gt;,
## #   `2014M11` &amp;lt;chr&amp;gt;, `2014M10` &amp;lt;chr&amp;gt;, `2014M09` &amp;lt;chr&amp;gt;, `2014M08` &amp;lt;chr&amp;gt;,
## #   `2014M07` &amp;lt;chr&amp;gt;, `2014M06` &amp;lt;chr&amp;gt;, `2014M05` &amp;lt;chr&amp;gt;, `2014M04` &amp;lt;chr&amp;gt;,
## #   `2014M03` &amp;lt;chr&amp;gt;, `2014M02` &amp;lt;chr&amp;gt;, `2014M01` &amp;lt;chr&amp;gt;, `2014` &amp;lt;chr&amp;gt;,
## #   `2013Q4` &amp;lt;chr&amp;gt;, `2013Q3` &amp;lt;chr&amp;gt;, `2013Q2` &amp;lt;chr&amp;gt;, `2013Q1` &amp;lt;chr&amp;gt;,
## #   `2013M12` &amp;lt;chr&amp;gt;, `2013M11` &amp;lt;chr&amp;gt;, `2013M10` &amp;lt;chr&amp;gt;, `2013M09` &amp;lt;chr&amp;gt;,
## #   `2013M08` &amp;lt;chr&amp;gt;, `2013M07` &amp;lt;chr&amp;gt;, `2013M06` &amp;lt;chr&amp;gt;, `2013M05` &amp;lt;chr&amp;gt;,
## #   `2013M04` &amp;lt;chr&amp;gt;, `2013M03` &amp;lt;chr&amp;gt;, `2013M02` &amp;lt;chr&amp;gt;, `2013M01` &amp;lt;chr&amp;gt;,
## #   `2013` &amp;lt;chr&amp;gt;, `2012Q4` &amp;lt;chr&amp;gt;, `2012Q3` &amp;lt;chr&amp;gt;, `2012Q2` &amp;lt;chr&amp;gt;,
## #   `2012Q1` &amp;lt;chr&amp;gt;, `2012M12` &amp;lt;chr&amp;gt;, `2012M11` &amp;lt;chr&amp;gt;, `2012M10` &amp;lt;chr&amp;gt;,
## #   `2012M09` &amp;lt;chr&amp;gt;, `2012M08` &amp;lt;chr&amp;gt;, `2012M07` &amp;lt;chr&amp;gt;, `2012M06` &amp;lt;chr&amp;gt;,
## #   `2012M05` &amp;lt;chr&amp;gt;, `2012M04` &amp;lt;chr&amp;gt;, `2012M03` &amp;lt;chr&amp;gt;, `2012M02` &amp;lt;chr&amp;gt;,
## #   `2012M01` &amp;lt;chr&amp;gt;, `2012` &amp;lt;chr&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So yeah, useless in that state. The first column actually is composed of 3 columns, merged together,
and instead of having one column with the date, and another with the value, we have one column
per date. Some cleaning is necessary before using this data.&lt;/p&gt;
&lt;p&gt;Let’s start with going from a wide to a long data set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia %&amp;gt;%
    select(&amp;quot;unit,tra_meas,airp_pr\\time&amp;quot;, contains(&amp;quot;20&amp;quot;)) %&amp;gt;%
    gather(date, passengers, -`unit,tra_meas,airp_pr\\time`)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line makes it possible to only select the columns that contain the string “20”, so
selecting columns from 2000 onward. Then, using gather, I go from long to wide. The data looks
like this now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 117,070 x 3
##    `unit,tra_meas,airp_pr\\time`  date   passengers
##    &amp;lt;chr&amp;gt;                          &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;     
##  1 FLIGHT,CAF_PAS,LU_ELLX_AT_LOWW 2018Q1 511       
##  2 FLIGHT,CAF_PAS,LU_ELLX_BE_EBBR 2018Q1 :         
##  3 FLIGHT,CAF_PAS,LU_ELLX_CH_LSGG 2018Q1 :         
##  4 FLIGHT,CAF_PAS,LU_ELLX_CH_LSZH 2018Q1 485       
##  5 FLIGHT,CAF_PAS,LU_ELLX_DE_EDDF 2018Q1 834       
##  6 FLIGHT,CAF_PAS,LU_ELLX_DE_EDDI 2018Q1 :         
##  7 FLIGHT,CAF_PAS,LU_ELLX_DE_EDDM 2018Q1 1095      
##  8 FLIGHT,CAF_PAS,LU_ELLX_DE_EDDR 2018Q1 :         
##  9 FLIGHT,CAF_PAS,LU_ELLX_DE_EDDT 2018Q1 :         
## 10 FLIGHT,CAF_PAS,LU_ELLX_DK_EKCH 2018Q1 :         
## # … with 117,060 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s separate the first column into 3 columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia %&amp;gt;%
    select(&amp;quot;unit,tra_meas,airp_pr\\time&amp;quot;, contains(&amp;quot;20&amp;quot;)) %&amp;gt;%
    gather(date, passengers, -`unit,tra_meas,airp_pr\\time`) %&amp;gt;%
     separate(col = `unit,tra_meas,airp_pr\\time`, into = c(&amp;quot;unit&amp;quot;, &amp;quot;tra_meas&amp;quot;, &amp;quot;air_pr\\time&amp;quot;), sep = &amp;quot;,&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This separates the first column into 3 new columns, “unit”, “tra_meas” and “air_pr\time”. This step
is not necessary for the rest of the analysis, but might as well do it. The data looks like this now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 117,070 x 5
##    unit   tra_meas `air_pr\\time`  date   passengers
##    &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;     
##  1 FLIGHT CAF_PAS  LU_ELLX_AT_LOWW 2018Q1 511       
##  2 FLIGHT CAF_PAS  LU_ELLX_BE_EBBR 2018Q1 :         
##  3 FLIGHT CAF_PAS  LU_ELLX_CH_LSGG 2018Q1 :         
##  4 FLIGHT CAF_PAS  LU_ELLX_CH_LSZH 2018Q1 485       
##  5 FLIGHT CAF_PAS  LU_ELLX_DE_EDDF 2018Q1 834       
##  6 FLIGHT CAF_PAS  LU_ELLX_DE_EDDI 2018Q1 :         
##  7 FLIGHT CAF_PAS  LU_ELLX_DE_EDDM 2018Q1 1095      
##  8 FLIGHT CAF_PAS  LU_ELLX_DE_EDDR 2018Q1 :         
##  9 FLIGHT CAF_PAS  LU_ELLX_DE_EDDT 2018Q1 :         
## 10 FLIGHT CAF_PAS  LU_ELLX_DK_EKCH 2018Q1 :         
## # … with 117,060 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next steps are simple renamings. I have copy-pasted the information from the Eurostat page
where you can &lt;a href=&#34;http://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=avia_par_lu&amp;amp;lang=en&#34;&gt;view the data online&lt;/a&gt;.
If you click here:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/eurostat_click_here.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;you will be able to select the variables you want displayed in the table, as well as the dictionary
of the variables. I simply copy pasted it and recoded the variables. You can take a look at the
whole cleaning workflow by clicking “Click to expand” below:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click here to take a look at the whole cleaning workflow&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean &amp;lt;- avia %&amp;gt;%
    select(&amp;quot;unit,tra_meas,airp_pr\\time&amp;quot;, contains(&amp;quot;20&amp;quot;)) %&amp;gt;%
    gather(date, passengers, -`unit,tra_meas,airp_pr\\time`) %&amp;gt;%
    separate(col = `unit,tra_meas,airp_pr\\time`, into = c(&amp;quot;unit&amp;quot;, &amp;quot;tra_meas&amp;quot;, &amp;quot;air_pr\\time&amp;quot;), sep = &amp;quot;,&amp;quot;) %&amp;gt;%
    mutate(tra_meas = fct_recode(tra_meas,
         `Passengers on board` = &amp;quot;PAS_BRD&amp;quot;,
         `Passengers on board (arrivals)` = &amp;quot;PAS_BRD_ARR&amp;quot;,
         `Passengers on board (departures)` = &amp;quot;PAS_BRD_DEP&amp;quot;,
         `Passengers carried` = &amp;quot;PAS_CRD&amp;quot;,
         `Passengers carried (arrival)` = &amp;quot;PAS_CRD_ARR&amp;quot;,
         `Passengers carried (departures)` = &amp;quot;PAS_CRD_DEP&amp;quot;,
         `Passengers seats available` = &amp;quot;ST_PAS&amp;quot;,
         `Passengers seats available (arrivals)` = &amp;quot;ST_PAS_ARR&amp;quot;,
         `Passengers seats available (departures)` = &amp;quot;ST_PAS_DEP&amp;quot;,
         `Commercial passenger air flights` = &amp;quot;CAF_PAS&amp;quot;,
         `Commercial passenger air flights (arrivals)` = &amp;quot;CAF_PAS_ARR&amp;quot;,
         `Commercial passenger air flights (departures)` = &amp;quot;CAF_PAS_DEP&amp;quot;)) %&amp;gt;%
    mutate(unit = fct_recode(unit,
                             Passenger = &amp;quot;PAS&amp;quot;,
                             Flight = &amp;quot;FLIGHT&amp;quot;,
                             `Seats and berths` = &amp;quot;SEAT&amp;quot;)) %&amp;gt;%
    mutate(destination = fct_recode(`air_pr\\time`,
                                     `WIEN-SCHWECHAT` = &amp;quot;LU_ELLX_AT_LOWW&amp;quot;,
                                     `BRUSSELS` = &amp;quot;LU_ELLX_BE_EBBR&amp;quot;,
                                     `GENEVA` = &amp;quot;LU_ELLX_CH_LSGG&amp;quot;,
                                     `ZURICH` = &amp;quot;LU_ELLX_CH_LSZH&amp;quot;,
                                     `FRANKFURT/MAIN` = &amp;quot;LU_ELLX_DE_EDDF&amp;quot;,
                                     `HAMBURG` = &amp;quot;LU_ELLX_DE_EDDH&amp;quot;,
                                     `BERLIN-TEMPELHOF` = &amp;quot;LU_ELLX_DE_EDDI&amp;quot;,
                                     `MUENCHEN` = &amp;quot;LU_ELLX_DE_EDDM&amp;quot;,
                                     `SAARBRUECKEN` = &amp;quot;LU_ELLX_DE_EDDR&amp;quot;,
                                     `BERLIN-TEGEL` = &amp;quot;LU_ELLX_DE_EDDT&amp;quot;,
                                     `KOBENHAVN/KASTRUP` = &amp;quot;LU_ELLX_DK_EKCH&amp;quot;,
                                     `HURGHADA / INTL` = &amp;quot;LU_ELLX_EG_HEGN&amp;quot;,
                                     `IRAKLION/NIKOS KAZANTZAKIS` = &amp;quot;LU_ELLX_EL_LGIR&amp;quot;,
                                     `FUERTEVENTURA` = &amp;quot;LU_ELLX_ES_GCFV&amp;quot;,
                                     `GRAN CANARIA` = &amp;quot;LU_ELLX_ES_GCLP&amp;quot;,
                                     `LANZAROTE` = &amp;quot;LU_ELLX_ES_GCRR&amp;quot;,
                                     `TENERIFE SUR/REINA SOFIA` = &amp;quot;LU_ELLX_ES_GCTS&amp;quot;,
                                     `BARCELONA/EL PRAT` = &amp;quot;LU_ELLX_ES_LEBL&amp;quot;,
                                     `ADOLFO SUAREZ MADRID-BARAJAS` = &amp;quot;LU_ELLX_ES_LEMD&amp;quot;,
                                     `MALAGA/COSTA DEL SOL` = &amp;quot;LU_ELLX_ES_LEMG&amp;quot;,
                                     `PALMA DE MALLORCA` = &amp;quot;LU_ELLX_ES_LEPA&amp;quot;,
                                     `SYSTEM - PARIS` = &amp;quot;LU_ELLX_FR_LF90&amp;quot;,
                                     `NICE-COTE D&amp;#39;AZUR` = &amp;quot;LU_ELLX_FR_LFMN&amp;quot;,
                                     `PARIS-CHARLES DE GAULLE` = &amp;quot;LU_ELLX_FR_LFPG&amp;quot;,
                                     `STRASBOURG-ENTZHEIM` = &amp;quot;LU_ELLX_FR_LFST&amp;quot;,
                                     `KEFLAVIK` = &amp;quot;LU_ELLX_IS_BIKF&amp;quot;,
                                     `MILANO/MALPENSA` = &amp;quot;LU_ELLX_IT_LIMC&amp;quot;,
                                     `BERGAMO/ORIO AL SERIO` = &amp;quot;LU_ELLX_IT_LIME&amp;quot;,
                                     `ROMA/FIUMICINO` = &amp;quot;LU_ELLX_IT_LIRF&amp;quot;,
                                     `AGADIR/AL MASSIRA` = &amp;quot;LU_ELLX_MA_GMAD&amp;quot;,
                                     `AMSTERDAM/SCHIPHOL` = &amp;quot;LU_ELLX_NL_EHAM&amp;quot;,
                                     `WARSZAWA/CHOPINA` = &amp;quot;LU_ELLX_PL_EPWA&amp;quot;,
                                     `PORTO` = &amp;quot;LU_ELLX_PT_LPPR&amp;quot;,
                                     `LISBOA` = &amp;quot;LU_ELLX_PT_LPPT&amp;quot;,
                                     `STOCKHOLM/ARLANDA` = &amp;quot;LU_ELLX_SE_ESSA&amp;quot;,
                                     `MONASTIR/HABIB BOURGUIBA` = &amp;quot;LU_ELLX_TN_DTMB&amp;quot;,
                                     `ENFIDHA-HAMMAMET INTERNATIONAL` = &amp;quot;LU_ELLX_TN_DTNH&amp;quot;,
                                     `ENFIDHA ZINE EL ABIDINE BEN ALI` = &amp;quot;LU_ELLX_TN_DTNZ&amp;quot;,
                                     `DJERBA/ZARZIS` = &amp;quot;LU_ELLX_TN_DTTJ&amp;quot;,
                                     `ANTALYA (MIL-CIV)` = &amp;quot;LU_ELLX_TR_LTAI&amp;quot;,
                                     `ISTANBUL/ATATURK` = &amp;quot;LU_ELLX_TR_LTBA&amp;quot;,
                                     `SYSTEM - LONDON` = &amp;quot;LU_ELLX_UK_EG90&amp;quot;,
                                     `MANCHESTER` = &amp;quot;LU_ELLX_UK_EGCC&amp;quot;,
                                     `LONDON GATWICK` = &amp;quot;LU_ELLX_UK_EGKK&amp;quot;,
                                     `LONDON/CITY` = &amp;quot;LU_ELLX_UK_EGLC&amp;quot;,
                                     `LONDON HEATHROW` = &amp;quot;LU_ELLX_UK_EGLL&amp;quot;,
                                     `LONDON STANSTED` = &amp;quot;LU_ELLX_UK_EGSS&amp;quot;,
                                     `NEWARK LIBERTY INTERNATIONAL, NJ.` = &amp;quot;LU_ELLX_US_KEWR&amp;quot;,
                                     `O.R TAMBO INTERNATIONAL` = &amp;quot;LU_ELLX_ZA_FAJS&amp;quot;)) %&amp;gt;%
    mutate(passengers = as.numeric(passengers)) %&amp;gt;%
    select(unit, tra_meas, destination, date, passengers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;There is quarterly data and monthly data. Let’s separate the two:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_quarterly &amp;lt;- avia_clean %&amp;gt;%
    filter(tra_meas == &amp;quot;Passengers on board (arrivals)&amp;quot;,
           !is.na(passengers)) %&amp;gt;%
    filter(str_detect(date, &amp;quot;Q&amp;quot;)) %&amp;gt;%
    mutate(date = yq(date))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the “date” column, I detect the observations with “Q” in their name, indicating that it is quarterly data.
I do the same for monthly data, but I have to add the string “01” to the dates. This transforms
a date that looks like this “2018M1” to this “2018M101”. “2018M101” can then be converted into a
date by using the &lt;code&gt;ymd()&lt;/code&gt; function from lubridate. &lt;code&gt;yq()&lt;/code&gt; was used for the quarterly data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly &amp;lt;- avia_clean %&amp;gt;%
    filter(tra_meas == &amp;quot;Passengers on board (arrivals)&amp;quot;,
           !is.na(passengers)) %&amp;gt;%
    filter(str_detect(date, &amp;quot;M&amp;quot;)) %&amp;gt;%
    mutate(date = paste0(date, &amp;quot;01&amp;quot;)) %&amp;gt;%
    mutate(date = ymd(date)) %&amp;gt;%
    select(destination, date, passengers)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time for some plots. Let’s start with the raw data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Raw data&amp;quot;) +
    geom_line(aes(y = total, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) + 
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now with the logged data (or rather, the data transformed using the inverted hyperbolic sine
transformation):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Logged data&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) + 
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We clearly see a seasonal pattern in the data. There is also an upward trend. We will have to deal
with these two problems if we want to do some forecasting. For this, let’s limit ourselves to data
from before 2015, and convert the “passengers” column from the data to a time series object, using
the &lt;code&gt;ts()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_train &amp;lt;- avia_clean_monthly %&amp;gt;%
    select(date, passengers) %&amp;gt;%
    filter(year(date) &amp;lt; 2015) %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total_passengers = sum(passengers)) %&amp;gt;%
    pull(total_passengers) %&amp;gt;%
    ts(., frequency = 12, start = c(2005, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will try to &lt;em&gt;pseudo&lt;/em&gt;-forecast the data from 2015 to the last point available, March 2018.
First, let’s tranform the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logged_data &amp;lt;- ihs(avia_clean_train)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Taking the log, or ihs of the data deals with stabilizing the variance of the time series.&lt;/p&gt;
&lt;p&gt;There might also be a need to difference the data. Computing the differences between consecutive
observations makes the time-series stationary. This will be taken care of by the &lt;code&gt;auto.arima()&lt;/code&gt;
function, if needed. The &lt;code&gt;auto.arima()&lt;/code&gt; function returns the best ARIMA model according to different
statistical criterions, such as the AIC, AICc or BIC.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(model_fit &amp;lt;- auto.arima(logged_data))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Series: logged_data 
## ARIMA(2,1,1)(2,1,0)[12] 
## 
## Coefficients:
##           ar1      ar2      ma1     sar1     sar2
##       -0.4061  -0.2431  -0.3562  -0.5590  -0.3282
## s.e.   0.2003   0.1432   0.1994   0.0911   0.0871
## 
## sigma^2 estimated as 0.004503:  log likelihood=137.11
## AIC=-262.21   AICc=-261.37   BIC=-246.17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;auto.arima()&lt;/code&gt; found that the best model would be an &lt;span class=&#34;math inline&#34;&gt;\(ARIMA(2, 1, 1)(2, 1, 0)_{12}\)&lt;/span&gt;. This is an
seasonal autoregressive model, with p = 2, d = 1, q = 1, P = 2 and D = 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_forecast &amp;lt;- forecast(model_fit, h = 39)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now forecast the model for the next 39 months (which correspond to the data available).&lt;/p&gt;
&lt;p&gt;To plot the forecast, one could do a simple call to the plot function. But the resulting plot
is not very aesthetic. To plot my own, I have to grab the data that was forecast, and do some
munging again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;point_estimate &amp;lt;- model_forecast$mean %&amp;gt;%
    as_tsibble() %&amp;gt;%
    rename(point_estimate = value,
           date = index)

upper &amp;lt;- model_forecast$upper %&amp;gt;%
    as_tsibble() %&amp;gt;%
    spread(key, value) %&amp;gt;%
    rename(date = index,
           upper80 = `80%`,
           upper95 = `95%`)

lower &amp;lt;- model_forecast$lower %&amp;gt;%
    as_tsibble() %&amp;gt;%
    spread(key, value) %&amp;gt;%
    rename(date = index,
           lower80 = `80%`,
           lower95 = `95%`)

estimated_data &amp;lt;- reduce(list(point_estimate, upper, lower), full_join, by = &amp;quot;date&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;as_tsibble()&lt;/code&gt; is a function from the &lt;code&gt;{tsibble}&lt;/code&gt; package that converts objects that are &lt;em&gt;time-series aware&lt;/em&gt;
to &lt;em&gt;time-aware&lt;/em&gt; tibbles. If you are not familiar with &lt;code&gt;ts_tibble()&lt;/code&gt;, I urge you to run the above lines
one by one, and especially to compare &lt;code&gt;as_tsibble()&lt;/code&gt; with the standard &lt;code&gt;as_tibble()&lt;/code&gt; from the &lt;code&gt;{tibble}&lt;/code&gt;
package.&lt;/p&gt;
&lt;p&gt;This is how &lt;code&gt;estimated_data&lt;/code&gt; looks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(estimated_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tsibble: 6 x 6 [1M]
##       date point_estimate upper80 upper95 lower80 lower95
##      &amp;lt;mth&amp;gt;          &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 2015 Jan           11.9    12.0    12.1    11.8    11.8
## 2 2015 Feb           11.9    12.0    12.0    11.8    11.7
## 3 2015 Mar           12.1    12.2    12.3    12.0    12.0
## 4 2015 Apr           12.2    12.3    12.4    12.1    12.1
## 5 2015 May           12.3    12.4    12.4    12.2    12.1
## 6 2015 Jun           12.3    12.4    12.5    12.2    12.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now plot the data, with the forecast, and with the 95% confidence interval:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avia_clean_monthly %&amp;gt;%
    group_by(date) %&amp;gt;%
    summarise(total = sum(passengers)) %&amp;gt;%
    mutate(total_ihs = ihs(total)) %&amp;gt;%
    ggplot() +
    ggtitle(&amp;quot;Logged data&amp;quot;) +
    geom_line(aes(y = total_ihs, x = date), colour = &amp;quot;#82518c&amp;quot;) +
    scale_x_date(date_breaks = &amp;quot;1 year&amp;quot;, date_labels = &amp;quot;%m-%Y&amp;quot;) +
    geom_ribbon(data = estimated_data, aes(x = date, ymin = lower95, ymax = upper95), fill = &amp;quot;#666018&amp;quot;, alpha = 0.2) +
    geom_line(data = estimated_data, aes(x = date, y = point_estimate), linetype = 2, colour = &amp;quot;#8e9d98&amp;quot;) +
    theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-14-luxairport_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The pseudo-forecast (the dashed line) is not very far from the truth, only overestimating the
seasonal peaks, but the true line is within the 95% confidence interval, which is good!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing NetHack data, part 2: What players kill the most</title>
      <link>https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=VnW2g6qbbrA&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/monsters.png&#34; title = &#34;Wizard of Yendor battle music&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Link to &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-01-nethack/&#34;&gt;webscraping the data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Link to &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis/&#34;&gt;Analysis, part 1&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This is the third blog post that deals with data from the game NetHack, and oh boy, did a lot of
things happen since the last blog post! Here’s a short timeline of the events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I scraped data from &lt;a href=&#34;https://alt.org/nethack/&#34;&gt;alt.org/nethack&lt;/a&gt; and made a package with the data available on Github
(that package was too big for CRAN)&lt;/li&gt;
&lt;li&gt;Then, I analyzed the data, focusing on what monsters kill the players the most, and also where
players die the most&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;@GridSageGames&lt;/span&gt;, developer of the roguelike Cogmind and moderator of the roguelike subreddit,
posted the blog post on reddit&lt;/li&gt;
&lt;li&gt;I noticed that actually, by scraping the data like I did, I only got a sample of 100 daily games&lt;/li&gt;
&lt;li&gt;This point was also discussed on Reddit, and bhhak, an UnNetHack developer (UnNetHack is a fork
of NetHack) suggested I used the xlogfiles instead&lt;/li&gt;
&lt;li&gt;xlogfiles are log files generated by NetHack, and are also available on alt.org/nethack&lt;/li&gt;
&lt;li&gt;I started scraping them, and getting a lot more data&lt;/li&gt;
&lt;li&gt;I got contacted on twitter by &lt;span class=&#34;citation&#34;&gt;@paxed&lt;/span&gt;, an admin of alt.org/nethack:&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;There was no need for scraping, we&amp;#39;ll happily give out the whole database if you want.&lt;/p&gt;&amp;mdash; Pasi Kallinen (@paxed) &lt;a href=&#34;https://twitter.com/paxed/status/1059333642592366593?ref_src=twsrc%5Etfw&#34;&gt;November 5, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;ul&gt;
&lt;li&gt;He gave me access to ALL THE DATA on alt.org/nethack!&lt;/li&gt;
&lt;li&gt;The admins of &lt;a href=&#34;https://alt.org/nethack/&#34;&gt;alt.org/nethack&lt;/a&gt; will release all the data to the public!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, I will now continue with the blog post I wanted to do in the first place; focusing now on what
roles players choose to play the most, and also which monsters they kill the most. BUT! Since all the data
will be released to the public, my &lt;code&gt;{nethack}&lt;/code&gt; package that contains data that I scraped is not
that useful anymore. So I changed the nature of the package.
Now the package contains some functions: a function to parse and prepare the xlogfiles from NetHack that
you can download from &lt;a href=&#34;https://alt.org/nethack/&#34;&gt;alt.org/nethack&lt;/a&gt; (or from any other public server), a function
to download dumplogs such as this &lt;a href=&#34;http://archive.is/7awsb&#34;&gt;one&lt;/a&gt;. These dumplogs contain a lot of
info that I will extract in this blog post, using another function included in the &lt;code&gt;{nethack}&lt;/code&gt; package.
The package also contains a sample of 6000 runs from NetHack version 3.6.1.&lt;/p&gt;
&lt;p&gt;You can install the package with the following command line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/nethack&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-nethack-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The &lt;code&gt;{nethack}&lt;/code&gt; package&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis/&#34;&gt;part 1&lt;/a&gt; I showed what killed
players the most. Here, I will focus on what monsters players kill the most.
Let’s start by loading some packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(magrittr)
library(ggridges)
library(brotools)
library(rvest)
library(nethack)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s first describe the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brotools::describe(nethack) %&amp;gt;% 
  print(n = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 23 x 17
##    variable type    nobs     mean       sd mode       min     max      q05
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 deathdn… Nume… 6.00e3  8.45e-1  1.30e+0 2       0.      7.00e0   0.    
##  2 deathlev Nume… 6.00e3  4.32e+0  3.69e+0 10     -5.00e0  4.50e1   1.00e0
##  3 deaths   Nume… 6.00e3  8.88e-1  3.54e-1 1       0.      5.00e0   0.    
##  4 endtime  Nume… 6.00e3  1.53e+9  4.72e+6 1534…   1.52e9  1.54e9   1.53e9
##  5 hp       Nume… 6.00e3  6.64e+0  4.96e+1 -1     -9.40e1  1.79e3  -8.00e0
##  6 maxhp    Nume… 6.00e3  3.82e+1  5.29e+1 57      2.00e0  1.80e3   1.10e1
##  7 maxlvl   Nume… 6.00e3  5.52e+0  6.36e+0 10      1.00e0  5.30e1   1.00e0
##  8 points   Nume… 6.00e3  4.69e+4  4.18e+5 10523   0.      9.92e6   1.40e1
##  9 realtime Nume… 6.00e3  4.42e+3  1.60e+4 4575    0.      3.23e5   6.90e1
## 10 startti… Nume… 6.00e3  1.53e+9  4.72e+6 1534…   1.52e9  1.54e9   1.53e9
## 11 turns    Nume… 6.00e3  3.60e+3  9.12e+3 6797    3.10e1  1.97e5   9.49e1
## 12 align    Char… 6.00e3 NA       NA       Cha    NA      NA       NA     
## 13 align0   Char… 6.00e3 NA       NA       Cha    NA      NA       NA     
## 14 death    Char… 6.00e3 NA       NA       kill…  NA      NA       NA     
## 15 gender   Char… 6.00e3 NA       NA       Fem    NA      NA       NA     
## 16 gender0  Char… 6.00e3 NA       NA       Fem    NA      NA       NA     
## 17 killed_… Char… 6.00e3 NA       NA       fain…  NA      NA       NA     
## 18 name     Char… 6.00e3 NA       NA       drud…  NA      NA       NA     
## 19 race     Char… 6.00e3 NA       NA       Elf    NA      NA       NA     
## 20 role     Char… 6.00e3 NA       NA       Wiz    NA      NA       NA     
## 21 dumplog  List  1.33e6 NA       NA       &amp;lt;NA&amp;gt;   NA      NA       NA     
## 22 birthda… Date  6.00e3 NA       NA       &amp;lt;NA&amp;gt;   NA      NA       NA     
## 23 deathda… Date  6.00e3 NA       NA       &amp;lt;NA&amp;gt;   NA      NA       NA     
## # ... with 8 more variables: q25 &amp;lt;dbl&amp;gt;, median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;,
## #   q95 &amp;lt;dbl&amp;gt;, n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;, starting_date &amp;lt;date&amp;gt;,
## #   ending_date &amp;lt;date&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All these columns are included in xlogfiles. The data was prepared using two functions, included
in &lt;code&gt;{nethack}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xlog &amp;lt;- read_delim(&amp;quot;~/path/to/nethack361_xlog.csv&amp;quot;, &amp;quot;\t&amp;quot;, escape_double = FALSE, 
                   col_names = FALSE, trim_ws = TRUE)

xlog_df &amp;lt;- clean_xlog(xlog)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;nethack361_xlog.csv&lt;/code&gt; is the raw xlogfiles that you can get from NetHack public servers.
&lt;code&gt;clean_xlog()&lt;/code&gt; is a function that parses an xlogfile and returns a clean data frame.
&lt;code&gt;xlog_df&lt;/code&gt; will be a data frame that will look just as the one included in &lt;code&gt;{nethack}&lt;/code&gt;. It is
then possible to get the dumplog from each run included in &lt;code&gt;xlog_df&lt;/code&gt; using &lt;code&gt;get_dumplog()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xlog_df &amp;lt;- get_dumplog(xlog_df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function adds a column called &lt;code&gt;dumplog&lt;/code&gt; with the dumplog of that run. I will now analyze
the dumplog file, by focusing on monsters vanquished, genocided or extinct. In a future blogpost
I will focus on other achievements.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;roles-played-and-other-starting-stats&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Roles played (and other starting stats)&lt;/h2&gt;
&lt;p&gt;I will take a look at the races, roles, gender and alignment players start with the most. I will do
pie charts to visualize these variable, so first, let’s start by writing a general function that
allows me to do just that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pie &amp;lt;- function(dataset, variable, repel = FALSE){

  if(repel){
    geom_label &amp;lt;- function(...){
      ggrepel::geom_label_repel(...)
    }
  }

  variable &amp;lt;- enquo(variable)

  dataset %&amp;gt;%
    count((!!variable)) %&amp;gt;%
    mutate(total = sum(n),
           freq = n/total,
           labels = scales::percent(freq)) %&amp;gt;% 
    arrange(desc(freq)) %&amp;gt;%
    ggplot(aes(x = &amp;quot;&amp;quot;, y = freq, fill = (!!variable))) + 
    geom_col() + 
    geom_label(aes(label = labels), position = position_stack(vjust = 0.25), show.legend = FALSE) + 
    coord_polar(&amp;quot;y&amp;quot;) + 
    theme_blog() + 
    scale_fill_blog() + 
    theme(legend.title = element_blank(),
          panel.grid = element_blank(),
          axis.text = element_blank(),
          axis.title = element_blank())
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can easily plot the share of races chosen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pie(nethack, race)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;or the share of alignment:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pie(nethack, align0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Same for the share of gender:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pie(nethack, gender0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and finally for the share of roles:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pie(nethack, role, repel = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;create_pie()&lt;/code&gt; is possible thanks to &lt;em&gt;tidy evaluation&lt;/em&gt; in &lt;a href=&#34;https://www.tidyverse.org/articles/2018/07/ggplot2-3-0-0/&#34;&gt;&lt;code&gt;{ggplot2}&lt;/code&gt;&lt;/a&gt;,
which makes it possible to write a function that passes data frame columns down to &lt;code&gt;aes()&lt;/code&gt;. Before
version 3.0 of &lt;code&gt;{ggplot2}&lt;/code&gt; this was not possible, and writing such a function would have been a bit
more complicated. Now, it’s as easy as pie, if I dare say.&lt;/p&gt;
&lt;p&gt;Something else I want to look at, is the distribution of turns by role:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(turns &amp;lt; quantile(turns, 0.98)) %&amp;gt;%
  ggplot(aes(x = turns, y = role, group = role, fill = role)) +
    geom_density_ridges(scale = 6, size = 0.25, rel_min_height = 0.01) + 
    theme_blog() + 
    scale_fill_blog() + 
    theme(axis.text.y = element_blank(),
          axis.title.y = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 486&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I use the very cool &lt;code&gt;{ggridges}&lt;/code&gt; package for that. The distribution seems to mostly be the same
(of course, one should do a statistical test to be sure), but the one for the role “Valkyrie”
seems to be quite different from the others. It is known that it is easier to win the game playing
as a Valkyrie, but a question remains: is it really easier as a Valkyrie, or do good players tend
to play as Valkyries more often?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creatures-vanquished-genocided-or-extinct&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creatures vanquished, genocided or extinct&lt;/h2&gt;
&lt;p&gt;The dumplog lists which, and how many of which, creatures were vanquished during the run, as well
as creatures that were genocided and extinct. The player can genocide an entire species by reading
a &lt;em&gt;scroll of genocide&lt;/em&gt; (or by sitting on a throne). A species gets extinct if the player manages to
kill every monster from that species (there’s other ways too, but for the sake of simplicity, let’s
just say that when the players kills every monster from a species, the species is extinct).
The following lines are an extract of a dumplog:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;Vanquished creatures:&amp;quot;
&amp;quot;    Baalzebub&amp;quot;
&amp;quot;    Orcus&amp;quot;
&amp;quot;    Juiblex&amp;quot;
&amp;quot;the Wizard of Yendor (4 times)&amp;quot;
&amp;quot;    Pestilence (thrice)&amp;quot;
&amp;quot;    Famine&amp;quot;
&amp;quot;    Vlad the Impaler&amp;quot;
&amp;quot;  4 arch-liches&amp;quot;
&amp;quot;  an arch-lich&amp;quot;
&amp;quot;  a high priest&amp;quot;
&amp;quot;...&amp;quot;
&amp;quot;...&amp;quot;
&amp;quot;...&amp;quot;
&amp;quot;2873 creatures vanquished.&amp;quot; &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I want to analyze this, I have to first solve some problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replace “a” and “an” by “1”&lt;/li&gt;
&lt;li&gt;Put the digit in the string “(4 times)” in front of the name of the monster (going from “the Wizard of Yendor (4 times)” to “4 the Wizard of Yendor”)&lt;/li&gt;
&lt;li&gt;Do something similar for “twice” and “thrice”&lt;/li&gt;
&lt;li&gt;Put everything into singular (for example, arch-liches into arch-lich)&lt;/li&gt;
&lt;li&gt;Trim whitespace&lt;/li&gt;
&lt;li&gt;Extract the genocided or extinct status from the dumplog too&lt;/li&gt;
&lt;li&gt;Finally, return a data frame with all the needed info&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wrote a function called &lt;code&gt;extracted_defeated_monsters()&lt;/code&gt; and included it in the &lt;code&gt;{nethack}&lt;/code&gt; package.
I discuss this function in appendix, but what it does is extracting information from dumplog files
about vanquished, genocided or extinct monsters and returns a tidy dataframe with that info. This
function has a lot of things going on inside it, so if you’re interested in learning more about
regular expression and other &lt;code&gt;{tidyverse}&lt;/code&gt; tricks, I really encourage you to read its source code.&lt;/p&gt;
&lt;p&gt;I can now easily add this info to my data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;lt;&amp;gt;%
  mutate(monsters_destroyed = map(dumplog, ~possibly(extract_defeated_monsters, otherwise = NA)(.)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at one of them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack$monsters_destroyed[[117]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 285 x 3
##    value monster              status
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt; 
##  1     1 baalzebub            &amp;lt;NA&amp;gt;  
##  2     1 orcu                 &amp;lt;NA&amp;gt;  
##  3     1 juiblex              &amp;lt;NA&amp;gt;  
##  4     4 the wizard of yendor &amp;lt;NA&amp;gt;  
##  5     3 pestilence           &amp;lt;NA&amp;gt;  
##  6     1 famine               &amp;lt;NA&amp;gt;  
##  7     1 vlad the impaler     &amp;lt;NA&amp;gt;  
##  8     4 arch-lich            &amp;lt;NA&amp;gt;  
##  9     1 high priest          &amp;lt;NA&amp;gt;  
## 10     1 medusa               &amp;lt;NA&amp;gt;  
## # ... with 275 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack$monsters_destroyed[[117]] %&amp;gt;% 
  count(status)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   status        n
##   &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt;
## 1 extinct       2
## 2 genocided     7
## 3 &amp;lt;NA&amp;gt;        276&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The status variable tells us if that monster was genocided or extinct during that run. &lt;code&gt;status&lt;/code&gt;
equal to “NA” means vanquished.&lt;/p&gt;
&lt;p&gt;It is now possible to look at, say, the top 15 vanquished monsters (normalized):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(!is.na(monsters_destroyed)) %&amp;gt;%
  pull(monsters_destroyed) %&amp;gt;%
  bind_rows %&amp;gt;%
  group_by(monster) %&amp;gt;%
  summarise(total = sum(value)) %&amp;gt;%
  top_n(15) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(norm_total = (total - min(total))/(max(total) - min(total))) %&amp;gt;%
  mutate(monster = fct_reorder(monster, norm_total, .desc = FALSE)) %&amp;gt;%
  ggplot() + 
  geom_col(aes(y = norm_total, x = monster)) + 
  coord_flip() + 
  theme_blog() + 
  scale_fill_blog() + 
  ylab(&amp;quot;Ranking&amp;quot;) +
  xlab(&amp;quot;Monster&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by total&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this type of graph, the most vanquished monster, “gnome” has a value of 1, and the least
vanquished one, 0. This normalization step is also used in the pre-processing step of machine learning
algorithms. This helps convergence of the gradient descent algorithm for instance.&lt;/p&gt;
&lt;p&gt;Monsters can also get genocided or extinct. Let’s make a pie chart of the proportion of genocided
and extinct monsters (I lump monsters that are genocided or extinct less than 5% of the times
into a category called other). Because I want two pie charts, I nest the data after having grouped
it by the status variable. This is a trick I discussed in this blog &lt;a href=&#34;https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/&#34;&gt;post&lt;/a&gt;
and that I use very often:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(!is.na(monsters_destroyed)) %&amp;gt;%
  pull(monsters_destroyed) %&amp;gt;%
  bind_rows %&amp;gt;%
  filter(!is.na(status)) %&amp;gt;%
  group_by(status) %&amp;gt;% 
  count(monster) %&amp;gt;% 
  mutate(monster = fct_lump(monster, prop = 0.05, w = n)) %&amp;gt;% 
  group_by(status, monster) %&amp;gt;% 
  summarise(total_count = sum(n)) %&amp;gt;%
  mutate(freq = total_count/sum(total_count),
         labels = scales::percent(freq)) %&amp;gt;%
  arrange(desc(freq)) %&amp;gt;%
  group_by(status) %&amp;gt;%
  nest() %&amp;gt;%
  mutate(pie_chart = map2(.x = status,
                          .y = data,
                          ~ggplot(data = .y,
                                  aes(x = &amp;quot;&amp;quot;, y = freq, fill = (monster))) + 
    geom_col() + 
    ggrepel::geom_label_repel(aes(label = labels), position = position_stack(vjust = 0.25), show.legend = FALSE) + 
    coord_polar(&amp;quot;y&amp;quot;) + 
    theme_blog() + 
    scale_fill_blog() + 
      ggtitle(.x) +
    theme(legend.title = element_blank(),
          panel.grid = element_blank(),
          axis.text = element_blank(),
          axis.title = element_blank())
  )) %&amp;gt;%
  pull(pie_chart)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in mutate_impl(.data, dots): Unequal factor levels: coercing to
## character&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in mutate_impl(.data, dots): binding character and factor vector,
## coercing into character vector

## Warning in mutate_impl(.data, dots): binding character and factor vector,
## coercing into character vector&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-17-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That was it for this one, the graphs are not that super sexy, but the amount of work that went
into making them was quite consequent. The main reason was that parsing xlogfiles was a bit tricky, but
the main challenge was extracting information from dumplog files. This proved to be a bit more
complicated than expected (just take a look at the source code of &lt;code&gt;extract_defeated_monsters()&lt;/code&gt;
to get an idea…).&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus plot&lt;/h2&gt;
&lt;div id=&#34;correct-number-of-daily-games&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correct number of daily games&lt;/h3&gt;
&lt;p&gt;The daily number of games are available &lt;a href=&#34;https://alt.org/nethack/dailygames_ct.html&#34;&gt;here&lt;/a&gt;. Let’s
extract this info and remake the plot that shows the number of runs per day:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;games &amp;lt;- read_html(&amp;quot;https://alt.org/nethack/dailygames_ct.html&amp;quot;) %&amp;gt;%
        html_nodes(xpath = &amp;#39;//table&amp;#39;) %&amp;gt;%
        html_table(fill = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This extracts all the tables and puts them into a list. Let’s take a look at one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(games[[1]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   2018  2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018
## 1         NA    1    2    3    4    5    6    7    8    9   10   11   12
## 2  Jan 11639  275  370  394  363  392  276  288  324  297  411  413  430
## 3  Feb 10819  375  384  359  376  440  345  498  457  416  376  421  416
## 4  Mar 12148  411  403  421  392  447  391  451  298  350  309  309  369
## 5  Apr 13957  456  513  482  516  475  490  397  431  436  438  541  493
## 6  May 13361  595  509  576  620  420  443  407  539  440  446  404  282
##   2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018
## 1   13   14   15   16   17   18   19   20   21   22   23   24   25   26
## 2  331  341  318  483  408  424  464  412  371  430  348  315  359  375
## 3  385  367  443  324  283  341  385  398  361  379  399  276  455  460
## 4  390  358  362  345  388  360  411  382  371  400  410  417  328  431
## 5  593  537  396  578  403  435  526  448  339  377  476  492  528  393
## 6  265  358  419  564  483  429  423  299  424  404  450  408  355  409
##   2018 2018 2018 2018 2018
## 1   27   28   29   30   31
## 2  432  371  385  440  399
## 3  353  347   NA   NA   NA
## 4  386  484  493  486  395
## 5  407  421  463  477   NA
## 6  417  433  360  391  389&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s clean this up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_table &amp;lt;- function(df){
  # Promotes first row to header
  colnames(df) &amp;lt;- df[1, ]
  df &amp;lt;- df[-1, ]
  
  # Remove column with total from the month
  df &amp;lt;- df[, -2]
  
  # Name the first column &amp;quot;month&amp;quot;
  
  colnames(df)[1] &amp;lt;- &amp;quot;month&amp;quot;
  
  # Now put it in a tidy format
  df %&amp;gt;%
    gather(day, games_played, -month)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can clean up all the tables. I apply this function to each element of the list &lt;code&gt;games&lt;/code&gt;. I
also add a year column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;games &amp;lt;- map(games, clean_table) %&amp;gt;%
  map2_dfr(.x = ., 
       .y = seq(2018, 2001),
       ~mutate(.x, year = .y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can easily create the plot I wanted&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;games %&amp;lt;&amp;gt;%
  mutate(date = lubridate::ymd(paste(year, month, day, sep = &amp;quot;-&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: 122 failed to parse.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(games, aes(y = games_played, x = date)) + 
  geom_point(colour = &amp;quot;#0f4150&amp;quot;) + 
  geom_smooth(colour = &amp;quot;#82518c&amp;quot;) + 
  theme_blog() + 
  ylab(&amp;quot;Total games played&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 452 rows containing non-finite values (stat_smooth).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 452 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-10-nethack_analysis_part2_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There’s actually a lot more games than 50 per day being played!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;div id=&#34;fuzzy-matching&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fuzzy matching&lt;/h3&gt;
&lt;p&gt;If you take a look at the &lt;code&gt;extract_defeated_monsters()&lt;/code&gt; source code, you’ll see that at some point
I “singularize” monster names. I decided to deal with this singular/plural issue, “by hand”,
but also explored other possibilities, such as matching the plural nouns with the singular
nouns fuzzily. In the end it didn’t work out so well, but here’s the code for future reference.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;monster_list &amp;lt;- read_html(&amp;quot;https://nethackwiki.com/wiki/Monsters_(by_difficulty)&amp;quot;) %&amp;gt;%
    html_nodes(&amp;quot;.prettytable&amp;quot;) %&amp;gt;% 
    .[[1]] %&amp;gt;%
    html_table(fill = TRUE)

monster_list %&amp;lt;&amp;gt;%
    select(monster = Name)

head(monster_list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      monster
## 1 Demogorgon
## 2   Asmodeus
## 3  Baalzebub
## 4   Dispater
## 5     Geryon
## 6      Orcus&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fuzzyjoin)

test_vanquished &amp;lt;- extract_defeated_monsters(nethack$dumplog[[117]])

head(test_vanquished)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   value monster              status
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt; 
## 1     1 baalzebub            &amp;lt;NA&amp;gt;  
## 2     1 orcu                 &amp;lt;NA&amp;gt;  
## 3     1 juiblex              &amp;lt;NA&amp;gt;  
## 4     4 the wizard of yendor &amp;lt;NA&amp;gt;  
## 5     3 pestilence           &amp;lt;NA&amp;gt;  
## 6     1 famine               &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can take a look at the result by expanding:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to expand&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stringdist_left_join(test_vanquished, monster_list) %&amp;gt;% 
  count(monster.y) %&amp;gt;%
  print(n = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining by: &amp;quot;monster&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 297 x 2
##     monster.y                   n
##     &amp;lt;chr&amp;gt;                   &amp;lt;int&amp;gt;
##   1 acid blob                   1
##   2 air elemental               2
##   3 Aleax                       1
##   4 aligned priest              1
##   5 Angel                       1
##   6 ape                         2
##   7 arch-lich                   1
##   8 Baalzebub                   1
##   9 baby black dragon           1
##  10 baby crocodile              1
##  11 baby gray dragon            1
##  12 baby green dragon           1
##  13 baby long worm              1
##  14 baby orange dragon          1
##  15 baby white dragon           1
##  16 baby yellow dragon          1
##  17 balrog                      1
##  18 baluchitherium              1
##  19 barbed devil                1
##  20 barrow wight                1
##  21 bat                         1
##  22 black dragon                1
##  23 black light                 1
##  24 black naga                  1
##  25 black pudding               1
##  26 black unicorn               1
##  27 blue dragon                 1
##  28 blue jelly                  1
##  29 bone devil                  1
##  30 brown mold                  1
##  31 brown pudding               1
##  32 bugbear                     1
##  33 captain                     1
##  34 carnivorous ape             1
##  35 cave spider                 1
##  36 centipede                   1
##  37 chameleon                   1
##  38 chickatrice                 2
##  39 clay golem                  1
##  40 cobra                       1
##  41 cockatrice                  2
##  42 couatl                      1
##  43 coyote                      1
##  44 crocodile                   1
##  45 demilich                    1
##  46 dingo                       1
##  47 disenchanter                1
##  48 dog                         1
##  49 doppelganger                1
##  50 dust vortex                 1
##  51 dwarf                       2
##  52 dwarf king                  1
##  53 dwarf lord                  1
##  54 dwarf mummy                 1
##  55 dwarf zombie                1
##  56 earth elemental             1
##  57 electric eel                1
##  58 elf                         1
##  59 elf mummy                   1
##  60 elf zombie                  1
##  61 elf-lord                    1
##  62 Elvenking                   1
##  63 energy vortex               1
##  64 erinys                      1
##  65 ettin                       1
##  66 ettin mummy                 1
##  67 ettin zombie                1
##  68 Famine                      1
##  69 fire ant                    2
##  70 fire elemental              2
##  71 fire giant                  2
##  72 fire vortex                 2
##  73 flaming sphere              1
##  74 flesh golem                 1
##  75 floating eye                1
##  76 fog cloud                   1
##  77 forest centaur              1
##  78 fox                         1
##  79 freezing sphere             1
##  80 frost giant                 1
##  81 gargoyle                    1
##  82 garter snake                1
##  83 gas spore                   1
##  84 gecko                       1
##  85 gelatinous cube             1
##  86 ghost                       2
##  87 ghoul                       2
##  88 giant ant                   3
##  89 giant bat                   3
##  90 giant beetle                1
##  91 giant eel                   1
##  92 giant mimic                 1
##  93 giant mummy                 1
##  94 giant rat                   3
##  95 giant spider                1
##  96 giant zombie                1
##  97 glass piercer               1
##  98 gnome                       1
##  99 gnome king                  1
## 100 gnome lord                  1
## 101 gnome mummy                 1
## 102 gnome zombie                1
## 103 gnomish wizard              1
## 104 goblin                      1
## 105 gold golem                  2
## 106 golden naga                 1
## 107 golden naga hatchling       1
## 108 gray ooze                   1
## 109 gray unicorn                1
## 110 Green-elf                   1
## 111 gremlin                     1
## 112 Grey-elf                    1
## 113 grid bug                    1
## 114 guardian naga               1
## 115 guardian naga hatchling     1
## 116 hell hound                  1
## 117 hell hound pup              1
## 118 hezrou                      1
## 119 high priest                 1
## 120 hill giant                  1
## 121 hill orc                    1
## 122 hobbit                      1
## 123 hobgoblin                   1
## 124 homunculus                  1
## 125 horned devil                1
## 126 horse                       2
## 127 housecat                    1
## 128 human                       1
## 129 human mummy                 1
## 130 human zombie                1
## 131 ice devil                   1
## 132 ice troll                   1
## 133 ice vortex                  2
## 134 iguana                      1
## 135 imp                         1
## 136 incubus                     1
## 137 iron golem                  1
## 138 iron piercer                1
## 139 jabberwock                  1
## 140 jackal                      1
## 141 jaguar                      1
## 142 jellyfish                   1
## 143 Juiblex                     1
## 144 Keystone Kop                1
## 145 ki-rin                      1
## 146 killer bee                  1
## 147 kitten                      1
## 148 kobold                      1
## 149 kobold lord                 1
## 150 kobold mummy                1
## 151 kobold shaman               1
## 152 kobold zombie               1
## 153 Kop Lieutenant              1
## 154 Kop Sergeant                1
## 155 kraken                      2
## 156 large cat                   1
## 157 large dog                   1
## 158 large kobold                1
## 159 large mimic                 1
## 160 leather golem               1
## 161 leocrotta                   1
## 162 leprechaun                  1
## 163 lich                        2
## 164 lichen                      2
## 165 lieutenant                  1
## 166 little dog                  1
## 167 lizard                      1
## 168 long worm                   1
## 169 Lord Surtur                 1
## 170 lurker above                1
## 171 lynx                        1
## 172 manes                       1
## 173 marilith                    1
## 174 master lich                 1
## 175 master mind flayer          1
## 176 Medusa                      1
## 177 mind flayer                 1
## 178 minotaur                    1
## 179 monk                        2
## 180 monkey                      1
## 181 Mordor orc                  1
## 182 mountain centaur            1
## 183 mountain nymph              1
## 184 mumak                       1
## 185 nalfeshnee                  1
## 186 Nazgul                      1
## 187 newt                        1
## 188 Norn                        1
## 189 nurse                       2
## 190 ochre jelly                 1
## 191 ogre                        1
## 192 ogre king                   1
## 193 ogre lord                   1
## 194 Olog-hai                    1
## 195 orange dragon               1
## 196 orc                         3
## 197 orc mummy                   1
## 198 orc shaman                  1
## 199 orc zombie                  1
## 200 orc-captain                 1
## 201 Orcus                       1
## 202 owlbear                     1
## 203 page                        2
## 204 panther                     1
## 205 paper golem                 1
## 206 Pestilence                  1
## 207 piranha                     1
## 208 pit fiend                   1
## 209 pit viper                   1
## 210 plains centaur              1
## 211 pony                        1
## 212 purple worm                 1
## 213 pyrolisk                    1
## 214 python                      1
## 215 quantum mechanic            1
## 216 quasit                      1
## 217 queen bee                   1
## 218 quivering blob              1
## 219 rabid rat                   1
## 220 ranger                      1
## 221 raven                       2
## 222 red dragon                  1
## 223 red mold                    1
## 224 red naga                    1
## 225 rock mole                   1
## 226 rock piercer                1
## 227 rock troll                  1
## 228 rogue                       2
## 229 rope golem                  1
## 230 roshi                       1
## 231 rothe                       1
## 232 rust monster                1
## 233 salamander                  1
## 234 sandestin                   1
## 235 sasquatch                   1
## 236 scorpion                    1
## 237 sergeant                    1
## 238 sewer rat                   1
## 239 shade                       3
## 240 shark                       2
## 241 shocking sphere             1
## 242 shrieker                    1
## 243 silver dragon               1
## 244 skeleton                    1
## 245 small mimic                 1
## 246 snake                       2
## 247 soldier                     1
## 248 soldier ant                 1
## 249 spotted jelly               1
## 250 stalker                     1
## 251 steam vortex                1
## 252 stone giant                 2
## 253 stone golem                 1
## 254 storm giant                 2
## 255 straw golem                 1
## 256 succubus                    1
## 257 tengu                       1
## 258 tiger                       1
## 259 titanothere                 1
## 260 trapper                     1
## 261 troll                       1
## 262 umber hulk                  1
## 263 Uruk-hai                    1
## 264 vampire                     1
## 265 vampire bat                 1
## 266 vampire lord                1
## 267 violet fungus               1
## 268 Vlad the Impaler            1
## 269 vrock                       1
## 270 warg                        2
## 271 warhorse                    1
## 272 water elemental             1
## 273 water moccasin              1
## 274 water nymph                 1
## 275 werejackal                  2
## 276 wererat                     2
## 277 werewolf                    2
## 278 white dragon                1
## 279 white unicorn               1
## 280 winged gargoyle             1
## 281 winter wolf                 1
## 282 winter wolf cub             1
## 283 wizard                      1
## 284 wolf                        1
## 285 wood golem                  2
## 286 wood nymph                  1
## 287 Woodland-elf                1
## 288 wraith                      1
## 289 wumpus                      1
## 290 xan                         3
## 291 xorn                        2
## 292 yellow dragon               1
## 293 yellow light                1
## 294 yellow mold                 1
## 295 yeti                        1
## 296 zruty                       1
## 297 &amp;lt;NA&amp;gt;                        1&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;As you can see, some matches fail, especially for words that end in “y” in the singular, so “ies”
in plural, or “fire vortices” that does not get matched to “fire vortex”. I tried all the methods
but it’s either worse, or marginally better.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;extracting-info-from-dumplogfiles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Extracting info from dumplogfiles&lt;/h3&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click here to take a look at the source code from extract_defeated_monsters&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; Extract information about defeated monsters from an xlogfile
#&amp;#39; @param xlog A raw xlogfile
#&amp;#39; @return A data frame with information on vanquished, genocided and extincted monsters
#&amp;#39; @importFrom dplyr mutate select filter bind_rows full_join
#&amp;#39; @importFrom tidyr separate
#&amp;#39; @importFrom tibble as_tibble tibble
#&amp;#39; @importFrom magrittr &amp;quot;%&amp;gt;%&amp;quot;
#&amp;#39; @importFrom purrr map2 possibly is_empty modify_if simplify discard
#&amp;#39; @importFrom readr read_lines
#&amp;#39; @importFrom stringr str_which str_replace_all str_replace str_trim str_detect str_to_lower str_extract_all str_extract
#&amp;#39; @export
#&amp;#39; @examples
#&amp;#39; \dontrun{
#&amp;#39; get_dumplog(xlog)
#&amp;#39; }
extract_defeated_monsters &amp;lt;- function(dumplog){

    if(any(str_detect(dumplog, &amp;quot;No creatures were vanquished.&amp;quot;))){
        return(NA)
    } else {

        start &amp;lt;- dumplog %&amp;gt;% # &amp;lt;- dectect the start of the list
            str_which(&amp;quot;Vanquished creatures&amp;quot;)

        end &amp;lt;- dumplog %&amp;gt;% # &amp;lt;- detect the end of the list
            str_which(&amp;quot;\\d+ creatures vanquished.&amp;quot;)

        if(is_empty(end)){ # This deals with the situation of only one vanquished creature
            end &amp;lt;- start + 2
        }

        list_creatures &amp;lt;- dumplog[(start + 1):(end - 1)] %&amp;gt;% # &amp;lt;- extract the list
            str_replace_all(&amp;quot;\\s+an? &amp;quot;, &amp;quot;1 &amp;quot;) %&amp;gt;% # &amp;lt;- replace a or an by 1
            str_trim() # &amp;lt;- trim white space

        # The following function first extracts the digit in the string (123 times)
        # and replaces the 1 with this digit
        # This means that: &amp;quot;1 the Wizard of Yendor (4 times)&amp;quot; becomes &amp;quot;4 the Wizard of Yendor (4 times)&amp;quot;
        str_extract_replace &amp;lt;- function(string){
            times &amp;lt;- str_extract(string, &amp;quot;\\d+(?=\\stimes)&amp;quot;)
            str_replace(string, &amp;quot;1&amp;quot;, times)
        }

        result &amp;lt;- list_creatures %&amp;gt;%
            # If a string starts with a letter, add a 1
            # This means that: &amp;quot;Baalzebub&amp;quot; becomes &amp;quot;1 Baalzebub&amp;quot;
            modify_if(str_detect(., &amp;quot;^[:alpha:]&amp;quot;), ~paste(&amp;quot;1&amp;quot;, .)) %&amp;gt;%
            # If the string &amp;quot;(twice)&amp;quot; is detected, replace &amp;quot;1&amp;quot; (that was added the line before) with &amp;quot;2&amp;quot;
            modify_if(str_detect(., &amp;quot;(twice)&amp;quot;), ~str_replace(., &amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;)) %&amp;gt;%
            # Same for &amp;quot;(thrice)&amp;quot;
            modify_if(str_detect(., &amp;quot;(thrice)&amp;quot;), ~str_replace(., &amp;quot;1&amp;quot;, &amp;quot;3&amp;quot;)) %&amp;gt;%
            # Exctract the digit in &amp;quot;digit times&amp;quot; and replace the &amp;quot;1&amp;quot; with digit
            modify_if(str_detect(., &amp;quot;(\\d+ times)&amp;quot;), str_extract_replace) %&amp;gt;%
            # Replace &amp;quot;(times)&amp;quot; or &amp;quot;(twice)&amp;quot; etc with &amp;quot;&amp;quot;
            str_replace_all(&amp;quot;\\(.*\\)&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
            str_trim() %&amp;gt;%
            simplify() %&amp;gt;%
            # Convert the resulting list to a tibble. This tibble has one column:
            # value
            # 1 Baalzebub
            # 2 dogs
            #...
            as_tibble() %&amp;gt;%
            # Use tidyr::separate to separate the &amp;quot;value&amp;quot; column into two columns. The extra pieces get merged
            # So for example &amp;quot;1 Vlad the Impaler&amp;quot; becomes &amp;quot;1&amp;quot; &amp;quot;Vlad the Impaler&amp;quot; instead of &amp;quot;1&amp;quot; &amp;quot;Vlad&amp;quot; which
            # would be the case without &amp;quot;extra = &amp;quot;merge&amp;quot;&amp;quot;
            separate(value, into = c(&amp;quot;value&amp;quot;, &amp;quot;monster&amp;quot;), extra = &amp;quot;merge&amp;quot;) %&amp;gt;%
            mutate(value = as.numeric(value)) %&amp;gt;%
            mutate(monster = str_to_lower(monster))

        # This function singularizes names:
        singularize_monsters &amp;lt;- function(nethack_data){
            nethack_data %&amp;gt;%
                mutate(monster = str_replace_all(monster, &amp;quot;mummies&amp;quot;, &amp;quot;mummy&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;jellies&amp;quot;, &amp;quot;jelly&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;vortices&amp;quot;, &amp;quot;vortex&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;elves&amp;quot;, &amp;quot;elf&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;wolves&amp;quot;, &amp;quot;wolf&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;dwarves&amp;quot;, &amp;quot;dwarf&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;liches&amp;quot;, &amp;quot;lich&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;baluchiteria&amp;quot;, &amp;quot;baluchiterium&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;homunculi&amp;quot;, &amp;quot;homonculus&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;mumakil&amp;quot;, &amp;quot;mumak&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;sasquatches&amp;quot;, &amp;quot;sasquatch&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;watchmen&amp;quot;, &amp;quot;watchman&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;zruties&amp;quot;, &amp;quot;zruty&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;xes$&amp;quot;, &amp;quot;x&amp;quot;),
                       monster = str_replace_all(monster, &amp;quot;s$&amp;quot;, &amp;quot;&amp;quot;))
        }

        result &amp;lt;- singularize_monsters(result)
    }
    # If a player did not genocide or extinct any species, return the result:
    if(any(str_detect(dumplog, &amp;quot;No species were genocided or became extinct.&amp;quot;))){
        result &amp;lt;- result %&amp;gt;%
            mutate(status = NA_character_)
        return(result)
    } else {

        # If the player genocided or extincted species, add this info:
        start &amp;lt;- dumplog %&amp;gt;% # &amp;lt;- dectect the start of the list
            str_which(&amp;quot;Genocided or extinct species:&amp;quot;) # &amp;lt;- sometimes this does not appear in the xlogfile

        end &amp;lt;- dumplog %&amp;gt;% # &amp;lt;- detect the end of the list
            str_which(&amp;quot;Voluntary challenges&amp;quot;)

       if(is_empty(start)){# This deals with the situation start does not exist
           start &amp;lt;- end - 2
       }

        list_creatures &amp;lt;- dumplog[(start + 1):(end - 1)] %&amp;gt;% # &amp;lt;- extract the list
            str_trim() # &amp;lt;- trim white space

        extinct_species &amp;lt;- list_creatures %&amp;gt;%
            str_extract_all(&amp;quot;[:alpha:]+\\s(?=\\(extinct\\))&amp;quot;, simplify = T) %&amp;gt;%
            str_trim %&amp;gt;%
            discard(`==`(., &amp;quot;&amp;quot;))

        extinct_species_df &amp;lt;- tibble(monster = extinct_species, status = &amp;quot;extinct&amp;quot;)

        genocided_species_index &amp;lt;- list_creatures %&amp;gt;%
            str_detect(pattern = &amp;quot;extinct|species&amp;quot;) %&amp;gt;%
            `!`

        genocided_species &amp;lt;- list_creatures[genocided_species_index]

        genocided_species_df &amp;lt;- tibble(monster = genocided_species, status = &amp;quot;genocided&amp;quot;)

        genocided_or_extinct_df &amp;lt;- singularize_monsters(bind_rows(extinct_species_df, genocided_species_df))

        result &amp;lt;- full_join(result, genocided_or_extinct_df, by = &amp;quot;monster&amp;quot;) %&amp;gt;%
            filter(monster != &amp;quot;&amp;quot;) # &amp;lt;- this is to remove lines that were added by mistake, for example if start was empty

        return(result)
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Analyzing NetHack data, part 1: What kills the players</title>
      <link>https://www.brodrigues.co/blog/2018-11-03-nethack_analysis/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-03-nethack_analysis/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=dpM2o4dRLto&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/deepfried_loss.png&#34; title = &#34;Click here to listen to epic music while reading&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In this post, I will analyse the data I scraped and put into an R package, which I called &lt;code&gt;{nethack}&lt;/code&gt;.
NetHack is a roguelike game; for more context, read my previous blog
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-01-nethack/&#34;&gt;post&lt;/a&gt;.
You can install the &lt;code&gt;{nethack}&lt;/code&gt; package and play around with the data yourself by installing it from github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/nethack&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to use it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nethack)
data(&amp;quot;nethack&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data contains information on games played from 2001 to 2018; 322485 rows and 14 columns. I
will analyze the data in a future blog post. This post focuses on getting and then sharing the
data. By the way, all the content from the public server I scrape is under the CC BY 4.0 license.&lt;/p&gt;
&lt;p&gt;I built the package by using the very useful &lt;code&gt;{devtools}&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;What I want from this first analysis are several, simple things: how many players manage to ascend
(meaning, winning), what monster kills most players, and finally extract data from the &lt;code&gt;dumplog&lt;/code&gt;
column. The &lt;code&gt;dumplog&lt;/code&gt; column is a bit special; each element of the dumplog column is a log file
that contains a lot of information from the last turns of a player. I will leave this for a future
blog post, though.&lt;/p&gt;
&lt;p&gt;Let’s load some packages first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nethack)
library(tidyverse)
library(lubridate)
library(magrittr)
library(brotools)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{brotools}&lt;/code&gt; is my own package that contains some functions that I use daily. If you want to
install it, run the following line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/brotools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The documentation is not up-to-date, I think I’ll do that and release it on CRAN. Some day.&lt;/p&gt;
&lt;p&gt;Now, let’s load the “nethack” data, included in the &lt;code&gt;{nethack}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   rank score     name time turns lev_max hp_max role race gender alignment
## 1    1   360      jkm &amp;lt;NA&amp;gt;    NA     2/2  -2/25  Sam  Hum    Mal       Law
## 2    2   172 yosemite &amp;lt;NA&amp;gt;    NA     1/1  -1/10  Tou  Hum    Fem       Neu
## 3    3  2092    dtype &amp;lt;NA&amp;gt;    NA     6/7  -2/47  Val  Hum    Fem       Neu
## 4    4    32   joorko &amp;lt;NA&amp;gt;    NA     1/1   0/15  Sam  Hum    Mal       Law
## 5    5   118    jorko &amp;lt;NA&amp;gt;    NA     1/1   0/11  Rog  Orc    Fem       Cha
## 6    6  1757   aaronl &amp;lt;NA&amp;gt;    NA     5/5   0/60  Bar  Hum    Mal       Neu
##                                                      death       date
## 1                                   killed by a brown mold 2001-10-24
## 2                                       killed by a jackal 2001-10-24
## 3                                     killed by a fire ant 2001-10-24
## 4                                       killed by a jackal 2001-10-24
## 5                                       killed by a jackal 2001-10-24
## 6 killed by a hallucinogen-distorted ghoul, while helpless 2001-10-24
##   dumplog
## 1      NA
## 2      NA
## 3      NA
## 4      NA
## 5      NA
## 6      NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;nethack&amp;quot;)

head(nethack)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s create some variables that might be helpful (or perhaps not, we’ll see):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;lt;&amp;gt;% 
  mutate(date = ymd(date),
         year = year(date),
         month = month(date),
         day = day(date))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes it easy to look at the data from, say, June 2017:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(year == 2017, month == 6) %&amp;gt;%
  brotools::describe()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 17 x 17
##    variable type   nobs    mean      sd mode    min     max   q05   q25
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 day      Nume…  1451    17.4  9.00e0 1         1      30     2   10 
##  2 month    Nume…  1451     6    0.     6         6       6     6    6 
##  3 rank     Nume…  1451    47.1  2.95e1 1         1     100     4   20 
##  4 score    Nume…  1451 38156.   3.39e5 488       0 5966425    94  402.
##  5 turns    Nume…  1451  4179.   1.23e4 812       1  291829   204  860.
##  6 year     Nume…  1451  2017    0.     2017   2017    2017  2017 2017 
##  7 alignme… Char…  1451    NA   NA      Law      NA      NA    NA   NA 
##  8 death    Char…  1451    NA   NA      kill…    NA      NA    NA   NA 
##  9 gender   Char…  1451    NA   NA      Mal      NA      NA    NA   NA 
## 10 hp_max   Char…  1451    NA   NA      -1/16    NA      NA    NA   NA 
## 11 lev_max  Char…  1451    NA   NA      4/4      NA      NA    NA   NA 
## 12 name     Char…  1451    NA   NA      ohno…    NA      NA    NA   NA 
## 13 race     Char…  1451    NA   NA      Hum      NA      NA    NA   NA 
## 14 role     Char…  1451    NA   NA      Kni      NA      NA    NA   NA 
## 15 time     Char…  1451    NA   NA      01:1…    NA      NA    NA   NA 
## 16 dumplog  List   1451    NA   NA      &amp;lt;NA&amp;gt;     NA      NA    NA   NA 
## 17 date     Date   1451    NA   NA      &amp;lt;NA&amp;gt;     NA      NA    NA   NA 
## # … with 7 more variables: median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;, q95 &amp;lt;dbl&amp;gt;,
## #   n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;, starting_date &amp;lt;date&amp;gt;,
## #   ending_date &amp;lt;date&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s also take a look at a dumplog:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to expand; the dumplog is quite long&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
    filter(year == 2018, month == 10) %&amp;gt;%
    slice(1) %&amp;gt;%
    pull(dumplog)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##   [1] &amp;quot;Unix NetHack Version 3.6.1 - last build Fri Apr 27 19:25:48 2018. (d4ebae12f1a709d1833cf466dd0c553fb97518d2)&amp;quot;
##   [2] &amp;quot;&amp;quot;                                                                                                            
##   [3] &amp;quot;Game began 2018-09-30 22:27:18, ended 2018-10-01 00:01:12.&amp;quot;                                                  
##   [4] &amp;quot;&amp;quot;                                                                                                            
##   [5] &amp;quot;brothertrebius, neutral female gnomish Ranger&amp;quot;                                                               
##   [6] &amp;quot;&amp;quot;                                                                                                            
##   [7] &amp;quot;                  -----&amp;quot;                                                                                     
##   [8] &amp;quot;   --------       |....#     -----      --------&amp;quot;                                                            
##   [9] &amp;quot;   |/..%.=|      #...^|######|...|    ##.......|&amp;quot;                                                            
##  [10] &amp;quot;   |/[%..%|      #|...|     #|...|    # |......|&amp;quot;                                                            
##  [11] &amp;quot;   |......|      #-----     #-...-######....&amp;lt;..|&amp;quot;                                                            
##  [12] &amp;quot;   -----|--      ###         -|-.-  #   |......|&amp;quot;                                                            
##  [13] &amp;quot;        ##         ##           #   #   ----f---&amp;quot;                                                            
##  [14] &amp;quot;         ####       #           #  ##       f@Y&amp;quot;                                                             
##  [15] &amp;quot;            #       #           #  #&amp;quot;                                                                        
##  [16] &amp;quot;       -----.-------#           #  #&amp;quot;                                                                        
##  [17] &amp;quot;       |........%..|#           #  #&amp;quot;                                                                        
##  [18] &amp;quot;       |............#           #  #&amp;quot;                                                                        
##  [19] &amp;quot;       |...........|          0##  #&amp;quot;                                                                        
##  [20] &amp;quot;       |...........|         -.--- #&amp;quot;                                                                        
##  [21] &amp;quot;       -------------         |^..|##&amp;quot;                                                                        
##  [22] &amp;quot;                             |...|#&amp;quot;                                                                         
##  [23] &amp;quot;                             |0&amp;gt;..#&amp;quot;                                                                         
##  [24] &amp;quot;                             -----&amp;quot;                                                                          
##  [25] &amp;quot;&amp;quot;                                                                                                            
##  [26] &amp;quot;Brothertre the Trailblazer   St:15 Dx:12 Co:16 In:13 Wi:15 Ch:6  Neutral&amp;quot;                                    
##  [27] &amp;quot;Dlvl:6  $:59 HP:0(54) Pw:40(40) AC:0  Exp:8 T:7398  Satiated Burdened&amp;quot;                                       
##  [28] &amp;quot;&amp;quot;                                                                                                            
##  [29] &amp;quot;Latest messages:&amp;quot;                                                                                            
##  [30] &amp;quot; In what direction? l&amp;quot;                                                                                       
##  [31] &amp;quot; You shoot 2 arrows.&amp;quot;                                                                                        
##  [32] &amp;quot; The 1st arrow hits the ape.&amp;quot;                                                                                
##  [33] &amp;quot; The 2nd arrow hits the ape!&amp;quot;                                                                                
##  [34] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [35] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [36] &amp;quot; The ape bites!&amp;quot;                                                                                             
##  [37] &amp;quot; You ready: q - 9 uncursed arrows.&amp;quot;                                                                          
##  [38] &amp;quot; In what direction? l&amp;quot;                                                                                       
##  [39] &amp;quot; The arrow hits the ape.&amp;quot;                                                                                    
##  [40] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [41] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [42] &amp;quot; The ape bites!&amp;quot;                                                                                             
##  [43] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [44] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [45] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [46] &amp;quot; In what direction? l&amp;quot;                                                                                       
##  [47] &amp;quot; You shoot 2 arrows.&amp;quot;                                                                                        
##  [48] &amp;quot; The 1st arrow hits the ape!&amp;quot;                                                                                
##  [49] &amp;quot; The 2nd arrow hits the ape.&amp;quot;                                                                                
##  [50] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [51] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [52] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [53] &amp;quot; In what direction? l&amp;quot;                                                                                       
##  [54] &amp;quot; You shoot 2 arrows.&amp;quot;                                                                                        
##  [55] &amp;quot; The 1st arrow misses the ape.&amp;quot;                                                                              
##  [56] &amp;quot; The 2nd arrow hits the ape.&amp;quot;                                                                                
##  [57] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [58] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [59] &amp;quot; The ape bites!&amp;quot;                                                                                             
##  [60] &amp;quot; In what direction? l&amp;quot;                                                                                       
##  [61] &amp;quot; The arrow hits the ape!&amp;quot;                                                                                    
##  [62] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [63] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [64] &amp;quot; The ape bites!&amp;quot;                                                                                             
##  [65] &amp;quot; You hear someone cursing shoplifters.&amp;quot;                                                                      
##  [66] &amp;quot; The ape misses!&amp;quot;                                                                                            
##  [67] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [68] &amp;quot; The ape bites!&amp;quot;                                                                                             
##  [69] &amp;quot; What do you want to write with? [- amnqsvBJM-OWZ or ?*] -&amp;quot;                                                  
##  [70] &amp;quot; You write in the dust with your fingertip.&amp;quot;                                                                 
##  [71] &amp;quot; What do you want to write in the dust here? Elbereth&amp;quot;                                                       
##  [72] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [73] &amp;quot; The ape hits!&amp;quot;                                                                                              
##  [74] &amp;quot; You die...&amp;quot;                                                                                                 
##  [75] &amp;quot; Do you want your possessions identified? [ynq] (y) y&amp;quot;                                                       
##  [76] &amp;quot; Do you want to see your attributes? [ynq] (y) n&amp;quot;                                                            
##  [77] &amp;quot; Do you want an account of creatures vanquished? [ynaq] (y) n&amp;quot;                                               
##  [78] &amp;quot; Do you want to see your conduct? [ynq] (y) n&amp;quot;                                                               
##  [79] &amp;quot; Do you want to see the dungeon overview? [ynq] (y) q&amp;quot;                                                       
##  [80] &amp;quot;&amp;quot;                                                                                                            
##  [81] &amp;quot;Inventory:&amp;quot;                                                                                                  
##  [82] &amp;quot; Coins&amp;quot;                                                                                                      
##  [83] &amp;quot;  $ - 59 gold pieces&amp;quot;                                                                                        
##  [84] &amp;quot; Weapons&amp;quot;                                                                                                    
##  [85] &amp;quot;  m - 17 blessed +1 arrows&amp;quot;                                                                                  
##  [86] &amp;quot;  n - a blessed +0 arrow&amp;quot;                                                                                    
##  [87] &amp;quot;  q - 3 +0 arrows (in quiver)&amp;quot;                                                                               
##  [88] &amp;quot;  s - a +0 bow (weapon in hand)&amp;quot;                                                                             
##  [89] &amp;quot;  B - 11 +1 darts&amp;quot;                                                                                           
##  [90] &amp;quot;  N - 11 +0 darts&amp;quot;                                                                                           
##  [91] &amp;quot;  a - a +1 dagger (alternate weapon; not wielded)&amp;quot;                                                           
##  [92] &amp;quot; Armor&amp;quot;                                                                                                      
##  [93] &amp;quot;  T - an uncursed +0 dwarvish iron helm (being worn)&amp;quot;                                                        
##  [94] &amp;quot;  z - an uncursed +0 pair of leather gloves (being worn)&amp;quot;                                                    
##  [95] &amp;quot;  U - a cursed -4 pair of iron shoes (being worn)&amp;quot;                                                           
##  [96] &amp;quot;  e - an uncursed +2 cloak of displacement (being worn)&amp;quot;                                                     
##  [97] &amp;quot;  h - a blessed +0 dwarvish mithril-coat (being worn)&amp;quot;                                                       
##  [98] &amp;quot; Comestibles&amp;quot;                                                                                                
##  [99] &amp;quot;  f - 3 uncursed cram rations&amp;quot;                                                                               
## [100] &amp;quot;  j - 2 uncursed food rations&amp;quot;                                                                               
## [101] &amp;quot;  L - an uncursed food ration&amp;quot;                                                                               
## [102] &amp;quot;  P - an uncursed lembas wafer&amp;quot;                                                                              
## [103] &amp;quot;  I - an uncursed lizard corpse&amp;quot;                                                                             
## [104] &amp;quot;  o - an uncursed tin of spinach&amp;quot;                                                                            
## [105] &amp;quot; Scrolls&amp;quot;                                                                                                    
## [106] &amp;quot;  G - 2 uncursed scrolls of blank paper&amp;quot;                                                                     
## [107] &amp;quot;  t - an uncursed scroll of confuse monster&amp;quot;                                                                 
## [108] &amp;quot;  V - an uncursed scroll of identify&amp;quot;                                                                        
## [109] &amp;quot; Potions&amp;quot;                                                                                                    
## [110] &amp;quot;  x - an uncursed potion of gain ability&amp;quot;                                                                    
## [111] &amp;quot;  H - a blessed potion of sleeping&amp;quot;                                                                          
## [112] &amp;quot;  g - 3 uncursed potions of water&amp;quot;                                                                           
## [113] &amp;quot; Rings&amp;quot;                                                                                                      
## [114] &amp;quot;  O - an uncursed ring of slow digestion (on left hand)&amp;quot;                                                     
## [115] &amp;quot;  v - an uncursed ring of stealth (on right hand)&amp;quot;                                                           
## [116] &amp;quot; Tools&amp;quot;                                                                                                      
## [117] &amp;quot;  p - an uncursed magic lamp&amp;quot;                                                                                
## [118] &amp;quot;  k - an uncursed magic whistle&amp;quot;                                                                             
## [119] &amp;quot;  Q - an uncursed mirror&amp;quot;                                                                                    
## [120] &amp;quot;  C - an uncursed saddle&amp;quot;                                                                                    
## [121] &amp;quot;  D - an uncursed stethoscope&amp;quot;                                                                               
## [122] &amp;quot;  y - a +0 unicorn horn&amp;quot;                                                                                     
## [123] &amp;quot;  i - 7 uncursed wax candles&amp;quot;                                                                                
## [124] &amp;quot; Gems/Stones&amp;quot;                                                                                                
## [125] &amp;quot;  W - an uncursed flint stone&amp;quot;                                                                               
## [126] &amp;quot;  M - an uncursed worthless piece of red glass&amp;quot;                                                              
## [127] &amp;quot;  Z - an uncursed worthless piece of violet glass&amp;quot;                                                           
## [128] &amp;quot;  J - an uncursed worthless piece of white glass&amp;quot;                                                            
## [129] &amp;quot;&amp;quot;                                                                                                            
## [130] &amp;quot;Brothertrebius the Ranger&amp;#39;s attributes:&amp;quot;                                                                     
## [131] &amp;quot;&amp;quot;                                                                                                            
## [132] &amp;quot;Background:&amp;quot;                                                                                                 
## [133] &amp;quot; You were a Trailblazer, a level 8 female gnomish Ranger.&amp;quot;                                                   
## [134] &amp;quot; You were neutral, on a mission for Venus&amp;quot;                                                                   
## [135] &amp;quot; who was opposed by Mercury (lawful) and Mars (chaotic).&amp;quot;                                                    
## [136] &amp;quot;&amp;quot;                                                                                                            
## [137] &amp;quot;Final Characteristics:&amp;quot;                                                                                      
## [138] &amp;quot; You had 0 hit points (max:54).&amp;quot;                                                                             
## [139] &amp;quot; You had 40 magic power (max:40).&amp;quot;                                                                           
## [140] &amp;quot; Your armor class was 0.&amp;quot;                                                                                    
## [141] &amp;quot; You had 1552 experience points.&amp;quot;                                                                            
## [142] &amp;quot; You entered the dungeon 7398 turns ago.&amp;quot;                                                                    
## [143] &amp;quot; Your strength was 15 (limit:18/50).&amp;quot;                                                                        
## [144] &amp;quot; Your dexterity was 12 (limit:18).&amp;quot;                                                                          
## [145] &amp;quot; Your constitution was 16 (limit:18).&amp;quot;                                                                       
## [146] &amp;quot; Your intelligence was 13 (limit:19).&amp;quot;                                                                       
## [147] &amp;quot; Your wisdom was 15 (limit:18).&amp;quot;                                                                             
## [148] &amp;quot; Your charisma was 6 (limit:18).&amp;quot;                                                                            
## [149] &amp;quot;&amp;quot;                                                                                                            
## [150] &amp;quot;Final Status:&amp;quot;                                                                                               
## [151] &amp;quot; You were satiated.&amp;quot;                                                                                         
## [152] &amp;quot; You were burdened; movement was slightly slowed.&amp;quot;                                                           
## [153] &amp;quot; You were wielding a bow.&amp;quot;                                                                                   
## [154] &amp;quot;&amp;quot;                                                                                                            
## [155] &amp;quot;Final Attributes:&amp;quot;                                                                                           
## [156] &amp;quot; You were piously aligned.&amp;quot;                                                                                  
## [157] &amp;quot; You were telepathic.&amp;quot;                                                                                       
## [158] &amp;quot; You had automatic searching.&amp;quot;                                                                               
## [159] &amp;quot; You had infravision.&amp;quot;                                                                                       
## [160] &amp;quot; You were displaced.&amp;quot;                                                                                        
## [161] &amp;quot; You were stealthy.&amp;quot;                                                                                         
## [162] &amp;quot; You had slower digestion.&amp;quot;                                                                                  
## [163] &amp;quot; You were guarded.&amp;quot;                                                                                          
## [164] &amp;quot; You are dead.&amp;quot;                                                                                              
## [165] &amp;quot;&amp;quot;                                                                                                            
## [166] &amp;quot;Vanquished creatures:&amp;quot;                                                                                       
## [167] &amp;quot;  a warhorse&amp;quot;                                                                                                
## [168] &amp;quot;  a tengu&amp;quot;                                                                                                   
## [169] &amp;quot;  a quivering blob&amp;quot;                                                                                          
## [170] &amp;quot; an iron piercer&amp;quot;                                                                                            
## [171] &amp;quot;  2 black lights&amp;quot;                                                                                            
## [172] &amp;quot;  a gold golem&amp;quot;                                                                                              
## [173] &amp;quot;  a werewolf&amp;quot;                                                                                                
## [174] &amp;quot;  3 lizards&amp;quot;                                                                                                 
## [175] &amp;quot;  2 dingoes&amp;quot;                                                                                                 
## [176] &amp;quot;  a housecat&amp;quot;                                                                                                
## [177] &amp;quot;  a white unicorn&amp;quot;                                                                                           
## [178] &amp;quot;  2 dust vortices&amp;quot;                                                                                           
## [179] &amp;quot;  a plains centaur&amp;quot;                                                                                          
## [180] &amp;quot; an ape&amp;quot;                                                                                                     
## [181] &amp;quot;  a Woodland-elf&amp;quot;                                                                                            
## [182] &amp;quot;  2 soldier ants&amp;quot;                                                                                            
## [183] &amp;quot;  a bugbear&amp;quot;                                                                                                 
## [184] &amp;quot; an imp&amp;quot;                                                                                                     
## [185] &amp;quot;  a wood nymph&amp;quot;                                                                                              
## [186] &amp;quot;  a water nymph&amp;quot;                                                                                             
## [187] &amp;quot;  a rock piercer&amp;quot;                                                                                            
## [188] &amp;quot;  a pony&amp;quot;                                                                                                    
## [189] &amp;quot;  3 fog clouds&amp;quot;                                                                                              
## [190] &amp;quot;  a yellow light&amp;quot;                                                                                            
## [191] &amp;quot;  a violet fungus&amp;quot;                                                                                           
## [192] &amp;quot;  2 gnome lords&amp;quot;                                                                                             
## [193] &amp;quot;  2 gnomish wizards&amp;quot;                                                                                         
## [194] &amp;quot;  2 gray oozes&amp;quot;                                                                                              
## [195] &amp;quot;  2 elf zombies&amp;quot;                                                                                             
## [196] &amp;quot;  a straw golem&amp;quot;                                                                                             
## [197] &amp;quot;  a paper golem&amp;quot;                                                                                             
## [198] &amp;quot;  2 giant ants&amp;quot;                                                                                              
## [199] &amp;quot;  2 little dogs&amp;quot;                                                                                             
## [200] &amp;quot;  3 floating eyes&amp;quot;                                                                                           
## [201] &amp;quot;  8 dwarves&amp;quot;                                                                                                 
## [202] &amp;quot;  a homunculus&amp;quot;                                                                                              
## [203] &amp;quot;  3 kobold lords&amp;quot;                                                                                            
## [204] &amp;quot;  3 kobold shamans&amp;quot;                                                                                          
## [205] &amp;quot; 13 hill orcs&amp;quot;                                                                                               
## [206] &amp;quot;  4 rothes&amp;quot;                                                                                                  
## [207] &amp;quot;  2 centipedes&amp;quot;                                                                                              
## [208] &amp;quot;  3 giant bats&amp;quot;                                                                                              
## [209] &amp;quot;  6 dwarf zombies&amp;quot;                                                                                           
## [210] &amp;quot;  a werejackal&amp;quot;                                                                                              
## [211] &amp;quot;  3 iguanas&amp;quot;                                                                                                 
## [212] &amp;quot; 23 killer bees&amp;quot;                                                                                             
## [213] &amp;quot; an acid blob&amp;quot;                                                                                               
## [214] &amp;quot;  a coyote&amp;quot;                                                                                                  
## [215] &amp;quot;  3 gas spores&amp;quot;                                                                                              
## [216] &amp;quot;  5 hobbits&amp;quot;                                                                                                 
## [217] &amp;quot;  7 manes&amp;quot;                                                                                                   
## [218] &amp;quot;  2 large kobolds&amp;quot;                                                                                           
## [219] &amp;quot;  a hobgoblin&amp;quot;                                                                                               
## [220] &amp;quot;  2 giant rats&amp;quot;                                                                                              
## [221] &amp;quot;  2 cave spiders&amp;quot;                                                                                            
## [222] &amp;quot;  a yellow mold&amp;quot;                                                                                             
## [223] &amp;quot;  6 gnomes&amp;quot;                                                                                                  
## [224] &amp;quot;  8 garter snakes&amp;quot;                                                                                           
## [225] &amp;quot;  2 gnome zombies&amp;quot;                                                                                           
## [226] &amp;quot;  8 geckos&amp;quot;                                                                                                  
## [227] &amp;quot; 11 jackals&amp;quot;                                                                                                 
## [228] &amp;quot;  5 foxes&amp;quot;                                                                                                   
## [229] &amp;quot;  2 kobolds&amp;quot;                                                                                                 
## [230] &amp;quot;  2 goblins&amp;quot;                                                                                                 
## [231] &amp;quot;  a sewer rat&amp;quot;                                                                                               
## [232] &amp;quot;  6 grid bugs&amp;quot;                                                                                               
## [233] &amp;quot;  3 lichens&amp;quot;                                                                                                 
## [234] &amp;quot;  2 kobold zombies&amp;quot;                                                                                          
## [235] &amp;quot;  5 newts&amp;quot;                                                                                                   
## [236] &amp;quot;206 creatures vanquished.&amp;quot;                                                                                   
## [237] &amp;quot;&amp;quot;                                                                                                            
## [238] &amp;quot;No species were genocided or became extinct.&amp;quot;                                                                
## [239] &amp;quot;&amp;quot;                                                                                                            
## [240] &amp;quot;Voluntary challenges:&amp;quot;                                                                                       
## [241] &amp;quot; You never genocided any monsters.&amp;quot;                                                                          
## [242] &amp;quot; You never polymorphed an object.&amp;quot;                                                                           
## [243] &amp;quot; You never changed form.&amp;quot;                                                                                    
## [244] &amp;quot; You used no wishes.&amp;quot;                                                                                        
## [245] &amp;quot;&amp;quot;                                                                                                            
## [246] &amp;quot;The Dungeons of Doom: levels 1 to 6&amp;quot;                                                                         
## [247] &amp;quot;   Level 1:&amp;quot;                                                                                                 
## [248] &amp;quot;      A fountain.&amp;quot;                                                                                           
## [249] &amp;quot;   Level 2:&amp;quot;                                                                                                 
## [250] &amp;quot;      A sink.&amp;quot;                                                                                               
## [251] &amp;quot;   Level 3:&amp;quot;                                                                                                 
## [252] &amp;quot;      A general store, a fountain.&amp;quot;                                                                          
## [253] &amp;quot;   Level 4:&amp;quot;                                                                                                 
## [254] &amp;quot;      A general store, a fountain.&amp;quot;                                                                          
## [255] &amp;quot;      Stairs down to The Gnomish Mines.&amp;quot;                                                                     
## [256] &amp;quot;   Level 5:&amp;quot;                                                                                                 
## [257] &amp;quot;      A fountain.&amp;quot;                                                                                           
## [258] &amp;quot;   Level 6: &amp;lt;- You were here.&amp;quot;                                                                               
## [259] &amp;quot;      A general store.&amp;quot;                                                                                      
## [260] &amp;quot;      Final resting place for&amp;quot;                                                                               
## [261] &amp;quot;         you, killed by an ape.&amp;quot;                                                                             
## [262] &amp;quot;The Gnomish Mines: levels 5 to 8&amp;quot;                                                                            
## [263] &amp;quot;   Level 5:&amp;quot;                                                                                                 
## [264] &amp;quot;   Level 6:&amp;quot;                                                                                                 
## [265] &amp;quot;   Level 7:&amp;quot;                                                                                                 
## [266] &amp;quot;      Many shops, a temple, some fountains.&amp;quot;                                                                 
## [267] &amp;quot;   Level 8:&amp;quot;                                                                                                 
## [268] &amp;quot;&amp;quot;                                                                                                            
## [269] &amp;quot;Game over:&amp;quot;                                                                                                  
## [270] &amp;quot;                       ----------&amp;quot;                                                                           
## [271] &amp;quot;                      /          \\&amp;quot;                                                                         
## [272] &amp;quot;                     /    REST    \\&amp;quot;                                                                        
## [273] &amp;quot;                    /      IN      \\&amp;quot;                                                                       
## [274] &amp;quot;                   /     PEACE      \\&amp;quot;                                                                      
## [275] &amp;quot;                  /                  \\&amp;quot;                                                                     
## [276] &amp;quot;                  |  brothertrebius  |&amp;quot;                                                                      
## [277] &amp;quot;                  |      59 Au       |&amp;quot;                                                                      
## [278] &amp;quot;                  | killed by an ape |&amp;quot;                                                                      
## [279] &amp;quot;                  |                  |&amp;quot;                                                                      
## [280] &amp;quot;                  |                  |&amp;quot;                                                                      
## [281] &amp;quot;                  |                  |&amp;quot;                                                                      
## [282] &amp;quot;                  |       2018       |&amp;quot;                                                                      
## [283] &amp;quot;                 *|     *  *  *      | *&amp;quot;                                                                    
## [284] &amp;quot;        _________)/\\\\_//(\\/(/\\)/\\//\\/|_)_______&amp;quot;                                                       
## [285] &amp;quot;&amp;quot;                                                                                                            
## [286] &amp;quot;Goodbye brothertrebius the Ranger...&amp;quot;                                                                        
## [287] &amp;quot;&amp;quot;                                                                                                            
## [288] &amp;quot;You died in The Dungeons of Doom on dungeon level 6 with 6652 points,&amp;quot;                                       
## [289] &amp;quot;and 59 pieces of gold, after 7398 moves.&amp;quot;                                                                    
## [290] &amp;quot;You were level 8 with a maximum of 54 hit points when you died.&amp;quot;                                             
## [291] &amp;quot;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;Now, I am curious to see how many games are played per day:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;runs_per_day &amp;lt;- nethack %&amp;gt;%
  group_by(date) %&amp;gt;%
  count() %&amp;gt;%
  ungroup() 


ggplot(runs_per_day, aes(y = n, x = date)) + 
  geom_point(colour = &amp;quot;#0f4150&amp;quot;) + 
  geom_smooth(colour = &amp;quot;#82518c&amp;quot;) + 
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39; and formula &amp;#39;y ~ s(x, bs = &amp;quot;cs&amp;quot;)&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The number of games seems to be stable since 2015, around 50. But what is also interesting is not
only the number of games played, but also how many of these games resulted in a win.&lt;/p&gt;
&lt;p&gt;For this, let’s also add a new column that tells us whether the played &lt;em&gt;ascended&lt;/em&gt; (won the game)
or not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;lt;&amp;gt;%
  mutate(Ascended = ifelse(death == &amp;quot;ascended&amp;quot;, &amp;quot;Ascended&amp;quot;, &amp;quot;Died an horrible death&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m curious to see how many players managed to ascend… NetHack being as hard as diamonds, probably
not a lot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ascensions_per_day &amp;lt;- nethack %&amp;gt;%
  group_by(date, Ascended) %&amp;gt;%
  count() %&amp;gt;%
  rename(Total = n)

ggplot(ascensions_per_day) + 
  geom_area(aes(y = Total, x = as.Date(date), fill = Ascended)) +
  theme_blog() +
  labs(y = &amp;quot;Number of runs&amp;quot;, x = &amp;quot;Date&amp;quot;) +
  scale_fill_blog() +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yeah, just as expected. Because there is so much data, it’s difficult to see clearly, though. Depending on
the size of the screen you’re reading this, it might seem that in some days there are a lot of ascensions.
This is only an impression due to the resolution of the picture. Let’s see the share of ascensions per
year (and how many times the quests fail miserably), and this will become more apparent:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ascensions_per_day %&amp;gt;%
  mutate(Year = year(as.Date(date))) %&amp;gt;%
  group_by(Year, Ascended) %&amp;gt;%
  summarise(Total = sum(Total, na.rm = TRUE)) %&amp;gt;%
  group_by(Year) %&amp;gt;%
  mutate(denom = sum(Total, na.rm = TRUE)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(Share = Total/denom) %&amp;gt;%
  ggplot() + 
  geom_col(aes(y = Share, x = Year, fill = Ascended)) + 
  theme_blog() + 
  scale_fill_blog() + 
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I will now convert the “time” column to seconds. I am not yet sure that this column is really useful,
because NetHack is a turn based game. This means that when the player does not move, neither do the
monsters. So the seconds spent playing might not be a good proxy for actual time spent playing.
But it makes for a good exercise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convert_to_seconds &amp;lt;- function(time_string){
    time_numeric &amp;lt;- time_string %&amp;gt;%
        str_split(&amp;quot;:&amp;quot;, simplify = TRUE) %&amp;gt;%
        as.numeric

    time_in_seconds &amp;lt;- sum(time_numeric * c(3600, 60, 1))

    time_in_seconds 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The strings I want to convert are of the form “01:34:43”, so I split at the “:” and then convert
the result to numeric. I end up with an atomic vector (&lt;code&gt;c(1, 34, 43)&lt;/code&gt;). Then I multiple each element
by the right number of seconds, and sum that to get the total. Let’s apply it to my data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;lt;&amp;gt;%
  mutate(time_in_seconds = map_dbl(time, convert_to_seconds))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the distribution of “time_in_seconds”?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  describe(time_in_seconds)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 15
##   variable type    nobs   mean     sd mode    min    max   q05   q25 median
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 time_in… Nume… 322485 23529. 2.73e5 &amp;lt;NA&amp;gt;     61 2.72e7   141   622   1689
## # … with 4 more variables: q75 &amp;lt;dbl&amp;gt;, q95 &amp;lt;dbl&amp;gt;, n_missing &amp;lt;int&amp;gt;,
## #   n_unique &amp;lt;lgl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the minimum of &lt;code&gt;time_in_seconds&lt;/code&gt; is 61 whereas the maximum is of the order of 27200000…
This must be a mistake, because that is almost one year!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(time_in_seconds == max(time_in_seconds, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   rank      score   name       time   turns lev_max  hp_max role race
## 1   28 3173960108 fisted 7553:41:49 6860357    4/47 362/362  Wiz  Elf
##   gender alignment                      death       date dumplog year
## 1    Mal       Neu drowned in a pool of water 2017-02-02      NA 2017
##   month day               Ascended time_in_seconds
## 1     2   2 Died an horrible death        27193309&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well… maybe “fisted” wanted to break the record of the longest NetHack game ever. Congratulations!&lt;/p&gt;
&lt;p&gt;Let’s take a look at the density but cut it at 90th percentile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(!is.na(time_in_seconds),
         time_in_seconds &amp;lt; quantile(time_in_seconds, 0.9, na.rm = TRUE)) %&amp;gt;%
  ggplot() + 
  geom_density(aes(x = time_in_seconds), colour = &amp;quot;#82518c&amp;quot;) + 
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the distribution is right skewed. However, as explained above NetHack is a turn based
game, meaning that if the player does not move, the monsters won’t move either. Perhaps it makes more
sense to look at the &lt;code&gt;turns&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  describe(turns)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 15
##   variable type    nobs  mean     sd mode    min    max   q05   q25 median
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 turns    Nume… 322485 4495. 19853. &amp;lt;NA&amp;gt;      1 6.86e6   202   871   1818
## # … with 4 more variables: q75 &amp;lt;dbl&amp;gt;, q95 &amp;lt;dbl&amp;gt;, n_missing &amp;lt;int&amp;gt;,
## #   n_unique &amp;lt;lgl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The maximum is quite large too. Just like before, let’s focus by cutting the variable at the 90th percentile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
  filter(!is.na(turns),
         turns &amp;lt; quantile(turns, 0.9, na.rm = TRUE)) %&amp;gt;% 
  ggplot() + 
  geom_density(aes(x = turns), colour = &amp;quot;#82518c&amp;quot;) + 
  theme_blog()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I think that using &lt;code&gt;turns&lt;/code&gt; makes more sense. In the a future blog post, I will estimate a survival
model and see how long players survive, and will use &lt;code&gt;turns&lt;/code&gt; instead of &lt;code&gt;time_in_seconds&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis&lt;/h2&gt;
&lt;div id=&#34;what-kills-the-players&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What kills the players&lt;/h3&gt;
&lt;p&gt;To know what kills players so much, some cleaning of the &lt;code&gt;death&lt;/code&gt; column is in order. Death can
occur from poisoning, starvation, accidents, drowning… of course monsters can kill the player too.
Here are some values of the &lt;code&gt;death&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;burned by a tower of flame
choked on a lichen corpse
died of starvation
fell into a pit of iron spikes
killed by a gnome
killed by a gnome called Blabla
killed by a gnome called Blabla while sleeping
slipped while mounting a saddled pony
slipped while mounting a saddled pony called Jolly Jumper
zapped her/himself with a spell&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To know what is the most frequent cause of death, I have to do some cleaning, because if not,
“killed by a gnome” and “killed by a gnome called Blabla” would be two different causes of death.
In the end, what interests me is to know how many times the player got killed by a gnome.&lt;/p&gt;
&lt;p&gt;The following lines do a cleanup of the &lt;code&gt;death&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;lt;&amp;gt;% 
  mutate(death2 = case_when(str_detect(death, &amp;quot;poisoned&amp;quot;) ~ &amp;quot;poisoned&amp;quot;,
                            str_detect(death, &amp;quot;slipped&amp;quot;) ~ &amp;quot;accident&amp;quot;,
                            str_detect(death, &amp;quot;petrified&amp;quot;) ~ &amp;quot;petrified&amp;quot;,
                            str_detect(death, &amp;quot;choked&amp;quot;) ~ &amp;quot;accident&amp;quot;,
                            str_detect(death, &amp;quot;caught.*self&amp;quot;) ~ &amp;quot;accident&amp;quot;,
                            str_detect(death, &amp;quot;starvation&amp;quot;) ~ &amp;quot;starvation&amp;quot;,
                            str_detect(death, &amp;quot;drowned&amp;quot;) ~ &amp;quot;drowned&amp;quot;,
                            str_detect(death, &amp;quot;fell&amp;quot;) ~ &amp;quot;fell&amp;quot;,
                            str_detect(death, &amp;quot;zapped&amp;quot;) ~ &amp;quot;zapped&amp;quot;,
                            str_detect(death, &amp;quot;killed&amp;quot;) ~ &amp;quot;killed&amp;quot;,
                            TRUE ~ death)) %&amp;gt;%
  mutate(death3 = str_extract(death, &amp;quot;(?&amp;lt;=by|while).*&amp;quot;)) %&amp;gt;%
  mutate(death3 = case_when(str_detect(death3, &amp;quot;,|\\bcalled\\b&amp;quot;) ~ str_extract(death3, &amp;quot;(.*?),|(.*?)\\bcalled\\b&amp;quot;), 
                            TRUE ~ death3)) %&amp;gt;%
  mutate(death3 = str_remove(death3, &amp;quot;,|called|\\ban?&amp;quot;),
         death3 = str_trim(death3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;death2&lt;/code&gt; is a new variable, in which I broadly categorize causes of death. Using regular expressions
I detect causes of death and aggregate some categories, for instance “slipped” and “chocked” into
“accident”. Then, I want to extract everything that comes after the strings “by” or while, and put
the result into a new variable called &lt;code&gt;death3&lt;/code&gt;. Then I detect the string “,” or “called”; if one
of these strings is present, I extract everything that comes before “,” or that comes before
“called”. Finally, I remove “,”, “called” or “a” or “an” from the string and trim the whitespaces.&lt;/p&gt;
&lt;p&gt;Let’s take a look at these new variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
nethack %&amp;gt;%
    select(name, death, death2, death3) %&amp;gt;%
    sample_n(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              name                     death   death2        death3
## 92740   DianaFury     killed by a death ray   killed     death ray
## 254216    Oddabit         killed by a tiger   killed         tiger
## 131889    shachaf      killed by a fire ant   killed      fire ant
## 284758        a43  poisoned by a killer bee poisoned    killer bee
## 303283      goast         killed by a gecko   killed         gecko
## 14692     liberty    killed by a gnome king   killed    gnome king
## 170303     arch18                  ascended ascended          &amp;lt;NA&amp;gt;
## 287786 foolishwtf           killed by a bat   killed           bat
## 177826    Renleve     killed by a giant bat   killed     giant bat
## 147248      TheOV killed by a black unicorn   killed black unicorn&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, it is quite easy to know what monsters are the meanest buttholes; let’s focus on the top 15.
Most likely, these are going to be early game monsters. Let’ see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
    filter(!is.na(death3)) %&amp;gt;%
    count(death3) %&amp;gt;%
    top_n(15) %&amp;gt;%
    mutate(death3 = fct_reorder(death3, n, .desc = FALSE)) %&amp;gt;%
    ggplot() + 
    geom_col(aes(y = n, x = death3)) + 
    coord_flip() + 
    theme_blog() + 
    scale_fill_blog() + 
    ylab(&amp;quot;Number of deaths caused&amp;quot;) +
    xlab(&amp;quot;Monster&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by n&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Seems like soldier ants are the baddest, followed by jackals and dwarfs. As expected, these are
mostly early game monsters. Thus, it would be interesting to look at this distribution, but at
different stages in the game. Let’s create a categorical variable that discretizes &lt;code&gt;turns&lt;/code&gt;,
and then create one plot per category:&lt;/p&gt;
&lt;details&gt;
&lt;p&gt;&lt;summary&gt;Click to expand&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack %&amp;gt;%
    filter(!is.na(death3)) %&amp;gt;%
    filter(!is.na(turns)) %&amp;gt;%
    mutate(turn_flag = case_when(between(turns, 1, 5000) ~ &amp;quot;Less than 5000&amp;quot;,
                                 between(turns, 5001, 10000) ~ &amp;quot;Between 5001 and 10000&amp;quot;,
                                 between(turns, 10001, 20000) ~ &amp;quot;Between 10001 and 20000&amp;quot;,
                                 between(turns, 20001, 40000) ~ &amp;quot;Between 20001 and 40000&amp;quot;,
                                 between(turns, 40001, 60000) ~ &amp;quot;Between 40001 and 60000&amp;quot;,
                                 turns &amp;gt; 60000 ~ &amp;quot;More than 60000&amp;quot;)) %&amp;gt;%
    mutate(turn_flag = factor(turn_flag, levels = c(&amp;quot;Less than 5000&amp;quot;, 
                                                    &amp;quot;Between 5001 and 10000&amp;quot;,
                                                    &amp;quot;Between 10001 and 20000&amp;quot;,
                                                    &amp;quot;Between 20001 and 40000&amp;quot;,
                                                    &amp;quot;Between 40001 and 60000&amp;quot;,
                                                    &amp;quot;More than 60000&amp;quot;), ordered = TRUE)) %&amp;gt;%
    group_by(turn_flag) %&amp;gt;%
    count(death3) %&amp;gt;%
    top_n(15) %&amp;gt;%
    nest() %&amp;gt;%
    mutate(data = map(data, ~mutate(., death3 = fct_reorder(death3, n, .desc = TRUE))))  %&amp;gt;%
    mutate(plots = map2(.x = turn_flag,
                         .y = data,
                         ~ggplot(data = .y) + 
                             geom_col(aes(y = n, x = death3)) + 
                             coord_flip() + 
                             theme_blog() + 
                             scale_fill_blog() + 
                             ylab(&amp;quot;Number of deaths caused&amp;quot;) +
                             xlab(&amp;quot;Monster&amp;quot;) + 
                             ggtitle(.x))) %&amp;gt;%
    pull(plots)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by n&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[3]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[4]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[5]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## [[6]]&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-26-6.png&#34; width=&#34;672&#34; /&gt;
&lt;/details&gt;
&lt;p&gt;Finally, for this section, I want to know if there are levels, or floors, where players die more
often than others. For this, we can take a look at the &lt;code&gt;lev_max&lt;/code&gt; column. Observations in this
column are of the form “8/10”. This means that the player died on level 8, but the lowest level
that was explored was the 10th. Let’s do this for the year 2017 first. Before anything, I have
to explain the layout of the levels of the game. You can see a diagram
&lt;a href=&#34;https://nethackwiki.com/wiki/Mazes_of_Menace#Map&#34;&gt;here&lt;/a&gt;. The player starts on floor 1,
and goes down to level 53. Then, the player can ascend, by going on levels -1 to -5. But there
are more levels than these ones. -6 and -9 are the sky, and the player can teleport there (but will
fall to his death). If the player teleports to level -10, he’ll enter heaven (and die too). Because
these levels are special, I do not consider them here. I do not consider level 0 either, which is
“Nowhere”. Let’s get the number of players who died on each floor, but also compute the cumulative
death count:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;died_on_level &amp;lt;- nethack %&amp;gt;%
    filter(Ascended == &amp;quot;Died an horrible death&amp;quot;) %&amp;gt;%
    mutate(died_on = str_extract(lev_max, &amp;quot;-?\\d{1,}&amp;quot;)) %&amp;gt;%
    mutate(died_on = as.numeric(died_on)) %&amp;gt;%
    group_by(year) %&amp;gt;%
    count(died_on) %&amp;gt;% 
    filter(died_on &amp;gt;= -5, died_on != 0) %&amp;gt;%
    mutate(died_on = case_when(died_on == -1 ~ 54,
                               died_on == -2 ~ 55,
                               died_on == -3 ~ 56,
                               died_on == -4 ~ 57,
                               died_on == -5 ~ 58,
                               TRUE ~ died_on)) %&amp;gt;%
    arrange(desc(died_on)) %&amp;gt;%
    mutate(cumul_deaths = cumsum(n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(died_on_level)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
## # Groups:   year [6]
##    year died_on     n cumul_deaths
##   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;        &amp;lt;int&amp;gt;
## 1  2002      58     5            5
## 2  2003      58    11           11
## 3  2004      58    19           19
## 4  2005      58    28           28
## 5  2006      58    25           25
## 6  2007      58    22           22&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s compute the number of players who ascended and add this to the cumulative count:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ascended_yearly &amp;lt;- nethack %&amp;gt;%
    filter(Ascended == &amp;quot;Ascended&amp;quot;) %&amp;gt;%
    group_by(year) %&amp;gt;%
    count(Ascended)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(ascended_yearly)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
## # Groups:   year [6]
##    year Ascended     n
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;
## 1  2001 Ascended     4
## 2  2002 Ascended    38
## 3  2003 Ascended   132
## 4  2004 Ascended   343
## 5  2005 Ascended   329
## 6  2006 Ascended   459&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will modify the dataset a little bit and merge it with the previous one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ascended_yearly %&amp;lt;&amp;gt;%
  rename(ascended_players = `n`) %&amp;gt;%
  select(-Ascended)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s add this to the data frame from before by merging both, and then we can compute the
surviving players:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;died_on_level %&amp;lt;&amp;gt;%
  full_join(ascended_yearly, by = &amp;quot;year&amp;quot;) %&amp;gt;%
  mutate(surviving_players = cumul_deaths + ascended_players)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can compute the share of players who died on each level:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;died_on_level %&amp;gt;%
    mutate(death_rate = n/surviving_players) %&amp;gt;% 
    ggplot(aes(y = death_rate, x = as.factor(died_on))) + 
    geom_line(aes(group = year, alpha = year), colour = &amp;quot;#82518c&amp;quot;) +
    theme_blog() + 
    ylab(&amp;quot;Death rate&amp;quot;) +
    xlab(&amp;quot;Level&amp;quot;) + 
    theme(axis.text.x = element_text(angle = 90),
          legend.position = &amp;quot;none&amp;quot;) + 
    scale_y_continuous(labels = scales::percent)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-11-03-nethack_analysis_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like level 7 is consistently the most dangerous! The death rate there is more than 35%!&lt;/p&gt;
&lt;p&gt;That’s it for this blog post, in the next one, I will focus on what players kill!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>From webscraping data to releasing it as an R package to share with the world: a full tutorial with data from NetHack</title>
      <link>https://www.brodrigues.co/blog/2018-11-01-nethack/</link>
      <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-11-01-nethack/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;If someone told me a decade ago (back before I&amp;#39;d ever heard the term &amp;quot;roguelike&amp;quot;) what I&amp;#39;d be doing today, I would have trouble believing this...&lt;br&gt;&lt;br&gt;Yet here we are. &lt;a href=&#34;https://t.co/N6Hh6A4tWl&#34;&gt;pic.twitter.com/N6Hh6A4tWl&lt;/a&gt;&lt;/p&gt;&amp;mdash; Josh Ge (@GridSageGames) &lt;a href=&#34;https://twitter.com/GridSageGames/status/1009664438683648001?ref_src=twsrc%5Etfw&#34;&gt;June 21, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;update-07-11-2018&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Update 07-11-2018&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;{nethack}&lt;/code&gt; package currently on Github contains a sample of 6000 NetHack games played
on the alt.org/nethack public server between April and November 2018. This data was kindly provided by &lt;a href=&#34;https://twitter.com/paxed&#34;&gt;&lt;code&gt;@paxed&lt;/code&gt;&lt;/a&gt;.
The tutorial in this blog post is still useful if you want to learn more about scraping with R
and building a data package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In this post, I am going to show you how you can scrape tables from a website, and then create a package
with the tidied data to share with the world. The data I am going to scrape comes from a NetHack
public server (&lt;a href=&#34;https://alt.org/nethack/&#34;&gt;link&lt;/a&gt;). The data I discuss in this blog post is
available in the &lt;code&gt;{nethack}&lt;/code&gt; package I created and I will walk you through the process of releasing
your package on CRAN. However, &lt;code&gt;{nethack}&lt;/code&gt; is too large to be on CRAN (75 mb, while the maximum
allowed is 5mb), so you can install it to play around with the data from github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/nethack&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to use it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(nethack)
data(&amp;quot;nethack&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data contains information on games played from 2001 to 2018; 322485 rows and 14 columns. I
will analyze the data in a future blog post. This post focuses on getting and then sharing the
data. By the way, all the content from the public server I scrape is under the CC BY 4.0 license.&lt;/p&gt;
&lt;p&gt;I built the package by using the very useful &lt;code&gt;{devtools}&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;NetHack is a game released in 1987 that is still being played and developed today.
NetHack is a roguelike game, meaning that is has procedurally generated dungeons and permadeath.
If you die, you have to start over, and because the dungeons are procedurally generated, this means
that you cannot learn the layout of the dungeons you explore or know when ennemies are going
to attack or even what ennemies are going to attack. Ennemies are not the only thing that you have
to be careful about; you can die from a lot of different events, as you will see in this post.
Objects that you find, such as a silver ring, might be helpful in a run, but be cursed in the next run.&lt;/p&gt;
&lt;p&gt;The latest version of the game, 3.6.1, was released on April 27th 2018, and this is how it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/f/ff/Nethack.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The graphics are… bare-bones to say the least. The game runs inside a terminal emulator and is
available for any platform. The goal of NetHack is to explore a dungeon and go down every
level until you find the Amulet of Yendor. Once you find this Amulet, you have to go all the way
back upstairs, enter and fight your way through the Elemental Planes, enter the final Astral Plane,
and then finally offer the Amulet of Yendor to your god to finish the game. Needless to say,
NetHack is very difficult and players can go years without ever finishing the game.&lt;/p&gt;
&lt;p&gt;When you start an new game, you have to create a character, which can have several attributes.
You have to choose a race (human, elf, orc, etc), a role (tourist, samurai, mage, etc) and an
alignment (neutral, law, chaos) and these choices impact your base stats.&lt;/p&gt;
&lt;p&gt;If you can’t get past the ASCII graphics, you can play NetHack with tileset:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vignette.wikia.nocookie.net/nethack/images/8/80/Vultures_eye.png/revision/latest?cb=20070313215112&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;You can install NetHack on your computer or you can play online on a public server, such as
this &lt;a href=&#34;https://alt.org/nethack/&#34;&gt;one&lt;/a&gt;. There are several advantages when playing on a pubic server;
the player does not have to install anyhing, and we data enthusiasts have access to a mine of
information! For example, you can view the following &lt;a href=&#34;https://alt.org/nethack/gamesday.php?date=20181025&#34;&gt;table&lt;/a&gt;
which contains data on all the games played on October 25th 2018. These tables start in the year 2001,
and I am going to scrape the info from these tables, which will allow me to answer several questions.
For instance, what is the floor most players die on? What kills most players?
What role do players choose more often? I will explore this questions in a future blog post, but for
now I will focus on scraping the data and realeasing it as a package to CRAN.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scraping-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scraping the data&lt;/h2&gt;
&lt;p&gt;To scrape the data I wrote a big function that does several things:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;rvest&amp;quot;)


scrape_one_day &amp;lt;- function(link){

    convert_to_seconds &amp;lt;- function(time_string){
        time_numeric &amp;lt;- time_string %&amp;gt;%
            str_split(&amp;quot;:&amp;quot;, simplify = TRUE) %&amp;gt;%
            as.numeric
     
     time_in_seconds &amp;lt;- time_numeric * c(3600, 60, 1)
     
     if(is.na(time_in_seconds)){
         time_in_seconds &amp;lt;- 61
     } else {
         time_in_seconds &amp;lt;- sum(time_in_seconds)
     }
     return(time_in_seconds)
    }

    Sys.sleep(1)

    date &amp;lt;- str_extract(link, &amp;quot;\\d{8}&amp;quot;)

    read_lines_slow &amp;lt;- function(...){
        Sys.sleep(1)
        read_lines(...)
    }
    
    page &amp;lt;- read_html(link)

        # Get links
    dumplogs &amp;lt;- page %&amp;gt;% 
        html_nodes(xpath = &amp;#39;//*[(@id = &amp;quot;perday&amp;quot;)]//td&amp;#39;) %&amp;gt;%
        html_children() %&amp;gt;%
        html_attr(&amp;quot;href&amp;quot;) %&amp;gt;%
        keep(str_detect(., &amp;quot;dumplog&amp;quot;))

    # Get table
    table &amp;lt;- page %&amp;gt;%
        html_node(xpath = &amp;#39;//*[(@id = &amp;quot;perday&amp;quot;)]&amp;#39;) %&amp;gt;%
        html_table(fill = TRUE)

    if(is_empty(dumplogs)){
        print(&amp;quot;dumplogs empty&amp;quot;)
        dumplogs &amp;lt;- rep(NA, nrow(table))
    } else {
        dumplogs &amp;lt;- dumplogs
    }
    
    final &amp;lt;- table %&amp;gt;%
        janitor::clean_names() %&amp;gt;%
        mutate(dumplog_links = dumplogs)

    print(paste0(&amp;quot;cleaning data of date &amp;quot;, date))
    
    clean_final &amp;lt;- final %&amp;gt;%
        select(-x) %&amp;gt;%
        rename(role = x_2,
               race = x_3,
               gender = x_4,
               alignment = x_5) %&amp;gt;%
        mutate(time_in_seconds = map(time, convert_to_seconds)) %&amp;gt;%
        filter(!(death %in% c(&amp;quot;quit&amp;quot;, &amp;quot;escaped&amp;quot;)), time_in_seconds &amp;gt; 60) %&amp;gt;%
        mutate(dumplog = map(dumplog_links, ~possibly(read_lines_slow, otherwise = NA)(.))) %&amp;gt;%
        mutate(time_in_seconds = ifelse(time_in_seconds == 61, NA, time_in_seconds))

    saveRDS(clean_final, paste0(&amp;quot;datasets/data_&amp;quot;, date, &amp;quot;.rds&amp;quot;))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s go through each part. The first part is a function that converts strings like “02:21:76” to
seconds:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convert_to_seconds &amp;lt;- function(time_string){
    time_numeric &amp;lt;- time_string %&amp;gt;%
        str_split(&amp;quot;:&amp;quot;, simplify = TRUE) %&amp;gt;%
        as.numeric
 
time_in_seconds &amp;lt;- time_numeric * c(3600, 60, 1)
 
if(is.na(time_in_seconds)){
  time_in_seconds &amp;lt;- 61
  } else {
    time_in_seconds &amp;lt;- sum(time_in_seconds)
    }
return(time_in_seconds)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will use this function on the column that gives the length of the run. However,
before March 2008 this column is always empty, this is why I have the &lt;code&gt;if()...else()&lt;/code&gt; statement at
the end; if the time in seconds is &lt;code&gt;NA&lt;/code&gt;, then I make it 61 seconds. I do this because I want to keep
runs longer than 60 seconds, something I use &lt;code&gt;filter()&lt;/code&gt; for later. But when filtering, if the condition
returns &lt;code&gt;NA&lt;/code&gt; (which happens when you do &lt;code&gt;NA &amp;gt; 60&lt;/code&gt;) then you get an error, and the function fails.&lt;/p&gt;
&lt;p&gt;The website links I am going to scrape all have the date of the day the runs took place. I am going to
keep this date because I will need to name the datasets I am going to write to disk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;date &amp;lt;- str_extract(link, &amp;quot;\\d{8}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I define this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_lines_slow &amp;lt;- function(...){
    Sys.sleep(1)
    read_lines(...)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a wrapper around the &lt;code&gt;readr::read_lines()&lt;/code&gt; with a call to &lt;code&gt;Sys.sleep(1)&lt;/code&gt;. I will be scraping
a lot of pages, so letting one second pass between each page will not overload the servers so much.&lt;/p&gt;
&lt;p&gt;I then read the link with &lt;code&gt;read_html()&lt;/code&gt; and start by getting the links of the dumplogs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;page &amp;lt;- read_html(link)

# Get links
dumplogs &amp;lt;- page %&amp;gt;% 
    html_nodes(xpath = &amp;#39;//*[(@id = &amp;quot;perday&amp;quot;)]//td&amp;#39;) %&amp;gt;%
    html_children() %&amp;gt;%
    html_attr(&amp;quot;href&amp;quot;) %&amp;gt;%
    keep(str_detect(., &amp;quot;dumplog&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might be wondering what are dumplogs. Take a look at this screenshot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::include_graphics(&amp;quot;/img/dumplogs.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/dumplogs.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;When you click on those &lt;code&gt;d&lt;/code&gt;‘s, you land on a page like this &lt;a href=&#34;http://archive.is/wljb3&#34;&gt;one&lt;/a&gt; (I
archived it to be sure that this link will not die). These logs contain a lot of info that I want
to keep. To find the right ’xpath’ to scrape the links, &#34;’//&lt;em&gt;&lt;span class=&#34;citation&#34;&gt;[(@id = &#34;perday&#34;)]&lt;/span&gt;//td’&#34;, I used
the &lt;/em&gt;SelectorGadget* extension for Chrome. First I chose the table:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::include_graphics(&amp;quot;/img/selectorgadget1.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/selectorgadget1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;and then the links I am interested in:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::include_graphics(&amp;quot;/img/selectorgadget2.png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/selectorgadget2.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Putting them together, I get the right “xpath”. But just as with the time of the run, dumplogs are
only available after a certain date. So in case the &lt;code&gt;dumplogs&lt;/code&gt; column is empty, I relpace it with &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(is_empty(dumplogs)){
    print(&amp;quot;dumplogs empty&amp;quot;)
    dumplogs &amp;lt;- rep(NA, nrow(table))
} else {
    dumplogs &amp;lt;- dumplogs
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rest is quite simple:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get table
table &amp;lt;- page %&amp;gt;%
    html_node(xpath = &amp;#39;//*[(@id = &amp;quot;perday&amp;quot;)]&amp;#39;) %&amp;gt;%
    html_table(fill = TRUE)
               
final &amp;lt;- table %&amp;gt;%
    janitor::clean_names() %&amp;gt;%
    mutate(dumplog_links = dumplogs)
           
print(paste0(&amp;quot;cleaning data of date &amp;quot;, date))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I scrape the table, and then join the dumplog links to the table inside a new column called “dumplog_links”.&lt;/p&gt;
&lt;p&gt;Because what follows is a long process, I print a message to let me know the progress of the scraping.&lt;/p&gt;
&lt;p&gt;Now the last part:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_final &amp;lt;- final %&amp;gt;%
    select(-x) %&amp;gt;%
    rename(role = x_2,
           race = x_3,
           gender = x_4,
           alignment = x_5) %&amp;gt;%
    mutate(time_in_seconds = map(time, convert_to_seconds)) %&amp;gt;%
    filter(!(death %in% c(&amp;quot;quit&amp;quot;, &amp;quot;escaped&amp;quot;)), time_in_seconds &amp;gt; 60) %&amp;gt;%
    mutate(dumplog = map(dumplog_links, ~possibly(read_lines_slow, otherwise = NA)(.))) %&amp;gt;%
    mutate(time_in_seconds = ifelse(time_in_seconds == 61, NA, time_in_seconds))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I first remove and remane columns. Then I convert the “time” column into seconds and also remove
runs that lasted less than 60 seconds or that ended either in “quit” (the player left the game)
or “escaped” (the player left the dungeon and the game ended immediately). There are a lot of runs
like that and they’re not interesting. Finally, and this is what takes long, I create a new
list-column where each element is the contents of the dumplog for that run. I wrap &lt;code&gt;read_lines_slow()&lt;/code&gt;
around &lt;code&gt;purrr::possibly()&lt;/code&gt; because dumplogs are missing for certains runs and when I try to read
them I get an 404 error back. Getting such an error stops the whole process, so with &lt;code&gt;purrr::possibly()&lt;/code&gt;
I can specify that in that case I want &lt;code&gt;NA&lt;/code&gt; back. Basically, a function wrapped inside &lt;code&gt;purrr::possibly()&lt;/code&gt;
never fails! Finally, if a game lasts for 61 seconds, I convert it back to &lt;code&gt;NA&lt;/code&gt; (remember this was
used to avoid having problems with the &lt;code&gt;filter()&lt;/code&gt; function).&lt;/p&gt;
&lt;p&gt;Finally, I export what I scraped to disk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(clean_final, paste0(&amp;quot;datasets/data_&amp;quot;, date, &amp;quot;.rds&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is where I use the date; to name the data. This is really important because scraping takes
a very long time, so if I don’t write the progress to disk as it goes, I might lose hours of work
if my internet goes down, or if computer freezes or whatever.&lt;/p&gt;
&lt;p&gt;In the lines below I build the links that I am going to scrape. They’re all of the form:
&lt;code&gt;https://alt.org/nethack/gamesday.php?date=YYYYMMDD&lt;/code&gt; so it’s quite easy to create a list of
dates to scrape, for example, for the year 2017:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;link &amp;lt;- &amp;quot;https://alt.org/nethack/gamesday.php?date=&amp;quot;

dates &amp;lt;- seq(as.Date(&amp;quot;2017/01/01&amp;quot;), as.Date(&amp;quot;2017/12/31&amp;quot;), by = &amp;quot;day&amp;quot;) %&amp;gt;%
    str_remove_all(&amp;quot;-&amp;quot;)

links &amp;lt;- paste0(link, dates)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can easily scrape the data. To make extra sure that I will not have problems during the
scraping process, for example if on a given day no games were played (and thus there is no table
to scrape, which would result in an error) , I use the same trick as above by using &lt;code&gt;purrr::possibly()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(links, ~possibly(scrape_one_day, otherwise = NULL)(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The scraping process took a very long time. I scraped all the data by letting my computer run for
three days!&lt;/p&gt;
&lt;p&gt;After this long process, I import all the &lt;code&gt;.rds&lt;/code&gt; files into R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;path_to_data &amp;lt;- Sys.glob(&amp;quot;datasets/*.rds&amp;quot;)
nethack_data &amp;lt;- map(path_to_data, readRDS)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and take a look at one of them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack_data[[5812]] %&amp;gt;% 
  View()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s convert the “score” column to integer. For this, I will need to convert strings that look
like “12,232” to integers. I’ll write a short function to do this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_numeric &amp;lt;- function(string){
  str_remove_all(string, &amp;quot;,&amp;quot;) %&amp;gt;%
    as.numeric
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack_data &amp;lt;- nethack_data %&amp;gt;%
  map(~mutate(., score = to_numeric(score)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s merge the data into a single data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack_data &amp;lt;- bind_rows(nethack_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have a nice data frame, I will remove some columns and start the process of making a
packages. I remove the columns that I created and that are now useless (such as the &lt;code&gt;dumplog_links&lt;/code&gt;
column).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack_data &amp;lt;- nethack_data %&amp;gt;%
  select(rank, score, name, time, turns, lev_max, hp_max, role, race, gender, alignment, death,
         date, dumplog)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Export this to &lt;code&gt;.rds&lt;/code&gt; format, as it will be needed later:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(nethack_data, &amp;quot;nethack_data.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;making-a-package-to-share-your-data-with-the-world&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making a package to share your data with the world&lt;/h2&gt;
&lt;p&gt;As stated in the beginning of this post, I will walk you through the process of creating and
releasing your package on CRAN. However, the data I scraped was too large to be made available
as a CRAN package. But you can still get the data from Github (link is in the abstract at the
beginning of the post).&lt;/p&gt;
&lt;p&gt;Making a data package is a great way to learn how to make packages, because it is relatively easy
to do (for example, you do not need to write unit tests). First, let’s start a new project
in RStudio:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/r_package1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Then select “R package”:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/r_package2.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Then name your package, create a git repository and then click on “Create Project”:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/r_package3.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;RStudio wil open the &lt;code&gt;hello.R&lt;/code&gt; script which you can now modify. You got to learn from the best, so
I suggest that you modify &lt;code&gt;hello.R&lt;/code&gt; by taking inspiration from the &lt;code&gt;babynames&lt;/code&gt; package made by Hadley
Wickham which you can find &lt;a href=&#34;https://github.com/hadley/babynames/blob/master/R/data.R&#34;&gt;here&lt;/a&gt;.
You do not need the first two lines, and can focus on lines 4 to 13. Then, rename the script to
&lt;code&gt;data.R&lt;/code&gt;. This is how &lt;code&gt;{nethack}&#39;s&lt;/code&gt; looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; NetHack runs data.
#&amp;#39;
#&amp;#39; Data on NetHack runs scraped from https://alt.org/nethack/gamesday.php
#&amp;#39;
#&amp;#39; @format A data frame with 14 variables: \code{rank}, \code{score},
#&amp;#39;   \code{name}, \code{time}, \code{turns}, \code{lev_max}, \code{hp_max}, \code{role}, \code{race},
#&amp;#39;   \code{gender}, \code{alignment}, \code{death}, \code{date} and \code{dumplog}
#&amp;#39; \describe{
#&amp;#39; \item{rank}{The rank of the player on that day}
#&amp;#39; \item{score}{The score the player achieved on that run}
#&amp;#39; \item{name}{The name of the player}
#&amp;#39; \item{time}{The time the player took to finish the game}
#&amp;#39; \item{turns}{The number of turns the player played before finishing the game}
#&amp;#39; \item{lev_max}{First digit: the level the player died on; second digit: the deepest explored level}
#&amp;#39; \item{hp_max}{The maximum character health points the player achieved}
#&amp;#39; \item{role}{The role the player chose to play as}
#&amp;#39; \item{race}{The race the player chose to play as}
#&amp;#39; \item{gender}{The gender the playr chose to play as}
#&amp;#39; \item{alignement}{The alignement the playr chose to play as}
#&amp;#39; \item{death}{The reason of death of the character}
#&amp;#39; \item{date}{The date the game took place}
#&amp;#39; \item{dumplog}{The log of the end game; this is a list column}
#&amp;#39; }
&amp;quot;nethack&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The comments are special, the “#” is followed by a &lt;code&gt;&#39;&lt;/code&gt;; these are special comments that will be
parsed by &lt;code&gt;roxygen2::roxygenise()&lt;/code&gt; and converted to documentation files.&lt;/p&gt;
&lt;p&gt;Next is the &lt;code&gt;DESCRIPTION&lt;/code&gt; file. Here is how &lt;code&gt;{nethack}&lt;/code&gt;’s looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Package: nethack
Type: Package
Title: Data from the Video Game NetHack
Version: 0.1.0
Authors@R: person(&amp;quot;Bruno André&amp;quot;, &amp;quot;Rodrigues Coelho&amp;quot;, email = &amp;quot;bruno@brodrigues.co&amp;quot;,
                  role = c(&amp;quot;aut&amp;quot;, &amp;quot;cre&amp;quot;))
Description: Data from NetHack runs played between 2001 to 2018 on 
    &amp;lt;https://alt.org/nethack/&amp;gt;, a NetHack public server.
Depends: R (&amp;gt;= 2.10)
License: CC BY 4.0
Encoding: UTF-8
LazyData: true
RoxygenNote: 6.1.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adapt yours accordingly. I chose the license &lt;code&gt;CC BY 4.0&lt;/code&gt; because this was the licence under which
the original data was published. It is also a good idea to add a &lt;em&gt;Vignette&lt;/em&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::use_vignette(&amp;quot;the_nethack_package&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vignettes are very useful documentation with more details and examples.&lt;/p&gt;
&lt;p&gt;It is also good practice to add the script that was used to scrape the data. Such scripts go into
&lt;code&gt;data-raw/&lt;/code&gt;. Create this folder with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::use_data_raw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates the &lt;code&gt;data-raw/&lt;/code&gt; folder where I save the script that scrapes the data. Now is time to
put the data in the package. Start by importing the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nethack &amp;lt;- readRDS(&amp;quot;nethack_data.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To add the data to your package, you can use the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::use_data(nethack, compress = &amp;quot;xz&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create the &lt;code&gt;data/&lt;/code&gt; folder and put the data in there in the &lt;code&gt;.rda&lt;/code&gt; format. I use the “compress”
option to make the data smaller. You can now create the documentation by running:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;roxygen2::roxygenise()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pay attention to the log messages: you might need to remove files (for example the documentation
&lt;code&gt;hello.R&lt;/code&gt;, under the folder &lt;code&gt;man/&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now you can finaly run &lt;code&gt;R CMD Check&lt;/code&gt; by clicking the &lt;code&gt;Check&lt;/code&gt; button on the “Build” pane:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/r_package_check.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This will extensively check the package for &lt;code&gt;ERRORS&lt;/code&gt;, &lt;code&gt;WARNINGS&lt;/code&gt; and &lt;code&gt;NOTES&lt;/code&gt;. You need to make sure
that the check passes without any &lt;code&gt;ERRORS&lt;/code&gt; or &lt;code&gt;WARNINGS&lt;/code&gt; and try as much as possible to remove all
&lt;code&gt;NOTES&lt;/code&gt; too. If you cannot remove a &lt;code&gt;NOTE&lt;/code&gt;, for example in my case the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;checking installed package size ... NOTE
  installed size is 169.7Mb
  sub-directories of 1Mb or more:
    data  169.6Mb
R CMD check results
0 errors | 0 warnings  | 1 note &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should document it in a new file called &lt;code&gt;cran-comments.md&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Test environments
* local openSUSE Tumbleweed install, R 3.5.1
* win-builder (devel and release)

## R CMD check results
There were no ERRORs or WARNINGs.

There was 1 NOTE:

    *   installed size is 169.7Mb
sub-directories of 1Mb or more:
    data  169.6Mb

The dataset contains 17 years of NetHack games played, hence the size. This package will not be updated often (max once a year).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have eliminated all errors and warnings, you are almost ready to go.&lt;/p&gt;
&lt;p&gt;You need now to test the package on different platforms. This depends a bit on the system you run,
for me, because I run openSUSE (a GNU+Linux distribution) I have to test on Windows. This can be done
with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; devtools::build_win(version = &amp;quot;R-release&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; devtools::build_win(version = &amp;quot;R-devel&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Explain that you have tested your package on several platforms in the &lt;code&gt;cran-comments.md&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;Finally you can add a &lt;code&gt;README.md&lt;/code&gt; and a &lt;code&gt;NEWS.md&lt;/code&gt; file and start the process of publishing the
package on CRAN:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools:release()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want many more details than what you can find in this blog post, I urge you to read
“R Packages” by Hadley Wickham, which you can read for free &lt;a href=&#34;http://r-pkgs.had.co.nz/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Maps with pie charts on top of each administrative division: an example with Luxembourg&#39;s elections data</title>
      <link>https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Bw8g_1VEEL8&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/europe_map_lux.png&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;abstract&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;p&gt;You can find the data used in this blog post here: &lt;a href=&#34;https://github.com/b-rodrigues/elections_lux&#34; class=&#34;uri&#34;&gt;https://github.com/b-rodrigues/elections_lux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a follow up to a &lt;a href=&#34;https://www.brodrigues.co/blog/2018-10-21-lux_elections/&#34;&gt;previous blog post&lt;/a&gt;
where I extracted data of the 2018 Luxembourguish elections from Excel Workbooks.
Now that I have the data, I will create a map of Luxembourg by commune, with pie charts of the
results on top of each commune! To do this, I use good ol’ &lt;code&gt;{ggplot2}&lt;/code&gt; and another packages
called &lt;code&gt;{scatterpie}&lt;/code&gt;. As a bonus, I have added the code to extract the data from the 2013
elections from Excel. You’ll find this code in the appendix at the end of the blog post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Before importing the data for the elections of 2018, let’s install some packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;#39;rgeos&amp;#39;, type=&amp;#39;source&amp;#39;) # Dependency of rgdal
install.packages(&amp;#39;rgdal&amp;#39;, type=&amp;#39;source&amp;#39;) # To read in the shapefile&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These packages might be very tricky to install on OSX and Linux, but they’re needed to import the
shapefile of the country, which is needed to draw a map. So to make things easier, I have
created an &lt;code&gt;rds&lt;/code&gt; object, from the shapefile of Luxembourg, that you can import natively in R without
needing these two packages. But if you want to use them, here is how:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes &amp;lt;- readOGR(&amp;quot;Limadmin_SHP/LIMADM_COMMUNES.shp&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the way, you can download the shapefile for Luxembourg &lt;a href=&#34;https://data.public.lu/en/datasets/limites-administratives-du-grand-duche-de-luxembourg/#_&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll use my shapefile though (that you can download from the same github repo as the data):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes_df &amp;lt;- readRDS(&amp;quot;commune_shapefile.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s how it looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(communes_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       long      lat order  hole piece      group       id
## 1 91057.65 101536.6     1 FALSE     1 Beaufort.1 Beaufort
## 2 91051.79 101487.3     2 FALSE     1 Beaufort.1 Beaufort
## 3 91043.43 101461.7     3 FALSE     1 Beaufort.1 Beaufort
## 4 91043.37 101449.8     4 FALSE     1 Beaufort.1 Beaufort
## 5 91040.42 101432.1     5 FALSE     1 Beaufort.1 Beaufort
## 6 91035.44 101405.6     6 FALSE     1 Beaufort.1 Beaufort&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s load some packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;tidyxl&amp;quot;)
library(&amp;quot;ggplot2&amp;quot;)
library(&amp;quot;scatterpie&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, now, let’s import the elections results data, which is the output of
&lt;a href=&#34;https://www.brodrigues.co/blog/2018-10-21-lux_elections/&#34;&gt;last week’s blog post&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections &amp;lt;- read_csv(&amp;quot;elections_2018.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Party = col_character(),
##   Year = col_double(),
##   Variables = col_character(),
##   Values = col_double(),
##   locality = col_character(),
##   division = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will only focus on the data at the commune level, and only use the share of votes for each party:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_map &amp;lt;- elections %&amp;gt;%
    filter(division == &amp;quot;Commune&amp;quot;,
           Variables == &amp;quot;Pourcentage&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I need to make sure that the names of the communes are the same between the elections data
and the shapefile. Usual suspects are the “Haute-Sûre” and the “Redange-sur-Attert” communes,
but let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;locality_elections &amp;lt;- unique(elections_map$locality)
locality_shapefile &amp;lt;- unique(communes_df$id)

setdiff(locality_elections, locality_shapefile)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Lac de la Haute-Sûre&amp;quot; &amp;quot;Redange Attert&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, exactly as expected. I’ve had problems with the names of these two communes in the past already.
Let’s rename these two communes in the elections data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_map &amp;lt;- elections_map %&amp;gt;%
    mutate(commune = case_when(locality == &amp;quot;Lac de la Haute-Sûre&amp;quot; ~ &amp;quot;Lac de la Haute Sûre&amp;quot;,
                          locality == &amp;quot;Redange Attert&amp;quot; ~ &amp;quot;Redange&amp;quot;,
                          TRUE ~ locality))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I can select the relevant columns from the shapefile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes_df &amp;lt;- communes_df %&amp;gt;%
    select(long, lat, commune = id)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and from the elections data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_map &amp;lt;- elections_map %&amp;gt;%
    select(commune, Party, Variables, Values)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-data-on-a-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the data on a map&lt;/h2&gt;
&lt;p&gt;Now, for the type of plot I want to make, using the &lt;code&gt;{scatterpie}&lt;/code&gt; package, I need the data to be
in the wide format, not long. For this I will use &lt;code&gt;tidyr::spread()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_map &amp;lt;- elections_map %&amp;gt;% 
    spread(Party, Values)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is how the data looks now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(elections_map)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 102
## Variables: 10
## $ commune     &amp;lt;chr&amp;gt; &amp;quot;Beaufort&amp;quot;, &amp;quot;Bech&amp;quot;, &amp;quot;Beckerich&amp;quot;, &amp;quot;Berdorf&amp;quot;, &amp;quot;Bertran…
## $ Variables   &amp;lt;chr&amp;gt; &amp;quot;Pourcentage&amp;quot;, &amp;quot;Pourcentage&amp;quot;, &amp;quot;Pourcentage&amp;quot;, &amp;quot;Pource…
## $ ADR         &amp;lt;dbl&amp;gt; 0.12835106, 0.09848661, 0.08596748, 0.16339234, 0.04…
## $ CSV         &amp;lt;dbl&amp;gt; 0.2426239, 0.2945285, 0.3004751, 0.2604552, 0.290278…
## $ `déi gréng` &amp;lt;dbl&amp;gt; 0.15695672, 0.21699651, 0.24072721, 0.15619529, 0.15…
## $ `déi Lénk`  &amp;lt;dbl&amp;gt; 0.04043732, 0.03934808, 0.05435776, 0.02295273, 0.04…
## $ DP          &amp;lt;dbl&amp;gt; 0.15875393, 0.19394645, 0.12899689, 0.15444466, 0.30…
## $ KPL         &amp;lt;dbl&amp;gt; 0.015875393, 0.006519208, 0.004385164, 0.011476366, …
## $ LSAP        &amp;lt;dbl&amp;gt; 0.11771754, 0.11455180, 0.08852549, 0.16592103, 0.09…
## $ PIRATEN     &amp;lt;dbl&amp;gt; 0.13928411, 0.03562282, 0.09656496, 0.06516242, 0.04…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this to work, I need two datasets; one to draw the map (&lt;code&gt;commune_df&lt;/code&gt;) and one to draw the
pie charts over each commune, with the data to draw the charts, but also the position of where I
want the pie charts. For this, I will compute the average of the longitude and latitude, which
should be good enough:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scatterpie_data &amp;lt;- communes_df %&amp;gt;%
    group_by(commune) %&amp;gt;%
    summarise(long = mean(long),
              lat = mean(lat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s join the two datasets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_data &amp;lt;- left_join(scatterpie_data, elections_map, by = &amp;quot;commune&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have all the ingredients to finally plot the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
    geom_polygon(data = communes_df, aes(x = long, y = lat, group = commune), colour = &amp;quot;grey&amp;quot;, fill = NA) +
    geom_scatterpie(data = final_data, aes(x=long, y=lat, group=commune), 
                    cols = c(&amp;quot;ADR&amp;quot;, &amp;quot;CSV&amp;quot;, &amp;quot;déi gréng&amp;quot;, &amp;quot;déi Lénk&amp;quot;, &amp;quot;DP&amp;quot;, &amp;quot;KPL&amp;quot;, &amp;quot;LSAP&amp;quot;, &amp;quot;PIRATEN&amp;quot;)) +
    labs(title = &amp;quot;Share of total vote in each commune, 2018 elections&amp;quot;) +
    theme_void() +
    theme(legend.position = &amp;quot;bottom&amp;quot;,
          legend.title = element_blank(),
          legend.text = element_text(colour = &amp;quot;white&amp;quot;),
          plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
          plot.title = element_text(colour = &amp;quot;white&amp;quot;)) +
    scale_fill_manual(values = c(&amp;quot;ADR&amp;quot; = &amp;quot;#009dd1&amp;quot;,
                                 &amp;quot;CSV&amp;quot; = &amp;quot;#ee7d00&amp;quot;,
                                 &amp;quot;déi gréng&amp;quot; = &amp;quot;#45902c&amp;quot;,
                                 &amp;quot;déi Lénk&amp;quot; = &amp;quot;#e94067&amp;quot;,
                                 &amp;quot;DP&amp;quot; = &amp;quot;#002a54&amp;quot;,
                                 &amp;quot;KPL&amp;quot; = &amp;quot;#ff0000&amp;quot;,
                                 &amp;quot;LSAP&amp;quot; = &amp;quot;#ad3648&amp;quot;,
                                 &amp;quot;PIRATEN&amp;quot; = &amp;quot;#ad5ea9&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not too bad, but we can’t really read anything from the pie charts. I will now make their size
proportional to the number of voters in each commune. For this, I need to go back to the Excel
sheets, and look for the right cell:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/electeurs_inscrits.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;It will be easy to extract this info. It located in cell “E5”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_raw_2018 &amp;lt;- xlsx_cells(&amp;quot;leg-2018-10-14-22-58-09-737.xlsx&amp;quot;)

electors_commune &amp;lt;- elections_raw_2018 %&amp;gt;%
    filter(!(sheet %in% c(&amp;quot;Le Grand-Duché de Luxembourg&amp;quot;, &amp;quot;Centre&amp;quot;, &amp;quot;Est&amp;quot;, &amp;quot;Nord&amp;quot;, &amp;quot;Sud&amp;quot;, &amp;quot;Sommaire&amp;quot;))) %&amp;gt;%
    filter(address == &amp;quot;E5&amp;quot;) %&amp;gt;%
    select(sheet, numeric) %&amp;gt;%
    rename(commune = sheet,
           electors = numeric)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now add this to the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_data &amp;lt;- final_data %&amp;gt;% 
    full_join(electors_commune) %&amp;gt;%
    mutate(log_electors = log(electors) * 200)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;commune&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the last line, I create a new column called &lt;code&gt;log_electors&lt;/code&gt; that I then multiply by 200. This
will be useful later.&lt;/p&gt;
&lt;p&gt;Now I can add the &lt;code&gt;r&lt;/code&gt; argument inside the &lt;code&gt;aes()&lt;/code&gt; function on the third line, to make the pie chart
size proportional to the number of electors in that commune:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_polygon(data = communes_df, aes(x = long, y = lat, group = commune), colour = &amp;quot;grey&amp;quot;, fill = NA) +
    geom_scatterpie(data = final_data, aes(x=long, y=lat, group = commune, r = electors), 
                    cols = c(&amp;quot;ADR&amp;quot;, &amp;quot;CSV&amp;quot;, &amp;quot;déi gréng&amp;quot;, &amp;quot;déi Lénk&amp;quot;, &amp;quot;DP&amp;quot;, &amp;quot;KPL&amp;quot;, &amp;quot;LSAP&amp;quot;, &amp;quot;PIRATEN&amp;quot;)) +
    labs(title = &amp;quot;Share of total vote in each commune, 2018 elections&amp;quot;) +
    theme_void() +
    theme(legend.position = &amp;quot;bottom&amp;quot;,
          legend.title = element_blank(),
          legend.text = element_text(colour = &amp;quot;white&amp;quot;),
          plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
          plot.title = element_text(colour = &amp;quot;white&amp;quot;)) +
    scale_fill_manual(values = c(&amp;quot;ADR&amp;quot; = &amp;quot;#009dd1&amp;quot;,
                                 &amp;quot;CSV&amp;quot; = &amp;quot;#ee7d00&amp;quot;,
                                 &amp;quot;déi gréng&amp;quot; = &amp;quot;#45902c&amp;quot;,
                                 &amp;quot;déi Lénk&amp;quot; = &amp;quot;#182024&amp;quot;,
                                 &amp;quot;DP&amp;quot; = &amp;quot;#002a54&amp;quot;,
                                 &amp;quot;KPL&amp;quot; = &amp;quot;#ff0000&amp;quot;,
                                 &amp;quot;LSAP&amp;quot; = &amp;quot;#ad3648&amp;quot;,
                                 &amp;quot;PIRATEN&amp;quot; = &amp;quot;#ad5ea9&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 32 rows containing non-finite values (stat_pie).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, that was not a good idea! Perhaps the best option would be to have one map per circonscription.
For this, I need the list of communes by circonscription. This is available on Wikipedia. Here are
the lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;centre &amp;lt;- c(&amp;quot;Bissen&amp;quot;, &amp;quot;Colmar-Berg&amp;quot;, &amp;quot;Fischbach&amp;quot;, &amp;quot;Heffingen&amp;quot;, &amp;quot;Larochette&amp;quot;,
            &amp;quot;Lintgen&amp;quot;, &amp;quot;Lorentzweiler&amp;quot;, &amp;quot;Mersch&amp;quot;, &amp;quot;Nommern&amp;quot;, &amp;quot;Helperknapp&amp;quot;, &amp;quot;Bertrange&amp;quot;, &amp;quot;Contern&amp;quot;, 
            &amp;quot;Hesperange&amp;quot;, &amp;quot;Luxembourg&amp;quot;, &amp;quot;Niederanven&amp;quot;, &amp;quot;Sandweiler&amp;quot;, &amp;quot;Schuttrange&amp;quot;, &amp;quot;Steinsel&amp;quot;, 
            &amp;quot;Strassen&amp;quot;, &amp;quot;Walferdange&amp;quot;, &amp;quot;Weiler-la-Tour&amp;quot;)

est &amp;lt;- c(&amp;quot;Beaufort&amp;quot;, &amp;quot;Bech&amp;quot;, &amp;quot;Berdorf&amp;quot;, &amp;quot;Consdorf&amp;quot;, &amp;quot;Echternach&amp;quot;, &amp;quot;Rosport-Mompach&amp;quot;, &amp;quot;Waldbillig&amp;quot;,
         &amp;quot;Betzdorf&amp;quot;, &amp;quot;Biwer&amp;quot;, &amp;quot;Flaxweiler&amp;quot;, &amp;quot;Grevenmacher&amp;quot;, &amp;quot;Junglinster&amp;quot;, &amp;quot;Manternach&amp;quot;, &amp;quot;Mertert&amp;quot;,
         &amp;quot;Wormeldange&amp;quot;,&amp;quot;Bous&amp;quot;, &amp;quot;Dalheim&amp;quot;, &amp;quot;Lenningen&amp;quot;, &amp;quot;Mondorf-les-Bains&amp;quot;, &amp;quot;Remich&amp;quot;, &amp;quot;Schengen&amp;quot;,
         &amp;quot;Stadtbredimus&amp;quot;, &amp;quot;Waldbredimus&amp;quot;)

nord &amp;lt;- c(&amp;quot;Clervaux&amp;quot;, &amp;quot;Parc Hosingen&amp;quot;, &amp;quot;Troisvierges&amp;quot;, &amp;quot;Weiswampach&amp;quot;, &amp;quot;Wincrange&amp;quot;, &amp;quot;Bettendorf&amp;quot;, 
          &amp;quot;Bourscheid&amp;quot;, &amp;quot;Diekirch&amp;quot;, &amp;quot;Erpeldange-sur-Sûre&amp;quot;, &amp;quot;Ettelbruck&amp;quot;, &amp;quot;Feulen&amp;quot;, &amp;quot;Mertzig&amp;quot;, &amp;quot;Reisdorf&amp;quot;, 
          &amp;quot;Schieren&amp;quot;, &amp;quot;Vallée de l&amp;#39;Ernz&amp;quot;, &amp;quot;Beckerich&amp;quot;, &amp;quot;Ell&amp;quot;, &amp;quot;Grosbous&amp;quot;, &amp;quot;Préizerdaul&amp;quot;, 
          &amp;quot;Rambrouch&amp;quot;, &amp;quot;Redange&amp;quot;, &amp;quot;Saeul&amp;quot;, &amp;quot;Useldange&amp;quot;, &amp;quot;Vichten&amp;quot;, &amp;quot;Wahl&amp;quot;, &amp;quot;Putscheid&amp;quot;, &amp;quot;Tandel&amp;quot;,
          &amp;quot;Vianden&amp;quot;, &amp;quot;Boulaide&amp;quot;, &amp;quot;Esch-sur-Sûre&amp;quot;, &amp;quot;Goesdorf&amp;quot;, &amp;quot;Kiischpelt&amp;quot;, &amp;quot;Lac de la Haute Sûre&amp;quot;,
          &amp;quot;Wiltz&amp;quot;, &amp;quot;Winseler&amp;quot;)

sud &amp;lt;- c(&amp;quot;Dippach&amp;quot;, &amp;quot;Garnich&amp;quot;, &amp;quot;Käerjeng&amp;quot;, &amp;quot;Kehlen&amp;quot;, &amp;quot;Koerich&amp;quot;, &amp;quot;Kopstal&amp;quot;, &amp;quot;Mamer&amp;quot;, 
         &amp;quot;Habscht&amp;quot;, &amp;quot;Steinfort&amp;quot;, &amp;quot;Bettembourg&amp;quot;, &amp;quot;Differdange&amp;quot;, &amp;quot;Dudelange&amp;quot;, &amp;quot;Esch-sur-Alzette&amp;quot;, 
         &amp;quot;Frisange&amp;quot;, &amp;quot;Kayl&amp;quot;, &amp;quot;Leudelange&amp;quot;, &amp;quot;Mondercange&amp;quot;, &amp;quot;Pétange&amp;quot;, &amp;quot;Reckange-sur-Mess&amp;quot;, &amp;quot;Roeser&amp;quot;,
         &amp;quot;Rumelange&amp;quot;, &amp;quot;Sanem&amp;quot;, &amp;quot;Schifflange&amp;quot;)

circonscriptions &amp;lt;- list(&amp;quot;centre&amp;quot; = centre, &amp;quot;est&amp;quot; = est,
                         &amp;quot;nord&amp;quot; = nord, &amp;quot;sud&amp;quot; = sud)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I can make one map per circonscription. First, let’s split the data sets by circonscription:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes_df_by_circonscription &amp;lt;- circonscriptions %&amp;gt;%
    map(~filter(communes_df, commune %in% .))

final_data_by_circonscription &amp;lt;- circonscriptions %&amp;gt;%
    map(~filter(final_data, commune %in% .))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By using &lt;code&gt;pmap()&lt;/code&gt;, I can reuse the code to generate the plot to each element of the two lists.
This is nice because I do not need to copy and paste the code 4 times:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pmap(list(x = communes_df_by_circonscription,
          y = final_data_by_circonscription,
          z = names(communes_df_by_circonscription)),
     function(x, y, z){
         ggplot() +
        geom_polygon(data = x, aes(x = long, y = lat, group = commune), 
                     colour = &amp;quot;grey&amp;quot;, fill = NA) +
        geom_scatterpie(data = y, aes(x=long, y=lat, group = commune), 
                        cols = c(&amp;quot;ADR&amp;quot;, &amp;quot;CSV&amp;quot;, &amp;quot;déi gréng&amp;quot;, &amp;quot;déi Lénk&amp;quot;, &amp;quot;DP&amp;quot;, &amp;quot;KPL&amp;quot;, &amp;quot;LSAP&amp;quot;, &amp;quot;PIRATEN&amp;quot;)) +
        labs(title = paste0(&amp;quot;Share of total vote in each commune, 2018 elections for circonscription &amp;quot;, z)) +
        theme_void() +
        theme(legend.position = &amp;quot;bottom&amp;quot;,
              legend.title = element_blank(),
              legend.text = element_text(colour = &amp;quot;white&amp;quot;),
              plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
              plot.title = element_text(colour = &amp;quot;white&amp;quot;)) + 
        scale_fill_manual(values = c(&amp;quot;ADR&amp;quot; = &amp;quot;#009dd1&amp;quot;,
                                     &amp;quot;CSV&amp;quot; = &amp;quot;#ee7d00&amp;quot;,
                                     &amp;quot;déi gréng&amp;quot; = &amp;quot;#45902c&amp;quot;,
                                     &amp;quot;déi Lénk&amp;quot; = &amp;quot;#182024&amp;quot;,
                                     &amp;quot;DP&amp;quot; = &amp;quot;#002a54&amp;quot;,
                                     &amp;quot;KPL&amp;quot; = &amp;quot;#ff0000&amp;quot;,
                                     &amp;quot;LSAP&amp;quot; = &amp;quot;#ad3648&amp;quot;,
                                     &amp;quot;PIRATEN&amp;quot; = &amp;quot;#ad5ea9&amp;quot;))
     }
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $centre&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $est&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-24-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $nord&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-24-3.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $sud&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-24-4.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I created an anonymous function of three argument, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt;. If you are unfamiliar with
&lt;code&gt;pmap()&lt;/code&gt;, study the above code closely. If you have questions, do not hesitate to reach out!&lt;/p&gt;
&lt;p&gt;The pie charts are still quite small, but if I try to change the size of the pie charts,
I’ll have the same problem as before: inside the same circonscription, some communes have really a
lot of electors, and some a very small number. Perhaps I can try with the log of the electors?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pmap(list(x = communes_df_by_circonscription,
          y = final_data_by_circonscription,
          z = names(communes_df_by_circonscription)),
     function(x, y, z){
         ggplot() +
        geom_polygon(data = x, aes(x = long, y = lat, group = commune), 
                     colour = &amp;quot;grey&amp;quot;, fill = NA) +
        geom_scatterpie(data = y, aes(x=long, y=lat, group = commune, r = log_electors), 
                        cols = c(&amp;quot;ADR&amp;quot;, &amp;quot;CSV&amp;quot;, &amp;quot;déi gréng&amp;quot;, &amp;quot;déi Lénk&amp;quot;, &amp;quot;DP&amp;quot;, &amp;quot;KPL&amp;quot;, &amp;quot;LSAP&amp;quot;, &amp;quot;PIRATEN&amp;quot;)) +
        labs(title = paste0(&amp;quot;Share of total vote in each commune, 2018 elections for circonscription &amp;quot;, z)) +
        theme_void() +
        theme(legend.position = &amp;quot;bottom&amp;quot;,
              legend.title = element_blank(),
              legend.text = element_text(colour = &amp;quot;white&amp;quot;),
              plot.background = element_rect(&amp;quot;#272b30&amp;quot;),
              plot.title = element_text(colour = &amp;quot;white&amp;quot;)) + 
        scale_fill_manual(values = c(&amp;quot;ADR&amp;quot; = &amp;quot;#009dd1&amp;quot;,
                                     &amp;quot;CSV&amp;quot; = &amp;quot;#ee7d00&amp;quot;,
                                     &amp;quot;déi gréng&amp;quot; = &amp;quot;#45902c&amp;quot;,
                                     &amp;quot;déi Lénk&amp;quot; = &amp;quot;#182024&amp;quot;,
                                     &amp;quot;DP&amp;quot; = &amp;quot;#002a54&amp;quot;,
                                     &amp;quot;KPL&amp;quot; = &amp;quot;#ff0000&amp;quot;,
                                     &amp;quot;LSAP&amp;quot; = &amp;quot;#ad3648&amp;quot;,
                                     &amp;quot;PIRATEN&amp;quot; = &amp;quot;#ad5ea9&amp;quot;))
     }
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $centre&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $est&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-25-2.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $nord&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 16 rows containing non-finite values (stat_pie).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-25-3.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## $sud&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-27-lux_elections_analysis_files/figure-html/unnamed-chunk-25-4.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks better now!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Having data in a machine readable format is really important. The amount of code I had to write
to go from the Excel Workbooks that contained the data to this plots is quite large, but if the
data was in a machine readable format to start with, I could have focused on the plots immediately.&lt;/p&gt;
&lt;p&gt;The good thing is that I got to practice my skills and discovered &lt;code&gt;{scatterpie}&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;Hope you enjoyed! If you found this blog post useful, you might want to follow
me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates or
&lt;a href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;buy me an espresso&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;p&gt;The following lines of code extract the data (from the 2013 elections) from the Excel Workbooks
that can be found in Luxembourguish &lt;a href=&#34;https://data.public.lu/fr/datasets/elections-legislatives-2013-donnees-officieuses/#_&#34;&gt;Open Data Portal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I will not comment them, as they work in a similar way than in the previous blog post where I
extracted the data from the 2018 elections. The only difference, is that the sheet with the
national level data was totally different, so I did not extract it. The first reason is because
I don’t need it for this blog post, the second is because I was lazy. For me, that’s two pretty
good reasons not to do something. If you have a question concerning the code below, don’t
hesitate to reach out though!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;tidyxl&amp;quot;)
library(&amp;quot;brotools&amp;quot;)

path &amp;lt;- Sys.glob(&amp;quot;content/blog/2013*xlsx&amp;quot;)[-5]

elections_raw_2013 &amp;lt;- map(path, xlsx_cells) %&amp;gt;%
    map(~filter(., sheet != &amp;quot;Sommaire&amp;quot;))

elections_sheets_2013 &amp;lt;- map(map(path, xlsx_sheet_names), ~`%-l%`(., &amp;quot;Sommaire&amp;quot;))

list_targets &amp;lt;- list(&amp;quot;Centre&amp;quot; = seq(9, 32),
                    &amp;quot;Est&amp;quot; = seq(9, 18),
                    &amp;quot;Nord&amp;quot; = seq(9, 20),
                    &amp;quot;Sud&amp;quot; = seq(9, 34))

position_parties_national &amp;lt;- seq(1, 24, by = 3)

extract_party &amp;lt;- function(dataset, starting_col, target_rows){
    
    almost_clean &amp;lt;- dataset %&amp;gt;%
        filter(row %in% target_rows) %&amp;gt;%
        filter(col %in% c(starting_col, starting_col + 1)) %&amp;gt;%
        select(character, numeric) %&amp;gt;%
        fill(numeric, .direction = &amp;quot;up&amp;quot;) %&amp;gt;%
        filter(!is.na(character))
    
    party_name &amp;lt;- almost_clean$character[1]
    
    almost_clean$character[1] &amp;lt;- &amp;quot;Pourcentage&amp;quot;
    
    almost_clean$party &amp;lt;- party_name
    
    colnames(almost_clean) &amp;lt;- c(&amp;quot;Variables&amp;quot;, &amp;quot;Values&amp;quot;, &amp;quot;Party&amp;quot;)
    
    almost_clean %&amp;gt;%
        mutate(Year = 2013) %&amp;gt;%
        select(Party, Year, Variables, Values)
    
}


# Treat one district

extract_district &amp;lt;- function(dataset, sheets, target_rows, position_parties_national){

    list_data_districts &amp;lt;- map(sheets, ~filter(.data = dataset, sheet == .)) 

    elections_districts_2013 &amp;lt;- map(.x = list_data_districts,
                                    ~map_df(position_parties_national, extract_party, dataset = .x, target_rows = target_rows))

    map2(.y = elections_districts_2013, .x = sheets,
         ~mutate(.y, locality = .x, division = &amp;quot;Commune&amp;quot;, Year = &amp;quot;2013&amp;quot;)) %&amp;gt;%
        bind_rows()
}

elections_2013 &amp;lt;- pmap_dfr(list(x = elections_raw_2013, 
          y = elections_sheets_2013,
          z = list_targets), 
     function(x, y, z){
         map_dfr(position_parties_national, 
             ~extract_district(dataset = x, sheets = y, target_rows = z, position_parties_national = .))
     })

# Correct districts
elections_2013 &amp;lt;- elections_2013 %&amp;gt;%
    mutate(division = case_when(locality == &amp;quot;CENTRE&amp;quot; ~ &amp;quot;Electoral district&amp;quot;,
                                locality == &amp;quot;EST&amp;quot; ~ &amp;quot;Electoral district&amp;quot;,
                                locality == &amp;quot;NORD&amp;quot; ~ &amp;quot;Electoral district&amp;quot;,
                                locality == &amp;quot;SUD&amp;quot; ~ &amp;quot;Electoral district&amp;quot;,
                                TRUE ~ division))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting the data from the Luxembourguish elections out of Excel</title>
      <link>https://www.brodrigues.co/blog/2018-10-21-lux_elections/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-10-21-lux_elections/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=yjzUxDhuXig&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/gambia.png&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this blog post, similar to a &lt;a href=&#34;https://www.brodrigues.co/blog/2018-09-11-human_to_machine/&#34;&gt;previous blog post&lt;/a&gt;
I am going to show you how we can go from an Excel workbook that contains data to flat file. I will
taking advantage of the structure of the tables inside the Excel sheets by writing a function
that extracts the tables and then mapping it to each sheet!&lt;/p&gt;
&lt;p&gt;Last week, October 14th, Luxembourguish nationals went to the polls to elect the Grand Duke! No,
actually, the Grand Duke does not get elected. But Luxembourguish citizen did go to the polls
to elect the new members of the Chamber of Deputies (a sort of parliament if you will).
The way the elections work in Luxembourg is quite interesting; you can vote for a party, or vote
for individual candidates from different parties. The candidates that get the most votes will
then seat in the parliament. If you vote for a whole party,
each of the candidates get a vote. You get as many votes as there are candidates to vote for. So,
for example, if you live in the capital city, also called Luxembourg, you get 21 votes to distribute.
You could decide to give 10 votes to 10 candidates of party A and 11 to 11 candidates of party B.
Why 21 votes? The chamber of Deputies is made up 60 deputies, and the country is divided into four
legislative circonscriptions. So each voter in a circonscription gets an amount of votes that is
proportional to the population size of that circonscription.&lt;/p&gt;
&lt;p&gt;Now you certainly wonder why I put the flag of Gambia on top of this post? This is because the
government that was formed after the 2013 elections was made up of a coalition of 3 parties;
the Luxembourg Socialist Worker’s Party, the Democratic Party and The Greens.
The LSAP managed to get 13 seats in the Chamber, while the DP got 13 and The Greens 6,
meaning 32 seats out of 60. So because they made this coalition, they could form the government,
and this coalition was named the Gambia coalition because of the colors of these 3 parties:
red, blue and green. If you want to take a look at the ballot from 2013 for the southern circonscription,
click &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Specimen_Elections_legislatives_Luxembourg_2013.png/1280px-Specimen_Elections_legislatives_Luxembourg_2013.png&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now that you have the context, we can go back to some data science. The results of the elections
of last week can be found on Luxembourg’s Open Data portal, right &lt;a href=&#34;https://data.public.lu/fr/datasets/elections-legislatives-du-14-octobre-2018-donnees-officieuses/&#34;&gt;here&lt;/a&gt;.
The data is trapped inside Excel sheets; just like I explained in a &lt;a href=&#34;https://www.brodrigues.co/blog/2018-09-11-human_to_machine/&#34;&gt;previous blog post&lt;/a&gt;
the data is easily read by human, but not easily digested by any type of data analysis software.
So I am going to show you how we are going from this big Excel workbook to a flat file.&lt;/p&gt;
&lt;p&gt;First of all, if you open the Excel workbook, you will notice that there are a lot of sheets; there
is one for the whole country, named “Le Grand-Duché de Luxembourg”, one for the four circonscriptions,
“Centre”, “Nord”, “Sud”, “Est” and 102 more for each &lt;strong&gt;commune&lt;/strong&gt; of the country (a commune is an
administrative division). However, the tables are all very similarly shaped, and roughly at the
same position.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/elections_data.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This is good, because we can write a function to extracts the data and then map it over
all the sheets. First, let’s load some packages and the data for the country:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;tidyxl&amp;quot;)
library(&amp;quot;brotools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# National Level 2018
elections_raw_2018 &amp;lt;- xlsx_cells(&amp;quot;leg-2018-10-14-22-58-09-737.xlsx&amp;quot;,
                        sheets = &amp;quot;Le Grand-Duché de Luxembourg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{brotools}&lt;/code&gt; is my own package. You can install it with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/brotools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;it contains a function that I will use down below. The function I wrote to extract the tables
is not very complex, but requires that you are familiar with how &lt;code&gt;{tidyxl}&lt;/code&gt; imports Excel workbooks.
So if you are not familiar with it, study the imported data frame for a few minutes. It will make
understanding the next function easier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_party &amp;lt;- function(dataset, starting_col, target_rows){

    almost_clean &amp;lt;- dataset %&amp;gt;%
        filter(row %in% target_rows) %&amp;gt;%
        filter(col %in% c(starting_col, starting_col + 1)) %&amp;gt;%
        select(character, numeric) %&amp;gt;%
        fill(numeric, .direction = &amp;quot;up&amp;quot;) %&amp;gt;%
        filter(!is.na(character))

    party_name &amp;lt;- almost_clean$character[1] %&amp;gt;%
        str_split(&amp;quot;-&amp;quot;, simplify = TRUE) %&amp;gt;%
        .[2] %&amp;gt;%
        str_trim()

    almost_clean$character[1] &amp;lt;- &amp;quot;Pourcentage&amp;quot;

    almost_clean$party &amp;lt;- party_name

    colnames(almost_clean) &amp;lt;- c(&amp;quot;Variables&amp;quot;, &amp;quot;Values&amp;quot;, &amp;quot;Party&amp;quot;)

    almost_clean %&amp;gt;%
        mutate(Year = 2018) %&amp;gt;%
        select(Party, Year, Variables, Values)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function has three arguments, &lt;code&gt;dataset&lt;/code&gt;, &lt;code&gt;starting_col&lt;/code&gt; and &lt;code&gt;target_rows&lt;/code&gt;. &lt;code&gt;dataset&lt;/code&gt; is the
data I loaded with &lt;code&gt;xlsx_cells&lt;/code&gt; from the &lt;code&gt;{tidyxl}&lt;/code&gt; package. I think the following picture illustrates
easily what the function does:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/elections_logic.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;So the function first filters only the rows we are interested in, then the cols. I then select
the columns I want which are called &lt;code&gt;character&lt;/code&gt; and &lt;code&gt;numeric&lt;/code&gt; (if the Excel cell contains characters then
you will find them in the character column, if it contains numbers you will them in the numeric
column), then I fill the empty cells with the values from the &lt;code&gt;numeric&lt;/code&gt; column and the I remove
the NA’s. These two last steps might not be so clear; this is how the data looks like up until the
&lt;code&gt;select()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; elections_raw_2018 %&amp;gt;%
+     filter(row %in% seq(11,19)) %&amp;gt;%
+     filter(col %in% c(1, 2)) %&amp;gt;%
+     select(character, numeric)
# A tibble: 18 x 2
   character                       numeric
   &amp;lt;chr&amp;gt;                             &amp;lt;dbl&amp;gt;
 1 1 - PIRATEN - PIRATEN           NA     
 2 NA                               0.0645
 3 Suffrage total                  NA     
 4 NA                          227549     
 5 Suffrages de liste              NA     
 6 NA                          181560     
 7 Suffrage nominatifs             NA     
 8 NA                           45989     
 9 Pourcentage pondéré             NA     
10 NA                               0.0661
11 Suffrage total pondéré          NA     
12 NA                           13394.    
13 Suffrages de liste pondéré      NA     
14 NA                           10308     
15 Suffrage nominatifs pondéré     NA     
16 NA                            3086.    
17 Mandats attribués               NA     
18 NA                               2  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So by filling the NA’s in the numeric the data now looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; elections_raw_2018 %&amp;gt;%
+     filter(row %in% seq(11,19)) %&amp;gt;%
+     filter(col %in% c(1, 2)) %&amp;gt;%
+     select(character, numeric) %&amp;gt;%
+     fill(numeric, .direction = &amp;quot;up&amp;quot;)
# A tibble: 18 x 2
   character                       numeric
   &amp;lt;chr&amp;gt;                             &amp;lt;dbl&amp;gt;
 1 1 - PIRATEN - PIRATEN            0.0645
 2 NA                               0.0645
 3 Suffrage total              227549     
 4 NA                          227549     
 5 Suffrages de liste          181560     
 6 NA                          181560     
 7 Suffrage nominatifs          45989     
 8 NA                           45989     
 9 Pourcentage pondéré              0.0661
10 NA                               0.0661
11 Suffrage total pondéré       13394.    
12 NA                           13394.    
13 Suffrages de liste pondéré   10308     
14 NA                           10308     
15 Suffrage nominatifs pondéré   3086.    
16 NA                            3086.    
17 Mandats attribués                2     
18 NA                               2 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then I filter out the NA’s from the character column, and that’s almost it! I simply need
to add a new column with the party’s name and rename the other columns. I also add a “Year” colmun.&lt;/p&gt;
&lt;p&gt;Now, each party will have a different starting column. The table with the data for the first party
starts on column 1, for the second party it starts on column 4, column 7 for the third party…
So the following vector contains all the starting columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;position_parties_national &amp;lt;- seq(1, 24, by = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(If you study the Excel workbook closely, you will notice that I do not extract the last two parties.
This is because these parties were not present in all of the 4 circonscriptions and are very, very,
very small.)&lt;/p&gt;
&lt;p&gt;The target rows are always the same, from 11 to 19. Now, I simply need to map this function to
this list of positions and I get the data for all the parties:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_national_2018 &amp;lt;- map_df(position_parties_national, extract_party, 
                         dataset = elections_raw_2018, target_rows = seq(11, 19)) %&amp;gt;%
    mutate(locality = &amp;quot;Grand-Duchy of Luxembourg&amp;quot;, division = &amp;quot;National&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also added the &lt;code&gt;locality&lt;/code&gt; and &lt;code&gt;division&lt;/code&gt; columns to the data.&lt;/p&gt;
&lt;p&gt;Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(elections_national_2018)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 72
## Variables: 6
## $ Party     &amp;lt;chr&amp;gt; &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;,…
## $ Year      &amp;lt;dbl&amp;gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, …
## $ Variables &amp;lt;chr&amp;gt; &amp;quot;Pourcentage&amp;quot;, &amp;quot;Suffrage total&amp;quot;, &amp;quot;Suffrages de liste&amp;quot;,…
## $ Values    &amp;lt;dbl&amp;gt; 6.446204e-02, 2.275490e+05, 1.815600e+05, 4.598900e+04…
## $ locality  &amp;lt;chr&amp;gt; &amp;quot;Grand-Duchy of Luxembourg&amp;quot;, &amp;quot;Grand-Duchy of Luxembour…
## $ division  &amp;lt;chr&amp;gt; &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;Natio…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Very nice.&lt;/p&gt;
&lt;p&gt;Now we need to do the same for the 4 electoral circonscriptions. First, let’s load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Electoral districts 2018
districts &amp;lt;- c(&amp;quot;Centre&amp;quot;, &amp;quot;Nord&amp;quot;, &amp;quot;Sud&amp;quot;, &amp;quot;Est&amp;quot;)

elections_district_raw_2018 &amp;lt;- xlsx_cells(&amp;quot;leg-2018-10-14-22-58-09-737.xlsx&amp;quot;,
                                      sheets = districts)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now things get trickier. Remember I said that the number of seats is proportional to the population
of each circonscription? We simply can’t use the same target rows as before. For example, for the
“Centre” circonscription, the target rows go from 12 to 37, but for the “Est” circonscription
only from 12 to 23. Ideally, we would need a function that would return the target rows.&lt;/p&gt;
&lt;p&gt;This is that function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The target rows I need to extract are different from district to district
get_target_rows &amp;lt;- function(dataset, sheet_to_extract, reference_address){

    last_row &amp;lt;- dataset %&amp;gt;%
        filter(sheet == sheet_to_extract) %&amp;gt;%
        filter(address == reference_address) %&amp;gt;%
        pull(numeric)

    seq(12, (11 + 5 + last_row))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function needs a &lt;code&gt;dataset&lt;/code&gt;, a &lt;code&gt;sheet_to_extract&lt;/code&gt; and a &lt;code&gt;reference_address&lt;/code&gt;. The reference
address is a cell that actually contains the number of seats in that circonscription, in our
case “B5”. We can easily get the list of target rows now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get the target rows
list_targets &amp;lt;- map(districts, get_target_rows, dataset = elections_district_raw_2018, 
                    reference_address = &amp;quot;B5&amp;quot;)

list_targets&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##  [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
## [24] 35 36 37
## 
## [[2]]
##  [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25
## 
## [[3]]
##  [1] 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34
## [24] 35 36 37 38 39
## 
## [[4]]
##  [1] 12 13 14 15 16 17 18 19 20 21 22 23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s split the data we imported into a list, where each element of the list is a dataframe
with the data from one circonscription:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_data_districts &amp;lt;- map(districts, ~filter(.data = elections_district_raw_2018, sheet == .)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can easily map the function I defined above, &lt;code&gt;extract_party&lt;/code&gt; to this list of datasets. Well,
I say easily, but it’s a bit more complicated than before because I have now a list of datasets
and a list of target rows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_district_2018 &amp;lt;- map2(.x = list_data_districts, .y = list_targets,
     ~map_df(position_parties_national, extract_party, dataset = .x, target_rows = .y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The way to understand this is that for each element of &lt;code&gt;list_data_districts&lt;/code&gt; and &lt;code&gt;list_targets&lt;/code&gt;,
I have to map &lt;code&gt;extract_party&lt;/code&gt; to each element of &lt;code&gt;position_parties_national&lt;/code&gt;. This gives the intented
result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_district_2018&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 208 x 4
##    Party    Year Variables               Values
##    &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                    &amp;lt;dbl&amp;gt;
##  1 PIRATEN  2018 Pourcentage             0.0514
##  2 PIRATEN  2018 CLEMENT Sven (1)     8007     
##  3 PIRATEN  2018 WEYER Jerry (2)      3446     
##  4 PIRATEN  2018 CLEMENT Pascal (3)   3418     
##  5 PIRATEN  2018 KUNAKOVA Lucie (4)   2860     
##  6 PIRATEN  2018 WAMPACH Jo (14)      2693     
##  7 PIRATEN  2018 LAUX Cynthia (6)     2622     
##  8 PIRATEN  2018 ISEKIN Christian (5) 2610     
##  9 PIRATEN  2018 SCHWEICH Georges (9) 2602     
## 10 PIRATEN  2018 LIESCH Mireille (8)  2551     
## # … with 198 more rows
## 
## [[2]]
## # A tibble: 112 x 4
##    Party    Year Variables                             Values
##    &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                                  &amp;lt;dbl&amp;gt;
##  1 PIRATEN  2018 Pourcentage                           0.0767
##  2 PIRATEN  2018 COLOMBERA Jean (2)                 5074     
##  3 PIRATEN  2018 ALLARD Ben (1)                     4225     
##  4 PIRATEN  2018 MAAR Andy (3)                      2764     
##  5 PIRATEN  2018 GINTER Joshua (8)                  2536     
##  6 PIRATEN  2018 DASBACH Angelika (4)               2473     
##  7 PIRATEN  2018 GRÜNEISEN Sam (6)                  2408     
##  8 PIRATEN  2018 BAUMANN Roy (5)                    2387     
##  9 PIRATEN  2018 CONRAD Pierre (7)                  2280     
## 10 PIRATEN  2018 TRAUT ép. MOLITOR Angela Maria (9) 2274     
## # … with 102 more rows
## 
## [[3]]
## # A tibble: 224 x 4
##    Party    Year Variables                    Values
##    &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                         &amp;lt;dbl&amp;gt;
##  1 PIRATEN  2018 Pourcentage                  0.0699
##  2 PIRATEN  2018 GOERGEN Marc (1)          9818     
##  3 PIRATEN  2018 FLOR Starsky (2)          6737     
##  4 PIRATEN  2018 KOHL Martine (3)          6071     
##  5 PIRATEN  2018 LIESCH Camille (4)        6025     
##  6 PIRATEN  2018 KOHL Sylvie (6)           5628     
##  7 PIRATEN  2018 WELTER Christian (5)      5619     
##  8 PIRATEN  2018 DA GRAÇA DIAS Yanick (10) 5307     
##  9 PIRATEN  2018 WEBER Jules (7)           5301     
## 10 PIRATEN  2018 CHMELIK Libor (8)         5247     
## # … with 214 more rows
## 
## [[4]]
## # A tibble: 96 x 4
##    Party    Year Variables                           Values
##    &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                                &amp;lt;dbl&amp;gt;
##  1 PIRATEN  2018 Pourcentage                         0.0698
##  2 PIRATEN  2018 FRÈRES Daniel (1)                4152     
##  3 PIRATEN  2018 CLEMENT Jill (7)                 1943     
##  4 PIRATEN  2018 HOUDREMONT Claire (2)            1844     
##  5 PIRATEN  2018 BÖRGER Nancy (3)                 1739     
##  6 PIRATEN  2018 MARTINS DOS SANTOS Catarina (6)  1710     
##  7 PIRATEN  2018 BELLEVILLE Tatjana (4)           1687     
##  8 PIRATEN  2018 CONTRERAS Gerald (5)             1687     
##  9 PIRATEN  2018 Suffrages total                 14762     
## 10 PIRATEN  2018 Suffrages de liste              10248     
## # … with 86 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now need to add the &lt;code&gt;locality&lt;/code&gt; and &lt;code&gt;division&lt;/code&gt; columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_district_2018 &amp;lt;- map2(.y = elections_district_2018, .x = districts, 
     ~mutate(.y, locality = .x, division = &amp;quot;Electoral district&amp;quot;)) %&amp;gt;%
    bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’re almost done! Now we need to do the same for the 102 remaining sheets, one for each &lt;strong&gt;commune&lt;/strong&gt;
of Luxembourg. This will now go very fast, because we got all the building blocks from before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;communes &amp;lt;- xlsx_sheet_names(&amp;quot;leg-2018-10-14-22-58-09-737.xlsx&amp;quot;)

communes &amp;lt;- communes %-l% 
    c(&amp;quot;Le Grand-Duché de Luxembourg&amp;quot;, &amp;quot;Centre&amp;quot;, &amp;quot;Est&amp;quot;, &amp;quot;Nord&amp;quot;, &amp;quot;Sud&amp;quot;, &amp;quot;Sommaire&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let me introduce the following function: &lt;code&gt;%-l%&lt;/code&gt;. This function removes elements from lists:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;) %-l% c(&amp;quot;a&amp;quot;, &amp;quot;d&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;b&amp;quot; &amp;quot;c&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can think of it as “minus for lists”. This is called an infix operator.&lt;/p&gt;
&lt;p&gt;So this function is very useful to get the list of communes, and is part of my package, &lt;code&gt;{brotools}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As before, I load the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_communes_raw_2018 &amp;lt;- xlsx_cells(&amp;quot;leg-2018-10-14-22-58-09-737.xlsx&amp;quot;,
                                 sheets = communes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then get my list of targets, but I need to change the reference address. It’s “B8” now, not “B7”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get the target rows
list_targets &amp;lt;- map(communes, get_target_rows, 
                    dataset = elections_communes_raw_2018, reference_address = &amp;quot;B8&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now create a list of communes by mapping a filter function to the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_data_communes &amp;lt;- map(communes, ~filter(.data = elections_communes_raw_2018, sheet == .)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And just as before, I get the data I need by using &lt;code&gt;extract_party&lt;/code&gt;, and adding the “locality” and
“division” columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elections_communes_2018 &amp;lt;- map2(.x = list_data_communes, .y = list_targets,
                                ~map_df(position_parties_national, extract_party, dataset = .x, target_rows = .y))

elections_communes_2018 &amp;lt;- map2(.y = elections_communes_2018, .x = communes,
                                ~mutate(.y, locality = .x, division = &amp;quot;Commune&amp;quot;)) %&amp;gt;%
    bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The steps are so similar for the four circonscriptions and for the 102 &lt;strong&gt;communes&lt;/strong&gt; that I could
have write a big wrapper function and the use it for the circonscription and &lt;strong&gt;communes&lt;/strong&gt; at once.
But I was lazy.&lt;/p&gt;
&lt;p&gt;Finally, I bind everything together and have a nice, tidy, flat file:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Final results

elections_2018 &amp;lt;- bind_rows(list(elections_national_2018, elections_district_2018, elections_communes_2018))

glimpse(elections_2018)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 15,544
## Variables: 6
## $ Party     &amp;lt;chr&amp;gt; &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;, &amp;quot;PIRATEN&amp;quot;,…
## $ Year      &amp;lt;dbl&amp;gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, …
## $ Variables &amp;lt;chr&amp;gt; &amp;quot;Pourcentage&amp;quot;, &amp;quot;Suffrage total&amp;quot;, &amp;quot;Suffrages de liste&amp;quot;,…
## $ Values    &amp;lt;dbl&amp;gt; 6.446204e-02, 2.275490e+05, 1.815600e+05, 4.598900e+04…
## $ locality  &amp;lt;chr&amp;gt; &amp;quot;Grand-Duchy of Luxembourg&amp;quot;, &amp;quot;Grand-Duchy of Luxembour…
## $ division  &amp;lt;chr&amp;gt; &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;National&amp;quot;, &amp;quot;Natio…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This blog post is already quite long, so I will analyze the data now that R can easily ingest it
in a future blog post.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exporting editable plots from R to Powerpoint: making ggplot2 purrr with officer</title>
      <link>https://www.brodrigues.co/blog/2018-10-05-ggplot2_purrr_officer/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-10-05-ggplot2_purrr_officer/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oc9XOxUcvLY&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/officer_meme.jpg&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;A kind reader let me know that the function &lt;code&gt;create_pptx()&lt;/code&gt; is now outdated, and
proposed an update which you can find here:
&lt;a href=&#34;https://gist.github.com/b-rodrigues/ef4e97ed75028ca1ddd5987bb4085c1c&#34;&gt;here&lt;/a&gt;.
Thank you
&lt;a href=&#34;https://twitter.com/jerry_stones/status/1239625489578254336&#34;&gt;@Jeremy&lt;/a&gt;!
&lt;/p&gt;


&lt;p&gt;I was recently confronted to the following problem: creating hundreds of plots that could still be
edited by our client. What this meant was that I needed to export the graphs in Excel or Powerpoint
or some other such tool that was familiar to the client, and not export the plots directly to pdf or
png as I would normally do. I still wanted to use R to do it though, because I could do what I always
do to when I need to perform repetitive tasks such as producing hundreds of plots; map over a list
of, say, countries, and make one plot per country. This is something I discussed in a previous
blog post, &lt;a href=&#34;http://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/&#34;&gt;Make ggplot2 purrr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, after some online seaching, I found the &lt;code&gt;{officer}&lt;/code&gt; package. This package allows you to put
objects into Microsoft documents. For example, editable plots in a Powerpoint document. This is what
I will show in this blog post.&lt;/p&gt;
&lt;p&gt;Let’s start by loading the required packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;officer&amp;quot;)
library(&amp;quot;rvg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I will use the data from the time use survey, which I discussed in a previous blog post
&lt;a href=&#34;http://www.brodrigues.co/blog/2018-09-11-human_to_machine/&#34;&gt;Going from a human readable Excel file to a machine-readable csv with {tidyxl}&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can download the data &lt;a href=&#34;https://github.com/rbind/b-rodrigues.github.com/blob/master/content/blog/clean_data.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s import and prepare it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time_use &amp;lt;- rio::import(&amp;quot;clean_data.csv&amp;quot;)


time_use &amp;lt;- time_use %&amp;gt;%
    filter(population %in% c(&amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;)) %&amp;gt;%
    filter(activities %in% c(&amp;quot;Personal care&amp;quot;, &amp;quot;Sleep&amp;quot;, &amp;quot;Eating&amp;quot;, 
                             &amp;quot;Employment&amp;quot;, &amp;quot;Household and family care&amp;quot;)) %&amp;gt;%
    group_by(day) %&amp;gt;%
    nest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I only kept two categories, “Male” and “Female” and 5 activities. Then I grouped by day and nested
the data. This is how it looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time_use&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   day                         data             
##   &amp;lt;chr&amp;gt;                       &amp;lt;list&amp;gt;           
## 1 Year 2014_Monday til Friday &amp;lt;tibble [10 × 4]&amp;gt;
## 2 Year 2014_Saturday          &amp;lt;tibble [10 × 4]&amp;gt;
## 3 Year 2014_Sunday            &amp;lt;tibble [10 × 4]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As shown, &lt;code&gt;time_use&lt;/code&gt; is a tibble with 2 columns, the first &lt;code&gt;day&lt;/code&gt; contains the days, and the second
&lt;code&gt;data&lt;/code&gt;, is of type list, and each element of these lists are tibbles themselves. Let’s take a look
inside one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;time_use$data[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 10 x 4
##    population activities                time  time_in_minutes
##    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                     &amp;lt;chr&amp;gt;           &amp;lt;int&amp;gt;
##  1 Male       Personal care             11:00             660
##  2 Male       Sleep                     08:24             504
##  3 Male       Eating                    01:46             106
##  4 Male       Employment                08:11             491
##  5 Male       Household and family care 01:59             119
##  6 Female     Personal care             11:15             675
##  7 Female     Sleep                     08:27             507
##  8 Female     Eating                    01:48             108
##  9 Female     Employment                06:54             414
## 10 Female     Household and family care 03:49             229&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now create plots for each of the days with the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_plots &amp;lt;- time_use %&amp;gt;%
    mutate(plots = map2(.y = day, .x = data, ~ggplot(data = .x) + theme_minimal() +
                       geom_col(aes(y = time_in_minutes, x = activities, fill = population), 
                                position = &amp;quot;dodge&amp;quot;) +
                       ggtitle(.y) +
                       ylab(&amp;quot;Time in minutes&amp;quot;) +
                       xlab(&amp;quot;Activities&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These steps are all detailled in my blog post
&lt;a href=&#34;http://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/&#34;&gt;Make ggplot2 purrr&lt;/a&gt;.
Let’s take a look at &lt;code&gt;my_plots&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_plots&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   day                         data              plots 
##   &amp;lt;chr&amp;gt;                       &amp;lt;list&amp;gt;            &amp;lt;list&amp;gt;
## 1 Year 2014_Monday til Friday &amp;lt;tibble [10 × 4]&amp;gt; &amp;lt;gg&amp;gt;  
## 2 Year 2014_Saturday          &amp;lt;tibble [10 × 4]&amp;gt; &amp;lt;gg&amp;gt;  
## 3 Year 2014_Sunday            &amp;lt;tibble [10 × 4]&amp;gt; &amp;lt;gg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last column, called &lt;code&gt;plots&lt;/code&gt; is a list where each element is a plot! We can take a look at one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_plots$plots[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-10-05-ggplot2_purrr_officer_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, this is where I could export these plots as pdfs or pngs. But this is not what I need. I need
to export these plots as editable charts for Powerpoint. To do this for one image, I would do the
following (as per &lt;code&gt;{officer}&lt;/code&gt;’s documentation):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_pptx() %&amp;gt;%
    add_slide(layout = &amp;quot;Title and Content&amp;quot;, master = &amp;quot;Office Theme&amp;quot;) %&amp;gt;%
    ph_with_vg(code = print(one_plot), type = &amp;quot;body&amp;quot;) %&amp;gt;% 
    print(target = path)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To map this over a list of arguments, I wrote a wrapper:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_pptx &amp;lt;- function(plot, path){
    if(!file.exists(path)) {
        out &amp;lt;- read_pptx()
    } else {
        out &amp;lt;- read_pptx(path)
    }
    
    out %&amp;gt;%
        add_slide(layout = &amp;quot;Title and Content&amp;quot;, master = &amp;quot;Office Theme&amp;quot;) %&amp;gt;%
        ph_with_vg(code = print(plot), type = &amp;quot;body&amp;quot;) %&amp;gt;% 
        print(target = path)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes two arguments, &lt;code&gt;plot&lt;/code&gt; and &lt;code&gt;path&lt;/code&gt;. &lt;code&gt;plot&lt;/code&gt; must be an plot object such as the ones
contained inside the &lt;code&gt;plots&lt;/code&gt; column of &lt;code&gt;my_plots&lt;/code&gt; tibble. &lt;code&gt;path&lt;/code&gt; is the path of where I want to save
the pptx.&lt;/p&gt;
&lt;p&gt;The first lines check if the file exists, if yes, the slides get added to the existing file, if not
a new pptx gets created. The rest of the code is very similar to the one from the documentation. Now,
to create my pptx I simple need to map over the &lt;code&gt;plots&lt;/code&gt; column and provide a &lt;code&gt;path&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(my_plots$plots, create_pptx, path = &amp;quot;test.pptx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]

## Warning in doc_parse_file(con, encoding = encoding, as_html = as_html,
## options = options): Failed to parse QName &amp;#39;xsi:xmlns:&amp;#39; [202]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;/home/cbrunos/Documents/b-rodrigues.github.com/content/blog/test.pptx&amp;quot;
## 
## [[2]]
## [1] &amp;quot;/home/cbrunos/Documents/b-rodrigues.github.com/content/blog/test.pptx&amp;quot;
## 
## [[3]]
## [1] &amp;quot;/home/cbrunos/Documents/b-rodrigues.github.com/content/blog/test.pptx&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the end result:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/editable_plots.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Inside Powerpoint (or in this case Libreoffice), the plots are geometric shapes that can now
be edited!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How Luxembourguish residents spend their time: a small {flexdashboard} demo using the Time use survey data</title>
      <link>https://www.brodrigues.co/blog/2018-09-15-time_use/</link>
      <pubDate>Fri, 14 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-09-15-time_use/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://brodriguesco.shinyapps.io/time_use_luxembourg/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/time_use_dashboard.png&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In a &lt;a href=&#34;http://www.brodrigues.co/blog/2018-09-11-human_to_machine/&#34;&gt;previous blog post&lt;/a&gt; I have showed
how you could use the &lt;code&gt;{tidyxl}&lt;/code&gt; package to go from a human readable Excel Workbook to a tidy
data set (or flat file, as they are also called). Some people then contributed their solutions,
which is always something I really enjoy when it happens. This way, I also get to learn things!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/expersso&#34;&gt;&lt;code&gt;@expersso&lt;/code&gt;&lt;/a&gt; proposed a solution without &lt;code&gt;{tidyxl}&lt;/code&gt;:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Interesting data wrangling exercise in &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;. &lt;br&gt;My solution (without using {tidyxl}): &lt;a href=&#34;https://t.co/VjuOoM82yX&#34;&gt;https://t.co/VjuOoM82yX&lt;/a&gt; &lt;a href=&#34;https://t.co/VsXFyowigu&#34;&gt;https://t.co/VsXFyowigu&lt;/a&gt;
&lt;/p&gt;
— Eric (&lt;span class=&#34;citation&#34;&gt;@expersso&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/expersso/status/1039894727808757761?ref_src=twsrc%5Etfw&#34;&gt;September 12, 2018&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://www.benstenhaug.com/&#34;&gt;Ben Stenhaug&lt;/a&gt; also proposed a solution on his &lt;a href=&#34;https://github.com/stenhaug/shared/blob/master/tidyxl_bruno_blog.md&#34;&gt;github&lt;/a&gt;
which is simpler than my code in a lot of ways!&lt;/p&gt;
&lt;p&gt;Update: &lt;a href=&#34;https://twitter.com/nacnudus&#34;&gt;&lt;code&gt;@nacnudus&lt;/code&gt;&lt;/a&gt; also contributed his own version using &lt;code&gt;{unpivotr}&lt;/code&gt;:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Here&#39;s a version using unpivotr &lt;a href=&#34;https://t.co/l2hy6zCuKj&#34;&gt;https://t.co/l2hy6zCuKj&lt;/a&gt;
&lt;/p&gt;
— Duncan Garmonsway (&lt;span class=&#34;citation&#34;&gt;@nacnudus&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/nacnudus/status/1040905626317217792?ref_src=twsrc%5Etfw&#34;&gt;September 15, 2018&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Now, it would be too bad not to further analyze this data. I’ve been wanting to play around with
the &lt;code&gt;{flexdashboard}&lt;/code&gt; package for some time now, but never really got the opportunity to do so.
The opportunity has now arrived. Using the cleaned data from the last post, I will further tweak
it a little bit, and then produce a very simple dashboard using &lt;code&gt;{flexdashboard}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you want to skip the rest of the blog post and go directly to the dashboard, just click &lt;a href=&#34;https://brodriguesco.shinyapps.io/time_use_luxembourg/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To make the data useful, I need to convert the strings that represent the amount of time spent
doing a task (for example “1:23”) to minutes. For this I use the &lt;code&gt;{chron}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_data &amp;lt;- clean_data %&amp;gt;%
    mutate(time_in_minutes = paste0(time, &amp;quot;:00&amp;quot;)) %&amp;gt;% # I need to add &amp;quot;:00&amp;quot; for the seconds else it won&amp;#39;t work
    mutate(time_in_minutes = 
               chron::hours(chron::times(time_in_minutes)) * 60 + 
               chron::minutes(chron::times(time_in_minutes)))

rio::export(clean_data, &amp;quot;clean_data.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’re ready to go! Below is the code to build the dashboard; if you want to try, you should
copy and paste the code inside a Rmd document:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: &amp;quot;Time Use Survey of Luxembourguish residents&amp;quot;
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
runtime: shiny
---

`` `{r setup, include=FALSE}
library(flexdashboard)
library(shiny)
library(tidyverse)
library(plotly)
library(ggthemes)

main_categories &amp;lt;- c(&amp;quot;Personal care&amp;quot;,
                     &amp;quot;Employment&amp;quot;,
                     &amp;quot;Study&amp;quot;,
                     &amp;quot;Household and family care&amp;quot;,
                     &amp;quot;Voluntary work and meetings&amp;quot;,
                     &amp;quot;Social life and entertainment&amp;quot;,
                     &amp;quot;Sports and outdoor activities&amp;quot;,
                     &amp;quot;Hobbies and games&amp;quot;,
                     &amp;quot;Media&amp;quot;,
                     &amp;quot;Travel&amp;quot;)

df &amp;lt;- read.csv(&amp;quot;clean_data.csv&amp;quot;) %&amp;gt;%
    rename(Population = population) %&amp;gt;%
    rename(Activities = activities)
`` `

Inputs {.sidebar}
-----------------------------------------------------------------------

`` `{r}

selectInput(inputId = &amp;quot;activitiesName&amp;quot;, 
            label = &amp;quot;Choose an activity&amp;quot;, 
            choices = unique(df$Activities))

selectInput(inputId = &amp;quot;dayName&amp;quot;, 
            label = &amp;quot;Choose a day&amp;quot;, 
            choices = unique(df$day), 
            selected = &amp;quot;Year 2014_Monday til Friday&amp;quot;)

selectInput(inputId = &amp;quot;populationName&amp;quot;, 
            label = &amp;quot;Choose a population&amp;quot;, 
            choices = unique(df$Population), 
            multiple = TRUE, selected = c(&amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;))

`` `

The Time Use Survey (TUS) aims to measure accurately how people allocate their time across different day-to-day activities. To this end, people are asked to keep records of all their activities in a time diary. For each activity, additional information is collected about whether or not the person was alone doing it or together with other persons, where did the activity take place, etc. The main studies on time use have been conducted to calculate indicators making possible comparative analysis of quality of life within the same population or between countries. International studies care more about specific activities such as work (unpaid or not), free time, leisure, personal care (including sleep), etc.
Source: http://statistiques.public.lu/en/surveys/espace-households/time-use/index.html

Layout based on https://jjallaire.shinyapps.io/shiny-biclust/

Row
-----------------------------------------------------------------------

### Minutes spent per day on certain activities
    
`` `{r}
dfInput &amp;lt;- reactive({
        df %&amp;gt;% filter(Activities == input$activitiesName,
                      Population %in% input$populationName,
                      day %in% input$dayName)
    })

    dfInput2 &amp;lt;- reactive({
        df %&amp;gt;% filter(Activities %in% main_categories,
                      Population %in% input$populationName,
                      day %in% input$dayName)
    })
    
  renderPlotly({

        df1 &amp;lt;- dfInput()

        p1 &amp;lt;- ggplot(df1, 
                     aes(x = Activities, y = time_in_minutes, fill = Population)) +
            geom_col(position = &amp;quot;dodge&amp;quot;) + 
            theme_minimal() + 
            xlab(&amp;quot;Activities&amp;quot;) + 
            ylab(&amp;quot;Time in minutes&amp;quot;) +
            scale_fill_gdocs()

        ggplotly(p1)})
`` `

Row 
-----------------------------------------------------------------------

### Proportion of the day spent on main activities
    
`` `{r}
renderPlotly({
    
       df2 &amp;lt;- dfInput2()
       
       p2 &amp;lt;- ggplot(df2, 
                   aes(x = Population, y = time_in_minutes, fill = Activities)) +
           geom_bar(stat=&amp;quot;identity&amp;quot;, position=&amp;quot;fill&amp;quot;) + 
            xlab(&amp;quot;Proportion&amp;quot;) + 
            ylab(&amp;quot;Proportion&amp;quot;) +
           theme_minimal() +
           scale_fill_gdocs()
       
       ggplotly(p2)
   })
`` `&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will see that I have defined the following atomic vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;main_categories &amp;lt;- c(&amp;quot;Personal care&amp;quot;,
                     &amp;quot;Employment&amp;quot;,
                     &amp;quot;Study&amp;quot;,
                     &amp;quot;Household and family care&amp;quot;,
                     &amp;quot;Voluntary work and meetings&amp;quot;,
                     &amp;quot;Social life and entertainment&amp;quot;,
                     &amp;quot;Sports and outdoor activities&amp;quot;,
                     &amp;quot;Hobbies and games&amp;quot;,
                     &amp;quot;Media&amp;quot;,
                     &amp;quot;Travel&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you go back to the raw Excel file, you will see that these main categories are then split into
secondary activities. The first bar plot of the dashboard does not distinguish between the main and
secondary activities, whereas the second barplot only considers the main activities. I could
have added another column to the data that helped distinguish whether an activity was a main or secondary one,
but I was lazy. The source code of the dashboard is very simple as it uses R Markdown. To have
interactivity, I’ve used Shiny to dynamically filter the data, and built the plots with &lt;code&gt;{ggplot2}&lt;/code&gt;.
Finally, I’ve passed the plots to the &lt;code&gt;ggplotly()&lt;/code&gt; function from the &lt;code&gt;{plotly}&lt;/code&gt; package for some
quick and easy javascript goodness!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Going from a human readable Excel file to a machine-readable csv with {tidyxl}</title>
      <link>https://www.brodrigues.co/blog/2018-09-11-human_to_machine/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-09-11-human_to_machine/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=m-PE3OkJ8XE&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/1a9.gif&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I won’t write a very long introduction; we all know that Excel is ubiquitous in business, and that
it has a lot of very nice features, especially for business practitioners that do not know any
programming. However, when people use Excel for purposes it was not designed for, it can be a
hassle. Often, people use Excel as a reporting tool, which it is not; they create very elaborated
and complicated spreadsheets that are human readable, but impossible to import within any other tool.&lt;/p&gt;
&lt;p&gt;In this blog post (which will probably be part of a series), I show you how you can go from this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/time_use.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;to this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/time_use2.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;You can find the data I will use &lt;a href=&#34;http://statistiques.public.lu/stat/ReportFolders/ReportFolder.aspx?IF_Language=eng&amp;amp;MainTheme=3&amp;amp;FldrName=1&amp;amp;RFPath=14306&#34;&gt;here&lt;/a&gt;. Click on the “Time use” folder and you can download the workbook.&lt;/p&gt;
&lt;p&gt;The Excel workbook contains several sheets (in French and English) of the amount of time Luxembourguish
citizens spend from Monday to Sunday. For example, on average, people that are in employment spend
almost 8 hours sleeping during the week days, and 8:45 hours on Saturday.&lt;/p&gt;
&lt;p&gt;As you can see from the screenshot, each sheet contains several tables that have lots of headers
and these tables are next to one another. Trying to import these sheets with good ol’ &lt;code&gt;readxl::read_excel()&lt;/code&gt;
produces a monster.&lt;/p&gt;
&lt;p&gt;This is where &lt;code&gt;{tidyxl}&lt;/code&gt; comes into play. Let’s import the workbook with &lt;code&gt;{tidyxl}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidyxl)

time_use_xl &amp;lt;- xlsx_cells(&amp;quot;time-use.xlsx&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what happened:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(time_use_xl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 21
##   sheet address   row   col is_blank data_type error logical numeric
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;lgl&amp;gt;    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Index A1          1     1 FALSE    character &amp;lt;NA&amp;gt;  NA           NA
## 2 Index B1          1     2 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## 3 Index C1          1     3 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## 4 Index D1          1     4 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## 5 Index E1          1     5 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## 6 Index F1          1     6 TRUE     blank     &amp;lt;NA&amp;gt;  NA           NA
## # … with 12 more variables: date &amp;lt;dttm&amp;gt;, character &amp;lt;chr&amp;gt;,
## #   character_formatted &amp;lt;list&amp;gt;, formula &amp;lt;chr&amp;gt;, is_array &amp;lt;lgl&amp;gt;,
## #   formula_ref &amp;lt;chr&amp;gt;, formula_group &amp;lt;int&amp;gt;, comment &amp;lt;chr&amp;gt;, height &amp;lt;dbl&amp;gt;,
## #   width &amp;lt;dbl&amp;gt;, style_format &amp;lt;chr&amp;gt;, local_format_id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the sheet was imported, but the result might be unexpected. Actually, &lt;code&gt;time_use_xl&lt;/code&gt;
is a &lt;code&gt;tibble&lt;/code&gt; object, where each row is one cell of the Excel sheet. This might seem very complicated
to handle, but you will see that it actually makes things way easier.&lt;/p&gt;
&lt;p&gt;I only want to work on the English sheets so I use the following code to ignore the French ones:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sheets &amp;lt;- xlsx_sheet_names(&amp;quot;time-use.xlsx&amp;quot;) %&amp;gt;%
    keep(grepl(pattern = &amp;quot;.*day$&amp;quot;, .))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, there’s a sheet that aggregates the results for week days and weekends, which I also ignore.&lt;/p&gt;
&lt;p&gt;Now, to extract the tables from each sheet I wrote the following function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_data &amp;lt;- function(sheet){
    activities &amp;lt;- sheet %&amp;gt;%
        filter(col == 2) %&amp;gt;%
        select(row, character) %&amp;gt;%
        filter(row %in% seq(6,58)) %&amp;gt;%
        rename(activities = character) %&amp;gt;%
        select(-row)
    
    cols_to_extract &amp;lt;- sheet %&amp;gt;% 
        filter(grepl(&amp;quot;Population who completed.*&amp;quot;, character)) %&amp;gt;% 
        pull(col)
    
    headers_pos &amp;lt;- cols_to_extract - 1
    
    headers &amp;lt;- sheet %&amp;gt;%
        filter(col %in% headers_pos, row == 3) %&amp;gt;%
        pull(character)
    
    cols_to_extract %&amp;gt;% 
        map(~filter(sheet, col %in% .)) %&amp;gt;%
        map(~select(., sheet, address, row, col, character)) %&amp;gt;%
        map(~filter(., row %in% seq(6,58))) %&amp;gt;%
        map(~select(., character)) %&amp;gt;%
        map2(.x = ., .y = headers, ~mutate(.x, &amp;quot;population&amp;quot; = .y)) %&amp;gt;%
        map(., ~bind_cols(activities, .)) %&amp;gt;%
        bind_rows()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s study it step by step and see how it works. First, there’s the argument, &lt;code&gt;sheet&lt;/code&gt;. This function
will be mapped to each sheet of the workbook. Then, the first block I wrote, extracts the
activities:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    activities &amp;lt;- sheet %&amp;gt;%
        filter(col == 2) %&amp;gt;%
        select(row, character) %&amp;gt;%
        filter(row %in% seq(6,58)) %&amp;gt;%
        rename(activities = character) %&amp;gt;%
        select(-row)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I only keep the second column (&lt;code&gt;filter(col == 2)&lt;/code&gt;); &lt;code&gt;col&lt;/code&gt; is a column of the &lt;code&gt;tibble&lt;/code&gt; and if you
look inside the workbook, you will notice that the activities are on the second column, or the B
column. Then, I select two columns, the &lt;code&gt;row&lt;/code&gt; and the &lt;code&gt;character&lt;/code&gt; column. &lt;code&gt;row&lt;/code&gt; is self-explanatory
and &lt;code&gt;character&lt;/code&gt; actually contains whatever is written inside the cells. Then, I only keep rows
6 to 58, because that is what interests me; the rest is either empty cells, or unneeded. Finally,
I rename the &lt;code&gt;character&lt;/code&gt; column to activities and remove the &lt;code&gt;row&lt;/code&gt; column.&lt;/p&gt;
&lt;p&gt;The second block:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    cols_to_extract &amp;lt;- sheet %&amp;gt;% 
        filter(grepl(&amp;quot;Population who completed.*&amp;quot;, character)) %&amp;gt;% 
        pull(col)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;returns the index of the columns I want to extract. I am only interested in the people that have
completed the activities, so using &lt;code&gt;grepl()&lt;/code&gt; inside &lt;code&gt;filter()&lt;/code&gt;, I located these columns, and use
&lt;code&gt;pull()&lt;/code&gt;… to pull them out of the data frame! &lt;code&gt;cols_to_extract&lt;/code&gt; is thus a nice atomic vector of
columns that I want to keep.&lt;/p&gt;
&lt;p&gt;In the third block, I extract the headers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    headers_pos &amp;lt;- cols_to_extract - 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why &lt;code&gt;- 1&lt;/code&gt;? This is because if you look in the Excel, you will see that the headers are one column before
the column labeled “People who completed the activity”. For example on column G, I have “People who completed the activity”
and on column F I have the header, in this case “Male”.&lt;/p&gt;
&lt;p&gt;Now I actually extract the headers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    headers &amp;lt;- sheet %&amp;gt;%
        filter(col %in% headers_pos, row == 3) %&amp;gt;%
        pull(character)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Headers are always on the third row, but on different columns, hence the &lt;code&gt;col %in% headers_pos&lt;/code&gt;. I
then pull out the values inside the cells with &lt;code&gt;pull(character)&lt;/code&gt;. So my &lt;code&gt;headers&lt;/code&gt; object will be
an atomic vector with “All”, “Male”, “Female”, “10 - 19 years”, etc… everything on row 3.&lt;/p&gt;
&lt;p&gt;Finally, the last block, actually extracts the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    cols_to_extract %&amp;gt;% 
        map(~filter(sheet, col %in% .)) %&amp;gt;%
        map(~select(., sheet, address, row, col, character)) %&amp;gt;%
        map(~filter(., row %in% seq(6,58))) %&amp;gt;%
        map(~select(., character)) %&amp;gt;%
        map2(.x = ., .y = headers, ~mutate(.x, &amp;quot;population&amp;quot; = .y)) %&amp;gt;%
        map(., ~bind_cols(activities, .)) %&amp;gt;%
        bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;cols_to_extract&lt;/code&gt; is a vector with the positions of the columns that interest me. So for example
“4”, “7”, “10” and so on. I map this vector to the sheet, which returns me a list of extracted
data frames. I pass this down to a &lt;code&gt;select()&lt;/code&gt; (which is inside &lt;code&gt;map()&lt;/code&gt;… why? Because the input
parameter is a list of data frames). So for each data frame inside the list, I select the columns
&lt;code&gt;sheet&lt;/code&gt;, &lt;code&gt;address&lt;/code&gt;, &lt;code&gt;row&lt;/code&gt;, &lt;code&gt;col&lt;/code&gt; and &lt;code&gt;character&lt;/code&gt;. Then, for each data frame inside the list,
I use &lt;code&gt;filter()&lt;/code&gt; to only keep the rows from position 6 to 58. Then, I only select the &lt;code&gt;character&lt;/code&gt;
column, which actually contains the text inside the cell. Then, using &lt;code&gt;map2()&lt;/code&gt;, I add the values
inside the &lt;code&gt;headers&lt;/code&gt; object as a new column, called &lt;code&gt;population&lt;/code&gt;. Then, I bind the &lt;code&gt;activities&lt;/code&gt;
column to the data frame and bind all the rows together.&lt;/p&gt;
&lt;p&gt;Time to use this function! Let’s see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_data &amp;lt;- sheets %&amp;gt;%
    map(~filter(time_use_xl, sheet %in% .)) %&amp;gt;%
    set_names(sheets) %&amp;gt;%
    map(extract_data) %&amp;gt;%
    map2(.x = ., .y = sheets, ~mutate(.x, &amp;quot;day&amp;quot; = .y)) %&amp;gt;%
    bind_rows() %&amp;gt;%
    select(day, population, activities, time = character)

glimpse(clean_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 2,968
## Variables: 4
## $ day        &amp;lt;chr&amp;gt; &amp;quot;Year 2014_Monday til Friday&amp;quot;, &amp;quot;Year 2014_Monday til …
## $ population &amp;lt;chr&amp;gt; &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All&amp;quot;, &amp;quot;All…
## $ activities &amp;lt;chr&amp;gt; &amp;quot;Personal care&amp;quot;, &amp;quot;Sleep&amp;quot;, &amp;quot;Eating&amp;quot;, &amp;quot;Other personal c…
## $ time       &amp;lt;chr&amp;gt; &amp;quot;11:07&amp;quot;, &amp;quot;08:26&amp;quot;, &amp;quot;01:47&amp;quot;, &amp;quot;00:56&amp;quot;, &amp;quot;07:37&amp;quot;, &amp;quot;07:47&amp;quot;,…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So I map my list of sheets to the &lt;code&gt;tibble&lt;/code&gt; I imported with &lt;code&gt;readxl&lt;/code&gt;, use &lt;code&gt;set_names&lt;/code&gt; to
name the elements of my list (which is superfluous, but I wanted to show this; might interest you!)
and then map this result to my little function. I could stop here,
but I then add a new column to each data frame that contains the day on which the data was
measured, bind the rows together and reorder the columns. Done!&lt;/p&gt;
&lt;p&gt;Now, how did I come up with this function? I did not start with a function. I started by writing
some code that did what I wanted for one table only, inside one sheet only. Only when I got
something that worked, did I start to generalize to several tables and then to several sheets. Most
of the time spent was actually in trying to find patterns in the Excel sheet that I could use
to write my function (for example noticing that the headers I wanted where always one column before
the column I was interested in). This is my advice when working with function programming; always
solve the issue for one element, wrap this code inside a function, and then simply map this function
to a list of elements!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The year of the GNU&#43;Linux desktop is upon us: using user ratings of Steam Play compatibility to play around with regex and the tidyverse</title>
      <link>https://www.brodrigues.co/blog/2018-09-08-steam_linux/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-09-08-steam_linux/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4QokOwvPxrE&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/want_to_believe.jpg&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’ve been using GNU+Linux distros for about 10 years now, and have settled for openSUSE as my main operating system around 3 years ago, perhaps even more. If you’re a gamer, you might have heard about SteamOS
and how more and more games are available on GNU+Linux. I don’t really care about
games, I play the occasional one (currently &lt;a href=&#34;http://www.tangledeep.com/&#34;&gt;Tangledeep&lt;/a&gt;) when I find
the time, but still follow the news about gaming on GNU+Linux. Last week,
Valve announced something quite big; it is now possible to run Windows games on GNU+Linux directly
from Steam, using a modified version of &lt;a href=&#34;https://en.wikipedia.org/wiki/Wine_(software)&#34;&gt;Wine&lt;/a&gt;
they call Proton. The feature is still in Beta, and Valve announced that they guarantee around
30 games to work already flawlessly. Of course, people have tried running a lot of other games, and,
as was to be expected from Free Software and Open Source fans, GNU+Linux gamers created a Google Sheet
that lists which games were tried and how they run. You can take a look at the sheet &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1DcZZQ4HL_Ol969UbXJmFG8TzOHNnHoj8Q1f8DIFe8-8/htmlview?sle=true&amp;amp;pru=AAABZbqTTkc*IvT11ShwA2kjoe_4lPefiQ#gid=1003113831&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this blog post, I will play around with this sheet. This blog post lists some &lt;code&gt;{tidyverse}&lt;/code&gt; tricks
I find useful and use often. Perhaps these tricks will be useful to you too! Let’s start by loading
the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(magrittr)
library(readxl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since I’m lazy and don’t want to type the whole name of the file I’ll be using some little regex:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam &amp;lt;- read_excel(Sys.glob(&amp;quot;Steam*&amp;quot;), sheet = &amp;quot;Main&amp;quot;, skip = 2)

glimpse(steam)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 8,570
## Variables: 9
## $ SteamDB   &amp;lt;chr&amp;gt; &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;, &amp;quot;LINK&amp;quot;…
## $ Game      &amp;lt;chr&amp;gt; &amp;quot;64&amp;quot;, &amp;quot;1849&amp;quot;, &amp;quot;1982&amp;quot;, &amp;quot;1982&amp;quot;, &amp;quot;am Weapon: Revival&amp;quot;, &amp;quot;.…
## $ Submitted &amp;lt;chr&amp;gt; &amp;quot;5 days ago&amp;quot;, &amp;quot;12 days ago&amp;quot;, &amp;quot;11 days ago&amp;quot;, &amp;quot;11 days a…
## $ Status    &amp;lt;chr&amp;gt; &amp;quot;Garbage&amp;quot;, &amp;quot;Platinum&amp;quot;, &amp;quot;Gold&amp;quot;, &amp;quot;Platinum&amp;quot;, &amp;quot;Platinum&amp;quot;,…
## $ Notes     &amp;lt;chr&amp;gt; &amp;quot;Crashes with a debug log&amp;quot;, &amp;quot;Plays OK.&amp;quot;, &amp;quot;Gamepad supp…
## $ Distro    &amp;lt;chr&amp;gt; &amp;quot;Arch (4.18.5)&amp;quot;, &amp;quot;Manjaro XFCE&amp;quot;, &amp;quot;Gentoo AMD64 (Kernel…
## $ Driver    &amp;lt;chr&amp;gt; &amp;quot;Nvidia 396.54 / Intel xf86-video-intel (1:2.99.917+83…
## $ Specs     &amp;lt;chr&amp;gt; &amp;quot;Intel Core i7-7700HQ / Nvidia GTX 1050 (Mobile)&amp;quot;, &amp;quot;Ry…
## $ Proton    &amp;lt;chr&amp;gt; &amp;quot;3.7 Beta&amp;quot;, &amp;quot;3.7-4 Beta&amp;quot;, &amp;quot;3.7-4 Beta&amp;quot;, &amp;quot;Default&amp;quot;, &amp;quot;3.…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s count how many unique games are in the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    count(Game)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3,855 x 2
##    Game                                                                   n
##    &amp;lt;chr&amp;gt;                                                              &amp;lt;int&amp;gt;
##  1 .hack//G.U. Last Recode                                                2
##  2 $1 Ride                                                                1
##  3 0rbitalis                                                              1
##  4 10 Second Ninja                                                        4
##  5 100% Orange Juice                                                     17
##  6 1000 Amps                                                              3
##  7 12 Labours of Hercules VII: Fleecing the Fleece (Platinum Edition)     1
##  8 16bit trader                                                           1
##  9 1849                                                                   1
## 10 1953 - KGB Unleased                                                    1
## # … with 3,845 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s quite a lot of games! However, not everyone of them is playable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    count(Status)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 2
##   Status       n
##   &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;
## 1 Borked     205
## 2 bronze       1
## 3 Bronze     423
## 4 Garbage   2705
## 5 Gold       969
## 6 Platinum  2596
## 7 Primary      1
## 8 Silver    1670&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Around 2500 have the status “Platinum”, but some games might have more than one status:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    filter(Game == &amp;quot;100% Orange Juice&amp;quot;) %&amp;gt;%
    count(Status)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   Status       n
##   &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt;
## 1 Bronze       5
## 2 Garbage      3
## 3 Gold         2
## 4 Platinum     6
## 5 Silver       1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More games run like &lt;em&gt;Garbage&lt;/em&gt; than &lt;em&gt;Platinum&lt;/em&gt;. But perhaps we can dig a little deeper and see if
we find some patterns.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the GNU+Linux distros:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    count(Distro) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2,085 x 2
##    Distro                                         n
##    &amp;lt;chr&amp;gt;                                      &amp;lt;int&amp;gt;
##  1 &amp;lt;NA&amp;gt;                                           1
##  2 ?                                              2
##  3 &amp;quot;\&amp;quot;Arch Linux\&amp;quot; (64 bit)&amp;quot;                      1
##  4 &amp;quot;\&amp;quot;Linux Mint 18.3 Sylvia 64bit&amp;quot;               1
##  5 &amp;quot;\&amp;quot;Manjaro Stable 64-bit (Kernel 4.14.66)&amp;quot;     1
##  6 &amp;quot;\&amp;quot;Solus\&amp;quot; (64 bit)&amp;quot;                           2
##  7 (K)ubuntu 18.04 64-bit (Kernel 4.15.0)         2
##  8 (L)Ubuntu 18.04.1 LTS                          1
##  9 18.04.1                                        1
## 10 18.04.1 LTS                                    2
## # … with 2,075 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok the distro column is pretty messy. Let’s try to bring some order to it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;lt;&amp;gt;%
    mutate(distribution = as_factor(case_when(
        grepl(&amp;quot;buntu|lementary|antergos|steam|mint|18.|pop|neon&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Ubuntu&amp;quot;,
        grepl(&amp;quot;arch|manjaro&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Arch Linux&amp;quot;,
        grepl(&amp;quot;gentoo&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Gentoo&amp;quot;,
        grepl(&amp;quot;fedora&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Fedora&amp;quot;,
        grepl(&amp;quot;suse&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;openSUSE&amp;quot;,
        grepl(&amp;quot;debian|sid|stretch|lmde&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Debian&amp;quot;,
        grepl(&amp;quot;solus&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Solus&amp;quot;,
        grepl(&amp;quot;slackware&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Slackware&amp;quot;,
        grepl(&amp;quot;void&amp;quot;, Distro, ignore.case = TRUE) ~ &amp;quot;Void Linux&amp;quot;,
        TRUE ~ &amp;quot;Other&amp;quot;
    )))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;%&amp;lt;&amp;gt;%&lt;/code&gt; operator is shorthand for &lt;code&gt;a &amp;lt;- a %&amp;gt;% f()&lt;/code&gt;. It passes &lt;code&gt;a&lt;/code&gt; to &lt;code&gt;f()&lt;/code&gt; and assigns the
result back to &lt;code&gt;a&lt;/code&gt;. Anyways, let’s take a look at the &lt;code&gt;distribution&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    count(distribution)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 2
##    distribution     n
##    &amp;lt;fct&amp;gt;        &amp;lt;int&amp;gt;
##  1 Ubuntu        6632
##  2 Arch Linux     805
##  3 Solus          175
##  4 Debian         359
##  5 Fedora         355
##  6 Gentoo          42
##  7 Void Linux      38
##  8 Other           76
##  9 openSUSE        66
## 10 Slackware       22&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will group distributions that have less than 100 occurrences into a single category
(meaning I will keep the 5 more common values):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;lt;&amp;gt;%
    mutate(distribution = fct_lump(distribution, n = 5, other_level = &amp;quot;Other&amp;quot;)) 

steam %&amp;gt;%
    count(distribution)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   distribution     n
##   &amp;lt;fct&amp;gt;        &amp;lt;int&amp;gt;
## 1 Ubuntu        6632
## 2 Arch Linux     805
## 3 Solus          175
## 4 Debian         359
## 5 Fedora         355
## 6 Other          244&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s do the same for the CPUs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;lt;&amp;gt;%
    mutate(CPU = as_factor(case_when(
        grepl(&amp;quot;intel|i\\d|xeon|core2|\\d{4}k|q\\d{4}|pentium&amp;quot;, Specs, ignore.case = TRUE) ~ &amp;quot;Intel&amp;quot;,
        grepl(&amp;quot;ryzen|threadripper|tr|amd|fx|r\\d|\\d{4}x|phenom&amp;quot;, Specs, ignore.case = TRUE) ~ &amp;quot;AMD&amp;quot;,
        TRUE ~ NA_character_
    )))

steam %&amp;gt;%
    count(CPU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Factor `CPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   CPU       n
##   &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Intel  5768
## 2 AMD    2319
## 3 &amp;lt;NA&amp;gt;    483&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the same for the GPUs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;lt;&amp;gt;%
    mutate(GPU = as_factor(case_when(
        grepl(&amp;quot;nvidia|geforce|3\\d{2}|nouveau|gtx|gt\\s?\\d{1,}|9\\d0|1060|1070|1080&amp;quot;, Specs, ignore.case = TRUE) ~ &amp;quot;Nvidia&amp;quot;,
        grepl(&amp;quot;amd|radeon|ati|rx|vega|r9&amp;quot;, Specs, ignore.case = TRUE) ~ &amp;quot;AMD&amp;quot;,
        grepl(&amp;quot;intel|igpu|integrated|hd\\d{4}|hd\\sgraphics&amp;quot;, Specs, ignore.case = TRUE) ~ &amp;quot;Intel&amp;quot;,
        TRUE ~ NA_character_
    )))

steam %&amp;gt;%
    count(GPU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Factor `GPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   GPU        n
##   &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;
## 1 Nvidia  6086
## 2 AMD     1374
## 3 Intel    413
## 4 &amp;lt;NA&amp;gt;     697&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will also add a rank for the &lt;code&gt;Status&lt;/code&gt; column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;lt;&amp;gt;%
    mutate(rank_status = case_when(
        Status == &amp;quot;Platinum&amp;quot; ~ 5,
        Status == &amp;quot;Gold&amp;quot; ~ 4,
        Status == &amp;quot;Silver&amp;quot; ~ 3,
        Status == &amp;quot;Bronze&amp;quot; ~ 2,
        Status == &amp;quot;Garbage&amp;quot; ~ 1
    ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, what are the top 5 most frequent combinations of Status, distribution, CPU and GPU?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    filter(!is.na(CPU), !is.na(GPU)) %&amp;gt;%
    count(Status, distribution, CPU, GPU) %&amp;gt;%
    mutate(total = sum(n)) %&amp;gt;%
    mutate(freq = n / total) %&amp;gt;%
    top_n(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by freq&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 7
##   Status   distribution CPU   GPU        n total   freq
##   &amp;lt;chr&amp;gt;    &amp;lt;fct&amp;gt;        &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 Garbage  Ubuntu       Intel Nvidia  1025  7443 0.138 
## 2 Gold     Ubuntu       Intel Nvidia   361  7443 0.0485
## 3 Platinum Ubuntu       Intel Nvidia  1046  7443 0.141 
## 4 Platinum Ubuntu       AMD   Nvidia   338  7443 0.0454
## 5 Silver   Ubuntu       Intel Nvidia   650  7443 0.0873&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unsurprisingly, Ubuntu, or distributions using Ubuntu as a base, are the most popular ones. Nvidia
is the most popular GPU, Intel for CPUs and in most cases, this combo of hardware and distribution
is associated with positive ratings (even though there are almost as many “Garbage” ratings than
“Platinum” ratings).&lt;/p&gt;
&lt;p&gt;Now let’s compute some dumb averages of Statuses by distribution, CPU and GPU. Since I’m going
to run the same computation three times, I’ll write a function to do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_avg &amp;lt;- function(dataset, var){
    var &amp;lt;- enquo(var)
    dataset %&amp;gt;%
        select(rank_status, (!!var)) %&amp;gt;%
        group_by((!!var)) %&amp;gt;%
        mutate(wt = n()) %&amp;gt;%
        summarise(average_rating = weighted.mean(rank_status, (!!var), wt, na.rm = TRUE))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see now if we can rank distribution by Steam play rating:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_avg(steam, distribution)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   distribution average_rating
##   &amp;lt;fct&amp;gt;                 &amp;lt;dbl&amp;gt;
## 1 Ubuntu                 3.03
## 2 Arch Linux             3.05
## 3 Solus                  3.03
## 4 Debian                 3.01
## 5 Fedora                 3.07
## 6 Other                  3.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How about for hardware?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_avg(steam, GPU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Factor `GPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`

## Warning: Factor `GPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##   GPU    average_rating
##   &amp;lt;fct&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 Nvidia           3.07
## 2 AMD              2.90
## 3 Intel            3.01
## 4 &amp;lt;NA&amp;gt;            NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_avg(steam, CPU)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Factor `CPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`

## Warning: Factor `CPU` contains implicit NA, consider using
## `forcats::fct_explicit_na`&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   CPU   average_rating
##   &amp;lt;fct&amp;gt;          &amp;lt;dbl&amp;gt;
## 1 Intel           3.03
## 2 AMD             3.06
## 3 &amp;lt;NA&amp;gt;           NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To wrap this up, what are the games with the most ratings? Perhaps this can give us a hint about which
games GNU+Linux users prefer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;steam %&amp;gt;%
    count(Game) %&amp;gt;%
    top_n(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Selecting by n&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 2
##    Game                              n
##    &amp;lt;chr&amp;gt;                         &amp;lt;int&amp;gt;
##  1 Age of Empires II: HD Edition    43
##  2 Borderlands                      39
##  3 DiRT 3 Complete Edition          32
##  4 DOOM                             62
##  5 Fallout: New Vegas               45
##  6 Grim Dawn                        34
##  7 No Man&amp;#39;s Sky                     40
##  8 Path of Exile                    35
##  9 Quake Champions                  32
## 10 The Elder Scrolls V: Skyrim      46&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I actually laughed out loud when I saw that DOOM was the game with the most ratings! What else
was I expecting, really.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dealing with heteroskedasticity; regression with robust standard errors using R</title>
      <link>https://www.brodrigues.co/blog/2018-07-08-rob_stderr/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-07-08-rob_stderr/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/sandwich/index.html&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/bread-breakfast-bun-5678.jpg&#34; width=&#34;640&#34; height=&#34;360&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;First of all, is it heteros&lt;strong&gt;k&lt;/strong&gt;edasticity or heteros&lt;strong&gt;c&lt;/strong&gt;edasticity? According to
&lt;a href=&#34;https://www.jstor.org/stable/1911250&#34;&gt;McCulloch (1985)&lt;/a&gt;,
heteros&lt;strong&gt;k&lt;/strong&gt;edasticity is the proper spelling, because when transliterating Greek words, scientists
use the Latin letter k in place of the Greek letter κ (kappa). κ sometimes is transliterated as
the Latin letter c, but only when these words entered the English language through French, such
as scepter.&lt;/p&gt;
&lt;p&gt;Now that this is out of the way, we can get to the meat of this blogpost (foreshadowing pun).
A random variable is said to be heteroskedastic, if its variance is not constant. For example,
the variability of expenditures may increase with income. Richer families may spend a similar
amount on groceries as poorer people, but some rich families will sometimes buy expensive
items such as lobster. The variability of expenditures for rich families is thus quite large.
However, the expenditures on food of poorer families, who cannot afford lobster, will not vary much.
Heteroskedasticity can also appear when data is clustered; for example, variability of
expenditures on food may vary from city to city, but is quite constant within a city.&lt;/p&gt;
&lt;p&gt;To illustrate this, let’s first load all the packages needed for this blog post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(robustbase)
library(tidyverse)
library(sandwich)
library(lmtest)
library(modelr)
library(broom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, let’s load and prepare the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;education&amp;quot;)

education &amp;lt;- education %&amp;gt;% 
    rename(residents = X1,
           per_capita_income = X2,
           young_residents = X3,
           per_capita_exp = Y,
           state = State) %&amp;gt;% 
    mutate(region = case_when(
        Region == 1 ~ &amp;quot;northeast&amp;quot;,
        Region == 2 ~ &amp;quot;northcenter&amp;quot;,
        Region == 3 ~ &amp;quot;south&amp;quot;,
        Region == 4 ~ &amp;quot;west&amp;quot;
    )) %&amp;gt;% 
    select(-Region)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will be using the &lt;code&gt;education&lt;/code&gt; data set from the &lt;code&gt;{robustbase}&lt;/code&gt; package. I renamed some columns
and changed the values of the &lt;code&gt;Region&lt;/code&gt; column. Now, let’s do a scatterplot of per capita expenditures
on per capita income:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(education, aes(per_capita_income, per_capita_exp)) + 
    geom_point() +
    theme_dark()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-07-08-rob_stderr_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It would seem that, as income increases, variability of expenditures increases too. Let’s look
at the same plot by &lt;code&gt;region&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(education, aes(per_capita_income, per_capita_exp)) + 
    geom_point() + 
    facet_wrap(~region) + 
    theme_dark()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-07-08-rob_stderr_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I don’t think this shows much; it would seem that observations might be clustered, but there are
not enough observations to draw any conclusion from this plot (in any case, drawing conclusions
from only plots is dangerous).&lt;/p&gt;
&lt;p&gt;Let’s first run a good ol’ linear regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmfit &amp;lt;- lm(per_capita_exp ~ region + residents + young_residents + per_capita_income, data = education)

summary(lmfit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = per_capita_exp ~ region + residents + young_residents + 
##     per_capita_income, data = education)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -77.963 -25.499  -2.214  17.618  89.106 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)       -467.40283  142.57669  -3.278 0.002073 ** 
## regionnortheast     15.72741   18.16260   0.866 0.391338    
## regionsouth          7.08742   17.29950   0.410 0.684068    
## regionwest          34.32416   17.49460   1.962 0.056258 .  
## residents           -0.03456    0.05319  -0.650 0.519325    
## young_residents      1.30146    0.35717   3.644 0.000719 ***
## per_capita_income    0.07204    0.01305   5.520 1.82e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 39.88 on 43 degrees of freedom
## Multiple R-squared:  0.6292, Adjusted R-squared:  0.5774 
## F-statistic: 12.16 on 6 and 43 DF,  p-value: 6.025e-08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s test for heteroskedasticity using the Breusch-Pagan test that you can find in the &lt;code&gt;{lmtest}&lt;/code&gt;
package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bptest(lmfit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  studentized Breusch-Pagan test
## 
## data:  lmfit
## BP = 17.921, df = 6, p-value = 0.006432&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This test shows that we can reject the null that the variance of the residuals is constant,
thus heteroskedacity is present. To get the correct standard errors, we can use the &lt;code&gt;vcovHC()&lt;/code&gt;
function from the &lt;code&gt;{sandwich}&lt;/code&gt; package (hence the choice for the header picture of this post):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmfit %&amp;gt;% 
    vcovHC() %&amp;gt;% 
    diag() %&amp;gt;% 
    sqrt()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       (Intercept)   regionnortheast       regionsouth        regionwest 
##      311.31088691       25.30778221       23.56106307       24.12258706 
##         residents   young_residents per_capita_income 
##        0.09184368        0.68829667        0.02999882&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default &lt;code&gt;vcovHC()&lt;/code&gt; estimates a heteroskedasticity consistent (HC) variance covariance
matrix for the parameters. There are several ways to estimate such a HC matrix, and by default
&lt;code&gt;vcovHC()&lt;/code&gt; estimates the “HC3” one. You can refer to &lt;a href=&#34;https://www.jstatsoft.org/article/view/v011i10&#34;&gt;Zeileis (2004)&lt;/a&gt;
for more details.&lt;/p&gt;
&lt;p&gt;We see that the standard errors are much larger than before! The intercept and &lt;code&gt;regionwest&lt;/code&gt; variables
are not statistically significant anymore.&lt;/p&gt;
&lt;p&gt;You can achieve the same in one single step:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeftest(lmfit, vcov = vcovHC(lmfit))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##                      Estimate  Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)       -467.402827  311.310887 -1.5014  0.14056  
## regionnortheast     15.727405   25.307782  0.6214  0.53759  
## regionsouth          7.087424   23.561063  0.3008  0.76501  
## regionwest          34.324157   24.122587  1.4229  0.16198  
## residents           -0.034558    0.091844 -0.3763  0.70857  
## young_residents      1.301458    0.688297  1.8908  0.06540 .
## per_capita_income    0.072036    0.029999  2.4013  0.02073 *
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s is also easy to change the estimation method for the variance-covariance matrix:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeftest(lmfit, vcov = vcovHC(lmfit, type = &amp;quot;HC0&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## t test of coefficients:
## 
##                      Estimate  Std. Error t value  Pr(&amp;gt;|t|)    
## (Intercept)       -467.402827  172.577569 -2.7084  0.009666 ** 
## regionnortheast     15.727405   20.488148  0.7676  0.446899    
## regionsouth          7.087424   17.755889  0.3992  0.691752    
## regionwest          34.324157   19.308578  1.7777  0.082532 .  
## residents           -0.034558    0.054145 -0.6382  0.526703    
## young_residents      1.301458    0.387743  3.3565  0.001659 ** 
## per_capita_income    0.072036    0.016638  4.3296 8.773e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As I wrote above, by default, the &lt;code&gt;type&lt;/code&gt; argument is equal to “HC3”.&lt;/p&gt;
&lt;p&gt;Another way of dealing with heteroskedasticity is to use the &lt;code&gt;lmrob()&lt;/code&gt; function from the
&lt;code&gt;{robustbase}&lt;/code&gt; package. This package is quite interesting, and offers quite a lot of functions
for robust linear, and nonlinear, regression models. Running a robust linear regression
is just the same as with &lt;code&gt;lm()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmrobfit &amp;lt;- lmrob(per_capita_exp ~ region + residents + young_residents + per_capita_income, 
                  data = education)

summary(lmrobfit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lmrob(formula = per_capita_exp ~ region + residents + young_residents + per_capita_income, 
##     data = education)
##  \--&amp;gt; method = &amp;quot;MM&amp;quot;
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -57.074 -14.803  -0.853  24.154 174.279 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)       -156.37169  132.73828  -1.178  0.24526   
## regionnortheast     20.64576   26.45378   0.780  0.43940   
## regionsouth         10.79695   29.42746   0.367  0.71549   
## regionwest          45.22589   33.07950   1.367  0.17867   
## residents            0.03406    0.04412   0.772  0.44435   
## young_residents      0.57896    0.25512   2.269  0.02832 * 
## per_capita_income    0.04328    0.01442   3.000  0.00447 **
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Robust residual standard error: 26.4 
## Multiple R-squared:  0.6235, Adjusted R-squared:  0.571 
## Convergence in 24 IRWLS iterations
## 
## Robustness weights: 
##  observation 50 is an outlier with |weight| = 0 ( &amp;lt; 0.002); 
##  7 weights are ~= 1. The remaining 42 ones are summarized as
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.05827 0.85200 0.93870 0.85250 0.98700 0.99790 
## Algorithmic parameters: 
##        tuning.chi                bb        tuning.psi        refine.tol 
##         1.548e+00         5.000e-01         4.685e+00         1.000e-07 
##           rel.tol         scale.tol         solve.tol       eps.outlier 
##         1.000e-07         1.000e-10         1.000e-07         2.000e-03 
##             eps.x warn.limit.reject warn.limit.meanrw 
##         1.071e-08         5.000e-01         5.000e-01 
##      nResample         max.it       best.r.s       k.fast.s          k.max 
##            500             50              2              1            200 
##    maxit.scale      trace.lev            mts     compute.rd fast.s.large.n 
##            200              0           1000              0           2000 
##                   psi           subsampling                   cov 
##            &amp;quot;bisquare&amp;quot;         &amp;quot;nonsingular&amp;quot;         &amp;quot;.vcov.avar1&amp;quot; 
## compute.outlier.stats 
##                  &amp;quot;SM&amp;quot; 
## seed : int(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This however, gives you different estimates than when fitting a linear regression model.
The estimates should be the same, only the standard errors should be different. This is because
the estimation method is different, and is also robust to outliers (at least that’s my understanding,
I haven’t read the theoretical papers behind the package yet).&lt;/p&gt;
&lt;p&gt;Finally, it is also possible to bootstrap the standard errors. For this I will use the
&lt;code&gt;bootstrap()&lt;/code&gt; function from the &lt;code&gt;{modelr}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resamples &amp;lt;- 100

boot_education &amp;lt;- education %&amp;gt;% 
 modelr::bootstrap(resamples)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the &lt;code&gt;boot_education&lt;/code&gt; object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_education&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 2
##    strap      .id  
##    &amp;lt;list&amp;gt;     &amp;lt;chr&amp;gt;
##  1 &amp;lt;resample&amp;gt; 001  
##  2 &amp;lt;resample&amp;gt; 002  
##  3 &amp;lt;resample&amp;gt; 003  
##  4 &amp;lt;resample&amp;gt; 004  
##  5 &amp;lt;resample&amp;gt; 005  
##  6 &amp;lt;resample&amp;gt; 006  
##  7 &amp;lt;resample&amp;gt; 007  
##  8 &amp;lt;resample&amp;gt; 008  
##  9 &amp;lt;resample&amp;gt; 009  
## 10 &amp;lt;resample&amp;gt; 010  
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The column &lt;code&gt;strap&lt;/code&gt; contains resamples of the original data. I will run my linear regression
from before on each of the resamples:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
    boot_lin_reg &amp;lt;- boot_education %&amp;gt;% 
        mutate(regressions = 
                   map(strap, 
                       ~lm(per_capita_exp ~ region + residents + 
                               young_residents + per_capita_income, 
                           data = .))) 
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 3
##    strap      .id   regressions
##    &amp;lt;list&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt;     
##  1 &amp;lt;resample&amp;gt; 001   &amp;lt;lm&amp;gt;       
##  2 &amp;lt;resample&amp;gt; 002   &amp;lt;lm&amp;gt;       
##  3 &amp;lt;resample&amp;gt; 003   &amp;lt;lm&amp;gt;       
##  4 &amp;lt;resample&amp;gt; 004   &amp;lt;lm&amp;gt;       
##  5 &amp;lt;resample&amp;gt; 005   &amp;lt;lm&amp;gt;       
##  6 &amp;lt;resample&amp;gt; 006   &amp;lt;lm&amp;gt;       
##  7 &amp;lt;resample&amp;gt; 007   &amp;lt;lm&amp;gt;       
##  8 &amp;lt;resample&amp;gt; 008   &amp;lt;lm&amp;gt;       
##  9 &amp;lt;resample&amp;gt; 009   &amp;lt;lm&amp;gt;       
## 10 &amp;lt;resample&amp;gt; 010   &amp;lt;lm&amp;gt;       
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have added a new column called &lt;code&gt;regressions&lt;/code&gt; which contains the linear regressions on each
bootstrapped sample. Now, I will create a list of tidied regression results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
    tidied &amp;lt;- boot_lin_reg %&amp;gt;% 
        mutate(tidy_lm = 
                   map(regressions, broom::tidy))
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 4
##    strap      .id   regressions tidy_lm         
##    &amp;lt;list&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt;      &amp;lt;list&amp;gt;          
##  1 &amp;lt;resample&amp;gt; 001   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  2 &amp;lt;resample&amp;gt; 002   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  3 &amp;lt;resample&amp;gt; 003   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  4 &amp;lt;resample&amp;gt; 004   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  5 &amp;lt;resample&amp;gt; 005   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  6 &amp;lt;resample&amp;gt; 006   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  7 &amp;lt;resample&amp;gt; 007   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  8 &amp;lt;resample&amp;gt; 008   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
##  9 &amp;lt;resample&amp;gt; 009   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
## 10 &amp;lt;resample&amp;gt; 010   &amp;lt;lm&amp;gt;        &amp;lt;tibble [7 × 5]&amp;gt;
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;broom::tidy()&lt;/code&gt; creates a data frame of the regression results. Let’s look at one of these:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidied$tidy_lm[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 5
##   term              estimate std.error statistic  p.value
##   &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 (Intercept)       -571.     109.        -5.22  4.92e- 6
## 2 regionnortheast    -48.0     17.2       -2.80  7.71e- 3
## 3 regionsouth        -21.3     15.1       -1.41  1.66e- 1
## 4 regionwest           1.88    13.9        0.135 8.93e- 1
## 5 residents           -0.134    0.0608    -2.21  3.28e- 2
## 6 young_residents      1.50     0.308      4.89  1.47e- 5
## 7 per_capita_income    0.100    0.0125     8.06  3.85e-10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This format is easier to handle than the standard &lt;code&gt;lm()&lt;/code&gt; output:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidied$regressions[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = per_capita_exp ~ region + residents + young_residents + 
##     per_capita_income, data = .)
## 
## Coefficients:
##       (Intercept)    regionnortheast        regionsouth  
##         -571.0568           -48.0018           -21.3019  
##        regionwest          residents    young_residents  
##            1.8808            -0.1341             1.5042  
## per_capita_income  
##            0.1005&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have all these regression results, I can compute any statistic I need. But first,
let’s transform the data even further:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_mods &amp;lt;- tidied %&amp;gt;% 
    pull(tidy_lm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;list_mods&lt;/code&gt; is a list of the &lt;code&gt;tidy_lm&lt;/code&gt; data frames. I now add an index and
bind the rows together (by using &lt;code&gt;map2_df()&lt;/code&gt; instead of &lt;code&gt;map2()&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mods_df &amp;lt;- map2_df(list_mods, 
                   seq(1, resamples), 
                   ~mutate(.x, resample = .y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the final object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(mods_df, 25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 25 x 6
##    term              estimate std.error statistic  p.value resample
##    &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;
##  1 (Intercept)       -571.     109.        -5.22  4.92e- 6        1
##  2 regionnortheast    -48.0     17.2       -2.80  7.71e- 3        1
##  3 regionsouth        -21.3     15.1       -1.41  1.66e- 1        1
##  4 regionwest           1.88    13.9        0.135 8.93e- 1        1
##  5 residents           -0.134    0.0608    -2.21  3.28e- 2        1
##  6 young_residents      1.50     0.308      4.89  1.47e- 5        1
##  7 per_capita_income    0.100    0.0125     8.06  3.85e-10        1
##  8 (Intercept)        -97.2    145.        -0.672 5.05e- 1        2
##  9 regionnortheast     -1.48    10.8       -0.136 8.92e- 1        2
## 10 regionsouth         12.5     11.4        1.09  2.82e- 1        2
## # … with 15 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now this is a very useful format, because I now can group by the &lt;code&gt;term&lt;/code&gt; column and compute any
statistics I need, in the present case the standard deviation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(
    r.std.error &amp;lt;- mods_df %&amp;gt;% 
        group_by(term) %&amp;gt;% 
        summarise(r.std.error = sd(estimate))
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 2
##   term              r.std.error
##   &amp;lt;chr&amp;gt;                   &amp;lt;dbl&amp;gt;
## 1 (Intercept)          220.    
## 2 per_capita_income      0.0197
## 3 regionnortheast       24.5   
## 4 regionsouth           21.1   
## 5 regionwest            22.7   
## 6 residents              0.0607
## 7 young_residents        0.498&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can append this column to the linear regression model result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmfit %&amp;gt;% 
    broom::tidy() %&amp;gt;% 
    full_join(r.std.error) %&amp;gt;% 
    select(term, estimate, std.error, r.std.error)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;term&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 4
##   term               estimate std.error r.std.error
##   &amp;lt;chr&amp;gt;                 &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 (Intercept)       -467.      143.        220.    
## 2 regionnortheast     15.7      18.2        24.5   
## 3 regionsouth          7.09     17.3        21.1   
## 4 regionwest          34.3      17.5        22.7   
## 5 residents           -0.0346    0.0532      0.0607
## 6 young_residents      1.30      0.357       0.498 
## 7 per_capita_income    0.0720    0.0131      0.0197&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you see, using the whole bootstrapping procedure is longer than simply using either one of
the first two methods. However, this procedure is very flexible and can thus be adapted to a very
large range of situations. Either way, in the case of heteroskedasticity, you can see that
results vary a lot depending on the procedure you use, so I would advise to use them all as
robustness tests and discuss the differences.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Missing data imputation and instrumental variables regression: the tidy approach</title>
      <link>https://www.brodrigues.co/blog/2018-07-01-tidy_ive/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-07-01-tidy_ive/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=o5S7CreWiBY/&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/trumpet_boy.jpg&#34; width=&#34;640&#34; height=&#34;360&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this blog post I will discuss missing data imputation and instrumental variables regression. This
is based on a short presentation I will give at my job. You can find the data used here on this
website: &lt;a href=&#34;http://eclr.humanities.manchester.ac.uk/index.php/IV_in_R&#34; class=&#34;uri&#34;&gt;http://eclr.humanities.manchester.ac.uk/index.php/IV_in_R&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The data is used is from Wooldridge’s book, &lt;em&gt;Econometrics: A modern Approach&lt;/em&gt;.
You can download the data by clicking &lt;a href=&#34;http://eclr.humanities.manchester.ac.uk/images/5/5f/Mroz.csv&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is the variable description:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 1. inlf                     =1 if in labor force, 1975
 2. hours                    hours worked, 1975
 3. kidslt6                  # kids &amp;lt; 6 years
 4. kidsge6                  # kids 6-18
 5. age                      woman&amp;#39;s age in yrs
 6. educ                     years of schooling
 7. wage                     estimated wage from earns., hours
 8. repwage                  reported wage at interview in 1976
 9. hushrs                   hours worked by husband, 1975
10. husage                   husband&amp;#39;s age
11. huseduc                  husband&amp;#39;s years of schooling
12. huswage                  husband&amp;#39;s hourly wage, 1975
13. faminc                   family income, 1975
14. mtr                      fed. marginal tax rate facing woman
15. motheduc                 mother&amp;#39;s years of schooling
16. fatheduc                 father&amp;#39;s years of schooling
17. unem                     unem. rate in county of resid.
18. city                     =1 if live in SMSA
19. exper                    actual labor mkt exper
20. nwifeinc                 (faminc - wage*hours)/1000
21. lwage                    log(wage)
22. expersq                  exper^2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The goal is to first impute missing data in the data set, and then determine the impact of one added
year of education on wages. If one simply ignores missing values, bias can be introduced depending on
the missingness mechanism. The second problem here is that education is likely to be endogeneous
(and thus be correlated to the error term), as it is not randomly assigned. This causes biased estimates
and may lead to seriously wrong conclusions. So missingness and endogeneity should be dealt with, but
dealing with both issues is more of a programming challenge than an econometrics challenge.
Thankfully, the packages contained in the &lt;code&gt;{tidyverse}&lt;/code&gt; as well as &lt;code&gt;{mice}&lt;/code&gt; will save the day!&lt;/p&gt;
&lt;p&gt;If you inspect the data, you will see that there are no missing values. So I will use the &lt;code&gt;{mice}&lt;/code&gt;
package to first &lt;em&gt;ampute&lt;/em&gt; the data (which means adding missing values). This, of course, is done
for education purposes. If you’re lucky enough to not have missing values in your data, you shouldn’t
add them!&lt;/p&gt;
&lt;p&gt;Let’s load all the packages needed:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(AER)
library(naniar)
library(mice)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So first, let’s read in the data, and ampute it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wages_data &amp;lt;- read_csv(&amp;quot;http://eclr.humanities.manchester.ac.uk/images/5/5f/Mroz.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   .default = col_integer(),
##   wage = col_character(),
##   repwage = col_double(),
##   huswage = col_double(),
##   mtr = col_double(),
##   unem = col_double(),
##   nwifeinc = col_double(),
##   lwage = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## See spec(...) for full column specifications.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, I only select the variables I want to use and convert them to the correct class:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wages_data &amp;lt;- wages_data %&amp;gt;% 
    select(wage, educ, fatheduc, motheduc, inlf, hours, 
               kidslt6, kidsge6, age, huswage, 
               mtr, unem, city, exper) %&amp;gt;% 
    mutate_at(vars(kidslt6, kidsge6, hours, educ, age, wage, huswage, mtr,
                    motheduc, fatheduc, unem, exper), as.numeric) %&amp;gt;% 
    mutate_at(vars(city, inlf), as.character)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in evalq(as.numeric(wage), &amp;lt;environment&amp;gt;): NAs introduced by
## coercion&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the data, some women are not in the labour force, and thus do not have any wages; meaning they
should have a 0 there. Instead, this is represented with the following symbol: “.”. So I convert
these dots to 0. One could argue that the wages should not be 0, but that they’re truly missing.
This is true, and there are ways to deal with such questions (Heckman’s selection model for instance),
but this is not the point here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wages_data &amp;lt;- wages_data %&amp;gt;% 
    mutate(wage = ifelse(is.na(wage), 0, wage))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s double check if there are any missing values in the data, using &lt;code&gt;naniar::vis_miss()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vis_miss(wages_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-07-01-tidy_ive_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nope! Let’s ampute it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wages_mis &amp;lt;- ampute(wages_data)$amp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Data is made numeric because the calculation of weights requires
## numeric data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ampute()&lt;/code&gt; returns an object where the &lt;code&gt;amp&lt;/code&gt; element is the amputed data. This is what I save into
the new variable &lt;code&gt;wages_mis&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vis_miss(wages_mis)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-07-01-tidy_ive_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ok, so now we have missing values. Let’s use the recently added &lt;code&gt;mice::parlmice()&lt;/code&gt; function to
impute the dataset, in parallel:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages &amp;lt;- parlmice(data = wages_mis, m = 10, maxit = 20, cl.type = &amp;quot;FORK&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For reproducibility, I save these objects to disk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write_csv(wages_mis, &amp;quot;wages_mis.csv&amp;quot;)

saveRDS(imp_wages, &amp;quot;imp_wages.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a sanity check, let’s look at the missingness pattern for the first completed dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vis_miss(complete(imp_wages))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-07-01-tidy_ive_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mice::parlmice()&lt;/code&gt; was able to impute the dataset. I imputed it 10 times, so now I have 10 imputed
datasets. If I want to estimate a model using this data, I will need to do so 10 times.
This is where the tidyverse comes into play. First, let’s combine all the 10 imputed datasets into
one long dataset, with an index to differentiate them. This is done easily with &lt;code&gt;mice::complete()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_df &amp;lt;- mice::complete(imp_wages, &amp;quot;long&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(imp_wages_df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   .imp .id   wage educ fatheduc motheduc inlf hours kidslt6 kidsge6 age
## 1    1   1 3.3540   12        7       12    1  1610       1       0  32
## 2    1   2 1.3889   12        7        7    1  1656       0       2  30
## 3    1   3 4.5455   12        7       12    1  1980       0       3  35
## 4    1   4 1.0965   12        7        7    1   456       0       3  34
## 5    1   5 4.5918   14       14       12    1  1568       1       2  31
## 6    1   6 4.7421   12        7       14    1  2032       0       0  54
##   huswage    mtr unem city exper
## 1  4.0288 0.7215  5.0    0    14
## 2  8.4416 0.6615 11.0    1     5
## 3  3.5807 0.6915  5.0    0    15
## 4  3.5417 0.7815  5.0    0     6
## 5 10.0000 0.6215  9.5    1    14
## 6  4.7364 0.6915  7.5    1    33&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, there are two new columns, &lt;code&gt;.id&lt;/code&gt; and &lt;code&gt;.imp&lt;/code&gt;. &lt;code&gt;.imp&lt;/code&gt; equals &lt;code&gt;i&lt;/code&gt; means that it is the
&lt;code&gt;i&lt;/code&gt;th imputed dataset.&lt;/p&gt;
&lt;p&gt;Because I have 0’s in my dependent variable, I will not log the wages but instead use the Inverse
Hyperbolic Sine transformation. Marc F. Bellemare wrote a nice post about
it &lt;a href=&#34;http://marcfbellemare.com/wordpress/12856&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ihs &amp;lt;- function(x){
    log(x + sqrt(x**2 + 1))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can now apply this function, but first I have to group by &lt;code&gt;.imp&lt;/code&gt;. Remember, these are 10 separated
datasets. I also create the experience squared:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_df &amp;lt;- imp_wages_df %&amp;gt;% 
    group_by(.imp) %&amp;gt;% 
    mutate(ihs_wage = ihs(wage),
           exper2 = exper**2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now comes some tidyverse magic. I will create a new dataset by using the &lt;code&gt;nest()&lt;/code&gt; function from &lt;code&gt;tidyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(imp_wages &amp;lt;- imp_wages_df %&amp;gt;% 
    group_by(.imp) %&amp;gt;% 
    nest())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 2
##     .imp data               
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             
##  1     1 &amp;lt;tibble [753 × 17]&amp;gt;
##  2     2 &amp;lt;tibble [753 × 17]&amp;gt;
##  3     3 &amp;lt;tibble [753 × 17]&amp;gt;
##  4     4 &amp;lt;tibble [753 × 17]&amp;gt;
##  5     5 &amp;lt;tibble [753 × 17]&amp;gt;
##  6     6 &amp;lt;tibble [753 × 17]&amp;gt;
##  7     7 &amp;lt;tibble [753 × 17]&amp;gt;
##  8     8 &amp;lt;tibble [753 × 17]&amp;gt;
##  9     9 &amp;lt;tibble [753 × 17]&amp;gt;
## 10    10 &amp;lt;tibble [753 × 17]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, &lt;code&gt;imp_wages&lt;/code&gt; is now a dataset with two columns: &lt;code&gt;.imp&lt;/code&gt;, indexing the imputed datasets,
and a column called &lt;code&gt;data&lt;/code&gt;, where each element is itself a tibble! &lt;code&gt;data&lt;/code&gt; is a so-called list-column.
You can read more about it on the
&lt;a href=&#34;https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html&#34;&gt;&lt;code&gt;purrr&lt;/code&gt; tutorial&lt;/a&gt; written by
&lt;a href=&#34;https://twitter.com/JennyBryan&#34;&gt;Jenny Bryan&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Estimating a model now is easy, if you’re familiar with &lt;code&gt;purrr&lt;/code&gt;. This is how you do it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_reg = imp_wages %&amp;gt;% 
    mutate(lin_reg = map(data, 
                         ~lm(ihs_wage ~ educ + inlf + hours + 
                                 kidslt6 + kidsge6 + age + huswage + 
                                 mtr + unem + city + exper + exper2, 
                             data = .)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so what happened here? &lt;code&gt;imp_wages&lt;/code&gt; is a data frame, so it’s possible to add a column to it
with &lt;code&gt;mutate()&lt;/code&gt;. I call that column &lt;code&gt;lin_reg&lt;/code&gt; and use &lt;code&gt;map()&lt;/code&gt; on the column called &lt;code&gt;data&lt;/code&gt; (remember,
this column is actually a list of data frame objects, and &lt;code&gt;map()&lt;/code&gt; takes a list as an argument, and then a
function or formula) with the following formula:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;~lm(ihs_wage ~ educ + inlf + hours + 
        kidslt6 + kidsge6 + age + huswage + 
        mtr + unem + city + exper + exper2, 
    data = .)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This formula is nothing more that a good old linear regression. The last line &lt;code&gt;data = .&lt;/code&gt; means that
the data to be used inside &lt;code&gt;lm()&lt;/code&gt; should be coming from the list called &lt;code&gt;data&lt;/code&gt;, which is the second
column of &lt;code&gt;imp_wages&lt;/code&gt;. As I’m writing these lines, I realize it is confusing as hell. But I promise
you that learning to use &lt;code&gt;purrr&lt;/code&gt; is a bit like learning how to use a bicycle. Very difficult to explain,
but once you know how to do it, it feels super natural. Take some time to play with the lines above
to really understand what happened.&lt;/p&gt;
&lt;p&gt;Now, let’s take a look at the result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_reg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 3
##     .imp data                lin_reg
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;              &amp;lt;list&amp;gt; 
##  1     1 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  2     2 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  3     3 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  4     4 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  5     5 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  6     6 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  7     7 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  8     8 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
##  9     9 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;   
## 10    10 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;imp_wages_reg&lt;/code&gt; now has a third column called &lt;code&gt;lin_reg&lt;/code&gt; where each element is a linear model, estimated
on the data from the &lt;code&gt;data&lt;/code&gt; column! We can now pool the results of these 10 regressions using
&lt;code&gt;mice::pool()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pool_lin_reg &amp;lt;- pool(imp_wages_reg$lin_reg)

summary(pool_lin_reg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  estimate    std.error  statistic       df      p.value
## (Intercept)  1.2868701172 3.214473e-01  4.0033628 737.9337 6.876133e-05
## educ         0.0385310276 8.231906e-03  4.6806931 737.9337 3.401935e-06
## inlf         1.8845418354 5.078235e-02 37.1101707 737.9337 0.000000e+00
## hours       -0.0001164143 3.011378e-05 -3.8658143 737.9337 1.204773e-04
## kidslt6     -0.0438925013 3.793152e-02 -1.1571510 737.9337 2.475851e-01
## kidsge6     -0.0117978229 1.405226e-02 -0.8395678 737.9337 4.014227e-01
## age         -0.0030084595 2.666614e-03 -1.1281946 737.9337 2.596044e-01
## huswage     -0.0231736955 5.607364e-03 -4.1327255 737.9337 3.995866e-05
## mtr         -2.2109176781 3.188827e-01 -6.9333267 737.9337 8.982592e-12
## unem         0.0028775444 5.462973e-03  0.5267360 737.9337 5.985352e-01
## city         0.0157414671 3.633755e-02  0.4332011 737.9337 6.649953e-01
## exper        0.0164364027 6.118875e-03  2.6861806 737.9337 7.389936e-03
## exper2      -0.0002022602 1.916146e-04 -1.0555575 737.9337 2.915159e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function averages the results from the 10 regressions and computes correct standard errors. This
is based on Rubin’s rules (Rubin, 1987, p. 76). As you can see, the linear regression indicates that
one year of added education has a positive, significant effect of log wages (they’re not log wages,
I used the IHS transformation, but &lt;em&gt;log wages&lt;/em&gt; just sounds better than &lt;em&gt;inverted hyperbolic sined wages&lt;/em&gt;).
This effect is almost 4%.&lt;/p&gt;
&lt;p&gt;But education is not randomly assigned, and as such might be endogenous. This is where instrumental
variables come into play. An instrument is a variables that impacts the dependent variable only through
the endogenous variable (here, education). For example, the education of the parents do not have
a direct impact over one’s wage, but having college-educated parents means that you are likely
college-educated yourself, and thus have a higher wage that if you only have a high school diploma.&lt;/p&gt;
&lt;p&gt;I am thus going to instrument education with both parents’ education:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_reg = imp_wages_reg %&amp;gt;% 
    mutate(iv_reg = map(data, 
                         ~ivreg(ihs_wage ~ educ + inlf + hours + 
                                 kidslt6 + kidsge6 + age + huswage + 
                                 mtr + unem + city + exper + exper2 |.-educ + fatheduc + motheduc, 
                             data = .)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only difference from before is the formula:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;~ivreg(ihs_wage ~ educ + inlf + hours + 
           kidslt6 + kidsge6 + age + huswage + 
           mtr + unem + city + exper + exper2 |.-educ + fatheduc + motheduc, 
       data = .)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ~ivreg(ihs_wage ~ educ + inlf + hours + kidslt6 + kidsge6 + age + 
##     huswage + mtr + unem + city + exper + exper2 | . - educ + 
##     fatheduc + motheduc, data = .)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of &lt;code&gt;lm()&lt;/code&gt; I use &lt;code&gt;AER::ivreg()&lt;/code&gt; and the formula has a second part, after the &lt;code&gt;|&lt;/code&gt; symbol. This
is where I specify that I instrument education with the parents’ education.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;imp_wages_reg&lt;/code&gt; now looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_wages_reg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 4
##     .imp data                lin_reg iv_reg 
##    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;              &amp;lt;list&amp;gt;  &amp;lt;list&amp;gt; 
##  1     1 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  2     2 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  3     3 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  4     4 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  5     5 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  6     6 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  7     7 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  8     8 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
##  9     9 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;
## 10    10 &amp;lt;tibble [753 × 17]&amp;gt; &amp;lt;lm&amp;gt;    &amp;lt;ivreg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pool_iv_reg &amp;lt;- pool(imp_wages_reg$iv_reg)

summary(pool_iv_reg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  estimate    std.error  statistic       df      p.value
## (Intercept)  2.0091904157 5.146812e-01  3.9037568 737.9337 1.033832e-04
## educ         0.0038859137 2.086592e-02  0.1862326 737.9337 8.523136e-01
## inlf         1.9200207113 5.499457e-02 34.9129122 737.9337 0.000000e+00
## hours       -0.0001313866 3.157375e-05 -4.1612608 737.9337 3.537881e-05
## kidslt6     -0.0234593391 4.000689e-02 -0.5863824 737.9337 5.577979e-01
## kidsge6     -0.0123239220 1.422241e-02 -0.8665145 737.9337 3.864897e-01
## age         -0.0040874625 2.763340e-03 -1.4791748 737.9337 1.395203e-01
## huswage     -0.0242737100 5.706497e-03 -4.2536970 737.9337 2.373189e-05
## mtr         -2.6385172445 3.998419e-01 -6.5989008 737.9337 7.907430e-11
## unem         0.0047331976 5.622137e-03  0.8418859 737.9337 4.001246e-01
## city         0.0255647706 3.716783e-02  0.6878197 737.9337 4.917824e-01
## exper        0.0180917073 6.258779e-03  2.8906127 737.9337 3.957817e-03
## exper2      -0.0002291007 1.944599e-04 -1.1781381 737.9337 2.391213e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, education is not statistically significant anymore! This is why it is quite important
to think about endogeneity issues. However, it is not always very easy to find suitable instruments.
A series of tests exist to determine if you have relevant and strong instruments, but this blog post
is already long enough. I will leave this for a future blog post.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
&lt;style&gt;.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:&#39;Cookie&#39;, cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}&lt;/style&gt;
&lt;p&gt;&lt;link href=&#34;https://fonts.googleapis.com/css?family=Cookie&#34; rel=&#34;stylesheet&#34;&gt;&lt;a class=&#34;bmc-button&#34; target=&#34;_blank&#34; href=&#34;https://www.buymeacoffee.com/brodriguesco&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg&#34; alt=&#34;Buy me an Espresso&#34;&gt;&lt;span style=&#34;margin-left:5px&#34;&gt;Buy me an Espresso&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Forecasting my weight with R</title>
      <link>https://www.brodrigues.co/blog/2018-06-24-fun_ts/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-06-24-fun_ts/</guid>
      <description>&lt;p&gt;I’ve been measuring my weight almost daily for almost 2 years now; I actually started earlier, but
not as consistently. The goal of this blog post is to get re-acquaiented with time series; I haven’t
had the opportunity to work with time series for a long time now and I have seen that quite a few
packages that deal with time series have been released on CRAN. In this blog post, I will explore
my weight measurements using some functions from the &lt;code&gt;{tsibble}&lt;/code&gt; and &lt;code&gt;{tibbletime}&lt;/code&gt; packages,
and then do some predictions with the &lt;code&gt;{forecast}&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;First, let’s load the needed packages, read in the data and convert it to a &lt;code&gt;tsibble&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;readr&amp;quot;)
library(&amp;quot;forecast&amp;quot;)
library(&amp;quot;tsibble&amp;quot;)
library(&amp;quot;tibbletime&amp;quot;)
library(&amp;quot;mice&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight &amp;lt;- read_csv(&amp;quot;https://gist.githubusercontent.com/b-rodrigues/ea60679135f8dbed448ccf66a216811f/raw/18b469f3b0720f76ce5ee2715d0f9574b615f170/gistfile1.txt&amp;quot;) %&amp;gt;% 
    as_tsibble()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   Date = col_date(format = &amp;quot;&amp;quot;),
##   Poids = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The `index` is `Date`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about &lt;code&gt;{tsibble}&lt;/code&gt; &lt;a href=&#34;https://pkg.earo.me/tsibble/&#34;&gt;here&lt;/a&gt;. Here, I use &lt;code&gt;{tsibble}&lt;/code&gt; mostly
for the next step, which is using the function &lt;code&gt;fill_na()&lt;/code&gt; on the tsibble. &lt;code&gt;fill_na()&lt;/code&gt; turns
implicit missing values into explicit missing values. These are implicit missing values:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;          Date Poids
1   2013-01-01 84.10
2   2013-01-04 85.60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and this is the same view, but with explicit missing values:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;          Date Poids
1   2013-01-01 84.10
2   2013-01-02 NA
3   2013-01-03 NA
4   2013-01-04 85.60&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful to do, because I want to impute the missing values using the &lt;code&gt;{mice}&lt;/code&gt; package.
Let’s do this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight &amp;lt;- weight %&amp;gt;% 
    fill_na()

imp_weight &amp;lt;- mice(data = weight) %&amp;gt;% 
    mice::complete(&amp;quot;long&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  iter imp variable
##   1   1  Poids
##   1   2  Poids
##   1   3  Poids
##   1   4  Poids
##   1   5  Poids
##   2   1  Poids
##   2   2  Poids
##   2   3  Poids
##   2   4  Poids
##   2   5  Poids
##   3   1  Poids
##   3   2  Poids
##   3   3  Poids
##   3   4  Poids
##   3   5  Poids
##   4   1  Poids
##   4   2  Poids
##   4   3  Poids
##   4   4  Poids
##   4   5  Poids
##   5   1  Poids
##   5   2  Poids
##   5   3  Poids
##   5   4  Poids
##   5   5  Poids&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;imp_weight&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(imp_weight)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   .imp .id       Date Poids
## 1    1   1 2013-10-28  84.1
## 2    1   2 2013-10-29  84.4
## 3    1   3 2013-10-30  83.5
## 4    1   4 2013-10-31  84.1
## 5    1   5 2013-11-01  85.6
## 6    1   6 2013-11-02  85.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s select the relevant data. I filter from the 11th of July 2016, which is where I started
weighing myself almost every day, to the 31st of May 2018. I want to predict my weight for the
month of June (you might think of the month of June 2018 as the test data, and the rest as training
data):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_weight_train &amp;lt;- imp_weight %&amp;gt;% 
    filter(Date &amp;gt;= &amp;quot;2016-07-11&amp;quot;, Date &amp;lt;= &amp;quot;2018-05-31&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next lines, I create a column called &lt;code&gt;imputation&lt;/code&gt; which is simply the same as the column
&lt;code&gt;.imp&lt;/code&gt; but of character class, remove unneeded columns and rename some other columns (“Poids” is
French for weight):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_weight_train &amp;lt;- imp_weight_train %&amp;gt;% 
    mutate(imputation = as.character(.imp)) %&amp;gt;% 
    select(-.id, -.imp) %&amp;gt;% 
    rename(date = Date) %&amp;gt;% 
    rename(weight = Poids)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(imp_weight_train, aes(date, weight, colour = imputation)) +
    geom_line() + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-06-24-fun_ts_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plots gives some info, but it might be better to smooth the lines. This is possible by
computing a rolling mean. For this I will use the &lt;code&gt;rollify()&lt;/code&gt; function of the &lt;code&gt;{tibbletime}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_roll_5 &amp;lt;- rollify(mean, window = 5)
mean_roll_10 &amp;lt;- rollify(mean, window = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;rollify()&lt;/code&gt; can be seen as an adverb, pretty much like &lt;code&gt;purrr::safely()&lt;/code&gt;; &lt;code&gt;rollify()&lt;/code&gt; is a higher
order function that literally rollifies a function, in this case &lt;code&gt;mean()&lt;/code&gt; which means that
rollifying the mean creates a function that returns the rolling mean. The &lt;code&gt;window&lt;/code&gt; argument lets
you decide how smooth you want the curve to be: the higher the smoother. However, you will lose
some observations. Let’s use this functions to add the rolling means to the data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_weight_train &amp;lt;- imp_weight_train %&amp;gt;% 
    group_by(imputation) %&amp;gt;% 
    mutate(roll_5 = mean_roll_5(weight),
           roll_10 = mean_roll_10(weight))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s plot these new curves:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(imp_weight_train, aes(date, roll_5, colour = imputation)) +
    geom_line() + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 20 rows containing missing values (geom_path).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-06-24-fun_ts_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(imp_weight_train, aes(date, roll_10, colour = imputation)) +
    geom_line() + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 45 rows containing missing values (geom_path).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-06-24-fun_ts_files/figure-html/unnamed-chunk-11-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That’s easier to read, isn’t it?&lt;/p&gt;
&lt;p&gt;Now, I will use the &lt;code&gt;auto.arima()&lt;/code&gt; function to train a model on the data to forecast my weight for
the month of June. However, my data, &lt;code&gt;imp_weight_train&lt;/code&gt; is a list of datasets. &lt;code&gt;auto.arima()&lt;/code&gt; does
not take a data frame as an argument, much less so a list of datasets. I’ll create a wrapper around
&lt;code&gt;auto.arima()&lt;/code&gt; that works on a dataset, and then map it to the list of datasets:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;auto.arima.df &amp;lt;- function(data, y, ...){

    y &amp;lt;- enquo(y)

    yts &amp;lt;- data %&amp;gt;% 
        pull(!!y) %&amp;gt;% 
        as.ts()

    auto.arima(yts, ...)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;auto.arima.df()&lt;/code&gt; takes a data frame as argument, and then &lt;code&gt;y&lt;/code&gt;, which is the column that contains the
univariate time series. This column then gets pulled out of the data frame, converted to a time
series object with &lt;code&gt;as.ts()&lt;/code&gt;, and then passed down to &lt;code&gt;auto.arima()&lt;/code&gt;. I can now use this function
on my list of data sets. The first step is to nest the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nested_data &amp;lt;- imp_weight_train %&amp;gt;% 
    group_by(imputation) %&amp;gt;% 
    nest() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;nested_data&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nested_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   imputation data              
##   &amp;lt;chr&amp;gt;      &amp;lt;list&amp;gt;            
## 1 1          &amp;lt;tibble [690 × 4]&amp;gt;
## 2 2          &amp;lt;tibble [690 × 4]&amp;gt;
## 3 3          &amp;lt;tibble [690 × 4]&amp;gt;
## 4 4          &amp;lt;tibble [690 × 4]&amp;gt;
## 5 5          &amp;lt;tibble [690 × 4]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;nested_data&lt;/code&gt; is a tibble with a column called &lt;code&gt;data&lt;/code&gt;, which is a so-called list-column. Each
element of &lt;code&gt;data&lt;/code&gt; is itself a tibble. This is a useful structure, because now I can map &lt;code&gt;auto.arima.df()&lt;/code&gt;
to the data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models &amp;lt;- nested_data %&amp;gt;% 
    mutate(model = map(data, auto.arima.df, y = weight))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This trick can be a bit difficult to follow the first time you see it. The idea is the following:
&lt;code&gt;nested_data&lt;/code&gt; is a tibble. Thus, I can add a column to it using &lt;code&gt;mutate()&lt;/code&gt;. So far so good.
Now that I am “inside” the mutate call, I can use &lt;code&gt;purrr::map()&lt;/code&gt;. Why? &lt;code&gt;purrr::map()&lt;/code&gt; takes a list
and then a function as arguments. Remember that &lt;code&gt;data&lt;/code&gt; is a list column; you can see it above,
the type of the column &lt;code&gt;data&lt;/code&gt; is list. So &lt;code&gt;data&lt;/code&gt; is a list, and thus can be used inside &lt;code&gt;purrr::map()&lt;/code&gt;.
Great. Now, what is inside &lt;code&gt;data&lt;/code&gt;? tibbles, where inside each of them is a column
called &lt;code&gt;weight&lt;/code&gt;. This is the column that contains my univariate time series I want to model. Let’s
take a look at &lt;code&gt;models&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 3
##   imputation data               model      
##   &amp;lt;chr&amp;gt;      &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;     
## 1 1          &amp;lt;tibble [690 × 4]&amp;gt; &amp;lt;S3: ARIMA&amp;gt;
## 2 2          &amp;lt;tibble [690 × 4]&amp;gt; &amp;lt;S3: ARIMA&amp;gt;
## 3 3          &amp;lt;tibble [690 × 4]&amp;gt; &amp;lt;S3: ARIMA&amp;gt;
## 4 4          &amp;lt;tibble [690 × 4]&amp;gt; &amp;lt;S3: ARIMA&amp;gt;
## 5 5          &amp;lt;tibble [690 × 4]&amp;gt; &amp;lt;S3: ARIMA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;models&lt;/code&gt; is a tibble with a column called &lt;code&gt;model&lt;/code&gt;, where each element is a model of type &lt;code&gt;ARIMA&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Adding forecasts is based on the same trick as above, and we use the &lt;code&gt;forecast()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecasts &amp;lt;- models %&amp;gt;% 
    mutate(predictions = map(model, forecast, h = 24)) %&amp;gt;% 
    mutate(predictions = map(predictions, as_tibble)) %&amp;gt;% 
    pull(predictions) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I forecast 24 days (I am writing this on the 24th of June), and convert the predictions to tibbles,
and then pull only the predictions tibble:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecasts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 24 x 5
##    `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95`
##  *            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1             71.5    70.7    72.3    70.2    72.8
##  2             71.5    70.7    72.4    70.3    72.8
##  3             71.5    70.6    72.3    70.1    72.8
##  4             71.5    70.6    72.4    70.1    72.9
##  5             71.4    70.5    72.4    70.0    72.9
##  6             71.5    70.5    72.4    70.0    72.9
##  7             71.4    70.5    72.4    69.9    72.9
##  8             71.4    70.4    72.4    69.9    72.9
##  9             71.4    70.4    72.4    69.9    72.9
## 10             71.4    70.4    72.4    69.8    73.0
## # ... with 14 more rows
## 
## [[2]]
## # A tibble: 24 x 5
##    `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95`
##  *            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1             71.6    70.8    72.3    70.3    72.8
##  2             71.6    70.8    72.5    70.3    72.9
##  3             71.5    70.6    72.4    70.2    72.9
##  4             71.5    70.6    72.5    70.1    72.9
##  5             71.5    70.5    72.5    70.0    73.0
##  6             71.5    70.5    72.5    70.0    73.0
##  7             71.5    70.5    72.5    69.9    73.0
##  8             71.5    70.4    72.5    69.9    73.1
##  9             71.5    70.4    72.5    69.8    73.1
## 10             71.4    70.3    72.6    69.7    73.1
## # ... with 14 more rows
## 
## [[3]]
## # A tibble: 24 x 5
##    `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95`
##  *            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1             71.6    70.8    72.4    70.4    72.8
##  2             71.5    70.7    72.4    70.2    72.8
##  3             71.5    70.6    72.4    70.2    72.9
##  4             71.5    70.6    72.4    70.1    72.9
##  5             71.5    70.5    72.4    70.0    72.9
##  6             71.5    70.5    72.4    70.0    73.0
##  7             71.5    70.5    72.5    69.9    73.0
##  8             71.4    70.4    72.5    69.9    73.0
##  9             71.4    70.4    72.5    69.8    73.0
## 10             71.4    70.4    72.5    69.8    73.1
## # ... with 14 more rows
## 
## [[4]]
## # A tibble: 24 x 5
##    `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95`
##  *            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1             71.5    70.8    72.3    70.3    72.8
##  2             71.5    70.7    72.4    70.3    72.8
##  3             71.5    70.7    72.4    70.2    72.8
##  4             71.5    70.6    72.4    70.1    72.9
##  5             71.5    70.6    72.4    70.1    72.9
##  6             71.5    70.5    72.5    70.0    73.0
##  7             71.5    70.5    72.5    69.9    73.0
##  8             71.5    70.4    72.5    69.9    73.0
##  9             71.4    70.4    72.5    69.8    73.1
## 10             71.4    70.3    72.5    69.8    73.1
## # ... with 14 more rows
## 
## [[5]]
## # A tibble: 24 x 5
##    `Point Forecast` `Lo 80` `Hi 80` `Lo 95` `Hi 95`
##  *            &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1             71.5    70.8    72.3    70.3    72.8
##  2             71.5    70.7    72.4    70.3    72.8
##  3             71.5    70.7    72.4    70.2    72.8
##  4             71.5    70.6    72.4    70.1    72.9
##  5             71.5    70.6    72.4    70.1    72.9
##  6             71.5    70.5    72.4    70.0    73.0
##  7             71.5    70.5    72.5    69.9    73.0
##  8             71.5    70.4    72.5    69.9    73.0
##  9             71.4    70.4    72.5    69.8    73.1
## 10             71.4    70.3    72.5    69.8    73.1
## # ... with 14 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So &lt;code&gt;forecasts&lt;/code&gt; is a list of tibble, each containing a forecast. Remember that I have 5 tibbles, because
I imputed the data 5 times. I will merge this list of data sets together into one, but before I need
to add a column that indices the forecasts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecasts &amp;lt;- map2(.x = forecasts, .y = as.character(seq(1, 5)), 
     ~mutate(.x, id = .y)) %&amp;gt;% 
    bind_rows() %&amp;gt;% 
    select(-c(`Lo 80`, `Hi 80`))

colnames(forecasts) &amp;lt;- c(&amp;quot;point_forecast&amp;quot;, &amp;quot;low_95&amp;quot;, &amp;quot;hi_95&amp;quot;, &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look again at &lt;code&gt;forecasts&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecasts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 x 4
##    point_forecast low_95 hi_95 id   
##             &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
##  1           71.5   70.2  72.8 1    
##  2           71.5   70.3  72.8 1    
##  3           71.5   70.1  72.8 1    
##  4           71.5   70.1  72.9 1    
##  5           71.4   70.0  72.9 1    
##  6           71.5   70.0  72.9 1    
##  7           71.4   69.9  72.9 1    
##  8           71.4   69.9  72.9 1    
##  9           71.4   69.9  72.9 1    
## 10           71.4   69.8  73.0 1    
## # ... with 110 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I now select the true values for the month of June. I also imputed this data, but here I will
simply keep the average of the imputations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight_june &amp;lt;- imp_weight %&amp;gt;% 
    filter(Date &amp;gt;= &amp;quot;2018-06-01&amp;quot;) %&amp;gt;% 
    select(-.id) %&amp;gt;% 
    group_by(Date) %&amp;gt;% 
    summarise(true_weight = mean(Poids)) %&amp;gt;% 
    rename(date = Date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at &lt;code&gt;weight_june&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight_june&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 24 x 2
##    date       true_weight
##    &amp;lt;date&amp;gt;           &amp;lt;dbl&amp;gt;
##  1 2018-06-01        71.8
##  2 2018-06-02        70.8
##  3 2018-06-03        71.2
##  4 2018-06-04        71.4
##  5 2018-06-05        70.9
##  6 2018-06-06        70.8
##  7 2018-06-07        70.5
##  8 2018-06-08        70.1
##  9 2018-06-09        70.3
## 10 2018-06-10        71.0
## # ... with 14 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s repeat &lt;code&gt;weight_june&lt;/code&gt; 5 times, and add the index 1 to 5. Why? Because I want to merge the
true data with the forecasts, and having the data in this form makes things easier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;weight_june &amp;lt;- modify(list_along(1:5), ~`&amp;lt;-`(., weight_june)) %&amp;gt;% 
    map2(.y = as.character(seq(1, 5)), 
         ~mutate(.x, id = .y)) %&amp;gt;% 
    bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modify(list_along(1:5), ~`&amp;lt;-`(., weight_june)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;looks quite complicated, but you will see that it is not, once we break it apart. &lt;code&gt;modify()&lt;/code&gt;
modifies a list. The list to modify is &lt;code&gt;list_along(1:5)&lt;/code&gt;, which create a list of &lt;code&gt;NULL&lt;/code&gt;s:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_along(1:5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## NULL
## 
## [[2]]
## NULL
## 
## [[3]]
## NULL
## 
## [[4]]
## NULL
## 
## [[5]]
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second argument of &lt;code&gt;modify()&lt;/code&gt; is either a function or a formula. I created the following
formula:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~`&amp;lt;-`(., weight_june)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We all know the function &lt;code&gt;&amp;lt;-()&lt;/code&gt;, but are not used to see it that way. But consider the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;`&amp;lt;-`(a, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two formulations are equivalent. So these lines fill the empty element of the list of &lt;code&gt;NULL&lt;/code&gt;s
with the data frame &lt;code&gt;weight_june&lt;/code&gt;. Then I add the &lt;code&gt;id&lt;/code&gt; column and then bind the rows together: &lt;code&gt;bind_rows()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s bind the columns of &lt;code&gt;weight_june&lt;/code&gt; and &lt;code&gt;forecasts&lt;/code&gt; and take a look at it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;forecasts &amp;lt;- bind_cols(weight_june, forecasts) %&amp;gt;% 
    select(-id1)

forecasts&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 x 6
##    date       true_weight id    point_forecast low_95 hi_95
##    &amp;lt;date&amp;gt;           &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 2018-06-01        71.8 1               71.5   70.2  72.8
##  2 2018-06-02        70.8 1               71.5   70.3  72.8
##  3 2018-06-03        71.2 1               71.5   70.1  72.8
##  4 2018-06-04        71.4 1               71.5   70.1  72.9
##  5 2018-06-05        70.9 1               71.4   70.0  72.9
##  6 2018-06-06        70.8 1               71.5   70.0  72.9
##  7 2018-06-07        70.5 1               71.4   69.9  72.9
##  8 2018-06-08        70.1 1               71.4   69.9  72.9
##  9 2018-06-09        70.3 1               71.4   69.9  72.9
## 10 2018-06-10        71.0 1               71.4   69.8  73.0
## # ... with 110 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, for the last plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(forecasts, aes(x = date, colour = id)) +
    geom_line(aes(y = true_weight), size = 2) + 
    geom_line(aes(y = hi_95)) + 
    geom_line(aes(y = low_95)) + 
    theme(legend.position = &amp;quot;bottom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-06-24-fun_ts_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The true data fall within all the confidence intervals, but I am a bit surprised by the intervals,
especially the upper confidence intervals; they all are way above 72kg, however my true weight
has been fluctuating around 71kg for quite some months now. I think I have to refresh my memory
on time series, because I am certainly missing something!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting data from pdfs using the pdftools package</title>
      <link>https://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-06-10-scraping_pdfs/</guid>
      <description>&lt;p&gt;It is often the case that data is trapped inside pdfs, but thankfully there are ways to extract
it from the pdfs. A very nice package for this task is
&lt;code&gt;pdftools&lt;/code&gt; (&lt;a href=&#34;https://github.com/ropensci/pdftools&#34;&gt;Github link&lt;/a&gt;)
and this blog post will describe some basic functionality from that package.&lt;/p&gt;
&lt;p&gt;First, let’s find some pdfs that contain interesting data. For this post, I’m using the diabetes
country profiles from the World Health Organization. You can find them &lt;a href=&#34;http://www.who.int/diabetes/country-profiles/en/#U&#34;&gt;here&lt;/a&gt;.
If you open one of these pdfs, you are going to see this:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www.who.int/diabetes/country-profiles/lux_en.pdf?ua=1&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/diabetes_lux.png&#34; width=&#34;499&#34; height=&#34;680&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I’m interested in this table here in the middle:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www.who.int/diabetes/country-profiles/lux_en.pdf?ua=1&#34;&gt;
&lt;img src=&#34;https://www.brodrigues.co/img/diabetes_table.png&#34; width=&#34;499&#34; height=&#34;680&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I want to get the data from different countries, put it all into a nice data frame and make a
simple plot.&lt;/p&gt;
&lt;p&gt;Let’s first start by loading the needed packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;pdftools&amp;quot;)
library(&amp;quot;glue&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✔ ggplot2 2.2.1     ✔ purrr   0.2.5
## ✔ tibble  1.4.2     ✔ dplyr   0.7.5
## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
## ✔ readr   1.1.1     ✔ forcats 0.3.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ───────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::collapse() masks glue::collapse()
## ✖ dplyr::filter()   masks stats::filter()
## ✖ dplyr::lag()      masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;ggthemes&amp;quot;)

country &amp;lt;- c(&amp;quot;lux&amp;quot;, &amp;quot;fra&amp;quot;, &amp;quot;deu&amp;quot;, &amp;quot;usa&amp;quot;, &amp;quot;prt&amp;quot;, &amp;quot;gbr&amp;quot;)

url &amp;lt;- &amp;quot;http://www.who.int/diabetes/country-profiles/{country}_en.pdf?ua=1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first 4 lines load the needed packages for this exercise: &lt;code&gt;pdftools&lt;/code&gt; is the package that I
described in the beginning of the post, &lt;code&gt;glue&lt;/code&gt; is optional but offers a nice alternative to the
&lt;code&gt;paste()&lt;/code&gt; and &lt;code&gt;paste0()&lt;/code&gt; functions. Take a closer look at the url: you’ll see that I wrote &lt;code&gt;{country}&lt;/code&gt;.
This is not in the original links; the original links look like this (for example for the USA):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;http://www.who.int/diabetes/country-profiles/usa_en.pdf?ua=1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So because I’m interested in several countries, I created a vector with the country codes
of the countries I’m interested in. Now, using the &lt;code&gt;glue()&lt;/code&gt; function, something magical happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(urls &amp;lt;- glue(url))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## http://www.who.int/diabetes/country-profiles/lux_en.pdf?ua=1
## http://www.who.int/diabetes/country-profiles/fra_en.pdf?ua=1
## http://www.who.int/diabetes/country-profiles/deu_en.pdf?ua=1
## http://www.who.int/diabetes/country-profiles/usa_en.pdf?ua=1
## http://www.who.int/diabetes/country-profiles/prt_en.pdf?ua=1
## http://www.who.int/diabetes/country-profiles/gbr_en.pdf?ua=1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This created a vector with all the links where &lt;code&gt;{country}&lt;/code&gt; is replaced by each of the codes
contained in the variable &lt;code&gt;country&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I use the same trick to create the names of the pdfs that I will download:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pdf_names &amp;lt;- glue(&amp;quot;report_{country}.pdf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now I can download them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;walk2(urls, pdf_names, download.file, mode = &amp;quot;wb&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;walk2()&lt;/code&gt; is a function from the &lt;code&gt;purrr&lt;/code&gt; package that is similar to &lt;code&gt;map2()&lt;/code&gt;. You could use &lt;code&gt;map2()&lt;/code&gt;
for this, but &lt;code&gt;walk2()&lt;/code&gt; is cleaner here, because &lt;code&gt;dowload.file()&lt;/code&gt; is a function with a so-called
side effect; it downloads files. &lt;code&gt;map2()&lt;/code&gt; is used for functions without side effects.&lt;/p&gt;
&lt;p&gt;Now, I can finally use the &lt;code&gt;pdf_text()&lt;/code&gt; function from the &lt;code&gt;pdftools&lt;/code&gt; function to get the text
from the pdfs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_text &amp;lt;- map(pdf_names, pdf_text)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;raw_text&lt;/code&gt; is a list of where each element is the text from one of the pdfs. Let’s take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(raw_text)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 6
##  $ : chr &amp;quot;Luxembourg                                                                                                     &amp;quot;| __truncated__
##  $ : chr &amp;quot;France                                                                                                         &amp;quot;| __truncated__
##  $ : chr &amp;quot;Germany                                                                                                        &amp;quot;| __truncated__
##  $ : chr &amp;quot;United States Of America                                                                                       &amp;quot;| __truncated__
##  $ : chr &amp;quot;Portugal                                                                                                       &amp;quot;| __truncated__
##  $ : chr &amp;quot;United Kingdom                                                                                                 &amp;quot;| __truncated__&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a look at one of these elements, which is nothing but a very long character:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_text[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Luxembourg                                                                                                                                          Total population: 567 000\n                                                                                                                                                         Income group: High\nMortality\nNumber of diabetes deaths                                                                     Number of deaths attributable to high blood glucose\n                                                                     males         females                                                            males       females\nages 30–69                                                           &amp;lt;100            &amp;lt;100     ages 30–69                                              &amp;lt;100          &amp;lt;100\nages 70+                                                             &amp;lt;100            &amp;lt;100     ages 70+                                                &amp;lt;100          &amp;lt;100\nProportional mortality (% of total deaths, all ages)                                          Trends in age-standardized prevalence of diabetes\n                    Communicable,\n                   maternal, perinatal              Injuries                                                    35%\n                    and nutritional                   6%                     Cardiovascular\n                      conditions                                               diseases\n                          6%                                                      33%\n                                                                                                                30%\n                                                                                                                25%\n                                                                                              % of population\n               Other NCDs\n                  16%                                                                                           20%\n                                     No data available                                                          15%           No data available\n              Diabetes                                                                                          10%\n                 2%\n                                                                                                                5%\n                   Respiratory\n                    diseases\n                       6%                                                                                       0%\n                                                           Cancers\n                                                            31%\n                                                                                                                                  males     females\nPrevalence of diabetes and related risk factors\n                                                                                                                      males               females               total\nDiabetes                                                                                                              8.3%                 5.3%                 6.8%\nOverweight                                                                                                            70.7%               51.5%                61.0%\nObesity                                                                                                               28.3%               21.3%                24.8%\nPhysical inactivity                                                                                                   28.2%               31.7%                30.0%\nNational response to diabetes\nPolicies, guidelines and monitoring\nOperational policy/strategy/action plan for diabetes                                                                                                ND\nOperational policy/strategy/action plan to reduce overweight and obesity                                                                            ND\nOperational policy/strategy/action plan to reduce physical inactivity                                                                               ND\nEvidence-based national diabetes guidelines/protocols/standards                                                                                     ND\nStandard criteria for referral of patients from primary care to higher level of care                                                                ND\nDiabetes registry                                                                                                                                   ND\nRecent national risk factor survey in which blood glucose was measured                                                                              ND\nAvailability of medicines, basic technologies and procedures in the public health sector\nMedicines in primary care facilities                                                          Basic technologies in primary care facilities\nInsulin                                                                               ND      Blood glucose measurement                                             ND\nMetformin                                                                             ND      Oral glucose tolerance test                                           ND\nSulphonylurea                                                                         ND      HbA1c test                                                            ND\nProcedures                                                                                    Dilated fundus examination                                            ND\nRetinal photocoagulation                                                              ND      Foot vibration perception by tuning fork                              ND\nRenal replacement therapy by dialysis                                                 ND      Foot vascular status by Doppler                                       ND\nRenal replacement therapy by transplantation                                          ND      Urine strips for glucose and ketone measurement                       ND\nND = country did not respond to country capacity survey\n〇 = not generally available   ● = generally available\nWorld Health Organization – Diabetes country profiles, 2016.\n&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this is a very long character string with some line breaks (the &lt;code&gt;&amp;quot;\n&amp;quot;&lt;/code&gt; character).
So first, we need to split this string into a character vector by the &lt;code&gt;&amp;quot;\n&amp;quot;&lt;/code&gt; character. Also, it might
be difficult to see, but the table starts at the line with the following string:
&lt;code&gt;&amp;quot;Prevalence of diabetes&amp;quot;&lt;/code&gt; and ends with &lt;code&gt;&amp;quot;National response to diabetes&amp;quot;&lt;/code&gt;. Also, we need to get
the name of the country from the text and add it as a column. As you can see, a whole lot
of operations are needed, so what I do is put all these operations into a function that I will apply
to each element of &lt;code&gt;raw_text&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;clean_table &amp;lt;- function(table){
    table &amp;lt;- str_split(table, &amp;quot;\n&amp;quot;, simplify = TRUE)
    country_name &amp;lt;- table[1, 1] %&amp;gt;% 
        stringr::str_squish() %&amp;gt;% 
        stringr::str_extract(&amp;quot;.+?(?=\\sTotal)&amp;quot;)
    table_start &amp;lt;- stringr::str_which(table, &amp;quot;Prevalence of diabetes&amp;quot;)
    table_end &amp;lt;- stringr::str_which(table, &amp;quot;National response to diabetes&amp;quot;)
    table &amp;lt;- table[1, (table_start +1 ):(table_end - 1)]
    table &amp;lt;- str_replace_all(table, &amp;quot;\\s{2,}&amp;quot;, &amp;quot;|&amp;quot;)
    text_con &amp;lt;- textConnection(table)
    data_table &amp;lt;- read.csv(text_con, sep = &amp;quot;|&amp;quot;)
    colnames(data_table) &amp;lt;- c(&amp;quot;Condition&amp;quot;, &amp;quot;Males&amp;quot;, &amp;quot;Females&amp;quot;, &amp;quot;Total&amp;quot;)
    dplyr::mutate(data_table, Country = country_name)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I advise you to go through all these operations and understand what each does. However, I will
describe some of the lines, such as this one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;stringr::str_extract(&amp;quot;.+?(?=\\sTotal)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This uses a very bizarre looking regular expression: &lt;code&gt;&amp;quot;.+?(?=\\sTotal)&amp;quot;&lt;/code&gt;. This extracts everything
before a space, followed by the string &lt;code&gt;&amp;quot;Total&amp;quot;&lt;/code&gt;. This is because the first line, the one that contains
the name of the country looks like this: &lt;code&gt;&amp;quot;Luxembourg Total population: 567 000\n&amp;quot;&lt;/code&gt;. So everything
before a space followed by the word &lt;code&gt;&amp;quot;Total&amp;quot;&lt;/code&gt; is the country name. Then there’s these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;table &amp;lt;- str_replace_all(table, &amp;quot;\\s{2,}&amp;quot;, &amp;quot;|&amp;quot;)
text_con &amp;lt;- textConnection(table)
data_table &amp;lt;- read.csv(text_con, sep = &amp;quot;|&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first lines replaces 2 spaces or more (“&lt;code&gt;\\s{2,}&lt;/code&gt;”) with &lt;code&gt;&amp;quot;|&amp;quot;&lt;/code&gt;. The reason I do this is because
then I can read the table back into R as a data frame by specifying the separator as the “|” character.
On the second line, I define &lt;code&gt;table&lt;/code&gt; as a text connection, that I can then read back into R using
&lt;code&gt;read.csv()&lt;/code&gt;. On the second to the last line I change the column names and then I add a column
called &lt;code&gt;&amp;quot;Country&amp;quot;&lt;/code&gt; to the data frame.&lt;/p&gt;
&lt;p&gt;Now, I can map this useful function to the list of raw text extracted from the pdfs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diabetes &amp;lt;- map_df(raw_text, clean_table) %&amp;gt;% 
    gather(Sex, Share, Males, Females, Total) %&amp;gt;% 
    mutate(Share = as.numeric(str_extract(Share, &amp;quot;\\d{1,}\\.\\d{1,}&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I reshape the data with the &lt;code&gt;gather()&lt;/code&gt; function (see what the data looks like before and after
reshaping). I then convert the &lt;code&gt;&amp;quot;Share&amp;quot;&lt;/code&gt; column into a numeric (it goes from something that looks
like &lt;code&gt;&amp;quot;12.3 %&amp;quot;&lt;/code&gt; into &lt;code&gt;12.3&lt;/code&gt;) and then I can create a nice plot. But first let’s take a look at
the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diabetes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Condition                  Country     Sex Share
## 1             Diabetes               Luxembourg   Males   8.3
## 2           Overweight               Luxembourg   Males  70.7
## 3              Obesity               Luxembourg   Males  28.3
## 4  Physical inactivity               Luxembourg   Males  28.2
## 5             Diabetes                   France   Males   9.5
## 6           Overweight                   France   Males  69.9
## 7              Obesity                   France   Males  25.3
## 8  Physical inactivity                   France   Males  21.2
## 9             Diabetes                  Germany   Males   8.4
## 10          Overweight                  Germany   Males  67.0
## 11             Obesity                  Germany   Males  24.1
## 12 Physical inactivity                  Germany   Males  20.1
## 13            Diabetes United States Of America   Males   9.8
## 14          Overweight United States Of America   Males  74.1
## 15             Obesity United States Of America   Males  33.7
## 16 Physical inactivity United States Of America   Males  27.6
## 17            Diabetes                 Portugal   Males  10.7
## 18          Overweight                 Portugal   Males  65.0
## 19             Obesity                 Portugal   Males  21.4
## 20 Physical inactivity                 Portugal   Males  33.5
## 21            Diabetes           United Kingdom   Males   8.4
## 22          Overweight           United Kingdom   Males  71.1
## 23             Obesity           United Kingdom   Males  28.5
## 24 Physical inactivity           United Kingdom   Males  35.4
## 25            Diabetes               Luxembourg Females   5.3
## 26          Overweight               Luxembourg Females  51.5
## 27             Obesity               Luxembourg Females  21.3
## 28 Physical inactivity               Luxembourg Females  31.7
## 29            Diabetes                   France Females   6.6
## 30          Overweight                   France Females  58.6
## 31             Obesity                   France Females  26.1
## 32 Physical inactivity                   France Females  31.2
## 33            Diabetes                  Germany Females   6.4
## 34          Overweight                  Germany Females  52.7
## 35             Obesity                  Germany Females  21.4
## 36 Physical inactivity                  Germany Females  26.5
## 37            Diabetes United States Of America Females   8.3
## 38          Overweight United States Of America Females  65.3
## 39             Obesity United States Of America Females  36.3
## 40 Physical inactivity United States Of America Females  42.1
## 41            Diabetes                 Portugal Females   7.8
## 42          Overweight                 Portugal Females  55.0
## 43             Obesity                 Portugal Females  22.8
## 44 Physical inactivity                 Portugal Females  40.8
## 45            Diabetes           United Kingdom Females   6.9
## 46          Overweight           United Kingdom Females  62.4
## 47             Obesity           United Kingdom Females  31.1
## 48 Physical inactivity           United Kingdom Females  44.3
## 49            Diabetes               Luxembourg   Total   6.8
## 50          Overweight               Luxembourg   Total  61.0
## 51             Obesity               Luxembourg   Total  24.8
## 52 Physical inactivity               Luxembourg   Total  30.0
## 53            Diabetes                   France   Total   8.0
## 54          Overweight                   France   Total  64.1
## 55             Obesity                   France   Total  25.7
## 56 Physical inactivity                   France   Total  26.4
## 57            Diabetes                  Germany   Total   7.4
## 58          Overweight                  Germany   Total  59.7
## 59             Obesity                  Germany   Total  22.7
## 60 Physical inactivity                  Germany   Total  23.4
## 61            Diabetes United States Of America   Total   9.1
## 62          Overweight United States Of America   Total  69.6
## 63             Obesity United States Of America   Total  35.0
## 64 Physical inactivity United States Of America   Total  35.0
## 65            Diabetes                 Portugal   Total   9.2
## 66          Overweight                 Portugal   Total  59.8
## 67             Obesity                 Portugal   Total  22.1
## 68 Physical inactivity                 Portugal   Total  37.3
## 69            Diabetes           United Kingdom   Total   7.7
## 70          Overweight           United Kingdom   Total  66.7
## 71             Obesity           United Kingdom   Total  29.8
## 72 Physical inactivity           United Kingdom   Total  40.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s go for the plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(diabetes) + theme_fivethirtyeight() + scale_fill_hc() +
    geom_bar(aes(y = Share, x = Sex, fill = Country), 
             stat = &amp;quot;identity&amp;quot;, position = &amp;quot;dodge&amp;quot;) +
    facet_wrap(~Condition)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-06-10-scraping_pdfs_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That was a whole lot of work for such a simple plot!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>{pmice}, an experimental package for missing data imputation in parallel using {mice} and {furrr}</title>
      <link>https://www.brodrigues.co/blog/2018-04-15-announcing_pmice/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-04-15-announcing_pmice/</guid>
      <description>&lt;p&gt;Yesterday I wrote &lt;a href=&#34;http://www.brodrigues.co/blog/2018-04-14-playing_with_furrr/&#34;&gt;this blog post&lt;/a&gt;
which showed how one could use &lt;code&gt;{furrr}&lt;/code&gt; and &lt;code&gt;{mice}&lt;/code&gt; to impute missing data in parallel, thus
speeding up the process tremendously.&lt;/p&gt;
&lt;p&gt;To make using this snippet of code easier, I quickly cobbled together an experimental package
called &lt;code&gt;{pmice}&lt;/code&gt; that you can install from Github:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/pmice&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For now, it returns a list of &lt;code&gt;mids&lt;/code&gt; objects and not a &lt;code&gt;mids&lt;/code&gt; object like &lt;code&gt;mice::mice()&lt;/code&gt; does,
but I’ll be working on it. Contributions welcome!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Imputing missing values in parallel using {furrr}</title>
      <link>https://www.brodrigues.co/blog/2018-04-14-playing_with_furrr/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-04-14-playing_with_furrr/</guid>
      <description>&lt;p&gt;Today I saw this tweet on my timeline:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;For those of us that just can&amp;#39;t wait until RStudio officially supports parallel purrr in &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;, boy have I got something for you. &lt;br&gt;&lt;br&gt;Introducing `furrr`, parallel purrr through the use of futures. Go ahead, break things, you know you want to:&lt;a href=&#34;https://t.co/l9z1UC2Tew&#34;&gt;https://t.co/l9z1UC2Tew&lt;/a&gt;&lt;/p&gt;&amp;mdash; Davis Vaughan (@dvaughan32) &lt;a href=&#34;https://twitter.com/dvaughan32/status/984828716181319680?ref_src=twsrc%5Etfw&#34;&gt;April 13, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;and as a heavy &lt;code&gt;{purrr}&lt;/code&gt; user, as well as the happy owner of a 6-core AMD Ryzen 5 1600X cpu,
I was very excited to try out &lt;code&gt;{furrr}&lt;/code&gt;. For those unfamiliar with &lt;code&gt;{purrr}&lt;/code&gt;, you can
read some of my previous blog posts on it &lt;a href=&#34;http://www.brodrigues.co/blog/2017-03-24-lesser_known_purrr/&#34;&gt;here&lt;/a&gt;,
&lt;a href=&#34;http://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/&#34;&gt;here&lt;/a&gt; or
&lt;a href=&#34;http://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To summarize very quickly: &lt;code&gt;{purrr}&lt;/code&gt; contains so-called higher order functions, which are functions
that take other functions as argument. One such function is &lt;code&gt;map()&lt;/code&gt;. Consider the following simple example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;numbers &amp;lt;- seq(1, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want the square root of this numbers, you can of course simply use the &lt;code&gt;sqrt()&lt;/code&gt; function,
because it is vectorized:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(numbers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751
##  [8] 2.828427 3.000000 3.162278&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But in a lot of situations, the solution is not so simple. Sometimes you have to loop over the
values. This is what we would need to do if &lt;code&gt;sqrt()&lt;/code&gt; was not vectorized:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt_numbers &amp;lt;- rep(0, 10)

for(i in length(numbers)){
  sqrt_numbers[i] &amp;lt;- sqrt(numbers[i])
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, you need to initialize a container, and then you have to populate the &lt;code&gt;sqrt_numbers&lt;/code&gt; list with the results.
Using, &lt;code&gt;{purrr}&lt;/code&gt; is way easier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
map(numbers, sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1
## 
## [[2]]
## [1] 1.414214
## 
## [[3]]
## [1] 1.732051
## 
## [[4]]
## [1] 2
## 
## [[5]]
## [1] 2.236068
## 
## [[6]]
## [1] 2.44949
## 
## [[7]]
## [1] 2.645751
## 
## [[8]]
## [1] 2.828427
## 
## [[9]]
## [1] 3
## 
## [[10]]
## [1] 3.162278&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;map()&lt;/code&gt; is only one of the nice functions that are bundled inside &lt;code&gt;{purrr}&lt;/code&gt;. Mastering &lt;code&gt;{purrr}&lt;/code&gt; can really make you a much
more efficient R programmer. Anyways, recently, I have been playing around with imputation and the &lt;code&gt;{mice}&lt;/code&gt; package.
&lt;code&gt;{mice}&lt;/code&gt; comes with an example dataset called &lt;code&gt;boys&lt;/code&gt;, let’s take a look at it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mice)

data(boys)

brotools::describe(boys) %&amp;gt;%
  select(variable, type, n_missing, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 13
##   variable type    n_missing  nobs   mean    sd mode     min   max   q25
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numeric         0   748   9.16  6.89 0.035  0.035  21.2  1.58
## 2 bmi      Numeric        21   748  18.1   3.05 14.54 11.8    31.7 15.9 
## 3 hc       Numeric        46   748  51.5   5.91 33.7  33.7    65   48.1 
## 4 hgt      Numeric        20   748 132.   46.5  50.1  50     198   84.9 
## 5 tv       Numeric       522   748  11.9   7.99 &amp;lt;NA&amp;gt;   1      25    4   
## 6 wgt      Numeric         4   748  37.2  26.0  3.65   3.14  117.  11.7 
## 7 gen      Factor        503   748  NA    NA    &amp;lt;NA&amp;gt;  NA      NA   NA   
## 8 phb      Factor        503   748  NA    NA    &amp;lt;NA&amp;gt;  NA      NA   NA   
## 9 reg      Factor          3   748  NA    NA    south NA      NA   NA   
## # ... with 3 more variables: median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the code above I use the &lt;code&gt;describe()&lt;/code&gt; function from my personal package to get some summary
statistics of the &lt;code&gt;boys&lt;/code&gt; dataset (you can read more about this function
&lt;a href=&#34;http://www.brodrigues.co/blog/2018-04-10-brotools_describe&#34;&gt;here&lt;/a&gt;). I am especially interested in the number of
missing values, which is why I re-order the columns. If I did not re-order the columns, it would not appear in
the output on my blog.&lt;/p&gt;
&lt;p&gt;We see that some columns have a lot of missing values. Using the &lt;code&gt;mice&lt;/code&gt; function, it is very
easy to impute them:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start &amp;lt;- Sys.time()
imp_boys &amp;lt;- mice(boys, m = 10, maxit = 100, printFlag = FALSE)
end &amp;lt;- Sys.time() - start

print(end)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 3.290611 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imputation on a single core took around 3 minutes on my computer. This might seem ok, but if you
have a larger data set with more variables, 3 minutes can become 3 hours. And if you increase &lt;code&gt;maxit&lt;/code&gt;,
which helps convergence, or the number of imputations, 3 hours can become 30 hours. With a 6-core CPU
this could potentially be brought down to 5 hours (in theory). Let’s see if we can go faster,
but first let’s take a look at the imputed data.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;mice()&lt;/code&gt; function returns a &lt;code&gt;mids&lt;/code&gt; object. If you want to look at the data, you have to use
the &lt;code&gt;complete()&lt;/code&gt; function (careful, there is also a &lt;code&gt;complete()&lt;/code&gt; function in the &lt;code&gt;{tidyr}&lt;/code&gt; package,
so to avoid problems, I suggest you explicitely call &lt;code&gt;mice::complete()&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_boys &amp;lt;- mice::complete(imp_boys, &amp;quot;long&amp;quot;)

brotools::describe(imp_boys) %&amp;gt;%
  select(variable, type, n_missing, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 11 x 13
##    variable type   n_missing  nobs   mean     sd mode     min   max    q25
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1 .id      Numer…         0  7480 374.   216.   1      1     748   188.  
##  2 .imp     Numer…         0  7480   5.5    2.87 1      1      10     3   
##  3 age      Numer…         0  7480   9.16   6.89 0.035  0.035  21.2   1.58
##  4 bmi      Numer…         0  7480  18.0    3.03 14.54 11.8    31.7  15.9 
##  5 hc       Numer…         0  7480  51.6    5.89 33.7  33.7    65    48.3 
##  6 hgt      Numer…         0  7480 131.    46.5  50.1  50     198    83   
##  7 tv       Numer…         0  7480   8.39   8.09 2      1      25     2   
##  8 wgt      Numer…         0  7480  37.1   26.0  3.65   3.14  117.   11.7 
##  9 gen      Factor         0  7480  NA     NA    G1    NA      NA    NA   
## 10 phb      Factor         0  7480  NA     NA    P1    NA      NA    NA   
## 11 reg      Factor         0  7480  NA     NA    south NA      NA    NA   
## # ... with 3 more variables: median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, no more missing values. The “long” argument inside &lt;code&gt;mice::complete()&lt;/code&gt; is needed if you want the &lt;code&gt;complete()&lt;/code&gt;
function to return a long dataset. Doing the above “manually” using &lt;code&gt;{purrr}&lt;/code&gt; is possible with the following
code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start &amp;lt;- Sys.time()
imp_boys_purrr &amp;lt;- map(rep(1, 10), ~mice(data = boys, m = ., maxit = 100, printFlag = FALSE))
end &amp;lt;- Sys.time() - start

print(end)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 3.393966 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What this does is map the function &lt;code&gt;~mice(data = boys, m = ., maxit = 100, printFlag = FALSE)&lt;/code&gt;
to a list of &lt;code&gt;1&lt;/code&gt;s, and creates 10 imputed data sets. &lt;code&gt;m = .&lt;/code&gt; means that &lt;code&gt;m&lt;/code&gt; will be equal to whatever is inside
the list we are mapping our function over, so &lt;code&gt;1&lt;/code&gt;, then &lt;code&gt;1&lt;/code&gt; then another &lt;code&gt;1&lt;/code&gt; etc….
It took around the same amount of time as using &lt;code&gt;mice()&lt;/code&gt; directly.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;imp_boys_purrr&lt;/code&gt; is now a list of 10 &lt;code&gt;mids&lt;/code&gt; objects. We thus need to map &lt;code&gt;mice::complete()&lt;/code&gt;
to &lt;code&gt;imp_boys_purrr&lt;/code&gt; to get the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_boys_purrr_complete &amp;lt;- map(imp_boys_purrr, mice::complete)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, &lt;code&gt;imp_boys_purrr_complete&lt;/code&gt; is a list of 10 datasets. Let’s map &lt;code&gt;brotools::describe()&lt;/code&gt; to it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(imp_boys_purrr_complete, brotools::describe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.03 14.54 11.8    31.7 15.9    17.4  19.5
## 3 hc       Numer…   748  51.7   5.90 33.7  33.7    65   48.3    53.1  56  
## 4 hgt      Numer…   748 131.   46.5  50.1  50     198   84     146.  175. 
## 5 tv       Numer…   748   8.35  8.00 3      1      25    2       3    15  
## 6 wgt      Numer…   748  37.2  26.0  3.65   3.14  117.  11.7    34.7  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[2]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.03 14.54 11.8    31.7 15.9    17.5  19.5
## 3 hc       Numer…   748  51.6   5.88 33.7  33.7    65   48.3    53.2  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.5   145.  175  
## 5 tv       Numer…   748   8.37  8.02 1      1      25    2       3    15  
## 6 wgt      Numer…   748  37.1  26.0  3.65   3.14  117.  11.9    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P2    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[3]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.1   3.04 14.54 11.8    31.7 15.9    17.5  19.5
## 3 hc       Numer…   748  51.6   5.87 33.7  33.7    65   48.5    53.3  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.0   145.  175  
## 5 tv       Numer…   748   8.46  8.14 2      1      25    2       3    15  
## 6 wgt      Numer…   748  37.2  26.1  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[4]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.1   3.02 14.54 11.8    31.7 15.9    17.5  19.4
## 3 hc       Numer…   748  51.7   5.93 33.7  33.7    65   48.5    53.4  56  
## 4 hgt      Numer…   748 131.   46.5  50.1  50     198   82.9   145.  175  
## 5 tv       Numer…   748   8.45  8.11 2      1      25    2       3    15  
## 6 wgt      Numer…   748  37.2  26.0  3.65   3.14  117.  11.7    34.7  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[5]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.03 14.54 11.8    31.7 15.9    17.5  19.5
## 3 hc       Numer…   748  51.6   5.91 33.7  33.7    65   48.3    53.2  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.0   146.  175. 
## 5 tv       Numer…   748   8.21  8.02 3      1      25    2       3    15  
## 6 wgt      Numer…   748  37.1  26.0  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[6]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.05 14.54 11.8    31.7 15.9    17.4  19.5
## 3 hc       Numer…   748  51.7   5.89 33.7  33.7    65   48.3    53.2  56  
## 4 hgt      Numer…   748 131.   46.5  50.1  50     198   83.0   146.  175  
## 5 tv       Numer…   748   8.44  8.24 3      1      25    2       3    15  
## 6 wgt      Numer…   748  37.1  26.0  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[7]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.1   3.04 14.54 11.8    31.7 15.9    17.4  19.5
## 3 hc       Numer…   748  51.6   5.88 33.7  33.7    65   48.2    53.2  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.5   146.  175  
## 5 tv       Numer…   748   8.47  8.15 2      1      25    2       3    15  
## 6 wgt      Numer…   748  37.2  26.1  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[8]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.04 14.54 11.8    31.7 15.9    17.4  19.4
## 3 hc       Numer…   748  51.6   5.85 33.7  33.7    65   48.2    53.3  56  
## 4 hgt      Numer…   748 131.   46.5  50.1  50     198   83.0   146.  175  
## 5 tv       Numer…   748   8.36  8.06 2      1      25    2       3    15  
## 6 wgt      Numer…   748  37.2  26.1  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[9]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.05 14.54 11.8    31.7 15.9    17.4  19.5
## 3 hc       Numer…   748  51.6   5.90 33.7  33.7    65   48.3    53.2  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.9   146.  175  
## 5 tv       Numer…   748   8.57  8.25 1      1      25    2       3    15  
## 6 wgt      Numer…   748  37.1  26.1  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;
## 
## [[10]]
## # A tibble: 9 x 13
##   variable type    nobs   mean    sd mode     min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 age      Numer…   748   9.16  6.89 0.035  0.035  21.2  1.58   10.5  15.3
## 2 bmi      Numer…   748  18.0   3.04 14.54 11.8    31.7 15.9    17.4  19.5
## 3 hc       Numer…   748  51.6   5.89 33.7  33.7    65   48.3    53.1  56  
## 4 hgt      Numer…   748 131.   46.6  50.1  50     198   83.0   146.  175  
## 5 tv       Numer…   748   8.49  8.18 2      1      25    2       3    15  
## 6 wgt      Numer…   748  37.1  26.1  3.65   3.14  117.  11.7    34.6  59.6
## 7 gen      Factor   748  NA    NA    G1    NA      NA   NA      NA    NA  
## 8 phb      Factor   748  NA    NA    P1    NA      NA   NA      NA    NA  
## 9 reg      Factor   748  NA    NA    south NA      NA   NA      NA    NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before merging this 10 datasets together into one, it would be nice to have a column with the id of the datasets.
This can easily be done with a variant of &lt;code&gt;purrr::map()&lt;/code&gt;, called &lt;code&gt;map2()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_boys_purrr &amp;lt;- map2(.x = seq(1,10), .y = imp_boys_purrr_complete, ~mutate(.y, imp_id = as.character(.x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;map2()&lt;/code&gt; applies a function, say &lt;code&gt;f()&lt;/code&gt;, to 2 lists sequentially: &lt;code&gt;f(x_1, y_1)&lt;/code&gt;, then &lt;code&gt;f(x_2, y_2)&lt;/code&gt;, etc…
So here I map &lt;code&gt;mutate()&lt;/code&gt; to create a new column, &lt;code&gt;imp_id&lt;/code&gt; in each dataset. Now let’s bind the rows and
take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_boys_purrr &amp;lt;- bind_rows(imp_boys_purrr)

imp_boys_purrr %&amp;gt;%
  brotools::describe() %&amp;gt;%
  select(variable, type, n_missing, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 13
##    variable type     n_missing  nobs   mean    sd mode     min   max   q25
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;        &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 age      Numeric          0  7480   9.16  6.89 0.035  0.035  21.2  1.58
##  2 bmi      Numeric          0  7480  18.0   3.04 14.54 11.8    31.7 15.9 
##  3 hc       Numeric          0  7480  51.6   5.89 33.7  33.7    65   48.3 
##  4 hgt      Numeric          0  7480 131.   46.5  50.1  50     198   83   
##  5 tv       Numeric          0  7480   8.42  8.11 3      1      25    2   
##  6 wgt      Numeric          0  7480  37.1  26.0  3.65   3.14  117.  11.7 
##  7 imp_id   Charact…         0  7480  NA    NA    1     NA      NA   NA   
##  8 gen      Factor           0  7480  NA    NA    G1    NA      NA   NA   
##  9 phb      Factor           0  7480  NA    NA    P1    NA      NA   NA   
## 10 reg      Factor           0  7480  NA    NA    south NA      NA   NA   
## # ... with 3 more variables: median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may ask yourself why I am bothering with all this. This will become apparent now. We can now use
the code we wrote to get our 10 imputed datasets using &lt;code&gt;purrr::map()&lt;/code&gt; and simply use &lt;code&gt;furrr::future_map()&lt;/code&gt;
to parallelize the imputation process:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(furrr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: future&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plan(multiprocess)

start &amp;lt;- Sys.time()
imp_boys_future &amp;lt;- future_map(rep(1, 10), ~mice(data = boys, m = ., maxit = 100, printFlag = FALSE))
end &amp;lt;- Sys.time() - start

print(end)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 33.73772 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Boooom! Much faster! And simply by loading &lt;code&gt;{furrr}&lt;/code&gt;, then using &lt;code&gt;plan(multiprocess)&lt;/code&gt; to run the code in
parallel (if you forget that, the code will run on a single core) and using &lt;code&gt;future_map()&lt;/code&gt; instead of &lt;code&gt;map()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;imp_boys_future_complete &amp;lt;- map(imp_boys_future, mice::complete)

imp_boys_future &amp;lt;- map2(.x = seq(1,10), .y = imp_boys_future_complete, ~mutate(.y, imp_id = as.character(.x)))

imp_boys_future &amp;lt;- bind_rows(imp_boys_future)

imp_boys_future %&amp;gt;%
  brotools::describe() %&amp;gt;%
  select(variable, type, n_missing, everything())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 13
##    variable type     n_missing  nobs   mean    sd mode     min   max   q25
##    &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;        &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 age      Numeric          0  7480   9.16  6.89 0.035  0.035  21.2  1.58
##  2 bmi      Numeric          0  7480  18.0   3.04 14.54 11.8    31.7 15.9 
##  3 hc       Numeric          0  7480  51.6   5.89 33.7  33.7    65   48.4 
##  4 hgt      Numeric          0  7480 131.   46.5  50.1  50     198   83   
##  5 tv       Numeric          0  7480   8.35  8.09 3      1      25    2   
##  6 wgt      Numeric          0  7480  37.1  26.0  3.65   3.14  117.  11.7 
##  7 imp_id   Charact…         0  7480  NA    NA    1     NA      NA   NA   
##  8 gen      Factor           0  7480  NA    NA    G1    NA      NA   NA   
##  9 phb      Factor           0  7480  NA    NA    P1    NA      NA   NA   
## 10 reg      Factor           0  7480  NA    NA    south NA      NA   NA   
## # ... with 3 more variables: median &amp;lt;dbl&amp;gt;, q75 &amp;lt;dbl&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So imputation went from 3.4 minutes (around 200 seconds) to 30 seconds. How cool is that? If you want to play around
with &lt;code&gt;{furrr}&lt;/code&gt; you must install it from Github, as it is not yet available on CRAN:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;DavisVaughan/furrr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are not comfortable with &lt;code&gt;map()&lt;/code&gt; (and thus &lt;code&gt;future_map()&lt;/code&gt;) but still want to impute in parallel, there is this
very nice script &lt;a href=&#34;https://github.com/gerkovink/parlMICE&#34;&gt;here&lt;/a&gt; to do just that. I created a package around this script,
called &lt;a href=&#34;https://github.com/b-rodrigues/parlMICE&#34;&gt;parlMICE&lt;/a&gt; (the same name as the script), to make installation and
usage easier. You can install it like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/parlMICE&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Get basic summary statistics for all the variables in a data frame</title>
      <link>https://www.brodrigues.co/blog/2018-04-10-brotools_describe/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-04-10-brotools_describe/</guid>
      <description>&lt;p&gt;I have added a new function to my &lt;code&gt;{brotools}&lt;/code&gt; package, called &lt;code&gt;describe()&lt;/code&gt;,
which takes a data frame as an argument, and returns another data frame with descriptive
statistics. It is very much inspired by the &lt;a href=&#34;https://github.com/ropenscilabs/skimr&#34;&gt;&lt;code&gt;{skmir}&lt;/code&gt;&lt;/a&gt;
package but also by
&lt;a href=&#34;https://github.com/bjornerstedt/assist/blob/master/R/describe.R&#34;&gt;&lt;code&gt;assist::describe()&lt;/code&gt;&lt;/a&gt; (click
on the packages to be redirected to the respective Github repos)
but I wanted to write my own for two reasons: first, as an exercice, and second
I really only needed the function &lt;code&gt;skim_to_wide()&lt;/code&gt; from &lt;code&gt;{skimr}&lt;/code&gt;. So instead of installing a
whole package for a single function, I decided to write my own (since I use &lt;code&gt;{brotools}&lt;/code&gt; daily).&lt;/p&gt;
&lt;p&gt;Below you can see it in action:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
data(starwars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brotools::describe(starwars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 13
##    variable  type   nobs  mean    sd mode     min   max   q25 median   q75
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 birth_ye… Nume…    87  87.6 155.  19         8   896  35       52  72  
##  2 height    Nume…    87 174.   34.8 172       66   264 167      180 191  
##  3 mass      Nume…    87  97.3 169.  77        15  1358  55.6     79  84.5
##  4 eye_color Char…    87  NA    NA   blue      NA    NA  NA       NA  NA  
##  5 gender    Char…    87  NA    NA   male      NA    NA  NA       NA  NA  
##  6 hair_col… Char…    87  NA    NA   blond     NA    NA  NA       NA  NA  
##  7 homeworld Char…    87  NA    NA   Tatoo…    NA    NA  NA       NA  NA  
##  8 name      Char…    87  NA    NA   Luke …    NA    NA  NA       NA  NA  
##  9 skin_col… Char…    87  NA    NA   fair      NA    NA  NA       NA  NA  
## 10 species   Char…    87  NA    NA   Human     NA    NA  NA       NA  NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the object that is returned by &lt;code&gt;describe()&lt;/code&gt; is a &lt;code&gt;tibble&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For now, this function does not handle dates, but it’s in the pipeline.&lt;/p&gt;
&lt;p&gt;You can also only describe certain columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brotools::describe(starwars, height, mass, name)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 13
##   variable type    nobs  mean    sd mode      min   max   q25 median   q75
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 height   Numer…    87 174.   34.8 172        66   264 167      180 191  
## 2 mass     Numer…    87  97.3 169.  77         15  1358  55.6     79  84.5
## 3 name     Chara…    87  NA    NA   Luke S…    NA    NA  NA       NA  NA  
## # ... with 2 more variables: n_missing &amp;lt;int&amp;gt;, n_unique &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to try it out,
you can install &lt;code&gt;{brotools}&lt;/code&gt; from Github:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;devtools::install_github(&amp;quot;b-rodrigues/brotools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting {sparklyr}, {h2o}, {rsparkling} to work together and some fun with bash</title>
      <link>https://www.brodrigues.co/blog/2018-03-03-sparklyr_h2o_rsparkling/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-03-03-sparklyr_h2o_rsparkling/</guid>
      <description>&lt;p&gt;This is going to be the type of blog posts that would perhaps be better as a gist, but it is easier for me to use my blog as my own personal collection of gists. Plus, someone else might find this useful, so here it is! In this blog post I am going to show a little trick to randomly sample rows from a text file using bash, and then train a model using the &lt;code&gt;{h2o}&lt;/code&gt; package. I will also use the &lt;code&gt;{rsparkling}&lt;/code&gt; package. From &lt;code&gt;{rsparkling}&lt;/code&gt;’s documentation: &lt;em&gt;&lt;code&gt;{rsparkling}&lt;/code&gt; is a package that provides an R interface to the &lt;code&gt;H2O&lt;/code&gt; Sparkling Water machine learning library.&lt;/em&gt; and will be needed to transfer the data from Spark to H2O.&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&#34;http://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data/&#34;&gt;previous blog post&lt;/a&gt; I used the &lt;code&gt;{sparklyr}&lt;/code&gt; package to load a 30GB csv file into R. I created the file by combining around 300 csv files, each around 80MB big. Here, I would like to use the machine learning functions included in the &lt;code&gt;{h2o}&lt;/code&gt; packages to train a random forest on this data. However, I only want to have a simple prototype that simply runs, and check if all the packages work well together. If everything is ok, I’ll keep iterating to make the model better (in a possible subsequent post).&lt;/p&gt;
&lt;p&gt;For fast prototyping, using 30GB of data is not a good idea, so I am going to sample 500000 from this file using the linux command line (works on macOS too and also on Windows if you installed the linux subsystem). Why not use R to sample 500000 rows? Because on my machine, loading the 30GB file takes 25 minutes. Sampling half a million lines from it would take quite long too. So here are some bash lines that do that directly on the file, without needing to load it into R beforehand:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[18-03-03 21:50] brodriguesco in /Documents/AirOnTimeCSV ➤ get_seeded_random()
{
  seed=&amp;quot;$1&amp;quot;
  openssl enc -aes-256-ctr -pass pass:&amp;quot;$seed&amp;quot; -nosalt \
  &amp;lt;/dev/zero 2&amp;gt;/dev/null
}

[18-03-03 21:50] brodriguesco in /Documents/AirOnTimeCSV ➤ sed &amp;quot;1 d&amp;quot; combined.csv | shuf --random-source=&amp;lt;(get_seeded_random 42) -n 500000 &amp;gt; small_combined_temp.csv

[18-03-03 21:56] brodriguesco in /Documents/AirOnTimeCSV ➤ head -1 combined.csv &amp;gt; colnames.csv

[18-03-03 21:56] brodriguesco in /Documents/AirOnTimeCSV ➤ cat colnames.csv small_combined_temp.csv &amp;gt; small_combined.csv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first function I took from the &lt;a href=&#34;https://www.gnu.org/software/coreutils/manual/html_node/Random-sources.html&#34;&gt;gnu coreutils manual&lt;/a&gt; which allows me to fix the random seed to reproduce the same sampling of the file. Then I use &lt;code&gt;&amp;quot;sed 1 d&amp;quot; cobmined.csv&lt;/code&gt; to remove the first line of &lt;code&gt;combined.csv&lt;/code&gt; which is the header of the file. Then, I pipe the result of &lt;code&gt;sed&lt;/code&gt; using &lt;code&gt;|&lt;/code&gt; to &lt;code&gt;shuf&lt;/code&gt; which does the shuffling. The option &lt;code&gt;--random-source=&amp;lt;(get_seeded_random 42)&lt;/code&gt; fixes the seed, and &lt;code&gt;-n 500000&lt;/code&gt; only shuffles 500000 and not the whole file. The final bit of the line, &lt;code&gt;&amp;gt; small_combined_temp.csv&lt;/code&gt;, saves the result to &lt;code&gt;small_cobmined_temp.csv&lt;/code&gt;. Because I need to add back the header, I use &lt;code&gt;head -1&lt;/code&gt; to extract the first line of &lt;code&gt;combined.csv&lt;/code&gt; and save it into &lt;code&gt;colnames.csv&lt;/code&gt;. Finally, I bind the rows of both files using &lt;code&gt;cat colnames.csv small_combined_temp.csv&lt;/code&gt; and save the result into &lt;code&gt;small_combined.cvs&lt;/code&gt;. Taken together, all these steps took about 5 minutes (without counting the googling around for finding how to pass a fixed seed to &lt;code&gt;shuf&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now that I have this small dataset, I can write a small prototype:&lt;/p&gt;
&lt;p&gt;First, you need to install &lt;code&gt;{sparklyr}&lt;/code&gt;, &lt;code&gt;{rsparkling}&lt;/code&gt; and &lt;code&gt;{h2o}&lt;/code&gt;. Refer to &lt;a href=&#34;https://github.com/h2oai/rsparkling&#34;&gt;this&lt;/a&gt; to know how to install the packages. I had a mismatch between the version of H2O that was automatically installed when I installed the &lt;code&gt;{h2o}&lt;/code&gt; package, and the version of Spark that &lt;code&gt;{sparklyr}&lt;/code&gt; installed but thankfully the &lt;code&gt;{h2o}&lt;/code&gt; package returns a very helpful error message with the following lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;detach(&amp;quot;package:rsparkling&amp;quot;, unload = TRUE)
                       if (&amp;quot;package:h2o&amp;quot; %in% search()) { detach(&amp;quot;package:h2o&amp;quot;, unload = TRUE) }
                       if (isNamespaceLoaded(&amp;quot;h2o&amp;quot;)){ unloadNamespace(&amp;quot;h2o&amp;quot;) }
                       remove.packages(&amp;quot;h2o&amp;quot;)
                       install.packages(&amp;quot;h2o&amp;quot;, type = &amp;quot;source&amp;quot;, repos = &amp;quot;https://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/2/R&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which tells you which version to install.&lt;/p&gt;
&lt;p&gt;So now, let’s load everything:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sparklyr)
library(rsparkling)
library(h2o)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &amp;gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &amp;gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit http://docs.h2o.ai
## 
## ----------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;h2o&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     cor, sd, var&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:base&amp;#39;:
## 
##     &amp;amp;&amp;amp;, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,
##     colnames&amp;lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h2o.init()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     /tmp/Rtmph48vf9/h2o_cbrunos_started_from_r.out
##     /tmp/Rtmph48vf9/h2o_cbrunos_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: .. Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         1 seconds 944 milliseconds 
##     H2O cluster version:        3.16.0.2 
##     H2O cluster version age:    4 months and 15 days !!! 
##     H2O cluster name:           H2O_started_from_R_cbrunos_bpn152 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   6.98 GB 
##     H2O cluster total cores:    12 
##     H2O cluster allowed cores:  12 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.4.4 (2018-03-15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in h2o.clusterInfo(): 
## Your H2O cluster version is too old (4 months and 15 days)!
## Please download and install the latest version from http://h2o.ai/download/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I left all the startup messages because they’re quite helpful. Especially that bit telling you to start &lt;code&gt;H2O&lt;/code&gt; with &lt;code&gt;h2o.init()&lt;/code&gt;. If something’s wrong, &lt;code&gt;h2o.init()&lt;/code&gt; will give you helpful information.&lt;/p&gt;
&lt;p&gt;Now that all this is loaded, I can start working on the data (the steps below are explained in detail in my &lt;a href=&#34;http://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data/&#34;&gt;previous blog post&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;spark_dir = &amp;quot;/my_2_to_disk/spark/&amp;quot;

config = spark_config()

config$`sparklyr.shell.driver-memory` &amp;lt;- &amp;quot;4G&amp;quot;
config$`sparklyr.shell.executor-memory` &amp;lt;- &amp;quot;4G&amp;quot;
config$`spark.yarn.executor.memoryOverhead` &amp;lt;- &amp;quot;512&amp;quot;
config$`sparklyr.shell.driver-java-options` = paste0(&amp;quot;-Djava.io.tmpdir=&amp;quot;, spark_dir)

sc = spark_connect(master = &amp;quot;local&amp;quot;, config = config)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another useful function that allows you to check if everything is alright is &lt;code&gt;h2o_context()&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h2o_context(sc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;jobj[12]&amp;gt;
  org.apache.spark.h2o.H2OContext

Sparkling Water Context:
 * H2O name: sparkling-water-cbrunos_local-1520111879840
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54323)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54323 (CMD + click in Mac OSX)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s load the data into R with &lt;code&gt;{sparklyr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;air = spark_read_csv(sc, name = &amp;quot;air&amp;quot;, path = &amp;quot;small_combined.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, here, using Spark is overkill, because &lt;code&gt;small_combined.csv&lt;/code&gt; is only around 100MB big, so no need for &lt;code&gt;{sparklyr}&lt;/code&gt; but as stated in the beginning this is only to have a quick and dirty prototype. Once all the pieces are working together, I can iterate on the real data, for which &lt;code&gt;{sparklyr}&lt;/code&gt; will be needed. Now, if I needed to use &lt;code&gt;{dplyr}&lt;/code&gt; I could use it on &lt;code&gt;air&lt;/code&gt;, but I don’t want to do anything on it, so I convert it to a &lt;code&gt;h2o&lt;/code&gt; data frame. &lt;code&gt;h2o&lt;/code&gt; data frames are needed as arguments for the machine learning algorithms included in the &lt;code&gt;{h2o}&lt;/code&gt; package. &lt;code&gt;as_h2o_frame()&lt;/code&gt; is a function included in &lt;code&gt;{rsparkling}&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;air_hf = as_h2o_frame(sc, air)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I convert the columns I need to factors (I am only using factors here):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;air_hf$ORIGIN = as.factor(air_hf$ORIGIN)
air_hf$UNIQUE_CARRIER = as.factor(air_hf$UNIQUE_CARRIER)
air_hf$DEST = as.factor(air_hf$DEST)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;{h2o}&lt;/code&gt; functions need the names of the predictors and of the target columns, so let’s define that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;target = &amp;quot;ARR_DELAY&amp;quot;
predictors = c(&amp;quot;UNIQUE_CARRIER&amp;quot;, &amp;quot;ORIGIN&amp;quot;, &amp;quot;DEST&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s train a random Forest, without any hyper parameter tweaking:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model = h2o.randomForest(predictors, target, training_frame = air_hf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that this runs, I will in the future split the data into training, validation and test set, and train a model with better hyper parameters. For now, let’s take a look at the summary of &lt;code&gt;model&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Model Details:
==============

H2ORegressionModel: drf
Model Key:  DRF_model_R_1520111880605_1
Model Summary:
  number_of_trees number_of_internal_trees model_size_in_bytes min_depth
1              50                       50            11055998        20
  max_depth mean_depth min_leaves max_leaves mean_leaves
1        20   20.00000       1856       6129  4763.42000

H2ORegressionMetrics: drf
** Reported on training data. **
** Metrics reported on Out-Of-Bag training samples **

MSE:  964.9246
RMSE:  31.06324
MAE:  17.65517
RMSLE:  NaN
Mean Residual Deviance :  964.9246





Scoring History:
             timestamp   duration number_of_trees training_rmse training_mae
1  2018-03-03 22:52:24  0.035 sec               0
2  2018-03-03 22:52:25  1.275 sec               1      30.93581     17.78216
3  2018-03-03 22:52:25  1.927 sec               2      31.36998     17.78867
4  2018-03-03 22:52:26  2.272 sec               3      31.36880     17.80359
5  2018-03-03 22:52:26  2.564 sec               4      31.29683     17.79467
6  2018-03-03 22:52:26  2.854 sec               5      31.31226     17.79467
7  2018-03-03 22:52:27  3.121 sec               6      31.26214     17.78542
8  2018-03-03 22:52:27  3.395 sec               7      31.20749     17.75703
9  2018-03-03 22:52:27  3.666 sec               8      31.19706     17.74753
10 2018-03-03 22:52:27  3.935 sec               9      31.16108     17.73547
11 2018-03-03 22:52:28  4.198 sec              10      31.13725     17.72493
12 2018-03-03 22:52:32  8.252 sec              27      31.07608     17.66648
13 2018-03-03 22:52:36 12.462 sec              44      31.06325     17.65474
14 2018-03-03 22:52:38 14.035 sec              50      31.06324     17.65517
   training_deviance
1
2          957.02450
3          984.07580
4          984.00150
5          979.49147
6          980.45794
7          977.32166
8          973.90720
9          973.25655
10         971.01272
11         969.52856
12         965.72249
13         964.92530
14         964.92462

Variable Importances: (Extract with `h2o.varimp`)
=================================================

Variable Importances:
        variable relative_importance scaled_importance percentage
1         ORIGIN    291883392.000000          1.000000   0.432470
2           DEST    266749168.000000          0.913890   0.395230
3 UNIQUE_CARRIER    116289536.000000          0.398411   0.172301
&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Keep trying that api call with purrr::possibly()</title>
      <link>https://www.brodrigues.co/blog/2018-03-12-keep_trying/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-03-12-keep_trying/</guid>
      <description>&lt;p&gt;Sometimes you need to call an api to get some result from a web service, but sometimes this call might
fail. You might get an error 500 for example, or maybe you’re making too many calls too fast. Regarding
this last point, I really encourage you to read &lt;a href=&#34;https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01&#34;&gt;Ethics in Web Scraping&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this blog post I will show you how you can keep trying to make this api call using &lt;code&gt;purrr::possibly()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For this, let’s use this function that will simulate an api call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_data = function(){
  number = rbinom(1, 1, 0.9)
  ifelse(number == 0, &amp;quot;OK&amp;quot;, stop(&amp;quot;Error: too many calls!&amp;quot;))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function simply returns a random draw from a binomial distribution. If this number equals 0
with probability 0.1, the function returns “OK”, if not, it throws an error. Because the probability
of success is only 10%, your api call might be unsuccessful:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_data()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in ifelse(number == 0, &amp;quot;OK&amp;quot;, stop(&amp;quot;Error: too many calls!&amp;quot;)) :
  Error: too many calls!&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How to keep trying until it works? For this, we’re going to use &lt;code&gt;purrr::possibly()&lt;/code&gt;; this function
takes another function as argument and either returns the result, or another output in case of error,
that the user can define:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;possibly_get_data = purrr::possibly(get_data, otherwise = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(12)
possibly_get_data()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;set.seed(12)&lt;/code&gt;, the function returns a number different from 0, and thus throws an error: but
because we’re wrapping the function around &lt;code&gt;purrr::possibly()&lt;/code&gt;, the function now returns &lt;code&gt;NULL&lt;/code&gt;. The
first step is done; now we can use this to our advantage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;definitely_get_data = function(func, n_tries, sleep, ...){

  possibly_func = purrr::possibly(func, otherwise = NULL)

  result = NULL
  try_number = 1

  while(is.null(result) &amp;amp;&amp;amp; try_number &amp;lt;= n_tries){
    print(paste(&amp;quot;Try number: &amp;quot;, try_number))
    try_number = try_number + 1
    result = possibly_func(...)
    Sys.sleep(sleep)
  }

  return(result)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;definitely_get_data()&lt;/code&gt; is a function that takes any function as argument, as well as a user provided
number of tries (as well as &lt;code&gt;...&lt;/code&gt; to pass further arguments to &lt;code&gt;func()&lt;/code&gt;). Remember, if &lt;code&gt;func()&lt;/code&gt; fails,
it will return &lt;code&gt;NULL&lt;/code&gt;; the while loop ensures that while the result is &lt;code&gt;NULL&lt;/code&gt;, and the number of tries
is below what you provided, the function will keep getting called. I didn’t talk about &lt;code&gt;sleep&lt;/code&gt;; this
argument is provided to &lt;code&gt;Sys.sleep()&lt;/code&gt; which introduces a break between calls that is equal to &lt;code&gt;sleep&lt;/code&gt;
seconds. This ensures you don’t make too many calls too fast. Let’s try it out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
definitely_get_data(get_data, 10, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Try number:  1&amp;quot;
## [1] &amp;quot;Try number:  2&amp;quot;
## [1] &amp;quot;Try number:  3&amp;quot;
## [1] &amp;quot;Try number:  4&amp;quot;
## [1] &amp;quot;Try number:  5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;OK&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It took 5 tries to get the result! However, if after 10 tries &lt;code&gt;get_data()&lt;/code&gt; fails to return
what you need it will stop (but you can increase the number of tries…).&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Importing 30GB of data into R with sparklyr</title>
      <link>https://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data/</guid>
      <description>&lt;p&gt;Disclaimer: the first part of this blog post draws heavily from &lt;a href=&#34;http://bconnelly.net/working-with-csvs-on-the-command-line/&#34;&gt;Working with CSVs on the Command
Line&lt;/a&gt;, which is a beautiful resource
that lists very nice tips and tricks to work with CSV files before having to load them into R, or
any other statistical software. I highly recommend it! Also, if you find this interesting, read
also &lt;a href=&#34;https://www.datascienceatthecommandline.com/&#34;&gt;Data Science at the Command Line&lt;/a&gt; another great
resource!&lt;/p&gt;
&lt;p&gt;In this blog post I am going to show you how to analyze 30GB of data. 30GB of data does not qualify
as big data, but it’s large enough that you cannot simply import it into R and start working on it,
unless you have a machine with &lt;em&gt;a lot&lt;/em&gt; of RAM.&lt;/p&gt;
&lt;p&gt;Let’s start by downloading some data. I am going to import and analyze (very briefly) the airline
dataset that you can download from Microsoft
&lt;a href=&#34;https://packages.revolutionanalytics.com/datasets/&#34;&gt;here&lt;/a&gt;. I downloaded the file
&lt;code&gt;AirOnTimeCSV.zip&lt;/code&gt; from &lt;code&gt;AirOnTime87to12&lt;/code&gt;. Once you decompress it, you’ll end up with 303 csv
files, each around 80MB. Before importing them into R, I will use command line tools to bind the
rows together. But first, let’s make sure that the datasets all have the same columns. I am using
Linux, and if you are too, or if you are using macOS, you can follow along. Windows users that
installed the Linux Subsystem can also use the commands I am going to show! First, I’ll use
the &lt;code&gt;head&lt;/code&gt; command in bash. If you’re familiar with &lt;code&gt;head()&lt;/code&gt; from R, the &lt;code&gt;head&lt;/code&gt;
command in bash works exactly the same:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[18-02-15 21:12] brodriguesco in /Documents/AirOnTimeCSV ➤ head -5 airOT198710.csv
&amp;quot;YEAR&amp;quot;,&amp;quot;MONTH&amp;quot;,&amp;quot;DAY_OF_MONTH&amp;quot;,&amp;quot;DAY_OF_WEEK&amp;quot;,&amp;quot;FL_DATE&amp;quot;,&amp;quot;UNIQUE_CARRIER&amp;quot;,&amp;quot;TAIL_NUM&amp;quot;,&amp;quot;FL_NUM&amp;quot;,
1987,10,1,4,1987-10-01,&amp;quot;AA&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0901&amp;quot;,1.00,
1987,10,2,5,1987-10-02,&amp;quot;AA&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0901&amp;quot;,1.00
1987,10,3,6,1987-10-03,&amp;quot;AA&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0859&amp;quot;,-1.00
1987,10,4,7,1987-10-04,&amp;quot;AA&amp;quot;,&amp;quot;&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0900&amp;quot;,0.00,&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;let’s also check the 5 first lines of the last file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[18-02-15 21:13] cbrunos in brodriguesco in /Documents/AirOnTimeCSV ➤ head -5 airOT201212.csv
&amp;quot;YEAR&amp;quot;,&amp;quot;MONTH&amp;quot;,&amp;quot;DAY_OF_MONTH&amp;quot;,&amp;quot;DAY_OF_WEEK&amp;quot;,&amp;quot;FL_DATE&amp;quot;,&amp;quot;UNIQUE_CARRIER&amp;quot;,&amp;quot;TAIL_NUM&amp;quot;,&amp;quot;FL_NUM&amp;quot;,
2012,12,1,6,2012-12-01,&amp;quot;AA&amp;quot;,&amp;quot;N322AA&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0852&amp;quot;,
2012,12,2,7,2012-12-02,&amp;quot;AA&amp;quot;,&amp;quot;N327AA&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0853&amp;quot;,
2012,12,3,1,2012-12-03,&amp;quot;AA&amp;quot;,&amp;quot;N319AA&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;0856&amp;quot;
2012,12,4,2,2012-12-04,&amp;quot;AA&amp;quot;,&amp;quot;N329AA&amp;quot;,&amp;quot;1&amp;quot;,12478,&amp;quot;JFK&amp;quot;,&amp;quot;NY&amp;quot;,12892,&amp;quot;LAX&amp;quot;,&amp;quot;CA&amp;quot;,&amp;quot;0900&amp;quot;,&amp;quot;1006&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why do that in bash instead of R? This way, I don’t need to import the data into R before checking
its contents!&lt;/p&gt;
&lt;p&gt;It does look like the structure did not change. Before importing the data into R, I am going to
bind the rows of the datasets using other command line tools. Again, the reason I don’t import all the files
into R is because I would need around 30GB of RAM to do so. So it’s easier
to do it with bash:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;head -1 airOT198710.csv &amp;gt; combined.csv
for file in $(ls airOT*); do cat $file | sed &amp;quot;1 d&amp;quot; &amp;gt;&amp;gt; combined.csv; done&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the first line I use &lt;code&gt;head&lt;/code&gt; again to only copy the column names (the first line of the first
file) into a new file called &lt;code&gt;combined.csv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This &lt;code&gt;&amp;gt;&lt;/code&gt; operator looks like the now well known pipe operator in R, &lt;code&gt;%&amp;gt;%&lt;/code&gt;, but in
bash, &lt;code&gt;%&amp;gt;%&lt;/code&gt; is actually &lt;code&gt;|&lt;/code&gt;, not &lt;code&gt;&amp;gt;&lt;/code&gt;. &lt;code&gt;&amp;gt;&lt;/code&gt; redirects the output of the left hand side to a file on
the right hand side, not to another command. On the second line, I loop over the files. I
list the files with &lt;code&gt;ls&lt;/code&gt;, and because I want only to loop over those that are named &lt;code&gt;airOTxxxxx&lt;/code&gt; I
use a regular expression, &lt;code&gt;airOT*&lt;/code&gt; to only list those. The second part is &lt;code&gt;do cat $file&lt;/code&gt;. &lt;code&gt;do&lt;/code&gt; is
self-explanatory, and &lt;code&gt;cat&lt;/code&gt; stands for &lt;code&gt;catenate&lt;/code&gt;. Think of it as &lt;code&gt;head&lt;/code&gt;, but on all rows instead
of just 5; it prints &lt;code&gt;$file&lt;/code&gt; to the terminal. &lt;code&gt;$file&lt;/code&gt; one element of the list of files I am looping over.
But because I don’t want to see the contents of &lt;code&gt;$file&lt;/code&gt; on my terminal, I redirect the output with
the pipe, &lt;code&gt;|&lt;/code&gt; to another command, &lt;code&gt;sed&lt;/code&gt;. &lt;code&gt;sed&lt;/code&gt; has an option, &lt;code&gt;&amp;quot;1 d&amp;quot;&lt;/code&gt;, and what this does is filtering
out the first line, containing the header, from &lt;code&gt;$file&lt;/code&gt; before appending it with
&lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; to &lt;code&gt;combined.csv&lt;/code&gt;. If you found this interesting, read more about it
&lt;a href=&#34;http://bconnelly.net/working-with-csvs-on-the-command-line/#combining-rows-from-two-or-more-csvs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This creates a 30GB CSV file that you can then import. But how? There seems to be different ways to
import and work with larger than memory data in R using your personal computer. I chose to use
&lt;code&gt;{sparklyr}&lt;/code&gt;, an R package that allows you to work with Apache Spark from R. Apache Spark is a &lt;em&gt;fast
and general engine for large-scale data processing&lt;/em&gt;, and &lt;code&gt;{sparklyr}&lt;/code&gt; not only offers bindings to it,
but also provides a complete &lt;code&gt;{dplyr}&lt;/code&gt; backend. Let’s start:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sparklyr)
library(tidyverse)

spark_dir = &amp;quot;/my_2_to_disk/spark/&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I first load &lt;code&gt;{sparklyr}&lt;/code&gt; and the &lt;code&gt;{tidyverse}&lt;/code&gt; and also define a &lt;code&gt;spark_dir&lt;/code&gt;. This is because
Spark creates a lot of temporary files that I want to save there instead of my root partition,
which is on my SSD. My root partition only has around 20GO of space left, so whenever I tried to
import the data I would get the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java.io.IOException: No space left on device&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to avoid this error, I define this directory on my 2TO hard disk.
I then define the temporary directory using the two lines below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;config = spark_config()

config$`sparklyr.shell.driver-java-options` &amp;lt;-  paste0(&amp;quot;-Djava.io.tmpdir=&amp;quot;, spark_dir)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not sufficient however; when I tried to read in the data, I got another error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java.lang.OutOfMemoryError: Java heap space&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The solution for this one is to add the following lines to your &lt;code&gt;config()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;config$`sparklyr.shell.driver-memory` &amp;lt;- &amp;quot;4G&amp;quot;
config$`sparklyr.shell.executor-memory` &amp;lt;- &amp;quot;4G&amp;quot;
config$`spark.yarn.executor.memoryOverhead` &amp;lt;- &amp;quot;512&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, I can load the data. Because I am working on my machine, I &lt;em&gt;connect&lt;/em&gt; to a &lt;code&gt;&amp;quot;local&amp;quot;&lt;/code&gt; Spark
instance. Then, using &lt;code&gt;spark_read_csv()&lt;/code&gt;, I specify the Spark connection, &lt;code&gt;sc&lt;/code&gt;, I give a name to the
data that will be inside the database and the path to it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sc = spark_connect(master = &amp;quot;local&amp;quot;, config = config)

air = spark_read_csv(sc, name = &amp;quot;air&amp;quot;, path = &amp;quot;combined.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On my machine, this took around 25 minutes, and RAM usage was around 6GO.&lt;/p&gt;
&lt;p&gt;It is possible to use standard &lt;code&gt;{dplyr}&lt;/code&gt; verbs with &lt;code&gt;{sparklyr}&lt;/code&gt; objects, so if I want the mean
delay at departure per day, I can simply write:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic = Sys.time()
mean_dep_delay = air %&amp;gt;%
  group_by(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  summarise(mean_delay = mean(DEP_DELAY))
(toc = Sys.time() - tic)
Time difference of 0.05634999 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s amazing, only 0.06 seconds to compute these means! Wait a minute, that’s weird… I mean my computer
is brand new and quite powerful but still… Let’s take a look at &lt;code&gt;mean_dep_delay&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(mean_dep_delay)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Source:   lazy query [?? x 4]
# Database: spark_connection
# Groups:   YEAR, MONTH
   YEAR MONTH DAY_OF_MONTH mean_delay
  &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;        &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt;
1  1987    10            9       6.71
2  1987    10           10       3.72
3  1987    10           12       4.95
4  1987    10           14       4.53
5  1987    10           23       6.48
6  1987    10           29       5.77
Warning messages:
1: Missing values are always removed in SQL.
Use `AVG(x, na.rm = TRUE)` to silence this warning
2: Missing values are always removed in SQL.
Use `AVG(x, na.rm = TRUE)` to silence this warning&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Surprisingly, this takes around 5 minutes to print? Why? Look at the class of &lt;code&gt;mean_dep_delay&lt;/code&gt;:
it’s a lazy query that only gets evaluated once I need it. Look at the first line; &lt;code&gt;lazy query [?? x 4]&lt;/code&gt;.
This means that I don’t even know how many rows are in &lt;code&gt;mean_dep_delay&lt;/code&gt;!
The contents of &lt;code&gt;mean_dep_delay&lt;/code&gt; only get computed once I explicitly ask for them. I do so
with the &lt;code&gt;collect()&lt;/code&gt; function, which transfers the Spark object into R’s memory:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tic = Sys.time()
r_mean_dep_delay = collect(mean_dep_delay)
(toc = Sys.time() - tic)
Time difference of 5.2399 mins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, because it took such a long time to compute: I save it to disk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(r_mean_dep_delay, &amp;quot;mean_dep_delay.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now that I &lt;em&gt;transferred&lt;/em&gt; this sparklyr table to a standard tibble in R, I can create a nice plot
of departure delays:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)

dep_delay =  r_mean_dep_delay %&amp;gt;%
  arrange(YEAR, MONTH, DAY_OF_MONTH) %&amp;gt;%
  mutate(date = ymd(paste(YEAR, MONTH, DAY_OF_MONTH, sep = &amp;quot;-&amp;quot;)))

ggplot(dep_delay, aes(date, mean_delay)) + geom_smooth()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;gam&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2018-02-16-importing_30gb_of_data_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That’s it for now, but in a future blog post I will continue to explore this data!&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting job search by training a random forest on an unbalanced dataset</title>
      <link>https://www.brodrigues.co/blog/2018-02-11-census-random_forest/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-02-11-census-random_forest/</guid>
      <description>&lt;p&gt;Update 2022: there some literature advising against using techniques to artificially balance a dataset,
   for example
    &lt;a href=&#34;https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocac093/6605096?searchresult=1&amp;login=false#&#34;&gt;one&lt;/a&gt;.
   Use at your own risks!&lt;/p&gt;

&lt;p&gt;In this blog post, I am going to train a random forest on census data from the US to predict
the probability that someone is looking for a job. To this end, I downloaded the US 1990 census
data from the UCI &lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/US+Census+Data+%281990%29&#34;&gt;Machine Learning Repository&lt;/a&gt;.
Having a background in economics, I am always quite interested by such datasets. I downloaded the raw
data which is around 820mb uncompressed. You can download it from this folder
&lt;a href=&#34;https://archive.ics.uci.edu/ml/machine-learning-databases/census1990-mld/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before training a random forest on it, some preprocessing is needed. First problem: the columns
in the data do not have names. Actually, training a random forest on unamed variables is possible,
but I like my columns to have names. The names are on a separate file, called &lt;code&gt;USCensus1990raw.attributes.txt&lt;/code&gt;.
This is how this file looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VAR:        TYP:   DES:    LEN:   CAT:    VARIABLE/CATEGORY LABEL:
__________________________________________________________________________________
HISPANIC     C       X      3             Detailed Hispanic Origin Code See Append
                                  000     Not Hispanic 006 199
                                  001     Mexican, Mex Am 210 220
                                  002     Puerto Rican 261 270
                                  003     Cuban 271 274
                                  004     Other Hispanic 200 209, 250 260, 290 401

VAR:        TYP:   DES:    LEN:   CAT:    VARIABLE/CATEGORY LABEL:
__________________________________________________________________________________
HOUR89       C       X      2             Usual Hrs. Worked Per Week Last Yr. 1989
                                  00      N/a Less Than 16 Yrs. Old/did Not Work i
                                  99      99 or More Usual Hrs.

VAR:        TYP:   DES:    LEN:   CAT:    VARIABLE/CATEGORY LABEL:
__________________________________________________________________________________
HOURS        C       X      2             Hrs. Worked Last Week
                                  00      N/a Less Than 16 Yrs. Old/not At Work/un
                                  99      99 or More Hrs. Worked Last Week

VAR:        TYP:   DES:    LEN:   CAT:    VARIABLE/CATEGORY LABEL:
__________________________________________________________________________________
IMMIGR       C       X      2             Yr. of Entry
                                  00      Born in the U.S.
                                  01      1987 to 1990
                                  02      1985 to 1986
                                  03      1982 to 1984


                                  04      1980 or 1981
                                  05      1975 to 1979
                                  06      1970 to 1974
                                  07      1965 to 1969
                                  08      1960 to 1964
                                  09      1950 to 1959
                                  10      Before 1950&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable names are always written in upper case and sometimes end with some numbers.
Regular expressions will help extract these column names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

census_raw = import(&amp;quot;USCensus1990raw.data.txt&amp;quot;)

attributes_raw = readLines(&amp;quot;USCensus1990raw.attributes.txt&amp;quot;)

column_names = str_extract_all(attributes_raw, &amp;quot;^[A-Z]+(\\d{1,}|[A-Z])\\s+&amp;quot;) %&amp;gt;%
  flatten %&amp;gt;%
  str_trim %&amp;gt;%
  tolower&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using &lt;code&gt;readLines&lt;/code&gt; I load this text file into R. Then with &lt;code&gt;stringr::str_extract_all&lt;/code&gt;, I can extract
the variable names from this text file. The regular expression, &lt;code&gt;^[A-Z]+(\\d{1,}|[A-Z])\\s+&lt;/code&gt; can
seem complicated, but by breaking it up, it’ll be clear:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;^[A-Z]+&lt;/code&gt;: matches one or more uppercase letter, at the beginning of the line (hence the &lt;code&gt;^&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\\d{1,}&lt;/code&gt;: matches one or more digits&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[A-Z]\\s+&lt;/code&gt;: matches one uppercase letter, followed by one or more spaces&lt;/li&gt;
&lt;li&gt;&lt;code&gt;(\\d{1,}|[A-Z])\\s+&lt;/code&gt;: matches one or more digits OR (the &lt;code&gt;|&lt;/code&gt;) matches one uppercase letter, followed by one or more spaces&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This regular expression matches only the variable names. By using &lt;code&gt;^&lt;/code&gt; I only limit myself to the
uppercase letters at the start of the line, which already removes a lot of unneeded lines from the
text. Then, by matching numbers or letters, followed by spaces, I avoid matching strings such as
&lt;code&gt;VAR:&lt;/code&gt;. There’s probably a shorter way to write this regular expression, but since this one works,
I stopped looking for another solution.&lt;/p&gt;
&lt;p&gt;Now that I have a vector called &lt;code&gt;column_names&lt;/code&gt;, I can baptize the columns in my dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(census_raw) &amp;lt;- column_names&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also add a column called &lt;code&gt;caseid&lt;/code&gt; to the dataset, but it’s actually not really needed. But it
made me look for and find &lt;code&gt;rownames_to_column()&lt;/code&gt;, which can be useful:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census = census_raw %&amp;gt;%
  rownames_to_column(&amp;quot;caseid&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I select the variables I need. I use &lt;code&gt;dplyr::select()&lt;/code&gt; to select the columns I need (actually,
I will remove some of these later for the purposes of the blog post, but will continue exploring
them. Maybe write a part 2?):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census %&amp;lt;&amp;gt;%
  select(caseid, age, citizen, class, disabl1, disabl2, lang1, looking, fertil, hour89, hours, immigr,
         industry, means, occup, powpuma, powstate, pwgt1, race, ragechld, rearning,
         relat1, relat2, remplpar, rlabor, rpincome, rpob, rspouse, rvetserv, school, sex, tmpabsnt,
         travtime, week89, work89, worklwk, yearsch, yearwrk, yrsserv)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I convert factor variables to factors and only relevel the &lt;code&gt;race&lt;/code&gt; variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;census %&amp;lt;&amp;gt;%
  mutate(race = case_when(race == 1 ~ &amp;quot;white&amp;quot;,
                          race == 2 ~ &amp;quot;black&amp;quot;,
                          !(race %in% c(1, 2)) ~ &amp;quot;other&amp;quot;,
                          is.na(race) ~ NA_character_)) %&amp;gt;%
  filter(looking != 0) %&amp;gt;%
  mutate_at(vars(class, disabl1, disabl2, lang1, looking, fertil, immigr, industry, means,
                 occup, powstate, race, ragechld, remplpar, rlabor, rpob, rspouse,
                 rvetserv, school, sex, tmpabsnt, work89, worklwk, yearwrk),
            as.factor) %&amp;gt;%
  select(looking, age, class, disabl1, disabl2, lang1, fertil, immigr,
         race, ragechld, remplpar, rlabor, rpob, rspouse,
         rvetserv, school, sex, tmpabsnt, work89, worklwk, yearwrk, rpincome, rearning,
         travtime, week89, work89, hours, yearsch, yrsserv) %&amp;gt;%
  as_tibble

export(census, &amp;quot;regression_data.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the variable I want to predict is &lt;code&gt;looking&lt;/code&gt; which has 2 levels (I removed the level &lt;code&gt;0&lt;/code&gt;, which
stands for &lt;code&gt;NA&lt;/code&gt;). I convert all the variables that are supposed to be factors into factors using
&lt;code&gt;mutate_at()&lt;/code&gt; and then reselect a subsample of the columns. &lt;code&gt;census&lt;/code&gt; is now a tibble with 39
columns and 2458285 rows. I will train the forest on a subsample only, because with cross validation
it would take forever on the whole dataset.&lt;/p&gt;
&lt;p&gt;I run the training on another script, that I will then run using the &lt;code&gt;Rscript&lt;/code&gt; command instead of
running it from Spacemacs (yes, I don’t use RStudio at home but Spacemacs + ESS). Here’s the script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(caret)
library(doParallel)
library(rio)

reg_data = import(&amp;quot;regression_data.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;janitor::tabyl(reg_data$looking)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reg_data$looking      n   percent
1                1  75792 0.1089562
2                2 619827 0.8910438&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;90% of the individuals in the sample are not looking for a new job. For training purposes, I will
only use 50000 observations instead of the whole sample. I’m already thinking about writing another
blog post where I show how to use the whole data. But 50000 observations should be more than enough
to have a pretty nice model. However, having 90% of observations belonging to a single class can
cause problems with the model; the model might predict that everyone should belong to class 2 and in
doing so, the model would be 90% accurate! Let’s ignore this for now, but later I am going to
tackle this issue with a procedure calleds SMOTE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
sample_df = sample_n(reg_data, 50000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, using &lt;code&gt;caret::trainIndex()&lt;/code&gt;, I partition the data into a training sample and a testing
sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trainIndex = createDataPartition(sample_df$looking, p = 0.8,
                                 list = FALSE,
                                 times = 1)

train_data = sample_df[trainIndex, ]
test_data = sample_df[-trainIndex, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also save the testing data to disk, because when the training is done I’ll lose my R session
(remember, I’ll run the training using Rscript):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(test_data, &amp;quot;test_data.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before training the model, I’ll change some options; I’ll do 5-fold cross validation that I repeat
5 times. This will further split the training set into training/testing sets which will increase
my confidence in the metrics that I get from the training. This will ensure that the best model
really is the best, and not a fluke resulting from the splitting of the data that I did beforehand.
Then, I will test the best model on the testing data from above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitControl &amp;lt;- trainControl(
  method = &amp;quot;repeatedcv&amp;quot;,
  number = 5,
  repeats = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A very nice feature from the &lt;code&gt;caret&lt;/code&gt; package is the possibility to make the training in parallel.
For this, load the &lt;code&gt;doParallel&lt;/code&gt; package (which I did above), and then register the number of cores
you want to use for training with &lt;code&gt;makeCluster()&lt;/code&gt;. You can replace &lt;code&gt;detectCores()&lt;/code&gt; by the number of
cores you want to use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cl = makeCluster(detectCores())
registerDoParallel(cl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can train the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_caret = train(looking ~ .,
                  data = train_data,
                  trainControl = fitControl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because it takes around 1 and a half hours to train, I save the model to disk using &lt;code&gt;saveRDS()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(fit_caret, &amp;quot;model_unbalanced.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The picture below shows all the cores from my computer running and RAM usage being around 20gb during
the training process:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/training_cpu.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;And this the results of training the random forest on the unbalanced data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_unbalanced = readRDS(&amp;quot;model_unbalanced.rds&amp;quot;)

test_data = readRDS(&amp;quot;test_data.rds&amp;quot;)

plot(model_unbalanced)

preds = predict.train(model_unbalanced, newdata = test_data)

confusionMatrix(preds, reference = test_data$looking)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/plot_acc_unbalanced.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Confusion Matrix and Statistics

Reference
Prediction     1     2
1  1287   112
2   253 12348

Accuracy : 0.9739
95% CI : (0.9712, 0.9765)
    No Information Rate : 0.89
    P-Value [Acc &amp;gt; NIR] : &amp;lt; 2.2e-16

                  Kappa : 0.8613
 Mcnemar&amp;#39;s Test P-Value : 2.337e-13

            Sensitivity : 0.83571
            Specificity : 0.99101
         Pos Pred Value : 0.91994
         Neg Pred Value : 0.97992
             Prevalence : 0.11000
         Detection Rate : 0.09193
   Detection Prevalence : 0.09993
      Balanced Accuracy : 0.91336

       &amp;#39;Positive&amp;#39; Class : 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If someone really is looking for a job, the model is able to predict it correctly 92% of the times
and 98% of the times if that person is not looking for a job. It’s slightly better than simply saying
than no one is looking for a job, which would be right 90% of the times, but not great either.&lt;/p&gt;
&lt;p&gt;To train to make the model more accurate in predicting class 1, I will resample the training set, but by
downsampling class 2 and upsampling class 1. This can be done with the function &lt;code&gt;SMOTE()&lt;/code&gt; from the
&lt;code&gt;{DMwR}&lt;/code&gt; package. However, the testing set should have the same distribution as the population,
so I should not apply &lt;code&gt;SMOTE()&lt;/code&gt; to the testing set. I will resplit the data, but this time with a 95/5 % percent
split; this way I have 5% of the original dataset used for testing, I can use &lt;code&gt;SMOTE()&lt;/code&gt; on the
95% remaining training set. Because &lt;code&gt;SMOTE&lt;/code&gt;ing takes some time, I save the &lt;em&gt;SMOTE&lt;/em&gt;d training set
using &lt;code&gt;readRDS()&lt;/code&gt; for later use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reg_data = import(&amp;quot;regression_data.rds&amp;quot;)


set.seed(1234)
trainIndex = createDataPartition(reg_data$looking, p = 0.95,
                                 list = FALSE,
                                 times = 1)

test_data = reg_data[-trainIndex, ]

saveRDS(test_data, &amp;quot;test_smote.rds&amp;quot;)


# Balance training set
train_data = reg_data[trainIndex, ]

train_smote = DMwR::SMOTE(looking ~ ., train_data, perc.over = 100, perc.under=200)

saveRDS(train_smote, &amp;quot;train_smote.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The testing set has 34780 observations and below you can see the distribution of the target variable,
&lt;code&gt;looking&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;janitor::tabyl(test_data$looking)
  test_data$looking     n   percent
1                 1  3789 0.1089419
2                 2 30991 0.8910581&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_smote = readRDS(&amp;quot;model_smote.rds&amp;quot;)

test_smote = readRDS(&amp;quot;test_smote.rds&amp;quot;)

plot(model_smote)

preds = predict.train(model_smote, newdata = test_smote)

confusionMatrix(preds, reference = test_smote$looking)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Confusion Matrix and Statistics

Reference
Prediction     1     2
1  3328  1142
2   461 29849

Accuracy : 0.9539
95% CI : (0.9517, 0.9561)
    No Information Rate : 0.8911
    P-Value [Acc &amp;gt; NIR] : &amp;lt; 2.2e-16

                  Kappa : 0.78
 Mcnemar&amp;#39;s Test P-Value : &amp;lt; 2.2e-16

            Sensitivity : 0.87833
            Specificity : 0.96315
         Pos Pred Value : 0.74452
         Neg Pred Value : 0.98479
             Prevalence : 0.10894
         Detection Rate : 0.09569
   Detection Prevalence : 0.12852
      Balanced Accuracy : 0.92074

       &amp;#39;Positive&amp;#39; Class : 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/plot_acc_smote.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;The balanced accuracy is higher, but unlike what I expected (and hoped), this model is worse in
predicting class 1! I will be trying one last thing; since I have a lot of data at my disposal,
I will simply sample 25000 observations where the target variable &lt;code&gt;looking&lt;/code&gt; equals 1, and then sample
another 25000 observations where the target variable equals 2 (without using &lt;code&gt;SMOTE()&lt;/code&gt;). Then I’ll
simply bind the rows and train the model on that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reg_data = import(&amp;quot;regression_data.rds&amp;quot;)


set.seed(1234)
trainIndex = createDataPartition(reg_data$looking, p = 0.95,
                                 list = FALSE,
                                 times = 1)

test_data = reg_data[-trainIndex, ]

saveRDS(test_data, &amp;quot;test_up_down.rds&amp;quot;)


# Balance training set
train_data = reg_data[trainIndex, ]

train_data1 = train_data %&amp;gt;%
  filter(looking == 1)

set.seed(1234)
train_data1 = sample_n(train_data1, 25000)


train_data2 = train_data %&amp;gt;%
  filter(looking == 2)

set.seed(1234)
train_data2 = sample_n(train_data2, 25000)

train_up_down = bind_rows(train_data1, train_data2)


fitControl &amp;lt;- trainControl(
  method = &amp;quot;repeatedcv&amp;quot;,
  number = 5,
  repeats = 5)

cl = makeCluster(detectCores())
registerDoParallel(cl)

fit_caret = train(looking ~ .,
                  data = train_up_down,
                  trControl = fitControl,
                  preProcess = c(&amp;quot;center&amp;quot;, &amp;quot;scale&amp;quot;))

saveRDS(fit_caret, &amp;quot;model_up_down.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here are the results:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_up_down = readRDS(&amp;quot;model_up_down.rds&amp;quot;)

test_up_down = readRDS(&amp;quot;test_up_down.rds&amp;quot;)

plot(model_up_down)

preds = predict.train(model_up_down, newdata = test_up_down)

confusionMatrix(preds, reference = test_up_down$looking)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Confusion Matrix and Statistics

Reference
Prediction     1     2
1  3403  1629
2   386 29362

Accuracy : 0.9421
95% CI : (0.9396, 0.9445)
    No Information Rate : 0.8911
    P-Value [Acc &amp;gt; NIR] : &amp;lt; 2.2e-16

                  Kappa : 0.7391
 Mcnemar&amp;#39;s Test P-Value : &amp;lt; 2.2e-16

            Sensitivity : 0.89813
            Specificity : 0.94744
         Pos Pred Value : 0.67627
         Neg Pred Value : 0.98702
             Prevalence : 0.10894
         Detection Rate : 0.09784
   Detection Prevalence : 0.14468
      Balanced Accuracy : 0.92278

       &amp;#39;Positive&amp;#39; Class : 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/plot_acc_smote.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Looks like it’s not much better than using &lt;code&gt;SMOTE()&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;There are several ways I could achieve better predictions; tuning the model is one possibility,
or perhaps going with another type of model altogether. I will certainly come back to this dataset
in future blog posts!&lt;/p&gt;
&lt;p&gt;Using the best model, let’s take a look at which variables are the most important for predicting job search:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; varImp(model_unbalanced)
rf variable importance

only 20 most important variables shown (out of 109)

Overall
rlabor3   100.0000
rlabor6    35.2702
age         6.3758
rpincome    6.2964
tmpabsnt1   5.8047
rearning    5.3560
week89      5.2863
tmpabsnt2   4.0195
yearsch     3.4892
tmpabsnt3   1.7434
work892     1.3231
racewhite   0.9002
class1      0.7866
school2     0.7117
yearwrk2    0.6970
sex1        0.6955
disabl12    0.6809
lang12      0.6619
rpob23      0.6507
rspouse6    0.6330&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s also possible to have a plot of the above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(varImp(model_unbalanced))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/varimp.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;To make sense of this, we have to read the description of the features &lt;a href=&#34;https://archive.ics.uci.edu/ml/machine-learning-databases/census1990-mld/USCensus1990raw.attributes.txt&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rlabor3&lt;/code&gt; is the most important variable, and means that the individual is unemployed. &lt;code&gt;rlabor6&lt;/code&gt;
means not in the labour force. Then the age of the individual as well as the individual’s income
play a role. &lt;code&gt;tmpabsnt&lt;/code&gt; is a variable that equals 1 if the individual is temporary absent from work,
due to a layoff. All these variables having an influence on the probability of looking
for a job make sense, but looks like a very simple model focusing on just a couple of variables
would make as good a job as the random forest.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mapping a list of functions to a list of datasets with a list of columns as arguments</title>
      <link>https://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/</guid>
      <description>&lt;p&gt;This week I had the opportunity to teach R at my workplace, again. This course was the “advanced
R” course, and unlike the one I taught at the end of last year, I had one more day (so 3 days in total)
where I could show my colleagues the joys of the &lt;code&gt;tidyverse&lt;/code&gt; and R.&lt;/p&gt;
&lt;p&gt;To finish the section on programming with R, which was the very last section of the whole 3 day course
I wanted to blow their minds; I had already shown them packages from the &lt;code&gt;tidyverse&lt;/code&gt; in the previous
days, such as &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;purrr&lt;/code&gt; and &lt;code&gt;stringr&lt;/code&gt;, among others. I taught them how to use &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;broom&lt;/code&gt;
and &lt;code&gt;modelr&lt;/code&gt;. They also liked &lt;code&gt;janitor&lt;/code&gt; and &lt;code&gt;rio&lt;/code&gt; very much. I noticed that it took them a bit more
time and effort for them to digest &lt;code&gt;purrr::map()&lt;/code&gt; and &lt;code&gt;purrr::reduce()&lt;/code&gt;, but they all seemed to see
how powerful these functions were. To finish on a very high note, I showed them the ultimate
&lt;code&gt;purrr::map()&lt;/code&gt; use case.&lt;/p&gt;
&lt;p&gt;Consider the following; imagine you have a situation where you are working on a list of datasets.
These datasets might be the same, but for different years, or for different countries, or they might
be completely different datasets entirely. If you used &lt;code&gt;rio::import_list()&lt;/code&gt; to read them into R,
you will have them in a nice list. Let’s consider the following list as an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)
data(iris)

data_list = list(mtcars, iris)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I made the choice to have completely different datasets. Now, I would like to map some functions
to the columns of these datasets. If I only worked on one, for example on &lt;code&gt;mtcars&lt;/code&gt;, I would do
something like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_summarise_f = function(dataset, cols, funcs){
  dataset %&amp;gt;%
    summarise_at(vars(!!!cols), funs(!!!funcs))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then I would use my function like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
  my_summarise_f(quos(mpg, drat, hp), quos(mean, sd, max))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mpg_mean drat_mean  hp_mean   mpg_sd   drat_sd    hp_sd mpg_max drat_max
## 1 20.09062  3.596563 146.6875 6.026948 0.5346787 68.56287    33.9     4.93
##   hp_max
## 1    335&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;my_summarise_f()&lt;/code&gt; takes a dataset, a list of columns and a list of functions as arguments and uses
tidy evaluation to apply &lt;code&gt;mean()&lt;/code&gt;, &lt;code&gt;sd()&lt;/code&gt;, and &lt;code&gt;max()&lt;/code&gt; to the columns &lt;code&gt;mpg&lt;/code&gt;, &lt;code&gt;drat&lt;/code&gt; and &lt;code&gt;hp&lt;/code&gt;
of &lt;code&gt;mtcars&lt;/code&gt;. That’s pretty useful, but not useful enough! Now I want to apply this to the list of
datasets I defined above. For this, let’s define the list of columns I want to work on:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cols_mtcars = quos(mpg, drat, hp)
cols_iris = quos(Sepal.Length, Sepal.Width)

cols_list = list(cols_mtcars, cols_iris)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s use some &lt;code&gt;purrr&lt;/code&gt; magic to apply the functions I want to the columns I have defined in
&lt;code&gt;list_cols&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map2(data_list,
     cols_list,
     my_summarise_f, funcs = quos(mean, sd, max))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##   mpg_mean drat_mean  hp_mean   mpg_sd   drat_sd    hp_sd mpg_max drat_max
## 1 20.09062  3.596563 146.6875 6.026948 0.5346787 68.56287    33.9     4.93
##   hp_max
## 1    335
## 
## [[2]]
##   Sepal.Length_mean Sepal.Width_mean Sepal.Length_sd Sepal.Width_sd
## 1          5.843333         3.057333       0.8280661      0.4358663
##   Sepal.Length_max Sepal.Width_max
## 1              7.9             4.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s pretty useful, but not useful enough! I want to also use different functions to different datasets!&lt;/p&gt;
&lt;p&gt;Well, let’s define a list of functions then:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funcs_mtcars = quos(mean, sd, max)
funcs_iris = quos(median, min)

funcs_list = list(funcs_mtcars, funcs_iris)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because there is no &lt;code&gt;map3()&lt;/code&gt;, we need to use &lt;code&gt;pmap()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pmap(
  list(
    dataset = data_list,
    cols = cols_list,
    funcs = funcs_list
  ),
  my_summarise_f)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##   mpg_mean drat_mean  hp_mean   mpg_sd   drat_sd    hp_sd mpg_max drat_max
## 1 20.09062  3.596563 146.6875 6.026948 0.5346787 68.56287    33.9     4.93
##   hp_max
## 1    335
## 
## [[2]]
##   Sepal.Length_median Sepal.Width_median Sepal.Length_min Sepal.Width_min
## 1                 5.8                  3              4.3               2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I’m satisfied! Let me tell you, this blew their minds 😄!&lt;/p&gt;
&lt;p&gt;To be able to use things like that, I told them to always solve a problem for a single example, and
from there, try to generalize their solution using functional programming tools found in &lt;code&gt;purrr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you found this blog post useful, you might want to follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;
for blog post updates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s lists all the way down, part 2: We need to go deeper</title>
      <link>https://www.brodrigues.co/blog/2018-01-05-lists_all_the_way2/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-01-05-lists_all_the_way2/</guid>
      <description>&lt;p&gt;Shortly after my &lt;a href=&#34;http://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/&#34;&gt;previous blog post&lt;/a&gt;,
I saw this tweet on my timeline:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;The purrr resolution for 2018 -  learn at least one purrr function per week - is officially launched with encouragement and inspiration from &lt;a href=&#34;https://twitter.com/statwonk?ref_src=twsrc%5Etfw&#34;&gt;@statwonk&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/hadleywickham?ref_src=twsrc%5Etfw&#34;&gt;@hadleywickham&lt;/a&gt;.  We start with modify_depth: &lt;a href=&#34;https://t.co/dCMnSHP7Pl&#34;&gt;https://t.co/dCMnSHP7Pl&lt;/a&gt;. Please join to learn and share.  &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;&lt;/p&gt;&amp;mdash; Isabella R. Ghement (@IsabellaGhement) &lt;a href=&#34;https://twitter.com/IsabellaGhement/status/948685418731487232?ref_src=twsrc%5Etfw&#34;&gt;January 3, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;This is a great initiative, and a big coincidence, as I just had blogged about nested lists and how
to map over them. I also said this in my previous blog post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is also another function that you might want to study, modify_depth() which solves related
issues but I will end the blog post here. I might talk about it in a future blog post.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And so after I got this reply from &lt;a href=&#34;https://twitter.com/IsabellaGhement&#34;&gt;&lt;code&gt;@IsabellaGhement&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Bruno, I would love it if you would chime in with an explicit contrast between nested map calls (which I personally find a bit clunky) and alternatives.  In other words, present solutions side-by-side and highlight pros and cons.  That would be very useful! 🤗&lt;/p&gt;&amp;mdash; Isabella R. Ghement (@IsabellaGhement) &lt;a href=&#34;https://twitter.com/IsabellaGhement/status/949029796788367361?ref_src=twsrc%5Etfw&#34;&gt;January 4, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;What else was I supposed to do than blog about &lt;code&gt;purrr::modify_depth()&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;Bear in mind that I was not really familiar with this function before writing my last blog post;
and even then, I decided to keep it for another blog post, which is this one. Which came much faster
than what I had originally planned. So I might have missed some functionality; if that’s the case
don’t hesitate to tweet me an example or send me an email! (bruno at brodrigues dot co)&lt;/p&gt;
&lt;p&gt;So what is this blog post about? It’s about lists, nested lists, and some things that you can do with
them. Let’s use the same example as in my last post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)

nice_function = function(df, param1, param2){
  df = df %&amp;gt;%
    filter(cyl == param1, am == param2) %&amp;gt;%
    mutate(result = mpg * param1 * (2 - param2))

  return(df)
}

nice_function(mtcars, 4, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;values_cyl = c(4, 6, 8)

values_am = c(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we’re here, we would like to apply &lt;code&gt;nice_function()&lt;/code&gt; to each element of &lt;code&gt;values_cyl&lt;/code&gt; and
&lt;code&gt;values_am&lt;/code&gt;. In essence, loop over these values. But because loops are not really easy to manipulate,
(as explained, in part, &lt;a href=&#34;http://blog.rdata.lu/post/2017-12-21-skip-errors-in-r-by-not-writing-loops/&#34;&gt;here&lt;/a&gt;)
I use the &lt;code&gt;map*&lt;/code&gt; family of functions included in &lt;code&gt;purrr&lt;/code&gt; (When I teach R, I only show loops in the
&lt;em&gt;advanced topics&lt;/em&gt; chapter of my notes). So let’s “loop” over &lt;code&gt;values_cyl&lt;/code&gt; and &lt;code&gt;values_am&lt;/code&gt; with &lt;code&gt;map()&lt;/code&gt;
(and not &lt;code&gt;map_df()&lt;/code&gt;; there is a reason for this, bear with me):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result = map(values_am, ~map(values_cyl, nice_function, df = mtcars, param2 = .)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]][[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0
## 
## [[1]][[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 
## [[1]][[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 
## 
## [[2]]
## [[2]][[1]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 4 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 6 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 7 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 8 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 
## [[2]][[2]]
##    mpg cyl disp  hp drat    wt  qsec vs am gear carb result
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4  126.0
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4  126.0
## 3 19.7   6  145 175 3.62 2.770 15.50  0  1    5    6  118.2
## 
## [[2]][[3]]
##    mpg cyl disp  hp drat   wt qsec vs am gear carb result
## 1 15.8   8  351 264 4.22 3.17 14.5  0  1    5    4  126.4
## 2 15.0   8  301 335 3.54 3.57 14.6  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Until now, nothing new compared to my previous post (so if you have a hard time to follow what I’m
doing here, go read it &lt;a href=&#34;http://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;As far as I know, there is no way, in this example, to avoid this nested map call. However,
suppose now that you want to apply a function to each single data frame contained in the list &lt;code&gt;result&lt;/code&gt;.
Of course, here, you could simply use &lt;code&gt;bind_rows()&lt;/code&gt; to have a single data frame and then apply your
function to it. But suppose that you want to keep this list structure; at the end, I will give an
example of why you might want that, using another &lt;code&gt;purrr&lt;/code&gt; function, &lt;code&gt;walk()&lt;/code&gt; and Thomas’ J. Leeper
brilliant &lt;a href=&#34;https://github.com/leeper/rio&#34;&gt;&lt;code&gt;rio&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;So suppose you want to use this function here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_col = function(dataset, col){
  col = enquo(col)
  col_name = paste0(&amp;quot;double_&amp;quot;, quo_name(col))
  dataset %&amp;gt;%
    mutate(!!col_name := 2*(!!col))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to double the values of a column of a dataset. It uses &lt;code&gt;tidyeval&lt;/code&gt;’s &lt;code&gt;enquo()&lt;/code&gt;, &lt;code&gt;quo_name()&lt;/code&gt; and &lt;code&gt;!!()&lt;/code&gt;
functions to make it work with &lt;code&gt;tidyverse&lt;/code&gt; functions such as &lt;code&gt;mutate()&lt;/code&gt;. You can use it like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;double_col(mtcars, hp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb double_hp
## 1  21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4       220
## 2  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4       220
## 3  22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1       186
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1       220
## 5  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2       350
## 6  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1       210
## 7  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4       490
## 8  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2       124
## 9  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2       190
## 10 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4       246
## 11 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4       246
## 12 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3       360
## 13 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3       360
## 14 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3       360
## 15 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4       410
## 16 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4       430
## 17 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4       460
## 18 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1       132
## 19 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2       104
## 20 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1       130
## 21 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1       194
## 22 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2       300
## 23 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2       300
## 24 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4       490
## 25 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2       350
## 26 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1       132
## 27 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2       182
## 28 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2       226
## 29 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4       528
## 30 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6       350
## 31 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8       670
## 32 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2       218&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice, but you want to use this function on all of the data frames contained in your &lt;code&gt;result&lt;/code&gt; list.
You can use a nested &lt;code&gt;map()&lt;/code&gt; as before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(result, ~map(., .f = double_col, col = disp))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]][[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result double_disp
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2       293.4
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4       281.6
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0       240.2
## 
## [[1]][[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8       516.0
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2       450.0
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4       335.2
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6       335.2
## 
## [[1]][[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2       720.0
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8       720.0
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4       551.6
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8       551.6
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2       551.6
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4       944.0
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4       920.0
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2       880.0
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0       636.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2       608.0
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8       700.0
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2       800.0
## 
## 
## [[2]]
## [[2]][[1]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2       216.0
## 2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6       157.4
## 3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6       151.4
## 4 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6       142.2
## 5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2       158.0
## 6 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0       240.6
## 7 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6       190.2
## 8 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6       242.0
## 
## [[2]][[2]]
##    mpg cyl disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4  126.0         320
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4  126.0         320
## 3 19.7   6  145 175 3.62 2.770 15.50  0  1    5    6  118.2         290
## 
## [[2]][[3]]
##    mpg cyl disp  hp drat   wt qsec vs am gear carb result double_disp
## 1 15.8   8  351 264 4.22 3.17 14.5  0  1    5    4  126.4         702
## 2 15.0   8  301 335 3.54 3.57 14.6  0  1    5    8  120.0         602&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but there’s an easier solution, which is using &lt;code&gt;modify_depth()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result = modify_depth(result, .depth = 2, double_col, col = disp))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]][[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result double_disp
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2       293.4
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4       281.6
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0       240.2
## 
## [[1]][[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8       516.0
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2       450.0
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4       335.2
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6       335.2
## 
## [[1]][[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2       720.0
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8       720.0
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4       551.6
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8       551.6
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2       551.6
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4       944.0
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4       920.0
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2       880.0
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0       636.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2       608.0
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8       700.0
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2       800.0
## 
## 
## [[2]]
## [[2]][[1]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2       216.0
## 2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6       157.4
## 3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6       151.4
## 4 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6       142.2
## 5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2       158.0
## 6 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0       240.6
## 7 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6       190.2
## 8 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6       242.0
## 
## [[2]][[2]]
##    mpg cyl disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4  126.0         320
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4  126.0         320
## 3 19.7   6  145 175 3.62 2.770 15.50  0  1    5    6  118.2         290
## 
## [[2]][[3]]
##    mpg cyl disp  hp drat   wt qsec vs am gear carb result double_disp
## 1 15.8   8  351 264 4.22 3.17 14.5  0  1    5    4  126.4         702
## 2 15.0   8  301 335 3.54 3.57 14.6  0  1    5    8  120.0         602&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how does it work? &lt;code&gt;modify_depth()&lt;/code&gt; needs a list and a &lt;code&gt;.depth&lt;/code&gt; argument, which corresponds to
where you you want to apply your function. The following lines of code might help you understand:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Depth of 1:

result[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result double_disp
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2       293.4
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4       281.6
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0       240.2
## 
## [[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8       516.0
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2       450.0
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4       335.2
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6       335.2
## 
## [[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result double_disp
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2       720.0
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8       720.0
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4       551.6
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8       551.6
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2       551.6
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4       944.0
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4       920.0
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2       880.0
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0       636.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2       608.0
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8       700.0
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2       800.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, a depth of 1 corresponds to a list of three data frame. Can you use your function
&lt;code&gt;double_col()&lt;/code&gt; on a list of three data frames? No, because the domain of &lt;code&gt;double_col()&lt;/code&gt; is the set
of data frames, not the set of lists of data frames. So you need to go deeper:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Depth of 2:

result[[1]][[1]] # or try result[[1]][[2]] or result[[1]][[3]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result double_disp
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2       293.4
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4       281.6
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0       240.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the depth of 2, you’re dealing with data frames! So you can use your function &lt;code&gt;double_col()&lt;/code&gt;.
With a depth of 2, one might not see the added value of &lt;code&gt;modify_depth()&lt;/code&gt; over nested map calls, but
if you have to go even deeper, nested map calls are very confusing and verbose.&lt;/p&gt;
&lt;p&gt;Now for the last part; why doing all this, and not simply bind all the rows, apply &lt;code&gt;double_col()&lt;/code&gt;
and call it a day? Well, suppose that there is a reason you have these data frames inside lists; for
example, the first element, i.e., &lt;code&gt;result[[1]]&lt;/code&gt; might be data for, say, Portugal, for 3 different years.
&lt;code&gt;result[[2]]&lt;/code&gt; however, is data for France, for the same years. Suppose also that you have to give
this data, after having worked on it, to a colleague (or to another institution) in the Excel format;
one Excel workbook per country, one sheet per year. This example might seem contrived, but I have
been confronted to this exact situation very often. Well, if you bind all the rows together, how are
you going to save the data in the workbooks like you are required to?&lt;/p&gt;
&lt;p&gt;Well, thanks to &lt;code&gt;rio&lt;/code&gt;, one line of code is enough:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rio)

walk2(result, list(&amp;quot;portugal.xlsx&amp;quot;, &amp;quot;france.xlsx&amp;quot;), export)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I know what you’re thinking; &lt;em&gt;Bruno, that’s two lines of code!&lt;/em&gt;. Yes, but I had to load &lt;code&gt;rio&lt;/code&gt;. Also,
&lt;code&gt;walk()&lt;/code&gt; (and &lt;code&gt;walk2()&lt;/code&gt;) are basically the same as &lt;code&gt;map()&lt;/code&gt;, but you use &lt;code&gt;walk()&lt;/code&gt; over &lt;code&gt;map()&lt;/code&gt; when
you are only interested in the side effect of the function you are applying over your list; here, &lt;code&gt;export()&lt;/code&gt;
which is &lt;code&gt;rio&lt;/code&gt;’s function to write data to disk. The side effect of this function is… writing data to disk!
You could have used &lt;code&gt;map2()&lt;/code&gt; just the same, but I wanted to show you &lt;code&gt;walk2()&lt;/code&gt; (however, you cannot
replace &lt;code&gt;map()&lt;/code&gt; by &lt;code&gt;walk()&lt;/code&gt; in most cases; try it and see what happens).&lt;/p&gt;
&lt;p&gt;Here’s what it looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/deeper_xlsx.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I have two Excel workbooks, (one per list), where each sheet is a data frame!&lt;/p&gt;
&lt;p&gt;If you enjoy these blog posts, you can follow me on &lt;a href=&#34;https://twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s lists all the way down</title>
      <link>https://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/</guid>
      <description>&lt;p&gt;&lt;em&gt;There’s a part 2 to this post: read it &lt;a href=&#34;http://www.brodrigues.co/blog/2018-01-05-lists_all_the_way2/&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Today, I had the opportunity to help someone over at the R for Data Science Slack group (read more
about this group &lt;a href=&#34;https://medium.com/@kierisi/r4ds-the-next-iteration-d51e0a1b0b82&#34;&gt;here&lt;/a&gt;) and I
thought that the question asked could make for an interesting blog post, so here it is!&lt;/p&gt;
&lt;p&gt;Disclaimer: the way I’m doing things here is totally not optimal, but I want to illustrate how to map
functions over nested lists. But I show the optimal way at the end, so for the people that are
familiar with &lt;code&gt;purrr&lt;/code&gt; don’t get mad at me.&lt;/p&gt;
&lt;p&gt;Suppose you have to do certain data transformation tasks on a data frame, and you write a nice function
that does that for you:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)

nice_function = function(df, param1, param2){
  df = df %&amp;gt;%
    filter(cyl == param1, am == param2) %&amp;gt;%
    mutate(result = mpg * param1 * (2 - param2))

  return(df)
}

nice_function(mtcars, 4, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This might seem like a silly function and not a nice function, but it will illustrate the point I want
to make (and the question that was asked) very well. This function is completely useless, but bear
with me. Now, suppose that you want to do these operations for each value of &lt;code&gt;cyl&lt;/code&gt; and &lt;code&gt;am&lt;/code&gt; (of course
you can do that without using &lt;code&gt;nice_function()&lt;/code&gt;…). First, you might want to fix the value of &lt;code&gt;am&lt;/code&gt;
to 0, and then loop over the values of &lt;code&gt;cyl&lt;/code&gt;. But as I have explained in this
&lt;a href=&#34;http://blog.rdata.lu/post/2017-12-21-skip-errors-in-r-by-not-writing-loops/&#34;&gt;other blog post&lt;/a&gt; I
prefer using the &lt;code&gt;map()&lt;/code&gt; functions included in &lt;code&gt;purrr&lt;/code&gt;. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;values_cyl = c(4, 6, 8)

(result = map(values_cyl, nice_function, df = mtcars, param2 = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0
## 
## [[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 
## [[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What you get here is a list for each value in &lt;code&gt;values_cyl&lt;/code&gt;; so one list for &lt;code&gt;4&lt;/code&gt;, one for &lt;code&gt;6&lt;/code&gt; and
one for &lt;code&gt;8&lt;/code&gt;. Suppose now that you are feeling adventurous, and want to loop over the values of &lt;code&gt;am&lt;/code&gt; too:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;values_am = c(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So first, we need to map a function to each element of &lt;code&gt;values_am&lt;/code&gt;. But which function? Well, for
&lt;em&gt;given&lt;/em&gt; value of &lt;code&gt;am&lt;/code&gt;, our problem is the same as before; we need to map &lt;code&gt;nice_function()&lt;/code&gt; to each
value of &lt;code&gt;cyl&lt;/code&gt;. So, that’s what we’re going to do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result = map(values_am, ~map(values_cyl, nice_function, df = mtcars, param2 = .)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]][[1]]
##    mpg cyl  disp hp drat    wt  qsec vs am gear carb result
## 1 24.4   4 146.7 62 3.69 3.190 20.00  1  0    4    2  195.2
## 2 22.8   4 140.8 95 3.92 3.150 22.90  1  0    4    2  182.4
## 3 21.5   4 120.1 97 3.70 2.465 20.01  1  0    3    1  172.0
## 
## [[1]][[2]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 2 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 3 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 4 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 
## [[1]][[3]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 2  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 3  16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 4  17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 5  15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 6  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 7  10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 8  14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 9  15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 10 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 11 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 12 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 
## 
## [[2]]
## [[2]][[1]]
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 4 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 6 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 7 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 8 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 
## [[2]][[2]]
##    mpg cyl disp  hp drat    wt  qsec vs am gear carb result
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4  126.0
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4  126.0
## 3 19.7   6  145 175 3.62 2.770 15.50  0  1    5    6  118.2
## 
## [[2]][[3]]
##    mpg cyl disp  hp drat   wt qsec vs am gear carb result
## 1 15.8   8  351 264 4.22 3.17 14.5  0  1    5    4  126.4
## 2 15.0   8  301 335 3.54 3.57 14.6  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have a list of size 2 (for each value of &lt;code&gt;am&lt;/code&gt;) where each element is itself a list of size
3 (for each value of &lt;code&gt;cyl&lt;/code&gt;) where each element is a data frame. Are you still with me? Also, notice
that the second map is given as a formula (notice the &lt;code&gt;~&lt;/code&gt; in front of the second map). This creates
an anonymous function, where the parameter is given by the &lt;code&gt;.&lt;/code&gt; (think of the &lt;code&gt;.&lt;/code&gt; as being the &lt;code&gt;x&lt;/code&gt;
in &lt;code&gt;f(x)&lt;/code&gt;). So the &lt;code&gt;.&lt;/code&gt; is the stand-in for the values contained inside &lt;code&gt;values_am&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The people that are familiar with the &lt;code&gt;map()&lt;/code&gt; functions must be fuming right now; there is a way
to avoid this nested hell. I will talk about it soon, but first I want to play around with this list of lists.&lt;/p&gt;
&lt;p&gt;If you have a list of data frames, you can bind their rows together with &lt;code&gt;reduce(list_of_dfs, rbind)&lt;/code&gt;.
You would like to this here, but because your lists of data frames are contained inside another list…
you guessed it, you have to map over it!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result2 = map(result, ~reduce(., rbind)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  195.2
## 2  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  182.4
## 3  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  172.0
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 5  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 6  19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 7  17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 8  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 9  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 10 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 11 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 12 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 13 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 14 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 15 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 16 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 17 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 18 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 19 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 
## [[2]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 2  32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 3  30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 4  33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 5  27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 6  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 7  30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 8  21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 9  21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  126.0
## 10 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  126.0
## 11 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  118.2
## 12 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  126.4
## 13 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here again, I pass &lt;code&gt;reduce()&lt;/code&gt; as a formula to &lt;code&gt;map()&lt;/code&gt; to create an anonymous function. Again, the &lt;code&gt;.&lt;/code&gt;
is used as the stand-in for each element contained in &lt;code&gt;result&lt;/code&gt;; a list of data frames, where &lt;code&gt;reduce(., rbind)&lt;/code&gt;
knows what to do. Now that we have this we can use &lt;code&gt;reduce()&lt;/code&gt; with &lt;code&gt;rbind()&lt;/code&gt; again to get a single
data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result3 = reduce(result2, rbind))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  195.2
## 2  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  182.4
## 3  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  172.0
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 5  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 6  19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 7  17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 8  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 9  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 10 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 11 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 12 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 13 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 14 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 15 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 16 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 17 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 18 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 19 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 20 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 21 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 22 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 23 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 24 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 25 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 26 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 27 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 28 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  126.0
## 29 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  126.0
## 30 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  118.2
## 31 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  126.4
## 32 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, since &lt;code&gt;reduce(list_of_dfs, rbind)&lt;/code&gt; is such a common operation, you could have simply used
&lt;code&gt;dplyr::bind_rows&lt;/code&gt;, which does exactly this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result2 = map(result, bind_rows))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  195.2
## 2  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  182.4
## 3  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  172.0
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 5  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 6  19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 7  17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 8  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 9  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 10 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 11 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 12 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 13 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 14 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 15 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 16 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 17 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 18 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 19 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 
## [[2]]
##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 2  32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 3  30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 4  33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 5  27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 6  26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 7  30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 8  21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 9  21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  126.0
## 10 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  126.0
## 11 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  118.2
## 12 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  126.4
## 13 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result3 = bind_rows(result2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  195.2
## 2  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  182.4
## 3  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  172.0
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 5  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 6  19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 7  17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 8  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 9  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 10 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 11 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 12 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 13 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 14 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 15 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 16 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 17 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 18 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 19 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 20 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 21 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 22 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 23 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 24 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 25 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 26 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 27 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 28 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  126.0
## 29 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  126.0
## 30 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  118.2
## 31 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  126.4
## 32 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, things are even simpler: you can avoid this deeply nested monstrosity by using &lt;code&gt;map_df()&lt;/code&gt;
instead of &lt;code&gt;map()&lt;/code&gt;! &lt;code&gt;map_df()&lt;/code&gt; works just like &lt;code&gt;map()&lt;/code&gt; but return a data frame (hence the &lt;code&gt;_df&lt;/code&gt;
in the name) instead of a list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(result_df = map_df(values_am, ~map_df(values_cyl, nice_function, df = mtcars, param2 = .)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     mpg cyl  disp  hp drat    wt  qsec vs am gear carb result
## 1  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2  195.2
## 2  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  182.4
## 3  21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  172.0
## 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  256.8
## 5  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  217.2
## 6  19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  230.4
## 7  17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  213.6
## 8  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  299.2
## 9  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  228.8
## 10 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  262.4
## 11 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  276.8
## 12 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  243.2
## 13 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  166.4
## 14 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  166.4
## 15 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  235.2
## 16 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  248.0
## 17 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  243.2
## 18 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  212.8
## 19 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  307.2
## 20 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1   91.2
## 21 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1  129.6
## 22 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  121.6
## 23 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  135.6
## 24 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1  109.2
## 25 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2  104.0
## 26 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2  121.6
## 27 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2   85.6
## 28 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  126.0
## 29 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  126.0
## 30 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  118.2
## 31 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  126.4
## 32 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  120.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you look at the source code of &lt;code&gt;map_df()&lt;/code&gt; you see that &lt;code&gt;dplyr::bind_rows&lt;/code&gt; gets called at the end:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map_df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (.x, .f, ..., .id = NULL) 
## {
##     if (!is_installed(&amp;quot;dplyr&amp;quot;)) {
##         abort(&amp;quot;`map_df()` requires dplyr&amp;quot;)
##     }
##     .f &amp;lt;- as_mapper(.f, ...)
##     res &amp;lt;- map(.x, .f, ...)
##     dplyr::bind_rows(res, .id = .id)
## }
## &amp;lt;bytecode: 0x55dad486e6a0&amp;gt;
## &amp;lt;environment: namespace:purrr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So moral of the story? There are a lot of variants of the common &lt;code&gt;purrr::map()&lt;/code&gt; functions (as well
as of &lt;code&gt;dplyr&lt;/code&gt; verbs, such as &lt;code&gt;filter_at&lt;/code&gt;, &lt;code&gt;select_if&lt;/code&gt;, etc…) and learning about them can save you
from a lot of pain! However, if you need to apply a function to nested lists this is still possible;
you just have to think about the structure of the nested list for a bit. There is also another function
that you might want to study, &lt;code&gt;modify_depth()&lt;/code&gt; which solves related issues but I will end the
blog post here. I might talk about it in a future blog post.&lt;/p&gt;
&lt;p&gt;Also, if you want to learn more about R and the tidyverse, do read the link I posted in the introduction
of the post and join the R4ds slack group! There are a lot of very nice people there that want to help you
get better with your R-fu. Also, this is where I got the inspiration to write this blog post and I
am thankful to the people there for the discussions; I feel comfortable with R, but I still learn
new tips and tricks every day!&lt;/p&gt;
&lt;p&gt;If you enjoy these blog posts, you can follow me on &lt;a href=&#34;https://twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;.
And happy new yeaR!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building formulae</title>
      <link>https://www.brodrigues.co/blog/2017-12-27-build_formulae/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-12-27-build_formulae/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/47957081/k-fold-cross-validation-in-purr-and-model&#34;&gt;This&lt;/a&gt;
Stackoverflow question made me think about how to build formulae. For example, you might want to
programmatically build linear model formulae and then map these models on data. For example,
suppose the following (output suppressed):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)

lm(mpg ~ hp, data = mtcars)
lm(mpg ~I(hp^2), data = mtcars)
lm(mpg ~I(hp^3), data = mtcars)
lm(mpg ~I(hp^4), data = mtcars)
lm(mpg ~I(hp^5), data = mtcars)
lm(mpg ~I(hp^6), data = mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To avoid doing this, one can write a function that builds the formulae:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;create_form = function(power){
  rhs = substitute(I(hp^pow), list(pow=power))
  rlang::new_formula(quote(mpg), rhs)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you are not familiar with &lt;code&gt;substitute()&lt;/code&gt;, try the following to understand what it does:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;substitute(y ~ x, list(x = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## y ~ 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then using &lt;code&gt;rlang::new_formula()&lt;/code&gt; I build a formula by providing the left hand side, which is
&lt;code&gt;quote(mpg)&lt;/code&gt; here, and the right hand side, which I built using &lt;code&gt;substitute()&lt;/code&gt;. Now I can create a
list of formulae:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

list_formulae = map(seq(1, 6), create_form)

str(list_formulae)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 6
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^1L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605f897ca0&amp;gt; 
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^2L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605f891418&amp;gt; 
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^3L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605da76098&amp;gt; 
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^4L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605da6a600&amp;gt; 
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^5L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605da68980&amp;gt; 
##  $ :Class &amp;#39;formula&amp;#39;  language mpg ~ I(hp^6L)
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: 0x55605da66d38&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, &lt;code&gt;power&lt;/code&gt; got replaced by 1, 2, 3,… and each element of the list is a nice formula.
Exactly what &lt;code&gt;lm()&lt;/code&gt; needs. So now it’s easy to map &lt;code&gt;lm()&lt;/code&gt; to this list of formulae:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)

map(list_formulae, lm, data = mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^1)  
##    30.09886     -0.06823  
## 
## 
## [[2]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^2)  
##  24.3887252   -0.0001649  
## 
## 
## [[3]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^3)  
##   2.242e+01   -4.312e-07  
## 
## 
## [[4]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^4)  
##   2.147e+01   -1.106e-09  
## 
## 
## [[5]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^5)  
##   2.098e+01   -2.801e-12  
## 
## 
## [[6]]
## 
## Call:
## .f(formula = .x[[i]], data = ..1)
## 
## Coefficients:
## (Intercept)      I(hp^6)  
##   2.070e+01   -7.139e-15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is still a new topic for me there might be more elegant ways to do that, using tidyeval to remove
the hardcoding of the columns in &lt;code&gt;create_form()&lt;/code&gt;. I might continue exploring this.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching the tidyverse to beginners</title>
      <link>https://www.brodrigues.co/blog/2017-12-17-teaching_tidyverse/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-12-17-teaching_tidyverse/</guid>
      <description>&lt;p&gt;End October I tweeted this:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;will teach &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; soon again but this time following &lt;a href=&#34;https://twitter.com/drob?ref_src=twsrc%5Etfw&#34;&gt;@drob&lt;/a&gt; &amp;#39;s suggestion of the tidyverse first as laid out here: &lt;a href=&#34;https://t.co/js8SsUs8Nv&#34;&gt;https://t.co/js8SsUs8Nv&lt;/a&gt;&lt;/p&gt;&amp;mdash; Bruno Rodrigues (@brodriguesco@fosstodon.org) (@brodriguesco) &lt;a href=&#34;https://twitter.com/brodriguesco/status/922741554992812032?ref_src=twsrc%5Etfw&#34;&gt;October 24, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;and it generated some discussion. Some people believe that this is the right approach, and some
others think that one should first present &lt;em&gt;base&lt;/em&gt; R and then show how the &lt;code&gt;tidyverse&lt;/code&gt; complements
it. This year, I taught three classes; a 12-hour class to colleagues that work with me, a 15-hour
class to master’s students and 3 hours again to some of my colleagues. Each time, I decided to
focus on the &lt;code&gt;tidyverse&lt;/code&gt;(almost) entirely, and must say that I am not disappointed with the results!&lt;/p&gt;
&lt;p&gt;The 12 hour class was divided in two 6 hours days. It was a bit intense, especially the last 3 hours
that took place Friday afternoon. The crowd was composed of some economists that had experience
with STATA, some others that were mostly using Excel and finally some colleagues from the IT
department that sometimes need to dig into some data themselves. Apart from 2 people, all the other
never had any experience with R.&lt;/p&gt;
&lt;p&gt;We went from 0 to being able to do the plot below after the end of the first day
(so 6 hours in). Keep in mind that practically none of them even had opened RStudio before. I
show the code so you can see the progress made in just a few hours:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(Ecdat)
library(tidyverse)
library(ggthemes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(Bwages)
bwages = Bwages %&amp;gt;%
  mutate(educ_level = case_when(educ == 1 ~ &amp;quot;Primary School&amp;quot;,
                                educ == 2 ~ &amp;quot;High School&amp;quot;,
                                educ == 3 ~ &amp;quot;Some university&amp;quot;,
                                educ == 4 ~ &amp;quot;Master&amp;#39;s degree&amp;quot;,
                                educ == 5 ~ &amp;quot;Doctoral degree&amp;quot;))

ggplot(bwages) +
  geom_smooth(aes(exper, wage, colour = educ_level)) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;, legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using method = &amp;#39;loess&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2017-12-17-teaching_tidyverse_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Of course some of them needed some help here and there, and I also gave them hints (for example I told
them about &lt;code&gt;case_when()&lt;/code&gt; and try to use it inside &lt;code&gt;mutate()&lt;/code&gt; instead of nested ifs)
but it was mostly due to lack of experience and because they hadn’t had the time to fully digest
R’s syntax which was for most people involved completely new.&lt;/p&gt;
&lt;p&gt;On the second day I showed &lt;code&gt;purrr::map()&lt;/code&gt; and &lt;code&gt;purrr::reduce()&lt;/code&gt; and overall it went quite well too.
I even showed list-columns, and this is where I started losing some of them; I did not insist too
much on it though, only wanted to show them the flexibility of &lt;code&gt;data.frame&lt;/code&gt; objects. Some of them
were quite impressed by list-columns! Then I started showing (for and while) loops and writing
functions. I even showed them &lt;code&gt;tidyeval&lt;/code&gt; and again, it went relatively well. Once they had the
opportunity to play a bit around with it, I think it clicked (plus they have lots of code examples
to go back too).&lt;/p&gt;
&lt;p&gt;At the end, people seemed to have enjoyed the course, but told me that Friday was heavy; indeed it
was, but I feel that it was mostly because 12 hours spread on 2 days is not the best format for this
type of material, but we all had time constraints.&lt;/p&gt;
&lt;p&gt;The 15 hour Master’s course was spread over 4 days, and covered basically the same. I just
used the last 3 hours to show the students some basic functions for model estimation
(linear, count, logit/probit and survival models). Again, the students were quite impressed by how
easily they could get descriptive statistics by first grouping by some variables. Through their
questions, I even got to show them scoped versions of &lt;code&gt;dplyr&lt;/code&gt; verbs, such as &lt;code&gt;select_if()&lt;/code&gt; and
&lt;code&gt;summarise_at()&lt;/code&gt;. I was expecting to lose them there, but actually most of them got these scoped
versions quite fast. These students already had some experience with R though, but none with
the &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally the 3 hour course was perhaps the most interesting; I only had 100% total beginners. Some
just knew R by name and had never heard/seen/opened RStudio (with the exception of one person)!
I did not show them any loops, function definitions and no plots. I only showed them how RStudio
looked and worked, what were (and how to install) packages (as well as the CRAN Task Views) and
then how to import data with &lt;code&gt;rio&lt;/code&gt; and do descriptive statistics only with &lt;code&gt;dplyr&lt;/code&gt;. They were
really interested and quite impressed by &lt;code&gt;rio&lt;/code&gt; (“what do you mean I can use the same code for
importing any dataset, in any format?”) but also by the simplicity of &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In all the courses, I did show the &lt;code&gt;$&lt;/code&gt; primitive to refer to columns inside a &lt;code&gt;data.frame&lt;/code&gt;. First I
showed them lists which is where I introduced &lt;code&gt;$&lt;/code&gt;. Then it was easy to explain to them why it was
the same for a column inside a &lt;code&gt;data.frame&lt;/code&gt;; a &lt;code&gt;data.frame&lt;/code&gt; is simply a list! This is also the
distinction I made from the previous years; I simply mentioned (and showed really quickly) matrices
and focused almost entirely on lists. Most participants, if not all, had learned to program
statistics by thinking about linear algebra and matrices. Nothing wrong with that, but I feel that R
really shines when you focus on lists and on how to work with them.&lt;/p&gt;
&lt;p&gt;Overall as the teacher, I think that focusing on the &lt;code&gt;tidyverse&lt;/code&gt; might be a very good strategy. I
might have to do some adjustments here and there for the future courses, but my hunch is that the
difficulties that some participants had were not necessarily due to the &lt;code&gt;tidyverse&lt;/code&gt; but simply to
lack of time to digest what was shown, as well as a total lack of experience with R.
I do not think that these participants would have better understood a more traditional, &lt;code&gt;base&lt;/code&gt;,
matrix-oriented course.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional peace of mind</title>
      <link>https://www.brodrigues.co/blog/2017-11-14-peace_r/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-11-14-peace_r/</guid>
      <description>&lt;p&gt;I think what I enjoy the most about functional programming is the peace of mind that comes with it.
With functional programming, there’s a lot of stuff you don’t need to think about. You can write
functions that are general enough so that they solve a variety of problems. For example, imagine
for a second that R does not have the &lt;code&gt;sum()&lt;/code&gt; function anymore. If you want to compute the sum of,
say, the first 100 integers, you could write a loop that would do that for you:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;numbers = 0

for (i in 1:100){
  numbers = numbers + i
}

print(numbers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5050&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem with this approach, is that you cannot reuse any of the code there, even if you put it
inside a function. For instance, what if you want to merge 4 datasets together? You would need
something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
data(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars1 = mtcars %&amp;gt;%
  mutate(id = &amp;quot;1&amp;quot;)

mtcars2 = mtcars %&amp;gt;%
  mutate(id = &amp;quot;2&amp;quot;)

mtcars3 = mtcars %&amp;gt;%
  mutate(id = &amp;quot;3&amp;quot;)

mtcars4 = mtcars %&amp;gt;%
  mutate(id = &amp;quot;4&amp;quot;)

datasets = list(mtcars1, mtcars2, mtcars3, mtcars4)

temp = datasets[[1]]

for(i in 1:3){
  temp = full_join(temp, datasets[[i+1]])
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)
## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)
## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(temp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 128
## Variables: 12
## $ mpg  &amp;lt;dbl&amp;gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19....
## $ cyl  &amp;lt;dbl&amp;gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, ...
## $ disp &amp;lt;dbl&amp;gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 1...
## $ hp   &amp;lt;dbl&amp;gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, ...
## $ drat &amp;lt;dbl&amp;gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.9...
## $ wt   &amp;lt;dbl&amp;gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3...
## $ qsec &amp;lt;dbl&amp;gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 2...
## $ vs   &amp;lt;dbl&amp;gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, ...
## $ am   &amp;lt;dbl&amp;gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...
## $ gear &amp;lt;dbl&amp;gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, ...
## $ carb &amp;lt;dbl&amp;gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, ...
## $ id   &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, the logic is very similar as before, but you need to think carefully about the structure
holding your elements (which can be numbers, datasets, characters, etc…) as well as be careful
about indexing correctly… and depending on the type of objects you are working on, you might need
to tweak the code further.&lt;/p&gt;
&lt;p&gt;How would a functional programming approach make this easier? Of course, you could use
&lt;code&gt;purrr::reduce()&lt;/code&gt; to solve these problems. However, since I assumed that &lt;code&gt;sum()&lt;/code&gt; does not exist,
I will also assume that &lt;code&gt;purrr::reduce()&lt;/code&gt; does not exist either and write my own, clumsy
implementation. Here’s the code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_reduce = function(a_list, a_func, init = NULL, ...){

  if(is.null(init)){
    init = `[[`(a_list, 1)
    a_list = tail(a_list, -1)
  }

  car = `[[`(a_list, 1)
  cdr = tail(a_list, -1)
  init = a_func(init, car, ...)

  if(length(cdr) != 0){
    my_reduce(cdr, a_func, init, ...)
  }
  else {
    init
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can look much more complicated than before, but the idea is quite simple; &lt;em&gt;if you know about
recursive functions&lt;/em&gt; (recursive functions are functions that call themselves). I won’t explain how
the function works, because it is not the main point of the article (but if
you’re curious, I encourage you to play around with it). The point is that now, I can do the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_reduce(list(1,2,3,4,5), `+`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_reduce(datasets, full_join) %&amp;gt;% glimpse&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)
## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)
## Joining, by = c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;disp&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;drat&amp;quot;, &amp;quot;wt&amp;quot;, &amp;quot;qsec&amp;quot;, &amp;quot;vs&amp;quot;, &amp;quot;am&amp;quot;, &amp;quot;gear&amp;quot;, &amp;quot;carb&amp;quot;, &amp;quot;id&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 128
## Variables: 12
## $ mpg  &amp;lt;dbl&amp;gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19....
## $ cyl  &amp;lt;dbl&amp;gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, ...
## $ disp &amp;lt;dbl&amp;gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 1...
## $ hp   &amp;lt;dbl&amp;gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, ...
## $ drat &amp;lt;dbl&amp;gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.9...
## $ wt   &amp;lt;dbl&amp;gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3...
## $ qsec &amp;lt;dbl&amp;gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 2...
## $ vs   &amp;lt;dbl&amp;gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, ...
## $ am   &amp;lt;dbl&amp;gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...
## $ gear &amp;lt;dbl&amp;gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, ...
## $ carb &amp;lt;dbl&amp;gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, ...
## $ id   &amp;lt;chr&amp;gt; &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1&amp;quot;, &amp;quot;1...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And if I need to merge another dataset, I don’t need to change anything at all. Plus, because &lt;code&gt;my_reduce()&lt;/code&gt;
is very general, I can even use it for situation I didn’t write it for in the first place:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_reduce(list(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;e&amp;quot;), paste)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a b c d e&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, &lt;code&gt;paste()&lt;/code&gt; is vectorized, so you could just as well do &lt;code&gt;paste(1, 2, 3, 4, 5)&lt;/code&gt;, but again, I want
to insist on the fact that writing or using such functions allows you to abstract over a lot of thing.
There is nothing specific to any type of object in &lt;code&gt;my_reduce()&lt;/code&gt;, whereas the loops have to be tailored
for the kind of object you’re working with. As long as the &lt;code&gt;a_func&lt;/code&gt; argument is a binary operator
that combines the elements inside &lt;code&gt;a_list&lt;/code&gt;, it’s going to work. And I don’t need to think about
indexing, about having temporary variables or thinking about the structure that will hold my
results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Easy peasy STATA-like marginal effects with R</title>
      <link>https://www.brodrigues.co/blog/2017-10-26-margins_r/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-10-26-margins_r/</guid>
      <description>&lt;p&gt;Model interpretation is essential in the social sciences. If one wants to know the effect of
variable &lt;code&gt;x&lt;/code&gt; on the dependent variable &lt;code&gt;y&lt;/code&gt;, marginal effects are an easy way to get the answer.
STATA includes a &lt;code&gt;margins&lt;/code&gt; command that has been ported to R
by &lt;a href=&#34;http://thomasleeper.com/&#34;&gt;Thomas J. Leeper&lt;/a&gt;
of the London School of Economics and Political Science.
You can find the source code of the package
&lt;a href=&#34;https://github.com/leeper/margins&#34;&gt;on github&lt;/a&gt;. In this short blog post, I demo some of the
functionality of &lt;code&gt;margins&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, let’s load some packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(tibble)
library(broom)
library(margins)
library(Ecdat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an example, we are going to use the &lt;code&gt;Participation&lt;/code&gt; data from the &lt;code&gt;Ecdat&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(Participation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?Participation&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Labor Force Participation

Description

a cross-section

number of observations : 872

observation : individuals

country : Switzerland

Usage

data(Participation)
Format

A dataframe containing :

lfp
labour force participation ?

lnnlinc
the log of nonlabour income

age
age in years divided by 10

educ
years of formal education

nyc
the number of young children (younger than 7)

noc
number of older children

foreign
foreigner ?

Source

Gerfin, Michael (1996) “Parametric and semiparametric estimation of the binary response”, Journal of Applied Econometrics, 11(3), 321-340.

References

Davidson, R. and James G. MacKinnon (2004) Econometric Theory and Methods, New York, Oxford University Press, http://www.econ.queensu.ca/ETM/, chapter 11.

Journal of Applied Econometrics data archive : http://qed.econ.queensu.ca/jae/.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable of interest is &lt;code&gt;lfp&lt;/code&gt;: whether the individual participates in the labour force or not.
To know which variables are relevant in the decision to participate in the labour force,
one could estimate a logit model, using &lt;code&gt;glm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logit_participation = glm(lfp ~ ., data = Participation, family = &amp;quot;binomial&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we ran the regression, we can take a look at the results. I like to use &lt;code&gt;broom::tidy()&lt;/code&gt;
to look at the results of regressions, as &lt;code&gt;tidy()&lt;/code&gt; returns a nice
&lt;code&gt;data.frame&lt;/code&gt;, but you could use &lt;code&gt;summary()&lt;/code&gt; if you’re only interested in reading the output:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(logit_participation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          term    estimate  std.error  statistic      p.value
## 1 (Intercept) 10.37434616 2.16685216  4.7877499 1.686617e-06
## 2     lnnlinc -0.81504064 0.20550116 -3.9661122 7.305449e-05
## 3         age -0.51032975 0.09051783 -5.6378920 1.721444e-08
## 4        educ  0.03172803 0.02903580  1.0927211 2.745163e-01
## 5         nyc -1.33072362 0.18017027 -7.3859224 1.514000e-13
## 6         noc -0.02198573 0.07376636 -0.2980454 7.656685e-01
## 7  foreignyes  1.31040497 0.19975784  6.5599678 5.381941e-11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the results above, one can only interpret the sign of the coefficients. To know how much a
variable influences the labour force participation, one has to use &lt;code&gt;margins()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;effects_logit_participation = margins(logit_participation) 

print(effects_logit_participation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Average marginal effects&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## glm(formula = lfp ~ ., family = &amp;quot;binomial&amp;quot;, data = Participation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  lnnlinc     age     educ     nyc       noc foreignyes
##  -0.1699 -0.1064 0.006616 -0.2775 -0.004584     0.2834&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using &lt;code&gt;summary()&lt;/code&gt; on the object returned by &lt;code&gt;margins()&lt;/code&gt; provides more details:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(effects_logit_participation)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      factor     AME     SE       z      p   lower   upper
##         age -0.1064 0.0176 -6.0494 0.0000 -0.1409 -0.0719
##        educ  0.0066 0.0060  1.0955 0.2733 -0.0052  0.0185
##  foreignyes  0.2834 0.0399  7.1102 0.0000  0.2053  0.3615
##     lnnlinc -0.1699 0.0415 -4.0994 0.0000 -0.2512 -0.0887
##         noc -0.0046 0.0154 -0.2981 0.7656 -0.0347  0.0256
##         nyc -0.2775 0.0333 -8.3433 0.0000 -0.3426 -0.2123&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And it is also possible to plot the effects with base graphics:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(effects_logit_participation)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2017-10-26-margins_r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This uses the basic R plotting capabilities, which is useful because it is a simple call to the
function &lt;code&gt;plot()&lt;/code&gt; but if you’ve been using &lt;code&gt;ggplot2&lt;/code&gt; and want this graph to have the same look as
the others made with &lt;code&gt;ggplot2&lt;/code&gt; you first need to save the summary in a variable.
Let’s overwrite this &lt;code&gt;effects_logit_participation&lt;/code&gt; variable with its summary:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;effects_logit_participation = summary(effects_logit_participation)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now it is possible to use &lt;code&gt;ggplot2&lt;/code&gt; to create the same plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = effects_logit_participation) +
  geom_point(aes(factor, AME)) +
  geom_errorbar(aes(x = factor, ymin = lower, ymax = upper)) +
  geom_hline(yintercept = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2017-10-26-margins_r_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So an infinitesimal increase, in say, non-labour income (&lt;code&gt;lnnlinc&lt;/code&gt;) of 0.001 is associated with a
decrease of the probability of labour force participation by 0.001*17 percentage points.&lt;/p&gt;
&lt;p&gt;You can also extract the marginal effects of a single variable, with &lt;code&gt;dydx()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dydx(Participation, logit_participation, &amp;quot;lnnlinc&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   dydx_lnnlinc
## 1  -0.15667764
## 2  -0.20014487
## 3  -0.18495109
## 4  -0.05377262
## 5  -0.18710476
## 6  -0.19586986&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which makes it possible to extract the effects for a list of individuals that you can create yourself:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_subjects = tribble(
    ~lfp,  ~lnnlinc, ~age, ~educ, ~nyc, ~noc, ~foreign,
    &amp;quot;yes&amp;quot;,   10.780,  7.0,     4,    1,    1,    &amp;quot;yes&amp;quot;,
     &amp;quot;no&amp;quot;,     1.30,  9.0,     1,    4,    1,    &amp;quot;yes&amp;quot;
)

dydx(my_subjects, logit_participation, &amp;quot;lnnlinc&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   dydx_lnnlinc
## 1  -0.09228119
## 2  -0.17953451&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I used the &lt;code&gt;tribble()&lt;/code&gt; function from the &lt;code&gt;tibble&lt;/code&gt; package to create this test data set, row by
row. Then, using &lt;code&gt;dydx()&lt;/code&gt;, I get the marginal effect of variable &lt;code&gt;lnnlinc&lt;/code&gt; for these two individuals.
No doubt that this package will be a huge help convincing more social scientists to try out R and
make a potential transition from STATA easier.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why I find tidyeval useful</title>
      <link>https://www.brodrigues.co/blog/2017-08-27-why_tidyeval/</link>
      <pubDate>Sun, 27 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-08-27-why_tidyeval/</guid>
      <description>&lt;p&gt;First thing’s first: maybe you shouldn’t care about &lt;code&gt;tidyeval&lt;/code&gt;. Maybe you don’t need it. If you
exclusively work interactively, I don’t think that learning about &lt;code&gt;tidyeval&lt;/code&gt; is important. I can
only speak for me, and explain to you why I personally find &lt;code&gt;tidyeval&lt;/code&gt; useful.&lt;/p&gt;
&lt;p&gt;I wanted to write this blog post after reading this
&lt;a href=&#34;https://twitter.com/dataandme/status/901429535266267136&#34;&gt;twitter thread&lt;/a&gt;
and specifically &lt;a href=&#34;https://twitter.com/Kwarizmi/status/901457435948236801&#34;&gt;this question&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/dataandme&#34;&gt;Mara Averick&lt;/a&gt; then wrote
&lt;a href=&#34;http://maraaverick.rbind.io/2017/08/tidyeval-resource-roundup/&#34;&gt;this blogpost&lt;/a&gt; linking to 6 other blog
posts that give some &lt;code&gt;tidyeval&lt;/code&gt; examples. Reading them, plus the
&lt;a href=&#34;http://dplyr.tidyverse.org/articles/programming.html&#34;&gt;Programming with dplyr&lt;/a&gt; vignette should help you
get started with &lt;code&gt;tidyeval&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But maybe now you know how to use it, but not why and when you should use it… Basically, whenever
you want to write a function that looks something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_function(my_data, one_column_inside_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is when you want to use the power of &lt;code&gt;tidyeval&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I work at &lt;a href=&#34;http://www.statistiques.public.lu/en/index.html&#34;&gt;STATEC&lt;/a&gt;,
Luxembourg’s national institute of statistics. I work on all kinds of different projects, and when
data gets updated (for example because a new round of data collection for some survey finished),
I run my own scripts on the fresh data to make the data nice and tidy for analysis. Because surveys
get updated, sometimes column names change a little bit, and this can cause some issues.&lt;/p&gt;
&lt;p&gt;Very recently, a dataset I work with got updated. Data collection was finished, so I
just loaded my hombrewed package written for this project, changed the path from last year’s script
to this year’s fresh data path, ran the code, and watched as the folders got populated with new
&lt;code&gt;ggplot2&lt;/code&gt; graphs and LaTeX tables with descriptive statistics and regression
results. This is then used to generate this year’s report. However, by looking at the graphs, I
noticed something weird; some graphs were showing some very strange patterns. It turns out that one
column got its name changed, and also one of its values got changed too.&lt;/p&gt;
&lt;p&gt;Last year, this column, let’s call it &lt;code&gt;spam&lt;/code&gt;, had values &lt;code&gt;1&lt;/code&gt; for &lt;code&gt;good&lt;/code&gt; and &lt;code&gt;0&lt;/code&gt; for &lt;code&gt;bad&lt;/code&gt;.
This year the column is called &lt;code&gt;Spam&lt;/code&gt; and the values are &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;2&lt;/code&gt;. When I found out that this was
the source of the problem, I just had to change the arguments of my functions from&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_spam_plot(dataset = data2016, column = spam, value = 1)
generate_spam_plot(dataset = data2016, column = spam, value = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;generate_spam_plot(dataset = data2017, column = Spam, value = 1)
generate_spam_plot(dataset = data2017, column = Spam, value = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;without needing to change anything else. This is why I use &lt;code&gt;tidyeval&lt;/code&gt;; without it, writing a
function such as &lt;code&gt;genereta_spam_plot&lt;/code&gt; would not be easy. It would be possible, but not easy.&lt;/p&gt;
&lt;p&gt;If you want to know more about &lt;code&gt;tidyeval&lt;/code&gt; and working programmatically with R, I shamelessly
invite you to read a book I’ve been working on: &lt;a href=&#34;https://b-rodrigues.github.io/fput/&#34; class=&#34;uri&#34;&gt;https://b-rodrigues.github.io/fput/&lt;/a&gt;
It’s still a WIP, but maybe you’ll find it useful. I plan on finishing it by the end of the year,
but there’s already some content to keep you busy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>tidyr::spread() and dplyr::rename_at() in action</title>
      <link>https://www.brodrigues.co/blog/2017-07-27-spread_rename_at/</link>
      <pubDate>Thu, 27 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-07-27-spread_rename_at/</guid>
      <description>&lt;p&gt;I was recently confronted to a situation that required going from a long dataset to a wide dataset,
but with a small twist: there were two datasets, which I had to merge into one. You might wonder
what kinda crappy twist that is, right? Well, let’s take a look at the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1; data2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 4
##    country date       variable_1       value
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;
##  1 lu      01/01/2005 maybe               22
##  2 lu      01/07/2005 maybe               13
##  3 lu      01/01/2006 maybe               40
##  4 lu      01/07/2006 maybe               25
##  5 lu      01/01/2005 totally_agree       42
##  6 lu      01/07/2005 totally_agree       17
##  7 lu      01/01/2006 totally_agree       25
##  8 lu      01/07/2006 totally_agree       16
##  9 lu      01/01/2005 totally_disagree    39
## 10 lu      01/07/2005 totally_disagree    17
## 11 lu      01/01/2006 totally_disagree    23
## 12 lu      01/07/2006 totally_disagree    21
## 13 lu      01/01/2005 kinda_disagree      69
## 14 lu      01/07/2005 kinda_disagree      12
## 15 lu      01/01/2006 kinda_disagree      10
## 16 lu      01/07/2006 kinda_disagree       9
## 17 lu      01/01/2005 kinda_agree         38
## 18 lu      01/07/2005 kinda_agree         31
## 19 lu      01/01/2006 kinda_agree         19
## 20 lu      01/07/2006 kinda_agree         12&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 20 x 4
##    country date       variable_2       value
##    &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;
##  1 lu      01/01/2005 kinda_agree         22
##  2 lu      01/07/2005 kinda_agree         13
##  3 lu      01/01/2006 kinda_agree         40
##  4 lu      01/07/2006 kinda_agree         25
##  5 lu      01/01/2005 totally_agree       42
##  6 lu      01/07/2005 totally_agree       17
##  7 lu      01/01/2006 totally_agree       25
##  8 lu      01/07/2006 totally_agree       16
##  9 lu      01/01/2005 totally_disagree    39
## 10 lu      01/07/2005 totally_disagree    17
## 11 lu      01/01/2006 totally_disagree    23
## 12 lu      01/07/2006 totally_disagree    21
## 13 lu      01/01/2005 maybe               69
## 14 lu      01/07/2005 maybe               12
## 15 lu      01/01/2006 maybe               10
## 16 lu      01/07/2006 maybe                9
## 17 lu      01/01/2005 kinda_disagree      38
## 18 lu      01/07/2005 kinda_disagree      31
## 19 lu      01/01/2006 kinda_disagree      19
## 20 lu      01/07/2006 kinda_disagree      12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As explained in &lt;a href=&#34;http://vita.had.co.nz/papers/tidy-data.html&#34;&gt;Hadley (2014)&lt;/a&gt;, this is how you should keep your data… But for a particular
purpose, I had to transform these datasets. What I was asked to do was to merge these into a single
wide data frame. Doing this for one dataset is easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 %&amp;gt;%
  spread(variable_1, value)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 7
##   country date       kinda_agree kinda_disagree maybe totally_agree
##   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;          &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;         &amp;lt;int&amp;gt;
## 1 lu      01/01/2005          38             69    22            42
## 2 lu      01/01/2006          19             10    40            25
## 3 lu      01/07/2005          31             12    13            17
## 4 lu      01/07/2006          12              9    25            16
## # ... with 1 more variable: totally_disagree &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But because &lt;code&gt;data1&lt;/code&gt; and &lt;code&gt;data2&lt;/code&gt; have the same levels for &lt;code&gt;variable_1&lt;/code&gt; and &lt;code&gt;variable_2&lt;/code&gt;, this would not
work. So the solution I found online, in this &lt;a href=&#34;https://stackoverflow.com/questions/43578723/conditional-replacement-of-column-name-in-tibble-using-dplyr&#34;&gt;SO thread&lt;/a&gt; was to use &lt;code&gt;tidyr::spread()&lt;/code&gt; with
&lt;code&gt;dplyr::rename_at()&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 &amp;lt;- data1 %&amp;gt;%
  spread(variable_1, value) %&amp;gt;%
  rename_at(vars(-country, -date), funs(paste0(&amp;quot;variable1:&amp;quot;, .)))

glimpse(data1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 4
## Variables: 7
## $ country                      &amp;lt;chr&amp;gt; &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;
## $ date                         &amp;lt;chr&amp;gt; &amp;quot;01/01/2005&amp;quot;, &amp;quot;01/01/2006&amp;quot;, &amp;quot;01/0...
## $ `variable1:kinda_agree`      &amp;lt;int&amp;gt; 38, 19, 31, 12
## $ `variable1:kinda_disagree`   &amp;lt;int&amp;gt; 69, 10, 12, 9
## $ `variable1:maybe`            &amp;lt;int&amp;gt; 22, 40, 13, 25
## $ `variable1:totally_agree`    &amp;lt;int&amp;gt; 42, 25, 17, 16
## $ `variable1:totally_disagree` &amp;lt;int&amp;gt; 39, 23, 17, 21&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data2 &amp;lt;- data2 %&amp;gt;%
  spread(variable_2, value) %&amp;gt;%
  rename_at(vars(-country, -date), funs(paste0(&amp;quot;variable2:&amp;quot;, .)))

glimpse(data2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 4
## Variables: 7
## $ country                      &amp;lt;chr&amp;gt; &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;
## $ date                         &amp;lt;chr&amp;gt; &amp;quot;01/01/2005&amp;quot;, &amp;quot;01/01/2006&amp;quot;, &amp;quot;01/0...
## $ `variable2:kinda_agree`      &amp;lt;int&amp;gt; 22, 40, 13, 25
## $ `variable2:kinda_disagree`   &amp;lt;int&amp;gt; 38, 19, 31, 12
## $ `variable2:maybe`            &amp;lt;int&amp;gt; 69, 10, 12, 9
## $ `variable2:totally_agree`    &amp;lt;int&amp;gt; 42, 25, 17, 16
## $ `variable2:totally_disagree` &amp;lt;int&amp;gt; 39, 23, 17, 21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;rename_at()&lt;/code&gt; needs variables which you pass to &lt;code&gt;vars()&lt;/code&gt;, a helper function to select variables, and
a function that will do the renaming, passed to &lt;code&gt;funs()&lt;/code&gt;. The function I use is simply &lt;code&gt;paste0()&lt;/code&gt;,
which pastes a string, for example “variable1:” with the name of the columns, given by the single ‘.’,
a dummy argument. Now these datasets can be merged:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data1 %&amp;gt;%
  full_join(data2) %&amp;gt;%
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;country&amp;quot;, &amp;quot;date&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 4
## Variables: 12
## $ country                      &amp;lt;chr&amp;gt; &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;, &amp;quot;lu&amp;quot;
## $ date                         &amp;lt;chr&amp;gt; &amp;quot;01/01/2005&amp;quot;, &amp;quot;01/01/2006&amp;quot;, &amp;quot;01/0...
## $ `variable1:kinda_agree`      &amp;lt;int&amp;gt; 38, 19, 31, 12
## $ `variable1:kinda_disagree`   &amp;lt;int&amp;gt; 69, 10, 12, 9
## $ `variable1:maybe`            &amp;lt;int&amp;gt; 22, 40, 13, 25
## $ `variable1:totally_agree`    &amp;lt;int&amp;gt; 42, 25, 17, 16
## $ `variable1:totally_disagree` &amp;lt;int&amp;gt; 39, 23, 17, 21
## $ `variable2:kinda_agree`      &amp;lt;int&amp;gt; 22, 40, 13, 25
## $ `variable2:kinda_disagree`   &amp;lt;int&amp;gt; 38, 19, 31, 12
## $ `variable2:maybe`            &amp;lt;int&amp;gt; 69, 10, 12, 9
## $ `variable2:totally_agree`    &amp;lt;int&amp;gt; 42, 25, 17, 16
## $ `variable2:totally_disagree` &amp;lt;int&amp;gt; 39, 23, 17, 21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hope this post helps you understand the difference between long and wide datasets better, as well
as &lt;code&gt;dplyr::rename_at()&lt;/code&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lesser known dplyr 0.7* tricks</title>
      <link>https://www.brodrigues.co/blog/2017-06-19-dplyr-0-70-tutorial/</link>
      <pubDate>Sun, 02 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-06-19-dplyr-0-70-tutorial/</guid>
      <description>&lt;p&gt;This blog post is an update to an older &lt;a href=&#34;http://www.brodrigues.co/blog/2017-02-17-lesser_known_tricks/&#34;&gt;one&lt;/a&gt;
I wrote in March.
In the post from March, &lt;code&gt;dplyr&lt;/code&gt; was at version 0.50, but since then a major update introduced some
changes that make some of the tips in that post obsolete. So here I revisit the blog post from March
by using &lt;code&gt;dplyr&lt;/code&gt; 0.70.&lt;/p&gt;
&lt;div id=&#34;create-new-columns-with-mutate-and-case_when&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create new columns with &lt;code&gt;mutate()&lt;/code&gt; and &lt;code&gt;case_when()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The basic things such as selecting columns, renaming them, filtering, etc did not change with this new
version. What did change however is creating new columns using &lt;code&gt;case_when()&lt;/code&gt;.
First, load &lt;code&gt;dplyr&lt;/code&gt; and the &lt;code&gt;mtcars&lt;/code&gt; dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;dplyr&amp;quot;)
data(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This was how it was done in version 0.50 (notice the ‘.$’ symbol before the variable ‘carb’):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
    mutate(carb_new = case_when(.$carb == 1 ~ &amp;quot;one&amp;quot;,
                                .$carb == 2 ~ &amp;quot;two&amp;quot;,
                                .$carb == 4 ~ &amp;quot;four&amp;quot;,
                                 TRUE ~ &amp;quot;other&amp;quot;)) %&amp;gt;%
    head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl disp  hp drat    wt  qsec vs am gear carb carb_new
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4     four
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4     four
## 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1      one
## 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1      one
## 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2      two&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This has been simplified to:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
    mutate(carb_new = case_when(carb == 1 ~ &amp;quot;one&amp;quot;,
                                carb == 2 ~ &amp;quot;two&amp;quot;,
                                carb == 4 ~ &amp;quot;four&amp;quot;,
                                TRUE ~ &amp;quot;other&amp;quot;)) %&amp;gt;%
    head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl disp  hp drat    wt  qsec vs am gear carb carb_new
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4     four
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4     four
## 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1      one
## 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1      one
## 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2      two&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No need for &lt;code&gt;.$&lt;/code&gt; anymore.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-a-function-to-certain-columns-only-by-rows-with-purrrlyr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply a function to certain columns only, by rows, with &lt;code&gt;purrrlyr&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dplyr&lt;/code&gt; wasn’t the only package to get an overhaul, &lt;code&gt;purrr&lt;/code&gt; also got the same treatment.&lt;/p&gt;
&lt;p&gt;In the past, I applied a function to certains columns like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
    select(am, gear, carb) %&amp;gt;%
    purrr::by_row(sum, .collate = &amp;quot;cols&amp;quot;, .to = &amp;quot;sum_am_gear_carb&amp;quot;) -&amp;gt; mtcars2
head(mtcars2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, &lt;code&gt;by_row()&lt;/code&gt; does not exist in &lt;code&gt;purrr&lt;/code&gt; anymore, but instead a new package called &lt;code&gt;purrrlyr&lt;/code&gt;
was introduced with functions that don’t really fit inside &lt;code&gt;purrr&lt;/code&gt; nor &lt;code&gt;dplyr&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
    select(am, gear, carb) %&amp;gt;%
    purrrlyr::by_row(sum, .collate = &amp;quot;cols&amp;quot;, .to = &amp;quot;sum_am_gear_carb&amp;quot;) -&amp;gt; mtcars2
head(mtcars2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##      am  gear  carb sum_am_gear_carb
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
## 1     1     4     4                9
## 2     1     4     4                9
## 3     1     4     1                6
## 4     0     3     1                4
## 5     0     3     2                5
## 6     0     3     1                4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Think of &lt;code&gt;purrrlyr&lt;/code&gt; as &lt;code&gt;purrr&lt;/code&gt;s and &lt;code&gt;dplyr&lt;/code&gt;s love child.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-dplyr-functions-inside-your-own-functions-or-what-is-tidyeval&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;dplyr&lt;/code&gt; functions inside your own functions, or what is &lt;code&gt;tidyeval&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Programming with &lt;code&gt;dplyr&lt;/code&gt; has been simplified a lot. Before version &lt;code&gt;0.70&lt;/code&gt;, one needed to use
&lt;code&gt;dplyr&lt;/code&gt; in conjuction with &lt;code&gt;lazyeval&lt;/code&gt; to use &lt;code&gt;dplyr&lt;/code&gt; functions inside one’s own fuctions. It was
not always very easy, especially if you mixed columns and values inside your functions. Here’s the
example from the March blog post:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_vars &amp;lt;- function(data, some_string){

  data %&amp;gt;%
    select_(lazyeval::interp(~contains(some_string))) -&amp;gt; data

  return(data)
}

extract_vars(mtcars, &amp;quot;spam&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More examples are available in &lt;a href=&#34;http://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/&#34;&gt;this other blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I will revisit them now with &lt;code&gt;dplyr&lt;/code&gt;’s new &lt;code&gt;tidyeval&lt;/code&gt; syntax. I’d recommend you read the &lt;em&gt;Tidy evaluation&lt;/em&gt;
vignette &lt;a href=&#34;https://cran.r-project.org/web/packages/rlang/vignettes/tidy-evaluation.html&#34;&gt;here&lt;/a&gt;. This vignette
is part of the &lt;code&gt;rlang&lt;/code&gt; package, which gets used under the hood by &lt;code&gt;dplyr&lt;/code&gt; for all your programming needs.
Here is the function I called &lt;code&gt;simpleFunction()&lt;/code&gt;, written with the old &lt;code&gt;dplyr&lt;/code&gt; syntax:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name){
  dataset %&amp;gt;%
    group_by_(col_name) %&amp;gt;%
    summarise(mean_mpg = mean(mpg)) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, &amp;quot;cyl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##     cyl mean_mpg
##   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     4     26.7
## 2     6     19.7
## 3     8     15.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the new synax, it must be rewritten a little bit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name){
  col_name &amp;lt;- enquo(col_name)
  dataset %&amp;gt;%
    group_by(!!col_name) %&amp;gt;%
    summarise(mean_mpg = mean(mpg)) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##     cyl mean_mpg
##   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1     4     26.7
## 2     6     19.7
## 3     8     15.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What has changed? Forget the underscore versions of the usual functions such as &lt;code&gt;select_()&lt;/code&gt;,
&lt;code&gt;group_by_()&lt;/code&gt;, etc. Now, you must quote the column name using &lt;code&gt;enquo()&lt;/code&gt; (or just &lt;code&gt;quo()&lt;/code&gt; if working
interactively, outside a function), which returns a &lt;strong&gt;quosure&lt;/strong&gt;. This &lt;strong&gt;quosure&lt;/strong&gt; can then be
evaluated using &lt;code&gt;!!&lt;/code&gt; in front of the quosure and inside the usual &lt;code&gt;dplyr&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;Let’s look at another example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name, value){
  filter_criteria &amp;lt;- lazyeval::interp(~y == x, .values=list(y = as.name(col_name), x = value))
  dataset %&amp;gt;%
    filter_(filter_criteria) %&amp;gt;%
    summarise(mean_cyl = mean(cyl)) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, &amp;quot;am&amp;quot;, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean_cyl
## 1 5.076923&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, it’s a bit more complicated, as you needed to use &lt;code&gt;lazyeval::interp()&lt;/code&gt; to make it work.
With the improved &lt;code&gt;dplyr&lt;/code&gt;, here’s how it’s done:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name, value){
  col_name &amp;lt;- enquo(col_name)
  dataset %&amp;gt;%
    filter((!!col_name) == value) %&amp;gt;%
    summarise(mean_cyl = mean(cyl)) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, am, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean_cyl
## 1 5.076923&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Much, much easier! There is something that you must pay attention to though. Notice that I’ve written:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter((!!col_name) == value)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(!!col_name == value)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have enclosed &lt;code&gt;!!col_name&lt;/code&gt; inside parentheses. I struggled with this, but thanks to help
from &lt;a href=&#34;https://twitter.com/dmi3k/status/880374506291953664&#34;&gt;@dmi3k&lt;/a&gt; and
&lt;a href=&#34;https://twitter.com/_lionelhenry/status/880380691078361090&#34;&gt;@_lionelhenry&lt;/a&gt; I was able to understand
what was happening (isn’t the #rstats community on twitter great?).&lt;/p&gt;
&lt;p&gt;One last thing: let’s make this function a bit more general. I hard-coded the variable &lt;code&gt;cyl&lt;/code&gt; inside the
body of the function, but maybe you’d like the mean of another variable? Easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, group_col, mean_col, value){
  group_col &amp;lt;- enquo(group_col)
  mean_col &amp;lt;- enquo(mean_col)
  dataset %&amp;gt;%
    filter((!!group_col) == value) %&amp;gt;%
    summarise(mean((!!mean_col))) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, am, cyl, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean(cyl)
## 1  5.076923&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;«That’s very nice Bruno, but &lt;code&gt;mean((cyl))&lt;/code&gt; in the output looks ugly as sin»&lt;/em&gt; you might think, and you’d be
right. It is possible to set the name of the column in the output using &lt;code&gt;:=&lt;/code&gt; instead of &lt;code&gt;=&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, group_col, mean_col, value){
  group_col &amp;lt;- enquo(group_col)
  mean_col &amp;lt;- enquo(mean_col)
  mean_name &amp;lt;- paste0(&amp;quot;mean_&amp;quot;, mean_col)[2]
  dataset %&amp;gt;%
    filter((!!group_col) == value) %&amp;gt;%
    summarise(!!mean_name := mean((!!mean_col))) -&amp;gt; dataset
  return(dataset)
}


simpleFunction(mtcars, am, cyl, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean_cyl
## 1 5.076923&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the name of the column I added this line:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_name &amp;lt;- paste0(&amp;quot;mean_&amp;quot;, mean_col)[2]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see what it does, try the following inside an R interpreter (remember to us &lt;code&gt;quo()&lt;/code&gt; instead of &lt;code&gt;enquo()&lt;/code&gt;
outside functions!):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste0(&amp;quot;mean_&amp;quot;, quo(cyl))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;mean_~&amp;quot;   &amp;quot;mean_cyl&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;enquo()&lt;/code&gt; quotes the input, and with &lt;code&gt;paste0()&lt;/code&gt; it gets converted to a string that can be used as a column
name. However, the &lt;code&gt;~&lt;/code&gt; is in the way and the output of &lt;code&gt;paste0()&lt;/code&gt; is a vector of two strings: the correct
name is contained in the second element, hence the &lt;code&gt;[2]&lt;/code&gt;. There might be a more elegant way of doing that,
but for now this has been working well for me.&lt;/p&gt;
&lt;p&gt;That was it folks! I do recommend you read the &lt;em&gt;Programming with dplyr&lt;/em&gt; vignette
&lt;a href=&#34;https://cran.r-project.org/web/packages/dplyr/vignettes/programming.html&#34;&gt;here&lt;/a&gt; as well as other blog posts,
such as the one recommended to me by &lt;a href=&#34;https://twitter.com/dmi3k&#34;&gt;@dmi3k&lt;/a&gt;
&lt;a href=&#34;http://www.win-vector.com/blog/2017/06/non-standard-evaluation-and-function-composition-in-r/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Have fun with &lt;code&gt;dplyr 0.70&lt;/code&gt;!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Make ggplot2 purrr</title>
      <link>https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/</link>
      <pubDate>Wed, 29 Mar 2017 06:45:48 +0200</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr/</guid>
      <description>&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: I’ve included another way of saving a separate plot by group in this article, as pointed out
by &lt;a href=&#34;https://twitter.com/monitus/status/849033025631297536&#34;&gt;&lt;code&gt;@monitus&lt;/code&gt;&lt;/a&gt;. Actually, this is the preferred
solution; using &lt;code&gt;dplyr::do()&lt;/code&gt; is deprecated, according to Hadley Wickham &lt;a href=&#34;https://twitter.com/hadleywickham/status/719542847045636096&#34;&gt;himself&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll be honest: the title is a bit misleading. I will not use &lt;code&gt;purrr&lt;/code&gt; that much in this blog post.
Actually, I will use one single &lt;code&gt;purrr&lt;/code&gt; function, at the very end. I use &lt;code&gt;dplyr&lt;/code&gt; much more.
However &lt;em&gt;Make ggplot2 purrr&lt;/em&gt; sounds better than &lt;em&gt;Make ggplot dplyr&lt;/em&gt; or whatever the verb for &lt;code&gt;dplyr&lt;/code&gt; would be.&lt;/p&gt;
&lt;p&gt;Also, this blog post was inspired by a stackoverflow question and in particular one of the
&lt;a href=&#34;http://stackoverflow.com/a/29035145/1298051&#34;&gt;answers&lt;/a&gt;. So I don’t bring anything new to the table,
but I found this stackoverflow answer so useful and so underrated (only 16 upvotes as I’m writing
this!) that I wanted to write something about it.&lt;/p&gt;
&lt;p&gt;Basically the idea of this blog post is to show how to create graphs using &lt;code&gt;ggplot2&lt;/code&gt;, but by
grouping by a factor variable beforehand. To illustrate this idea, let’s use the data from the &lt;a href=&#34;http://www.rug.nl/ggdc/productivity/pwt/&#34;&gt;Penn World
Tables 9.0&lt;/a&gt;. The easiest way to get this data is to
install the package called &lt;code&gt;pwt9&lt;/code&gt; with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;pwt9&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then load the data with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;pwt9.0&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s load the needed packages. I am also using &lt;code&gt;ggthemes&lt;/code&gt; which makes themeing your ggplots
very easy. I’ll be making &lt;a href=&#34;https://en.wikipedia.org/wiki/Edward_Tufte&#34;&gt;Tufte&lt;/a&gt;-style plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(ggthemes)
library(dplyr)
library(tidyr)
library(purrr)
library(pwt9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First let’s select a list of countries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country_list &amp;lt;- c(&amp;quot;France&amp;quot;, &amp;quot;Germany&amp;quot;, &amp;quot;United States of America&amp;quot;, &amp;quot;Luxembourg&amp;quot;, &amp;quot;Switzerland&amp;quot;, &amp;quot;Greece&amp;quot;)

small_pwt &amp;lt;- pwt9.0 %&amp;gt;%
  filter(country %in% country_list)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s us also order the countries in the data frame as I have written them in &lt;code&gt;country_list&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_pwt &amp;lt;- small_pwt %&amp;gt;%
  mutate(country = factor(country, levels = country_list, ordered = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might be wondering why this is important. At the end of the article, we are going to save the
plots to disk. If we do not re-order the countries inside the data frame as in &lt;code&gt;country_list&lt;/code&gt;, the
name of the files will not correspond to the correct plots!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: While this can still be interesting to know, especially if you want to order the bars
of a barplot made with &lt;code&gt;ggplot2&lt;/code&gt;, I included a suggestion by &lt;a href=&#34;https://twitter.com/expersso/status/846986357792739328&#34;&gt;&lt;code&gt;@expersso&lt;/code&gt;&lt;/a&gt;
that does not require your data to be ordered!&lt;/p&gt;
&lt;p&gt;Now when you want to plot the same variable by countries, say &lt;code&gt;avh&lt;/code&gt; (&lt;em&gt;Average annual hours worked by
persons engaged&lt;/em&gt;), the usual way to do this is with one of &lt;code&gt;facet_wrap()&lt;/code&gt; or &lt;code&gt;facet_grid()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = small_pwt) + theme_tufte() +
  geom_line(aes(y = avh, x = year)) +
  facet_wrap(~country)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = small_pwt) + theme_tufte() +
  geom_line(aes(y = avh, x = year)) +
  facet_grid(country~.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/blog/2017-03-29-make-ggplot2-purrr_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see, for this particular example, &lt;code&gt;facet_grid()&lt;/code&gt; is not very useful, but do notice its
argument, &lt;code&gt;country~.&lt;/code&gt;, which is different from &lt;code&gt;facet_wrap()&lt;/code&gt;’s argument. This way, I get the graphs
stacked horizontally. If I had used &lt;code&gt;facet_grid(~country)&lt;/code&gt; the graphs would be side by side and completely
unreadable.&lt;/p&gt;
&lt;p&gt;Now, let’s go to the meat of this post: what if you would like to have one single graph for each
country? You’d probably think of using &lt;code&gt;dplyr::group_by()&lt;/code&gt; to form the groups and then the graphs. This
is the way to go, but you also have to use &lt;code&gt;dplyr::do()&lt;/code&gt;. This is because as far as I understand,
&lt;code&gt;ggplot2&lt;/code&gt; is not &lt;code&gt;dplyr&lt;/code&gt;-aware, and using an arbitrary function with groups is only possible with
&lt;code&gt;dplyr::do()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: As explained in the intro above, I also added the solution that uses &lt;code&gt;tidyr::nest()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Ancient, deprecated way of doing this
plots &amp;lt;- small_pwt %&amp;gt;%
  group_by(country) %&amp;gt;%
  do(plot = ggplot(data = .) + theme_tufte() +
       geom_line(aes(y = avh, x = year)) +
       ggtitle(unique(.$country)) +
       ylab(&amp;quot;Year&amp;quot;) +
       xlab(&amp;quot;Average annual hours worked by persons engaged&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And this is the approach that uses &lt;code&gt;tidyr::nest()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Preferred approach
plots &amp;lt;- small_pwt %&amp;gt;%
  group_by(country) %&amp;gt;%
  nest() %&amp;gt;%
  mutate(plot = map2(data, country, ~ggplot(data = .x) + theme_tufte() +
       geom_line(aes(y = avh, x = year)) +
       ggtitle(.y) +
       ylab(&amp;quot;Year&amp;quot;) +
       xlab(&amp;quot;Average annual hours worked by persons engaged&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you know &lt;code&gt;dplyr&lt;/code&gt; at least a little bit, the above lines should be easy for you to understand.
But notice how we get the title of the graphs, with &lt;code&gt;ggtitle(unique(.$country))&lt;/code&gt;, which was actually
the point of the stackoverflow question.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; The modern version uses &lt;code&gt;tidyr::nest()&lt;/code&gt;. Its documentation tells us:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;There are many possible ways one could choose to nest columns inside a data frame.
&lt;code&gt;nest()&lt;/code&gt; creates a list of data frames containing all the nested variables: this seems to be the most useful form in practice.&lt;/em&gt;
Let’s take a closer look at what it does exactly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_pwt %&amp;gt;%
  group_by(country) %&amp;gt;%
  nest() %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   country                  data              
##   &amp;lt;ord&amp;gt;                    &amp;lt;list&amp;gt;            
## 1 Switzerland              &amp;lt;tibble [65 × 46]&amp;gt;
## 2 Germany                  &amp;lt;tibble [65 × 46]&amp;gt;
## 3 France                   &amp;lt;tibble [65 × 46]&amp;gt;
## 4 Greece                   &amp;lt;tibble [65 × 46]&amp;gt;
## 5 Luxembourg               &amp;lt;tibble [65 × 46]&amp;gt;
## 6 United States of America &amp;lt;tibble [65 × 46]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is why I love lists in R; we get a &lt;code&gt;tibble&lt;/code&gt; where each element of the column &lt;code&gt;data&lt;/code&gt; is itself a &lt;code&gt;tibble&lt;/code&gt;.
We can now apply any function that we know works on lists.&lt;/p&gt;
&lt;p&gt;What might be surprising though, is the object that is created by this code. Let’s take a look at
&lt;code&gt;plots&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(plots)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   country                  data               plot    
##   &amp;lt;ord&amp;gt;                    &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;  
## 1 Switzerland              &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;
## 2 Germany                  &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;
## 3 France                   &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;
## 4 Greece                   &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;
## 5 Luxembourg               &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;
## 6 United States of America &amp;lt;tibble [65 × 46]&amp;gt; &amp;lt;S3: gg&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As &lt;code&gt;dplyr::do()&lt;/code&gt;’s documentation tells us, the return values get stored inside a list. And this is
exactly what we get back; a list of plots! Lists are a very flexible and useful class, and you cannot
spell &lt;em&gt;list&lt;/em&gt; without &lt;code&gt;purrr&lt;/code&gt; (at least not when you’re a ne&lt;code&gt;R&lt;/code&gt;d).&lt;/p&gt;
&lt;p&gt;Here are the final lines that use &lt;code&gt;purrr::map2()&lt;/code&gt; to save all these plots at once inside your working directory:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: I have changed the code below which does not require your data frame to be ordered according
to the variable &lt;code&gt;country_list&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# file_names &amp;lt;- paste0(country_list, &amp;quot;.pdf&amp;quot;)

map2(paste0(plots$country, &amp;quot;.pdf&amp;quot;), plots$plot, ggsave)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As I said before, if you do not re-order the countries inside the data frame, the names of the files
and the plots will not match. Try running all the code without re-ordering, you’ll see!&lt;/p&gt;
&lt;p&gt;I hope you found this post useful. You can follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt; for
blog updates.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: Many thanks to the readers of this article and for their useful suggestions. I love the R
community; everyday I learn something new and useful!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing brotools</title>
      <link>https://www.brodrigues.co/blog/2017-03-27-introducing_brotools/</link>
      <pubDate>Mon, 27 Mar 2017 09:23:56 +0200</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-03-27-introducing_brotools/</guid>
      <description>&lt;p&gt;I’m happy to announce my first R package, called &lt;code&gt;brotools&lt;/code&gt;. This is a package that contains
functions that are specific to my needs but that you might find also useful. I blogged about some
of these functions, so if you follow my blog you might already be familiar with some of them. It is
not on CRAN and might very well never be. The code is hosted on &lt;a href=&#34;https://bitbucket.org/b-rodrigues/brotools&#34;&gt;bitbucket&lt;/a&gt;
and you can install the package with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_bitbucket(&amp;quot;b-rodrigues/brotools&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hope you’ll find the &lt;code&gt;brotools&lt;/code&gt; useful!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lesser known purrr tricks</title>
      <link>https://www.brodrigues.co/blog/2017-03-24-lesser_known_purrr/</link>
      <pubDate>Fri, 24 Mar 2017 12:00:00 +0100</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-03-24-lesser_known_purrr/</guid>
      <description>&lt;p&gt;&lt;code&gt;purrr&lt;/code&gt; is a package that extends R’s functional programming capabilities. It brings a lot of new stuff to
the table and in this post I show you some of the most useful (at least to me) functions included in &lt;code&gt;purrr&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;getting-rid-of-loops-with-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting rid of loops with &lt;code&gt;map()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)

numbers &amp;lt;- list(11, 12, 13, 14)

map_dbl(numbers, sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.316625 3.464102 3.605551 3.741657&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might wonder why this might be preferred to a for loop? It’s a lot less verbose, and you do not need to
initialise any kind of structure to hold the result. If you google “create empty list in R” you will see that
this is very common. However, with the &lt;code&gt;map()&lt;/code&gt; family of functions, there is no need for an initial structure.
&lt;code&gt;map_dbl()&lt;/code&gt; returns an atomic list of real numbers, but if you use &lt;code&gt;map()&lt;/code&gt; you will get a list back. Try them all out!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;map-conditionally&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map conditionally&lt;/h2&gt;
&lt;div id=&#34;map_if&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;map_if()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a helper function that returns TRUE if a number is even
is_even &amp;lt;- function(x){
  !as.logical(x %% 2)
}

map_if(numbers, is_even, sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 11
## 
## [[2]]
## [1] 3.464102
## 
## [[3]]
## [1] 13
## 
## [[4]]
## [1] 3.741657&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;map_at&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;map_at()&lt;/h4&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map_at(numbers, c(1,3), sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 3.316625
## 
## [[2]]
## [1] 12
## 
## [[3]]
## [1] 3.605551
## 
## [[4]]
## [1] 14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;map_if()&lt;/code&gt; and &lt;code&gt;map_at()&lt;/code&gt; have a further argument than &lt;code&gt;map()&lt;/code&gt;; in the case of &lt;code&gt;map_if()&lt;/code&gt;, a predicate function (
a function that returns &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;) and a vector of positions for &lt;code&gt;map_at()&lt;/code&gt;. This allows you to map your
function only when certain conditions are met, which is also something that a lot of people google for.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;map-a-function-with-multiple-arguments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Map a function with multiple arguments&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;numbers2 &amp;lt;- list(1, 2, 3, 4)

map2(numbers, numbers2, `+`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 12
## 
## [[2]]
## [1] 14
## 
## [[3]]
## [1] 16
## 
## [[4]]
## [1] 18&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can map two lists to a function which takes two arguments using &lt;code&gt;map_2()&lt;/code&gt;. You can even map an arbitrary number
of lists to any function using &lt;code&gt;pmap()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;By the way, try this in: &lt;code&gt;`+`(1,3)&lt;/code&gt; and see what happens.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dont-stop-execution-of-your-function-if-something-goes-wrong&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Don’t stop execution of your function if something goes wrong&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;possible_sqrt &amp;lt;- possibly(sqrt, otherwise = NA_real_)

numbers_with_error &amp;lt;- list(1, 2, 3, &amp;quot;spam&amp;quot;, 4)

map(numbers_with_error, possible_sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] 1
## 
## [[2]]
## [1] 1.414214
## 
## [[3]]
## [1] 1.732051
## 
## [[4]]
## [1] NA
## 
## [[5]]
## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another very common issue is to keep running your loop even when something goes wrong. In most cases the loop simply stops
at the error, but you would like it to continue and see where it failed. Try to google “skip error in a loop”
or some variation of it and you’ll see that a lot of people really just want that.
This is possible by combining &lt;code&gt;map()&lt;/code&gt; and &lt;code&gt;possibly()&lt;/code&gt;. Most solutions involve the use of
&lt;code&gt;tryCatch()&lt;/code&gt; which I personally do not find very easy to use.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;dont-stop-execution-of-your-function-if-something-goes-wrong-and-capture-the-error&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Don’t stop execution of your function if something goes wrong and capture the error&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;safe_sqrt &amp;lt;- safely(sqrt, otherwise = NA_real_)

map(numbers_with_error, safe_sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]]$result
## [1] 1
## 
## [[1]]$error
## NULL
## 
## 
## [[2]]
## [[2]]$result
## [1] 1.414214
## 
## [[2]]$error
## NULL
## 
## 
## [[3]]
## [[3]]$result
## [1] 1.732051
## 
## [[3]]$error
## NULL
## 
## 
## [[4]]
## [[4]]$result
## [1] NA
## 
## [[4]]$error
## &amp;lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&amp;gt;
## 
## 
## [[5]]
## [[5]]$result
## [1] 2
## 
## [[5]]$error
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;safely()&lt;/code&gt; is very similar to &lt;code&gt;possibly()&lt;/code&gt; but it returns a list of lists. An element is thus a list of the result
and the accompagnying error message. If there is no error, the error component is &lt;code&gt;NULL&lt;/code&gt; if there is an error, it
returns the error message.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transpose-a-list&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transpose a list&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;safe_result_list &amp;lt;- map(numbers_with_error, safe_sqrt)

transpose(safe_result_list)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## $result[[1]]
## [1] 1
## 
## $result[[2]]
## [1] 1.414214
## 
## $result[[3]]
## [1] 1.732051
## 
## $result[[4]]
## [1] NA
## 
## $result[[5]]
## [1] 2
## 
## 
## $error
## $error[[1]]
## NULL
## 
## $error[[2]]
## NULL
## 
## $error[[3]]
## NULL
## 
## $error[[4]]
## &amp;lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&amp;gt;
## 
## $error[[5]]
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we transposed the above list. This means that we still have a list of lists, but where the first list holds
all the results (which you can then access with &lt;code&gt;safe_result_list$result&lt;/code&gt;) and the second list holds all the errors
(which you can access with &lt;code&gt;safe_result_list$error&lt;/code&gt;). This can be quite useful!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-a-function-to-a-lower-depth-of-a-list&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply a function to a lower depth of a list&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;transposed_list &amp;lt;- transpose(safe_result_list)

transposed_list %&amp;gt;%
    at_depth(2, is_null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: at_depth() is deprecated, please use `modify_depth()` instead&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $result
## $result[[1]]
## [1] FALSE
## 
## $result[[2]]
## [1] FALSE
## 
## $result[[3]]
## [1] FALSE
## 
## $result[[4]]
## [1] FALSE
## 
## $result[[5]]
## [1] FALSE
## 
## 
## $error
## $error[[1]]
## [1] TRUE
## 
## $error[[2]]
## [1] TRUE
## 
## $error[[3]]
## [1] TRUE
## 
## $error[[4]]
## [1] FALSE
## 
## $error[[5]]
## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sometimes working with lists of lists can be tricky, especially when we want to apply a function to the sub-lists. This
is easily done with &lt;code&gt;at_depth()&lt;/code&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;set-names-of-list-elements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Set names of list elements&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;name_element &amp;lt;- c(&amp;quot;sqrt()&amp;quot;, &amp;quot;ok?&amp;quot;)

set_names(transposed_list, name_element)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $`sqrt()`
## $`sqrt()`[[1]]
## [1] 1
## 
## $`sqrt()`[[2]]
## [1] 1.414214
## 
## $`sqrt()`[[3]]
## [1] 1.732051
## 
## $`sqrt()`[[4]]
## [1] NA
## 
## $`sqrt()`[[5]]
## [1] 2
## 
## 
## $`ok?`
## $`ok?`[[1]]
## NULL
## 
## $`ok?`[[2]]
## NULL
## 
## $`ok?`[[3]]
## NULL
## 
## $`ok?`[[4]]
## &amp;lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&amp;gt;
## 
## $`ok?`[[5]]
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reduce-a-list-to-a-single-value&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reduce a list to a single value&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reduce(numbers, `*`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 24024&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;reduce()&lt;/code&gt; applies the function &lt;code&gt;*&lt;/code&gt; iteratively to the list of numbers. There’s also &lt;code&gt;accumulate()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;accumulate(numbers, `*`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]    11   132  1716 24024&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which keeps the intermediary results.&lt;/p&gt;
&lt;p&gt;This function is very general, and you can reduce anything:&lt;/p&gt;
&lt;p&gt;Matrices:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat1 &amp;lt;- matrix(rnorm(10), nrow = 2)
mat2 &amp;lt;- matrix(rnorm(10), nrow = 2)
mat3 &amp;lt;- matrix(rnorm(10), nrow = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_mat &amp;lt;- list(mat1, mat2, mat3)

reduce(list_mat, `+`)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             [,1]       [,2]       [,3]     [,4]      [,5]
## [1,] -2.48530177  1.0110049  0.4450388 1.280802 1.3413979
## [2,]  0.07596679 -0.6872268 -0.6579242 1.615237 0.8231933&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;even data frames:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df1 &amp;lt;- as.data.frame(mat1)
df2 &amp;lt;- as.data.frame(mat2)
df3 &amp;lt;- as.data.frame(mat3)

list_df &amp;lt;- list(df1, df2, df3)

reduce(list_df, dplyr::full_join)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = c(&amp;quot;V1&amp;quot;, &amp;quot;V2&amp;quot;, &amp;quot;V3&amp;quot;, &amp;quot;V4&amp;quot;, &amp;quot;V5&amp;quot;)
## Joining, by = c(&amp;quot;V1&amp;quot;, &amp;quot;V2&amp;quot;, &amp;quot;V3&amp;quot;, &amp;quot;V4&amp;quot;, &amp;quot;V5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           V1         V2          V3          V4         V5
## 1 -0.6264538 -0.8356286  0.32950777  0.48742905  0.5757814
## 2  0.1836433  1.5952808 -0.82046838  0.73832471 -0.3053884
## 3 -0.8969145  1.5878453 -0.08025176  0.70795473  1.9844739
## 4  0.1848492 -1.1303757  0.13242028 -0.23969802 -0.1387870
## 5 -0.9619334  0.2587882  0.19578283  0.08541773 -1.2188574
## 6 -0.2925257 -1.1521319  0.03012394  1.11661021  1.2673687&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hope you enjoyed this list of useful functions! If you enjoy the content of my blog, you can follow me on &lt;a href=&#34;https://www.twitter.com/brodriguesco&#34;&gt;twitter&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lesser known dplyr tricks</title>
      <link>https://www.brodrigues.co/blog/2017-02-17-lesser_known_tricks/</link>
      <pubDate>Wed, 08 Mar 2017 12:00:00 +0100</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-02-17-lesser_known_tricks/</guid>
      <description>&lt;p&gt;In this blog post I share some lesser-known (at least I believe they are) tricks that use mainly functions from &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;removing-unneeded-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Removing unneeded columns&lt;/h2&gt;
&lt;p&gt;Did you know that you can use &lt;code&gt;-&lt;/code&gt; in front of a column name to remove it from a data frame?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    select(-disp) %&amp;gt;% 
    head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    mpg cyl  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6 105 2.76 3.460 20.22  1  0    3    1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;re-ordering-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Re-ordering columns&lt;/h2&gt;
&lt;p&gt;Still using &lt;code&gt;select()&lt;/code&gt;, it is easy te re-order columns in your data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    select(cyl, disp, hp, everything()) %&amp;gt;% 
    head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   cyl disp  hp  mpg drat    wt  qsec vs am gear carb
## Mazda RX4           6  160 110 21.0 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       6  160 110 21.0 3.90 2.875 17.02  0  1    4    4
## Datsun 710          4  108  93 22.8 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive      6  258 110 21.4 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout   8  360 175 18.7 3.15 3.440 17.02  0  0    3    2
## Valiant             6  225 105 18.1 2.76 3.460 20.22  1  0    3    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As its name implies &lt;code&gt;everything()&lt;/code&gt; simply means all the other columns.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;renaming-columns-with-rename&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Renaming columns with &lt;code&gt;rename()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars &amp;lt;- rename(mtcars, spam_mpg = mpg)
mtcars &amp;lt;- rename(mtcars, spam_disp = disp)
mtcars &amp;lt;- rename(mtcars, spam_hp = hp)

head(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   spam_mpg cyl spam_disp spam_hp drat    wt  qsec vs am
## Mazda RX4             21.0   6       160     110 3.90 2.620 16.46  0  1
## Mazda RX4 Wag         21.0   6       160     110 3.90 2.875 17.02  0  1
## Datsun 710            22.8   4       108      93 3.85 2.320 18.61  1  1
## Hornet 4 Drive        21.4   6       258     110 3.08 3.215 19.44  1  0
## Hornet Sportabout     18.7   8       360     175 3.15 3.440 17.02  0  0
## Valiant               18.1   6       225     105 2.76 3.460 20.22  1  0
##                   gear carb
## Mazda RX4            4    4
## Mazda RX4 Wag        4    4
## Datsun 710           4    1
## Hornet 4 Drive       3    1
## Hornet Sportabout    3    2
## Valiant              3    1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;selecting-columns-with-a-regexp&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Selecting columns with a regexp&lt;/h2&gt;
&lt;p&gt;It is easy to select the columns that start with “spam” with some helper functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    select(contains(&amp;quot;spam&amp;quot;)) %&amp;gt;% 
    head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   spam_mpg spam_disp spam_hp
## Mazda RX4             21.0       160     110
## Mazda RX4 Wag         21.0       160     110
## Datsun 710            22.8       108      93
## Hornet 4 Drive        21.4       258     110
## Hornet Sportabout     18.7       360     175
## Valiant               18.1       225     105&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;take also a look at &lt;code&gt;starts_with()&lt;/code&gt;, &lt;code&gt;ends_with()&lt;/code&gt;, &lt;code&gt;contains()&lt;/code&gt;, &lt;code&gt;matches()&lt;/code&gt;, &lt;code&gt;num_range()&lt;/code&gt;, &lt;code&gt;one_of()&lt;/code&gt; and &lt;code&gt;everything()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-new-columns-with-mutate-and-if_else&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create new columns with &lt;code&gt;mutate()&lt;/code&gt; and &lt;code&gt;if_else()&lt;/code&gt;&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    mutate(vs_new = if_else(
        vs == 1, 
        &amp;quot;one&amp;quot;, 
        &amp;quot;zero&amp;quot;, 
        NA_character_)) %&amp;gt;% 
    head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   spam_mpg cyl spam_disp spam_hp drat    wt  qsec vs am gear carb vs_new
## 1     21.0   6       160     110 3.90 2.620 16.46  0  1    4    4   zero
## 2     21.0   6       160     110 3.90 2.875 17.02  0  1    4    4   zero
## 3     22.8   4       108      93 3.85 2.320 18.61  1  1    4    1    one
## 4     21.4   6       258     110 3.08 3.215 19.44  1  0    3    1    one
## 5     18.7   8       360     175 3.15 3.440 17.02  0  0    3    2   zero
## 6     18.1   6       225     105 2.76 3.460 20.22  1  0    3    1    one&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might want to create a new variable conditionally on several values of another column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    mutate(carb_new = case_when(.$carb == 1 ~ &amp;quot;one&amp;quot;,
                                .$carb == 2 ~ &amp;quot;two&amp;quot;,
                                .$carb == 4 ~ &amp;quot;four&amp;quot;,
                                 TRUE ~ &amp;quot;other&amp;quot;)) %&amp;gt;% 
    head(15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    spam_mpg cyl spam_disp spam_hp drat    wt  qsec vs am gear carb
## 1      21.0   6     160.0     110 3.90 2.620 16.46  0  1    4    4
## 2      21.0   6     160.0     110 3.90 2.875 17.02  0  1    4    4
## 3      22.8   4     108.0      93 3.85 2.320 18.61  1  1    4    1
## 4      21.4   6     258.0     110 3.08 3.215 19.44  1  0    3    1
## 5      18.7   8     360.0     175 3.15 3.440 17.02  0  0    3    2
## 6      18.1   6     225.0     105 2.76 3.460 20.22  1  0    3    1
## 7      14.3   8     360.0     245 3.21 3.570 15.84  0  0    3    4
## 8      24.4   4     146.7      62 3.69 3.190 20.00  1  0    4    2
## 9      22.8   4     140.8      95 3.92 3.150 22.90  1  0    4    2
## 10     19.2   6     167.6     123 3.92 3.440 18.30  1  0    4    4
## 11     17.8   6     167.6     123 3.92 3.440 18.90  1  0    4    4
## 12     16.4   8     275.8     180 3.07 4.070 17.40  0  0    3    3
## 13     17.3   8     275.8     180 3.07 3.730 17.60  0  0    3    3
## 14     15.2   8     275.8     180 3.07 3.780 18.00  0  0    3    3
## 15     10.4   8     472.0     205 2.93 5.250 17.98  0  0    3    4
##    carb_new
## 1      four
## 2      four
## 3       one
## 4       one
## 5       two
## 6       one
## 7      four
## 8       two
## 9       two
## 10     four
## 11     four
## 12    other
## 13    other
## 14    other
## 15     four&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mind the &lt;code&gt;.$&lt;/code&gt; before the variable &lt;code&gt;carb&lt;/code&gt;. There is a &lt;a href=&#34;https://github.com/hadley/dplyr/issues/1965&#34;&gt;github issue&lt;/a&gt;
about this, and it is already fixed in the development version of &lt;code&gt;dplyr&lt;/code&gt;, which means that in the next version
of &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;case_when()&lt;/code&gt; will work as any other specialized &lt;code&gt;dplyr&lt;/code&gt; function inside &lt;code&gt;mutate()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-a-function-to-certain-columns-only-by-rows&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply a function to certain columns only, by rows&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;%
    select(am, gear, carb) %&amp;gt;%
    purrr::by_row(sum, .collate = &amp;quot;cols&amp;quot;, .to = &amp;quot;sum_am_gear_carb&amp;quot;) -&amp;gt; mtcars2
head(mtcars2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this, I had to use &lt;code&gt;purrr&lt;/code&gt;’s &lt;code&gt;by_row()&lt;/code&gt; function. You can then add this column to your original data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars &amp;lt;- cbind(mtcars, &amp;quot;sum_am_gear_carb&amp;quot; = mtcars2$sum_am_gear_carb)
head(mtcars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   spam_mpg cyl spam_disp spam_hp drat    wt  qsec vs am
## Mazda RX4             21.0   6       160     110 3.90 2.620 16.46  0  1
## Mazda RX4 Wag         21.0   6       160     110 3.90 2.875 17.02  0  1
## Datsun 710            22.8   4       108      93 3.85 2.320 18.61  1  1
## Hornet 4 Drive        21.4   6       258     110 3.08 3.215 19.44  1  0
## Hornet Sportabout     18.7   8       360     175 3.15 3.440 17.02  0  0
## Valiant               18.1   6       225     105 2.76 3.460 20.22  1  0
##                   gear carb sum_am_gear_carb
## Mazda RX4            4    4                9
## Mazda RX4 Wag        4    4                9
## Datsun 710           4    1                6
## Hornet 4 Drive       3    1                4
## Hornet Sportabout    3    2                5
## Valiant              3    1                4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;use-do-to-do-any-arbitrary-operation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Use &lt;code&gt;do()&lt;/code&gt; to do any arbitrary operation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% 
    group_by(cyl) %&amp;gt;% 
    do(models = lm(spam_mpg ~ drat + wt, data = .)) %&amp;gt;% 
    broom::tidy(models)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 9 x 6
## # Groups:   cyl [3]
##     cyl term        estimate std.error statistic p.value
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1     4 (Intercept)   33.2      17.1       1.94  0.0877 
## 2     4 drat           1.32      3.45      0.384 0.711  
## 3     4 wt            -5.24      2.22     -2.37  0.0456 
## 4     6 (Intercept)   30.7       7.51      4.08  0.0151 
## 5     6 drat          -0.444     1.17     -0.378 0.725  
## 6     6 wt            -2.99      1.57     -1.91  0.129  
## 7     8 (Intercept)   29.7       7.09      4.18  0.00153
## 8     8 drat          -1.47      1.63     -0.903 0.386  
## 9     8 wt            -2.45      0.799    -3.07  0.0107&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;do()&lt;/code&gt; is useful when you want to use any R function (user defined functions work too!) with &lt;code&gt;dplyr&lt;/code&gt; functions.
First I grouped the observations by &lt;code&gt;cyl&lt;/code&gt; and then ran a linear model for each group. Then I converted the output
to a tidy data frame using &lt;code&gt;broom::tidy()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-dplyr-functions-inside-your-own-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;dplyr&lt;/code&gt; functions inside your own functions&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_vars &amp;lt;- function(data, some_string){
    
  data %&amp;gt;%
    select_(lazyeval::interp(~contains(some_string))) -&amp;gt; data
    
  return(data)
}

extract_vars(mtcars, &amp;quot;spam&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                     spam_mpg spam_disp spam_hp
## Mazda RX4               21.0     160.0     110
## Mazda RX4 Wag           21.0     160.0     110
## Datsun 710              22.8     108.0      93
## Hornet 4 Drive          21.4     258.0     110
## Hornet Sportabout       18.7     360.0     175
## Valiant                 18.1     225.0     105
## Duster 360              14.3     360.0     245
## Merc 240D               24.4     146.7      62
## Merc 230                22.8     140.8      95
## Merc 280                19.2     167.6     123
## Merc 280C               17.8     167.6     123
## Merc 450SE              16.4     275.8     180
## Merc 450SL              17.3     275.8     180
## Merc 450SLC             15.2     275.8     180
## Cadillac Fleetwood      10.4     472.0     205
## Lincoln Continental     10.4     460.0     215
## Chrysler Imperial       14.7     440.0     230
## Fiat 128                32.4      78.7      66
## Honda Civic             30.4      75.7      52
## Toyota Corolla          33.9      71.1      65
## Toyota Corona           21.5     120.1      97
## Dodge Challenger        15.5     318.0     150
## AMC Javelin             15.2     304.0     150
## Camaro Z28              13.3     350.0     245
## Pontiac Firebird        19.2     400.0     175
## Fiat X1-9               27.3      79.0      66
## Porsche 914-2           26.0     120.3      91
## Lotus Europa            30.4      95.1     113
## Ford Pantera L          15.8     351.0     264
## Ferrari Dino            19.7     145.0     175
## Maserati Bora           15.0     301.0     335
## Volvo 142E              21.4     121.0     109&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;About this last point, you can read more about it &lt;a href=&#34;http://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hope you liked this small list of tricks!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to use jailbreakr</title>
      <link>https://www.brodrigues.co/blog/2017-02-17-how_to_use_jailbreakr/</link>
      <pubDate>Fri, 17 Feb 2017 12:51:00 +0100</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-02-17-how_to_use_jailbreakr/</guid>
      <description>&lt;div id=&#34;what-is-jailbreakr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is &lt;code&gt;jailbreakr&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;jailbreakr&lt;/code&gt; package is probably one of the most interesting packages I came across recently.
This package makes it possible to extract messy data from spreadsheets. What is meant by messy? I
am sure you already had to deal with spreadsheets that contained little tables inside a single
sheet for example. As far as I know, there is no simple way of extracting these tables without having
to fiddle around a lot. This is now over with &lt;code&gt;jailbreakr&lt;/code&gt;. Well not entirely, because &lt;code&gt;jailbreakr&lt;/code&gt;
is still in development, but it works well already. If you want to know more about the planned
features, you can watch the
following
&lt;a href=&#34;https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/jailbreakr-Get-out-of-Excel-free&#34;&gt;video&lt;/a&gt; by
Jenny Bryan, one of the package’s authors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installation-and-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installation and data&lt;/h2&gt;
&lt;p&gt;You will have to install the package from Github, as it is not on CRAN
yet. &lt;a href=&#34;https://github.com/rsheets/jailbreakr&#34;&gt;Here is the Github link&lt;/a&gt;. To install the package, just
run the following commands in an R console:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(c(&amp;quot;hadley/xml2&amp;quot;,
                           &amp;quot;rsheets/linen&amp;quot;,
                           &amp;quot;rsheets/cellranger&amp;quot;,
                           &amp;quot;rsheets/rexcel&amp;quot;,
                           &amp;quot;rsheets/jailbreakr&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you get the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;devtools::install_github(&amp;quot;hadley/xml2&amp;quot;)
Downloading GitHub repo hadley/xml2@master
from URL https://api.github.com/repos/hadley/xml2/zipball/master
Error in system(full, intern = quiet, ignore.stderr = quiet, ...) :
    error in running command&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and if you’re on a GNU+Linux distribution try to run the following command:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;options(unzip = &amp;quot;internal&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then run &lt;code&gt;github_install()&lt;/code&gt; again.&lt;/p&gt;
&lt;p&gt;As you can see, you need some other packages to make it work. Now we are going to get some data. We
are going to download some time series from the European Commission, data I had to deal with
recently. Download the data by clicking &lt;a href=&#34;http://ec.europa.eu/economy_finance/db_indicators/surveys/documents/series/nace2_ecfin_1701/investment_total_nsa_nace2.zip&#34;&gt;here&lt;/a&gt;
and look for the spreadsheet titled &lt;code&gt;Investment_total_factors_nace2.xlsx&lt;/code&gt;. The data we are interested
in is on the second sheet, named &lt;code&gt;TOT&lt;/code&gt;. You cannot import this sheet easily into R because there
are four tables on the same sheet. Let us use &lt;code&gt;jailbreakr&lt;/code&gt; to get these tables out of the sheet and
into nice, tidy, data frames.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;jailbreakr-to-the-rescue&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;jailbreakr&lt;/code&gt; to the rescue&lt;/h2&gt;
&lt;p&gt;The first step is to read the data in. For this, we are going to use the &lt;code&gt;rexcel&lt;/code&gt; package, which is
also part of the &lt;code&gt;rsheets&lt;/code&gt; organization on Github that was set up by Jenny Brian and Rich Fitzjohn,
the authors of these packages. &lt;code&gt;rexcel&lt;/code&gt; imports the sheet you want but not in a way that is
immediately useful to you. It just gets the sheet into R, which makes it then possible to use
&lt;code&gt;jailbreakr&lt;/code&gt;’s magic on it. First, let’s import the packages we need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;rexcel&amp;quot;)
library(&amp;quot;jailbreakr&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to check which sheet to import. There are two sheets, and we want to import the one called
&lt;code&gt;TOT&lt;/code&gt;, the second one. But is it really the second one? I have noticed that sometimes, there are
hidden sheets which makes importing the one you want impossible. So first, let use use another
package, &lt;code&gt;readxl&lt;/code&gt; and its function &lt;code&gt;excel_sheets()&lt;/code&gt; to make sure we are extracting the sheet we
really need:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sheets &amp;lt;- readxl::excel_sheets(path_to_data)

tot_sheet &amp;lt;- which(sheets == &amp;quot;TOT&amp;quot;)

print(tot_sheet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the sheet we want is not the second, but the third! Let us import this sheet into R now
(this might take more time than you think; on my computer it takes around 10 seconds):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_sheet &amp;lt;- rexcel_read(path_to_data, sheet = tot_sheet)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can start using &lt;code&gt;jailbreakr&lt;/code&gt;. The function &lt;code&gt;split_sheet()&lt;/code&gt; is the one that splits the sheet
into little tables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tables &amp;lt;- split_sheet(my_sheet)
str(tables)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 4
##  $ :Classes &amp;#39;worksheet_view&amp;#39;, &amp;#39;R6&amp;#39; &amp;lt;worksheet_view&amp;gt;
##   Public:
##     cells: active binding
##     clone: function (deep = FALSE) 
##     data: NULL
##     dim: 34 28
##     header: NULL
##     idx: list
##     initialize: function (sheet, xr, filter, header, data) 
##     lookup: active binding
##     lookup2: active binding
##     merged: active binding
##     sheet: worksheet, R6
##     table: function (col_names = TRUE, ...) 
##     values: function () 
##     xr: cell_limits, list 
##  $ :Classes &amp;#39;worksheet_view&amp;#39;, &amp;#39;R6&amp;#39; &amp;lt;worksheet_view&amp;gt;
##   Public:
##     cells: active binding
##     clone: function (deep = FALSE) 
##     data: NULL
##     dim: 33 28
##     header: NULL
##     idx: list
##     initialize: function (sheet, xr, filter, header, data) 
##     lookup: active binding
##     lookup2: active binding
##     merged: active binding
##     sheet: worksheet, R6
##     table: function (col_names = TRUE, ...) 
##     values: function () 
##     xr: cell_limits, list 
##  $ :Classes &amp;#39;worksheet_view&amp;#39;, &amp;#39;R6&amp;#39; &amp;lt;worksheet_view&amp;gt;
##   Public:
##     cells: active binding
##     clone: function (deep = FALSE) 
##     data: NULL
##     dim: 32 28
##     header: NULL
##     idx: list
##     initialize: function (sheet, xr, filter, header, data) 
##     lookup: active binding
##     lookup2: active binding
##     merged: active binding
##     sheet: worksheet, R6
##     table: function (col_names = TRUE, ...) 
##     values: function () 
##     xr: cell_limits, list 
##  $ :Classes &amp;#39;worksheet_view&amp;#39;, &amp;#39;R6&amp;#39; &amp;lt;worksheet_view&amp;gt;
##   Public:
##     cells: active binding
##     clone: function (deep = FALSE) 
##     data: NULL
##     dim: 33 28
##     header: NULL
##     idx: list
##     initialize: function (sheet, xr, filter, header, data) 
##     lookup: active binding
##     lookup2: active binding
##     merged: active binding
##     sheet: worksheet, R6
##     table: function (col_names = TRUE, ...) 
##     values: function () 
##     xr: cell_limits, list&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;tables&lt;/code&gt; is actually a list containing &lt;code&gt;worksheet_view&lt;/code&gt; objects. Take a look at the &lt;code&gt;dim&lt;/code&gt;
attribute: you see the dimensions of the tables there. When I started using &lt;code&gt;jailbreakr&lt;/code&gt; I was
stuck here. I was looking for the function that would extract the data frames and could not find
it. Then I watched the video and I understood what I had to do: a &lt;code&gt;worksheet_view&lt;/code&gt; object has a
&lt;code&gt;values()&lt;/code&gt; method that does the extraction for you. This is a bit unusual in R (it made me feel
like I was using Python); maybe in future versions this &lt;code&gt;values()&lt;/code&gt; method will become a separate
function of its own in the package. What happens when we use &lt;code&gt;values()&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;purrr&amp;quot;)
list_of_data &amp;lt;-  map(tables, (function(x)(x$values())))
map(list_of_data, head)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
##      [,1]     [,2]    [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10]
## [1,] &amp;quot;TOT&amp;quot;    NA      NA    NA    NA    NA    NA    NA    NA    NA   
## [2,] &amp;quot;DEMAND&amp;quot; 33603   33969 34334 34699 35064 35430 35795 36160 36525
## [3,] &amp;quot;FDEMT&amp;quot;  &amp;quot;FDEMN&amp;quot; NA    NA    NA    NA    NA    NA    NA    NA   
## [4,] &amp;quot;EU&amp;quot;     &amp;quot;:&amp;quot;     16.9  -1.4  20.2  34.5  31.4  37.5  39    37.3 
## [5,] &amp;quot;EA&amp;quot;     &amp;quot;:&amp;quot;     15.5  -13.1 14.8  30.9  25.1  35.2  39.2  37.1 
## [6,] &amp;quot;BE&amp;quot;     &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   42.3  43.1 
##      [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]
## [1,] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [2,] 36891 37256 37621 37986 38352 38717 39082 39447 39813 40178 40543
## [3,] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [4,] 39.2  27.5  20.6  21.4  29.8  26.4  32.5  47.1  19    -1.3  23.5 
## [5,] 39.5  25.3  18.2  18.9  27.4  23    28.2  46.1  12.3  -9.3  19.3 
## [6,] 45.8  42.2  42.9  43.8  45.8  47.4  49.1  50.9  48.2  46.9  46.3 
##      [,22] [,23] [,24] [,25] [,26] [,27] [,28] 
## [1,] NA    NA    NA    NA    NA    NA    NA    
## [2,] 40908 41274 41639 42004 42369 42735 43100 
## [3,] NA    NA    NA    NA    NA    NA    NA    
## [4,] 29    22    21.1  25.6  31.8  22.9  &amp;quot;30.7&amp;quot;
## [5,] 26.2  18.6  15.7  21.7  28.8  17.3  26.6  
## [6,] 46.8  47.1  48.2  50.1  49.2  34.5  34.4  
## 
## [[2]]
##      [,1]        [,2]    [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10]
## [1,] &amp;quot;FINANCIAL&amp;quot; 33603   33969 34334 34699 35064 35430 35795 36160 36525
## [2,] &amp;quot;FFINT&amp;quot;     &amp;quot;FFINN&amp;quot; NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] &amp;quot;EU&amp;quot;        &amp;quot;:&amp;quot;     -5.1  -6.2  2.7   6.7   9     14.4  13.9  14   
## [4,] &amp;quot;EA&amp;quot;        &amp;quot;:&amp;quot;     -8.8  -13.5 -3.4  2.6   5.7   12.5  13.2  13.1 
## [5,] &amp;quot;BE&amp;quot;        &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   21.5  22.4 
## [6,] &amp;quot;BG&amp;quot;        &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;  
##      [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]
## [1,] 36891 37256 37621 37986 38352 38717 39082 39447 39813 40178 40543
## [2,] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] 16.4  9.4   7.4   8.1   12.4  8.4   13.6  23.4  4.1   -4    10.9 
## [4,] 16.5  8     6.8   5.1   9.9   4.8   8.4   24.3  -2.8  -10.5 9.3  
## [5,] 20.9  22.3  32.2  33.5  33.8  34.8  35    34.5  37.2  33.5  32.7 
## [6,] &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   20.8  24    27.1  28.3  33.4  37.5  37.7  26.6  30.4 
##      [,22] [,23] [,24] [,25] [,26] [,27] [,28] 
## [1,] 40908 41274 41639 42004 42369 42735 43100 
## [2,] NA    NA    NA    NA    NA    NA    NA    
## [3,] 12.4  10.2  8.8   13.4  17.4  6.2   &amp;quot;12.3&amp;quot;
## [4,] 9     7.2   5     11    13.1  -1    6.5   
## [5,] 31.5  32.3  33    31.7  32.2  19.9  20.5  
## [6,] 33.8  35.6  36    41.5  41.6  44.2  43.8  
## 
## [[3]]
##      [,1]        [,2]    [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10]
## [1,] &amp;quot;TECHNICAL&amp;quot; 33603   33969 34334 34699 35064 35430 35795 36160 36525
## [2,] &amp;quot;FTECT&amp;quot;     &amp;quot;FTECN&amp;quot; NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] &amp;quot;EU&amp;quot;        &amp;quot;:&amp;quot;     39.2  37.6  38.3  40    40.7  42.8  43.5  43.8 
## [4,] &amp;quot;EA&amp;quot;        &amp;quot;:&amp;quot;     39.7  36.2  37.5  41.2  40    44    44.8  44.9 
## [5,] &amp;quot;BE&amp;quot;        &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   58.8  58.5 
## [6,] &amp;quot;BG&amp;quot;        &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;  
##      [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]
## [1,] 36891 37256 37621 37986 38352 38717 39082 39447 39813 40178 40543
## [2,] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] 37    31.1  27.2  30.9  30.4  30.3  27.4  40.5  25.8  23.1  27.4 
## [4,] 37    30.3  27.4  31    29.9  29.7  24.8  41    23.4  19.5  26.4 
## [5,] 58.3  58.4  57.7  59.2  59.6  59.4  60.2  59.5  60.5  57.9  56.3 
## [6,] &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   17.3  17.5  21.1  21.5  25.3  28.2  26.1  21    25.3 
##      [,22] [,23] [,24] [,25] [,26] [,27] [,28] 
## [1,] 40908 41274 41639 42004 42369 42735 43100 
## [2,] NA    NA    NA    NA    NA    NA    NA    
## [3,] 28.9  26.3  31.3  32.1  32.1  30.2  &amp;quot;34.6&amp;quot;
## [4,] 28.5  25.9  32.1  32.4  33.1  30.2  36    
## [5,] 56.7  57.7  57.9  58.6  59.1  13.1  13.1  
## [6,] 24.6  26.8  30.4  31.9  34.1  34.8  33.7  
## 
## [[4]]
##      [,1]    [,2]    [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10] [,11]
## [1,] &amp;quot;OTHER&amp;quot; 33603   33969 34334 34699 35064 35430 35795 36160 36525 36891
## [2,] &amp;quot;FOTHT&amp;quot; &amp;quot;FOTHN&amp;quot; NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] &amp;quot;EU&amp;quot;    &amp;quot;:&amp;quot;     2.9   -0.5  3.9   3.9   1     4.1   4.7   7     7.2  
## [4,] &amp;quot;EA&amp;quot;    &amp;quot;:&amp;quot;     2.3   -4.9  1.4   1.3   -2.4  1.1   3.2   5.8   7    
## [5,] &amp;quot;BE&amp;quot;    &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   14    14.9  15.9 
## [6,] &amp;quot;BG&amp;quot;    &amp;quot;:&amp;quot;     &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;   &amp;quot;:&amp;quot;  
##      [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]
## [1,] 37256 37621 37986 38352 38717 39082 39447 39813 40178 40543 40908
## [2,] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
## [3,] -1.5  6.2   8.1   7.6   1.4   2.4   13.7  -1.9  -3.2  1.1   1.1  
## [4,] -3.7  5.5   7.1   7.2   -2.2  0.4   15.5  -4.6  -8.4  0.3   -3.3 
## [5,] 16.3  22.8  23.1  22.4  24.5  25.3  25.5  26.6  26.6  24.7  24.6 
## [6,] &amp;quot;:&amp;quot;   -2.3  -0.8  2.4   2.9   3.5   4.8   5.5   2.2   3.3   3.2  
##      [,23] [,24] [,25] [,26] [,27] [,28]
## [1,] 41274 41639 42004 42369 42735 43100
## [2,] NA    NA    NA    NA    NA    NA   
## [3,] -1.6  0.9   2.7   1.9   -3.3  &amp;quot;2.1&amp;quot;
## [4,] -2.3  0.6   2.5   2.1   -5.4  1.7  
## [5,] 26.4  25.9  25    25.3  4.7   5.2  
## [6,] 5.9   7     8.2   9.6   9.4   9.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are getting really close to something useful! Now we can get the first table and do some basic
cleaning to have a tidy dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset1 &amp;lt;- list_of_data[[1]]

dataset1 &amp;lt;- dataset1[-c(1:3), ]
dataset1[dataset1 == &amp;quot;:&amp;quot;] &amp;lt;- NA
colnames(dataset1) &amp;lt;- c(&amp;quot;country&amp;quot;, seq(from = 1991, to = 2017))

head(dataset1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      country 1991 1992 1993  1994 1995 1996 1997 1998 1999 2000 2001 2002
## [1,] &amp;quot;EU&amp;quot;    NA   16.9 -1.4  20.2 34.5 31.4 37.5 39   37.3 39.2 27.5 20.6
## [2,] &amp;quot;EA&amp;quot;    NA   15.5 -13.1 14.8 30.9 25.1 35.2 39.2 37.1 39.5 25.3 18.2
## [3,] &amp;quot;BE&amp;quot;    NA   NA   NA    NA   NA   NA   NA   42.3 43.1 45.8 42.2 42.9
## [4,] &amp;quot;BG&amp;quot;    NA   NA   NA    NA   NA   NA   NA   NA   NA   NA   NA   39.6
## [5,] &amp;quot;CZ&amp;quot;    NA   NA   NA    NA   NA   NA   NA   NA   NA   NA   NA   54.9
## [6,] &amp;quot;DK&amp;quot;    49.5 45   50    59.5 62.5 55.5 60.5 57.5 56   61.5 57.5 59.5
##      2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016
## [1,] 21.4 29.8 26.4 32.5 47.1 19   -1.3 23.5 29   22   21.1 25.6 31.8 22.9
## [2,] 18.9 27.4 23   28.2 46.1 12.3 -9.3 19.3 26.2 18.6 15.7 21.7 28.8 17.3
## [3,] 43.8 45.8 47.4 49.1 50.9 48.2 46.9 46.3 46.8 47.1 48.2 50.1 49.2 34.5
## [4,] 43   42.8 45.5 49.1 52.6 50.7 39.5 45.5 47.4 45.6 50.5 51.4 49.9 53.2
## [5,] 37   48.5 67.9 66.4 66.8 69.3 64.7 61   56   47.5 53   53.5 67.5 58  
## [6,] 53.5 50   59   64   63   56   33.5 57   47   48   52   45.5 40.5 36.5
##      2017  
## [1,] &amp;quot;30.7&amp;quot;
## [2,] 26.6  
## [3,] 34.4  
## [4,] 52.8  
## [5,] 59.5  
## [6,] 37.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Et voilà! We went from a messy spreadsheet to a tidy dataset in a matter of minutes. Even though
this package is still in early development and not all the features that are planned are available,
the basics are there and can save you a lot of pain!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Functional programming and unit testing for data munging with R available on Leanpub</title>
      <link>https://www.brodrigues.co/blog/2016-12-24-functional-programming-and-unit-testing-for-data-munging-with-r-available-on-leanpub/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-12-24-functional-programming-and-unit-testing-for-data-munging-with-r-available-on-leanpub/</guid>
      <description>&lt;p&gt;The book I&amp;rsquo;ve been working on these pasts months (you can read about it &lt;a href=&#34;http://www.brodrigues.co/2016/11/04/ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r&#34;&gt;here&lt;/a&gt;, and read it for free &lt;a href=&#34;http://www.brodrigues.co/fput&#34;&gt;here&lt;/a&gt;) is now available on Leanpub! You can grab a copy and read it on your ebook reader or on your computer, and what&amp;rsquo;s even better is that it is available for free (but you can also decide to buy it if you really like it). Here is the link on &lt;a href=&#34;https://leanpub.com/fput&#34;&gt;Leanpub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the book, I show you the basics of functional programming, unit testing and package development for the R programming language. The end goal is to make your data tidy in a reproducible way!&lt;/p&gt;

&lt;p&gt;Just a heads up: as the book is right now, the formatting is not perfect and images are missing. This is because I use &lt;code&gt;bookdown&lt;/code&gt; to write the book and convert it to Leanpub&amp;rsquo;s markdown flavour is not trivial. I will find a solution to automate the conversion from &lt;code&gt;bookdown&lt;/code&gt;&amp;rsquo;s version to Leanpub&amp;rsquo;s markdown and try to keep both versions in sync. Of course, once the book will be finished, the version on Leanpub and on my &lt;a href=&#34;http://www.brodrigues.co/fput&#34;&gt;website&lt;/a&gt; are going to be completely identical. If you want to read it on your computer offline, you can also download a pdf from the book&amp;rsquo;s website, by clicking on the pdf icon in the top left corner.  Do not hesitate to send me an email if you want to give me feedback (just click on the red envelope in the top right corner) or tweet me &lt;a href=&#34;https://twitter.com/brodriguesco&#34;&gt;@brodriguesco&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My free book has a cover!</title>
      <link>https://www.brodrigues.co/blog/2017-01-07-my-free-book-has-a-cover/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2017-01-07-my-free-book-has-a-cover/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m currently writing a book as a hobby. It&amp;rsquo;s titled &lt;em&gt;Functional programming and unit testing for data munging with R&lt;/em&gt; and you can get it for free &lt;a href=&#34;https://leanpub.com/fput/&#34;&gt;here&lt;/a&gt;. You can also read it online for free on my &lt;a href=&#34;http://www.brodrigues.co/fput&#34;&gt;webpage&lt;/a&gt; What&amp;rsquo;s the book about?&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the teaser text:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Learn the basics of functional programming, unit testing and package development for the R programming language in order to make your data tidy!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The book now has a beautiful cover thanks to &lt;a href=&#34;https://twitter.com/putosaure&#34;&gt;@putosaure&lt;/a&gt;. Putosaure is a Paris based graphic designer who also reviews video games. He is also a very good friend of mine and I am very happy he made this beautiful cover for my book:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.brodrigues.co/img/cover.png&#34; width=&#34;612&#34; height=&#34;792&#34;/&gt;&lt;/p&gt;

&lt;p&gt;In it, we see a guy holding a shield with the Greek letter lambda, which also happens to be the letter to designate functional programming. I&amp;rsquo;ve added the title with the &lt;a href=&#34;http://www.dafont.com/komika-title.font&#34;&gt;Komika Title&lt;/a&gt; font.&lt;/p&gt;

&lt;p&gt;Consider this cover in beta, it&amp;rsquo;ll probably evolve some more. But I couldn&amp;rsquo;t wait to use it!&lt;/p&gt;

&lt;p&gt;I love it. Hope you&amp;rsquo;ll love it too!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Work on lists of datasets instead of individual datasets by using functional programming</title>
      <link>https://www.brodrigues.co/blog/2016-12-21-work-on-lists-of-datasets-instead-of-individual-datasets-by-using-functional-programming/</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-12-21-work-on-lists-of-datasets-instead-of-individual-datasets-by-using-functional-programming/</guid>
      <description>&lt;p&gt;&lt;p&gt;Analyzing a lot of datasets can be tedious. In my work, I often have to compute descriptive statistics, or plot some graphs for some variables for a lot of datasets. The variables in question have the same name accross the datasets but are measured for different years. As an example, imagine you have this situation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data2000 &amp;lt;- mtcars
data2001 &amp;lt;- mtcars&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of argument, imagine that &lt;code&gt;data2000&lt;/code&gt; is data from a survey conducted in the year 2000 and &lt;code&gt;data2001&lt;/code&gt; is the same survey but conducted in the year 2001. For illustration purposes, I use the &lt;code&gt;mtcars&lt;/code&gt; dataset, but I could have used any other example. In these sort of situations, the variables are named the same in both datasets. Now if I want to check the summary statistics of a variable, I might do it by running:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(data2000$cyl)
summary(data2001$cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but this can get quite tedious, especially if instead of only having two years of data, you have 20 years. Another possibility is to merge both datasets and then check the summary statistics of the variable of interest. But this might require a lot of preprocessing, and sometimes you really just want to do a quick check, or some dirty graphs. So you might be tempted to write a loop, which would require to put these two datasets in some kind of structure, such as a list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_data &amp;lt;- list(&amp;quot;data2000&amp;quot; = data2000, &amp;quot;data2001&amp;quot; = data2001)&lt;/p&gt;

&lt;p&gt;for (i in 1:2){
    print(summary(list_data[[i]]$cyl))
 }&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  4.000   4.000   6.000   6.188   8.000   8.000
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  4.000   4.000   6.000   6.188   8.000   8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this also might get tedious, especially if you want to do this for a lot of different variables, and want to use different functions than &lt;code&gt;summary()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Another, simpler way of doing this, is to use &lt;code&gt;purrr::map()&lt;/code&gt; or &lt;code&gt;lapply()&lt;/code&gt;. But there is a catch though: how do we specify the column we want to work on? Let’s try some things out:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)&lt;/p&gt;

&lt;p&gt;map(list_data, summary(cyl))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Error in summary(cyl) : object &amp;lsquo;cyl&amp;rsquo; not found&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maybe this will work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(list_data, summary, cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data2000
     mpg             cyl             disp             hp&lt;br /&gt;
Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0&lt;br /&gt;
1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5&lt;br /&gt;
Median :19.20   Median :6.000   Median :196.3   Median :123.0&lt;br /&gt;
Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7&lt;br /&gt;
3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0&lt;br /&gt;
Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0&lt;br /&gt;
     drat             wt             qsec             vs&lt;br /&gt;
Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000&lt;br /&gt;
1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000&lt;br /&gt;
Median :3.695   Median :3.325   Median :17.71   Median :0.0000&lt;br /&gt;
Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375&lt;br /&gt;
3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000&lt;br /&gt;
Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000&lt;br /&gt;
      am              gear            carb&lt;br /&gt;
Min.   :0.0000   Min.   :3.000   Min.   :1.000&lt;br /&gt;
1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000&lt;br /&gt;
Median :0.0000   Median :4.000   Median :2.000&lt;br /&gt;
Mean   :0.4062   Mean   :3.688   Mean   :2.812&lt;br /&gt;
3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000&lt;br /&gt;
Max.   :1.0000   Max.   :5.000   Max.   :8.000&lt;/p&gt;

&lt;p&gt;data2001
     mpg             cyl             disp             hp&lt;br /&gt;
Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0&lt;br /&gt;
1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5&lt;br /&gt;
Median :19.20   Median :6.000   Median :196.3   Median :123.0&lt;br /&gt;
Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7&lt;br /&gt;
3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0&lt;br /&gt;
Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0&lt;br /&gt;
     drat             wt             qsec             vs&lt;br /&gt;
Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000&lt;br /&gt;
1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000&lt;br /&gt;
Median :3.695   Median :3.325   Median :17.71   Median :0.0000&lt;br /&gt;
Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375&lt;br /&gt;
3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000&lt;br /&gt;
Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000&lt;br /&gt;
      am              gear            carb&lt;br /&gt;
Min.   :0.0000   Min.   :3.000   Min.   :1.000&lt;br /&gt;
1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000&lt;br /&gt;
Median :0.0000   Median :4.000   Median :2.000&lt;br /&gt;
Mean   :0.4062   Mean   :3.688   Mean   :2.812&lt;br /&gt;
3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000&lt;br /&gt;
Max.   :1.0000   Max.   :5.000   Max.   :8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not quite! You get the summary statistics of every variable, &lt;code&gt;cyl&lt;/code&gt; simply gets ignored. This might be ok in our small toy example, but if you have dozens of datasets with hundreds of variables, the output becomes unreadable. The solution is to use an anonymous functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;map(list_data, (function(x) summary(x$cyl)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data2000
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  4.000   4.000   6.000   6.188   8.000   8.000&lt;/p&gt;

&lt;p&gt;$data2001
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  4.000   4.000   6.000   6.188   8.000   8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is, in my opinion, much more readable than a loop, and the output of this is another list, so it’s easy to save it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary_cyl &amp;lt;- map(list_data, (function(x) summary(x$cyl)))
str(summary_cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 2
$ data2000:Classes &amp;lsquo;summaryDefault&amp;rsquo;, &amp;lsquo;table&amp;rsquo;  Named num [1:6] 4 4 6 6.19 8 &amp;hellip;
 .. ..- attr(&lt;em&gt;, &amp;quot;names&amp;quot;)= chr [1:6] &amp;quot;Min.&amp;quot; &amp;quot;1st Qu.&amp;quot; &amp;quot;Median&amp;quot; &amp;quot;Mean&amp;quot; &amp;hellip;
$ data2001:Classes &amp;lsquo;summaryDefault&amp;rsquo;, &amp;lsquo;table&amp;rsquo;  Named num [1:6] 4 4 6 6.19 8 &amp;hellip;
 .. ..- attr(&lt;/em&gt;, &amp;quot;names&amp;quot;)= chr [1:6] &amp;quot;Min.&amp;quot; &amp;quot;1st Qu.&amp;quot; &amp;quot;Median&amp;quot; &amp;quot;Mean&amp;quot; &amp;hellip;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the loop, you would need to “allocate” an empty list that you would fill at each iteration.&lt;/p&gt;
&lt;p&gt;So this is already nice, but wouldn’t it be nicer to simply have to type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(list_data$cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and have the summary of variable &lt;code&gt;cyl&lt;/code&gt; for each dataset in the list? Well it is possible with the following function I wrote to make my life easier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;to_map &amp;lt;- function(func){
  function(list, column, &amp;hellip;){
    if(missing(column)){
        res &amp;lt;- purrr::map(list, (function(x) func(x, &amp;hellip;)))
      } else {
        res &amp;lt;- purrr::map(list, (function(x) func(x[column], &amp;hellip;)))
             }
    res
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By following &lt;a href=&#34;http://adv-r.had.co.nz/Function-operators.html&#34;&gt;this&lt;/a&gt; chapter of Hadley Wickham’s book, &lt;i&gt;Advanced R&lt;/i&gt;, I was able to write this function. What does it do? It basically &lt;i&gt;generalizes&lt;/i&gt; a function to work on a list of datasets instead of just on a dataset. So for example, in the case of &lt;code&gt;summary()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarymap &amp;lt;- to_map(summary)&lt;/p&gt;

&lt;p&gt;summarymap(list_data, &amp;quot;cyl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$data2000
     cyl&lt;br /&gt;
Min.   :4.000&lt;br /&gt;
1st Qu.:4.000&lt;br /&gt;
Median :6.000&lt;br /&gt;
Mean   :6.188&lt;br /&gt;
3rd Qu.:8.000&lt;br /&gt;
Max.   :8.000&lt;/p&gt;

&lt;p&gt;$data2001
     cyl&lt;br /&gt;
Min.   :4.000&lt;br /&gt;
1st Qu.:4.000&lt;br /&gt;
Median :6.000&lt;br /&gt;
Mean   :6.188&lt;br /&gt;
3rd Qu.:8.000&lt;br /&gt;
Max.   :8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now everytime I want to have summary statistics for a variable, I just need to use &lt;code&gt;summarymap()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarymap(list_data, &amp;quot;mpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data2000
      mpg&lt;br /&gt;
 Min.   :10.40&lt;br /&gt;
 1st Qu.:15.43&lt;br /&gt;
 Median :19.20&lt;br /&gt;
 Mean   :20.09&lt;br /&gt;
 3rd Qu.:22.80&lt;br /&gt;
 Max.   :33.90&lt;/p&gt;

&lt;p&gt;$data2001
      mpg&lt;br /&gt;
 Min.   :10.40&lt;br /&gt;
 1st Qu.:15.43&lt;br /&gt;
 Median :19.20&lt;br /&gt;
 Mean   :20.09&lt;br /&gt;
 3rd Qu.:22.80&lt;br /&gt;
 Max.   :33.90&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I want the summary statistics for every variable, I simply omit the column name:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarymap(list_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$data2000
      mpg             cyl             disp             hp&lt;br /&gt;
 Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0&lt;br /&gt;
 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5&lt;br /&gt;
 Median :19.20   Median :6.000   Median :196.3   Median :123.0&lt;br /&gt;
 Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7&lt;br /&gt;
 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0&lt;br /&gt;
 Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0&lt;br /&gt;
      drat             wt             qsec             vs&lt;br /&gt;
 Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000&lt;br /&gt;
 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000&lt;br /&gt;
 Median :3.695   Median :3.325   Median :17.71   Median :0.0000&lt;br /&gt;
 Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375&lt;br /&gt;
 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000&lt;br /&gt;
 Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000&lt;br /&gt;
       am              gear            carb&lt;br /&gt;
 Min.   :0.0000   Min.   :3.000   Min.   :1.000&lt;br /&gt;
 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000&lt;br /&gt;
 Median :0.0000   Median :4.000   Median :2.000&lt;br /&gt;
 Mean   :0.4062   Mean   :3.688   Mean   :2.812&lt;br /&gt;
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000&lt;br /&gt;
 Max.   :1.0000   Max.   :5.000   Max.   :8.000&lt;/p&gt;

&lt;p&gt;$data2001
      mpg             cyl             disp             hp&lt;br /&gt;
 Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0&lt;br /&gt;
 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5&lt;br /&gt;
 Median :19.20   Median :6.000   Median :196.3   Median :123.0&lt;br /&gt;
 Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7&lt;br /&gt;
 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0&lt;br /&gt;
 Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0&lt;br /&gt;
      drat             wt             qsec             vs&lt;br /&gt;
 Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000&lt;br /&gt;
 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000&lt;br /&gt;
 Median :3.695   Median :3.325   Median :17.71   Median :0.0000&lt;br /&gt;
 Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375&lt;br /&gt;
 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000&lt;br /&gt;
 Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000&lt;br /&gt;
       am              gear            carb&lt;br /&gt;
 Min.   :0.0000   Min.   :3.000   Min.   :1.000&lt;br /&gt;
 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000&lt;br /&gt;
 Median :0.0000   Median :4.000   Median :2.000&lt;br /&gt;
 Mean   :0.4062   Mean   :3.688   Mean   :2.812&lt;br /&gt;
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000&lt;br /&gt;
 Max.   :1.0000   Max.   :5.000   Max.   :8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can use any function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tablemap &amp;lt;- to_map(table)&lt;/p&gt;

&lt;p&gt;tablemap(list_data, &amp;quot;cyl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data2000&lt;/p&gt;

&lt;p&gt;4  6  8
11  7 14&lt;/p&gt;

&lt;p&gt;$data2001&lt;/p&gt;

&lt;p&gt;4  6  8
11  7 14&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tablemap(list_data, &amp;quot;mpg&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $data2000&lt;/p&gt;

&lt;p&gt;10.4 13.3 14.3 14.7   15 15.2 15.5 15.8 16.4 17.3 17.8 18.1 18.7 19.2 19.7
   2    1    1    1    1    2    1    1    1    1    1    1    1    2    1
  21 21.4 21.5 22.8 24.4   26 27.3 30.4 32.4 33.9
   2    2    1    2    1    1    1    2    1    1&lt;/p&gt;

&lt;p&gt;$data2001&lt;/p&gt;

&lt;p&gt;10.4 13.3 14.3 14.7   15 15.2 15.5 15.8 16.4 17.3 17.8 18.1 18.7 19.2 19.7
   2    1    1    1    1    2    1    1    1    1    1    1    1    2    1
  21 21.4 21.5 22.8 24.4   26 27.3 30.4 32.4 33.9
   2    2    1    2    1    1    1    2    1    1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I hope you will find this little function useful, and as usual, for any comments just drop me an email by clicking the red enveloppe in the top right corner or &lt;a href=&#34;https://twitter.com/brodriguesco&#34;&gt;tweet me&lt;/a&gt;.&lt;/p&gt;
&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;ve started writing a &#39;book&#39;: Functional programming and unit testing for data munging with R</title>
      <link>https://www.brodrigues.co/blog/2016-11-04-ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r/</link>
      <pubDate>Fri, 04 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-11-04-ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r/</guid>
      <description>&lt;p&gt;I have started writing a &amp;lsquo;book&amp;rsquo; using the awesome &lt;code&gt;bookdown&lt;/code&gt; package. In the book I explain and show why using functional programming
and putting your functions in your own packages is the way to go when you want to clean, prepare and transform large data sets.
It makes testing and documenting your code easier. You don&amp;rsquo;t need to think about managing paths either. The book is far from complete,
but I plan on working on it steadily. For now, you can read an intro to functional programming, unit testing and creating your own packages
that will hold your code. I also show you can write documentation for your functions. I am also looking for feedback; so if you have any
suggestions, do not hesitate to shoot me an email or a tweet! You can read the book by clicking &lt;a href=&#34;http://www.brodrigues.co/fput/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Merge a list of datasets together</title>
      <link>https://www.brodrigues.co/blog/2016-07-30-merge-a-list-of-datasets-together/</link>
      <pubDate>Sat, 30 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-07-30-merge-a-list-of-datasets-together/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.brodrigues.co/2016/07/26/read-a-lot-of-datasets-at-once-with-r&#34;&gt;Last week&lt;/a&gt; I showed how to read a lot of datasets at once with R, and this week I’ll continue from there and show a very simple function that uses this list of read datasets and merges them all together.&lt;/p&gt;
&lt;p&gt;First we’ll use &lt;code&gt;read_list()&lt;/code&gt; to read all the datasets at once (for more details read &lt;a href=&#34;http://www.brodrigues.co/2016/07/26/read-a-lot-of-datasets-at-once-with-r&#34;&gt;last week’s post&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;readr&amp;quot;)
library(&amp;quot;tibble&amp;quot;)

data_files &amp;lt;- list.files(pattern = &amp;quot;.csv&amp;quot;)

print(data_files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data_1.csv&amp;quot; &amp;quot;data_2.csv&amp;quot; &amp;quot;data_3.csv&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;list_of_data_sets &amp;lt;- read_list(data_files, read_csv)

glimpse(list_of_data_sets)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 3
##  $ data_1:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,018930679&amp;quot; &amp;quot;0,8748013128&amp;quot; &amp;quot;0,1025635934&amp;quot; &amp;quot;0,6246140983&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,0377725807&amp;quot; &amp;quot;0,5959457638&amp;quot; &amp;quot;0,4429121533&amp;quot; &amp;quot;0,558387159&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,6241767189&amp;quot; &amp;quot;0,031324594&amp;quot; &amp;quot;0,2238059868&amp;quot; &amp;quot;0,2773350732&amp;quot; ...
##  $ data_2:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,9098418493&amp;quot; &amp;quot;0,1127788509&amp;quot; &amp;quot;0,5818891392&amp;quot; &amp;quot;0,1011773532&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,7455905887&amp;quot; &amp;quot;0,4015039612&amp;quot; &amp;quot;0,6625796605&amp;quot; &amp;quot;0,029955339&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,327232932&amp;quot; &amp;quot;0,2784035673&amp;quot; &amp;quot;0,8092386735&amp;quot; &amp;quot;0,1216045306&amp;quot; ...
##  $ data_3:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,9236124896&amp;quot; &amp;quot;0,6303271761&amp;quot; &amp;quot;0,6413583054&amp;quot; &amp;quot;0,5573887416&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,2114708388&amp;quot; &amp;quot;0,6984538266&amp;quot; &amp;quot;0,0469865249&amp;quot; &amp;quot;0,9271510226&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,4941919971&amp;quot; &amp;quot;0,7391538511&amp;quot; &amp;quot;0,3876723797&amp;quot; &amp;quot;0,2815014394&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You see that all these datasets have the same column names. We can now merge them using this simple function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;multi_join &amp;lt;- function(list_of_loaded_data, join_func, ...){

    require(&amp;quot;dplyr&amp;quot;)

    output &amp;lt;- Reduce(function(x, y) {join_func(x, y, ...)}, list_of_loaded_data)

    return(output)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function uses &lt;code&gt;Reduce()&lt;/code&gt;. &lt;code&gt;Reduce()&lt;/code&gt; is a very important function that can be found in all functional programming languages. What does &lt;code&gt;Reduce()&lt;/code&gt; do? Let’s take a look at the following example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Reduce(`+`, c(1, 2, 3, 4, 5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Reduce()&lt;/code&gt; has several arguments, but you need to specify at least two: a function, here &lt;code&gt;+&lt;/code&gt; and a list, here &lt;code&gt;c(1, 2, 3, 4, 5)&lt;/code&gt;. The next code block shows what &lt;code&gt;Reduce()&lt;/code&gt; basically does:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;0 + c(1, 2, 3, 4, 5)
0 + 1 + c(2, 3, 4, 5)
0 + 1 + 2 + c(3, 4, 5)
0 + 1 + 2 + 3 + c(4, 5)
0 + 1 + 2 + 3 + 4 + c(5)
0 + 1 + 2 + 3 + 4 + 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;0&lt;/code&gt; had to be added as in “init”. You can also specify this “init” to &lt;code&gt;Reduce()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Reduce(`+`, c(1, 2, 3, 4, 5), init = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 35&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So what &lt;code&gt;multi_join()&lt;/code&gt; does, is the same operation as in the example above, but where the function is a user supplied join or merge function, and the list of datasets is the one read with &lt;code&gt;read_list()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s see what happens when we use &lt;code&gt;multi_join()&lt;/code&gt; on our list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;merged_data &amp;lt;- multi_join(list_of_data_sets, full_join)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(merged_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(merged_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 57
## Variables: 3
## $ col1 &amp;lt;chr&amp;gt; &amp;quot;0,018930679&amp;quot;, &amp;quot;0,8748013128&amp;quot;, &amp;quot;0,1025635934&amp;quot;, &amp;quot;0,6246140...
## $ col2 &amp;lt;chr&amp;gt; &amp;quot;0,0377725807&amp;quot;, &amp;quot;0,5959457638&amp;quot;, &amp;quot;0,4429121533&amp;quot;, &amp;quot;0,558387...
## $ col3 &amp;lt;chr&amp;gt; &amp;quot;0,6241767189&amp;quot;, &amp;quot;0,031324594&amp;quot;, &amp;quot;0,2238059868&amp;quot;, &amp;quot;0,2773350...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should make sure that all the data frames have the same column names but you can also join data frames with different column names if you give the argument &lt;code&gt;by&lt;/code&gt; to the join function. This is possible thanks to &lt;code&gt;...&lt;/code&gt; that allows you to pass further argument to &lt;code&gt;join_func()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This function was inspired by the one found on the blog &lt;a href=&#34;http://novicemetrics.blogspot.lu/2011/04/merging-multiple-data-files-into-one.html&#34;&gt;Coffee and Econometrics in the Morning&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Read a lot of datasets at once with R</title>
      <link>https://www.brodrigues.co/blog/2016-07-26-read-a-lot-of-datasets-at-once-with-r/</link>
      <pubDate>Tue, 26 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-07-26-read-a-lot-of-datasets-at-once-with-r/</guid>
      <description>&lt;p&gt;I often have to read a lot of datasets at once using R. So I’ve wrote the following function to solve this issue:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_list &amp;lt;- function(list_of_datasets, read_func){

        read_and_assign &amp;lt;- function(dataset, read_func){
                dataset_name &amp;lt;- as.name(dataset)
                dataset_name &amp;lt;- read_func(dataset)
        }

        # invisible is used to suppress the unneeded output
        output &amp;lt;- invisible(
                sapply(list_of_datasets,
                           read_and_assign, read_func = read_func, simplify = FALSE, USE.NAMES = TRUE))

        # Remove the extension at the end of the data set names
        names_of_datasets &amp;lt;- c(unlist(strsplit(list_of_datasets, &amp;quot;[.]&amp;quot;))[c(T, F)])
        names(output) &amp;lt;- names_of_datasets
        return(output)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You need to supply a list of datasets as well as the function to read the datasets to &lt;code&gt;read_list&lt;/code&gt;. So for example to read in &lt;code&gt;.csv&lt;/code&gt; files, you could use &lt;code&gt;read.csv()&lt;/code&gt; (or &lt;code&gt;read_csv()&lt;/code&gt; from the &lt;code&gt;readr&lt;/code&gt; package, which I prefer to use), or &lt;code&gt;read_dta()&lt;/code&gt; from the package &lt;code&gt;haven&lt;/code&gt; for STATA files, and so on.&lt;/p&gt;
&lt;p&gt;Now imagine you have some data in your working directory. First start by saving the name of the datasets in a variable:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_files &amp;lt;- list.files(pattern = &amp;quot;.csv&amp;quot;)

print(data_files)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data_1.csv&amp;quot; &amp;quot;data_2.csv&amp;quot; &amp;quot;data_3.csv&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you can read all the data sets and save them in a list with &lt;code&gt;read_list()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;readr&amp;quot;)
library(&amp;quot;tibble&amp;quot;)

list_of_data_sets &amp;lt;- read_list(data_files, read_csv)


glimpse(list_of_data_sets)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 3
##  $ data_1:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,018930679&amp;quot; &amp;quot;0,8748013128&amp;quot; &amp;quot;0,1025635934&amp;quot; &amp;quot;0,6246140983&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,0377725807&amp;quot; &amp;quot;0,5959457638&amp;quot; &amp;quot;0,4429121533&amp;quot; &amp;quot;0,558387159&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,6241767189&amp;quot; &amp;quot;0,031324594&amp;quot; &amp;quot;0,2238059868&amp;quot; &amp;quot;0,2773350732&amp;quot; ...
##  $ data_2:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,9098418493&amp;quot; &amp;quot;0,1127788509&amp;quot; &amp;quot;0,5818891392&amp;quot; &amp;quot;0,1011773532&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,7455905887&amp;quot; &amp;quot;0,4015039612&amp;quot; &amp;quot;0,6625796605&amp;quot; &amp;quot;0,029955339&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,327232932&amp;quot; &amp;quot;0,2784035673&amp;quot; &amp;quot;0,8092386735&amp;quot; &amp;quot;0,1216045306&amp;quot; ...
##  $ data_3:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:  19 obs. of  3 variables:
##   ..$ col1: chr [1:19] &amp;quot;0,9236124896&amp;quot; &amp;quot;0,6303271761&amp;quot; &amp;quot;0,6413583054&amp;quot; &amp;quot;0,5573887416&amp;quot; ...
##   ..$ col2: chr [1:19] &amp;quot;0,2114708388&amp;quot; &amp;quot;0,6984538266&amp;quot; &amp;quot;0,0469865249&amp;quot; &amp;quot;0,9271510226&amp;quot; ...
##   ..$ col3: chr [1:19] &amp;quot;0,4941919971&amp;quot; &amp;quot;0,7391538511&amp;quot; &amp;quot;0,3876723797&amp;quot; &amp;quot;0,2815014394&amp;quot; ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you prefer not to have the datasets in a list, but rather import them into the global environment, you can change the above function like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_list &amp;lt;- function(list_of_datasets, read_func){

        read_and_assign &amp;lt;- function(dataset, read_func){
                assign(dataset, read_func(dataset), envir = .GlobalEnv)
        }

        # invisible is used to suppress the unneeded output
        output &amp;lt;- invisible(
                sapply(list_of_datasets,
                           read_and_assign, read_func = read_func, simplify = FALSE, USE.NAMES = TRUE))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But I personnally don’t like this second option, but I put it here for completeness.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data frame columns as arguments to dplyr functions</title>
      <link>https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;Suppose that you would like to create a function which does a series of computations on a data frame. You would like to pass a column as this function’s argument. Something like:&lt;/p&gt;

&lt;p&gt;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(cars)
convertToKmh &amp;lt;- function(dataset, col_name){
  dataset$col_name &amp;lt;- dataset$speed * 1.609344
  return(dataset)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example is obviously not very interesting (you don’t need a function for this), but it will illustrate the point. You would like to append a column called &lt;code&gt;speed_in_kmh&lt;/code&gt; with the speed in kilometers per hour to this dataset, but this is what happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(convertToKmh(cars, &amp;quot;speed_in_kmh&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   speed dist  col_name
1     4    2  6.437376
2     4   10  6.437376
3     7    4 11.265408
4     7   22 11.265408
5     8   16 12.874752
6     9   10 14.484096&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your column is not called &lt;code&gt;speed_in_kmh&lt;/code&gt; but &lt;code&gt;col_name&lt;/code&gt;! It turns out that there is a very simple solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;convertToKmh &amp;lt;- function(dataset, col_name){
  dataset[col_name] &amp;lt;- dataset$speed * 1.609344
  return(dataset)
}&lt;/p&gt;

&lt;p&gt;head(convertToKmh(cars, &amp;quot;speed_in_kmh&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   speed dist speed_in_kmh
1     4    2     6.437376
2     4   10     6.437376
3     7    4    11.265408
4     7   22    11.265408
5     8   16    12.874752
6     9   10    14.484096&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can access columns with &lt;code&gt;[]&lt;/code&gt; instead of &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But sometimes you want to do more complex things and for example have a function that groups by a variable and then computes new variables, filters by another and so on. You would like to avoid having to hard code these variables in your function, because then why write a function and of course you would like to use &lt;code&gt;dplyr&lt;/code&gt; to do it.&lt;/p&gt;
&lt;p&gt;I often use &lt;code&gt;dplyr&lt;/code&gt; functions in my functions. For illustration purposes, consider this very simple function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name){
  require(&amp;quot;dplyr&amp;quot;)
  dataset %&amp;gt;%
    group_by(col_name) %&amp;gt;%
    summarise(mean_speed = mean(speed)) -&amp;gt; dataset
  return(dataset)
}&lt;/p&gt;

&lt;p&gt;simpleFunction(cars, &amp;quot;dist&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes a dataset as an argument, as well as a column name. However, this does not work. You get this error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error: unknown variable to group by : col_name &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable &lt;code&gt;col_name&lt;/code&gt; is passed to &lt;code&gt;simpleFunction()&lt;/code&gt; as a string, but &lt;code&gt;group_by()&lt;/code&gt; requires a variable name. So why not try to convert &lt;code&gt;col_name&lt;/code&gt; to a name?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name){
  require(&amp;quot;dplyr&amp;quot;)
  col_name &amp;lt;- as.name(col_name)
  dataset %&amp;gt;%
    group_by(col_name) %&amp;gt;%
    summarise(mean_speed = mean(speed)) -&amp;gt; dataset
  return(dataset)
}&lt;/p&gt;

&lt;p&gt;simpleFunction(cars, &amp;quot;dist&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You get the same error as before:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error: unknown variable to group by : col_name &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how can you pass a column name to &lt;code&gt;group_by()&lt;/code&gt;? Well, there is another version of &lt;code&gt;group_by()&lt;/code&gt; called &lt;code&gt;group_by_()&lt;/code&gt; that uses standard evaluation. You can learn more about it &lt;a href=&#34;https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html&#34;&gt;here&lt;/a&gt;. Let’s take a look at what happens when we use &lt;code&gt;group_by_()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name){
  require(&amp;quot;dplyr&amp;quot;)
  dataset %&amp;gt;%
    group_by_(col_name) %&amp;gt;%
    summarise(mean_speed = mean(speed)) -&amp;gt; dataset
  return(dataset)
}&lt;/p&gt;

&lt;p&gt;simpleFunction(cars, &amp;quot;dist&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;A tibble: 35 x 2
 dist mean_speed
&amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
1      2        4.0
2      4        7.0
3     10        6.5
4     14       12.0
5     16        8.0
6     17       11.0
7     18       10.0
8     20       13.5
9     22        7.0
10    24       12.0
 &amp;hellip; with 25 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can even use a formula instead of a string:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction(cars, ~dist)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; A tibble: 35 x 2
    dist mean_speed
   &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
1      2        4.0
2      4        7.0
3     10        6.5
4     14       12.0
5     16        8.0
6     17       11.0
7     18       10.0
8     20       13.5
9     22        7.0
10    24       12.0
&amp;hellip; with 25 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What if you want to pass column names and constants, for example to filter without hardcoding anything?&lt;/p&gt;
&lt;p&gt;Trying to do it naively will only yield pain and despair:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name, value){
  require(&amp;quot;dplyr&amp;quot;)
  dataset %&amp;gt;%
    filter_(col_name == value) %&amp;gt;%
    summarise(mean_speed = mean(speed)) -&amp;gt; dataset
  return(dataset)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; simpleFunction(cars, &amp;quot;dist&amp;quot;, 10)&lt;/p&gt;

&lt;p&gt;mean_speed
1        NaN&lt;/p&gt;

&lt;p&gt;&amp;gt; simpleFunction(cars, dist, 10)&lt;/p&gt;

&lt;p&gt;Error in col_name == value :
  comparison (1) is possible only for atomic and list types&lt;/p&gt;

&lt;p&gt;&amp;gt; simpleFunction(cars, ~dist, 10)&lt;/p&gt;

&lt;p&gt;mean_speed
1        NaN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve this issue, we need to know a little bit about two concepts, &lt;em&gt;lazy evaluation&lt;/em&gt; and &lt;em&gt;non-standard evaluation&lt;/em&gt;. I recommend you read &lt;a href=&#34;http://adv-r.had.co.nz/Computing-on-the-language.html&#34;&gt;the following document&lt;/a&gt; from Hadley Wickham’s book &lt;em&gt;Advanced R&lt;/em&gt; as well as the part on lazy evaluation &lt;a href=&#34;http://adv-r.had.co.nz/Functions.html#function-arguments&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A nice package called &lt;code&gt;lazyeval&lt;/code&gt; can help us out. We would like to make R understand that the column name is not &lt;code&gt;col_name&lt;/code&gt; but the string inside it &lt;code&gt;&amp;quot;dist&amp;quot;&lt;/code&gt;, and now we would like to use &lt;code&gt;filter()&lt;/code&gt; for &lt;code&gt;dist&lt;/code&gt; equal to &lt;code&gt;10&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;lazyeval&lt;/code&gt; package, you’ll find the function &lt;code&gt;interp()&lt;/code&gt;. &lt;code&gt;interp()&lt;/code&gt; allows you to&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;build an expression up from a mixture of constants and variables.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Take a look at this example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lazyeval)
interp(~x+y, x = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ~2 + y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What you get back is this nice formula that you can then use within functions. To see why this is useful, let’s look at the above example again, and make it work using &lt;code&gt;interp()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simpleFunction &amp;lt;- function(dataset, col_name, value){
  require(&amp;quot;dplyr&amp;quot;)
  require(&amp;quot;lazyeval&amp;quot;)
  filter_criteria &amp;lt;- interp(~y == x, .values=list(y = as.name(col_name), x = value))
  dataset %&amp;gt;%
    filter_(filter_criteria) %&amp;gt;%
    summarise(mean_speed = mean(speed)) -&amp;gt; dataset
  return(dataset)
}&lt;/p&gt;

&lt;p&gt;simpleFunction(cars, &amp;quot;dist&amp;quot;, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;  mean_speed
1        6.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now it works! For some reason, you have to pass the column name as a string though.&lt;/p&gt;
&lt;p&gt;Sources: apart from the documents above, the following stackoverflow threads helped me out quite a lot: &lt;a href=&#34;http://stackoverflow.com/questions/28973056/in-r-pass-column-name-as-argument-and-use-it-in-function-with-dplyrmutate-a&#34;&gt;In R: pass column name as argument and use it in function with dplyr::mutate() and lazyeval::interp()&lt;/a&gt; and &lt;a href=&#34;http://stackoverflow.com/questions/26492280/non-standard-evaluation-nse-in-dplyrs-filter-pulling-data-from-mysql&#34;&gt;Non-standard evaluation (NSE) in dplyr’s filter_ &amp;amp; pulling data from MySQL&lt;/a&gt;.&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Careful with tryCatch</title>
      <link>https://www.brodrigues.co/blog/2016-06-21-careful-with-trycatch/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-06-21-careful-with-trycatch/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;code&gt;tryCatch&lt;/code&gt; is one of the functions that allows the users to handle errors in a simple way. With it, you can do things like: &lt;code&gt;if(error), then(do this)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Take the following example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(&amp;quot;a&amp;quot;)
Error in sqrt(&amp;quot;a&amp;quot;) : non-numeric argument to mathematical function&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now maybe you’d want something to happen when such an error happens. You can achieve that with &lt;code&gt;tryCatch&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tryCatch(sqrt(&amp;quot;a&amp;quot;), error=function(e) print(&amp;quot;You can&#39;t take the square root of a character, silly!&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;You can&#39;t take the square root of a character, silly!&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why am I interested in &lt;code&gt;tryCatch&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;I am currently working with dates, specifically birthdays of people in my data sets. For a given mother, the birthday of her child is given in three distinct columns: a column for the child’s birth year, birth month and birth day respectively. I’ve wanted to put everything in a single column and convert the birthday to unix time (I have a very good reason to do that, but I won’t bore you with the details).&lt;/p&gt;
&lt;p&gt;Let’s create some data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother &amp;lt;- as.data.frame(list(month=12, day=1, year=1988))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my data, there’s a lot more columns of course, such as the mother’s wage, education level, etc, but for illustration purposes, this is all that’s needed.&lt;/p&gt;
&lt;p&gt;Now, to create this birthday column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother$birth1 &amp;lt;- as.POSIXct(paste0(as.character(mother$year), 
                                   &amp;quot;-&amp;quot;, as.character(mother$month), 
                                   &amp;quot;-&amp;quot;, as.character(mother$day)), 
                            origin=&amp;quot;1970-01-01&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and to convert it to unix time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother$birth1 &amp;lt;- as.numeric(as.POSIXct(paste0(as.character(mother$year), 
                                              &amp;quot;-&amp;quot;, as.character(mother$month), 
                                              &amp;quot;-&amp;quot;, as.character(mother$day)),
                                       origin=&amp;quot;1970-01-01&amp;quot;))

print(mother)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   month day year    birth1
## 1    12   1 1988 596934000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s see what happens in this other example here:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother2 &amp;lt;- as.data.frame(list(month=2, day=30, year=1988))

mother2$birth1 &amp;lt;- as.POSIXct(paste0(as.character(mother2$year), 
                                    &amp;quot;-&amp;quot;, as.character(mother2$month), 
                                    &amp;quot;-&amp;quot;, as.character(mother2$day)), 
                             origin=&amp;quot;1970-01-01&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is what happens:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error in as.POSIXlt.character(x, tz, ...) : 
  character string is not in a standard unambiguous format&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This error is to be expected; there is no 30th of February! It turns out that in some rare cases, weird dates like this exist in my data. Probably some encoding errors. Not a problem I thought, I could use &lt;code&gt;tryCatch&lt;/code&gt; and return &lt;code&gt;NA&lt;/code&gt; in the case of an error.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother2 &amp;lt;- as.data.frame(list(month=2, day=30, year=1988))

mother2$birth1 &amp;lt;- tryCatch(as.POSIXct(paste0(as.character(mother2$year), 
                                    &amp;quot;-&amp;quot;, as.character(mother2$month), 
                                    &amp;quot;-&amp;quot;, as.character(mother2$day)), 
                             origin=&amp;quot;1970-01-01&amp;quot;), error=function(e) NA)

print(mother2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   month day year birth1
## 1     2  30 1988     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretty great, right? Well, no. Take a look at what happens in this case:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother &amp;lt;- as.data.frame(list(month=c(12, 2), day=c(1, 30), year=c(1988, 1987)))
print(mother)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   month day year
## 1    12   1 1988
## 2     2  30 1987&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’d expect to have a correct date for the first mother and an &lt;code&gt;NA&lt;/code&gt; for the second. However, this is what happens&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mother$birth1 &amp;lt;- tryCatch(as.POSIXct(paste0(as.character(mother$year), 
                                    &amp;quot;-&amp;quot;, as.character(mother$month), 
                                    &amp;quot;-&amp;quot;, as.character(mother$day)), 
                             origin=&amp;quot;1970-01-01&amp;quot;), error=function(e) NA)

print(mother)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   month day year birth1
## 1    12   1 1988     NA
## 2     2  30 1987     NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, we now have an &lt;code&gt;NA&lt;/code&gt; for both mothers! That’s actually to be expected. Indeed, this little example illustrates it well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(c(4, 9, &amp;quot;haha&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in sqrt(c(4, 9, &amp;quot;haha&amp;quot;)) : 
  non-numeric argument to mathematical function&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But you’d like to have this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[1]  2  3 NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So you could make the same mistake as myself and use tryCatch:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tryCatch(sqrt(c(4, 9, &amp;quot;haha&amp;quot;)), error=function(e) NA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But you only get &lt;code&gt;NA&lt;/code&gt; in return. That’s actually completely normal, but it took me off-guard and I spent quite some time to figure out what was happening. Especially because I had written unit tests to test my function &lt;code&gt;create_birthdays()&lt;/code&gt; that was doing the above computations and all tests were passing! The problem was that in my tests, I only had a single individual, so for a wrong date, having &lt;code&gt;NA&lt;/code&gt; for this individual was expected behaviour. But in a panel, only some individuals have a weird date like the 30th of February, but because of those, the whole column was filled with &lt;code&gt;NA&lt;/code&gt;’s! What I’m doing now is trying to either remove these weird birthdays (there are mothers whose children were born on the 99-99-9999. Documentation is lacking, but this probably means &lt;code&gt;missing value&lt;/code&gt;), or tyring to figure out how to only get &lt;code&gt;NA&lt;/code&gt;’s for the “weird” dates. I guess that the answer lies with &lt;code&gt;dplyr&lt;/code&gt;’s &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;mutate()&lt;/code&gt; to compute this birthdays for each individual separately.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unit testing with R</title>
      <link>https://www.brodrigues.co/blog/2016-03-31-unit-testing-with-r/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2016-03-31-unit-testing-with-r/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;body&gt;
&lt;p&gt;I&amp;#39;ve been introduced to unit testing while working with colleagues on quite a big project for which
we use Python.&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;At first I was a bit skeptical about the need of writing unit tests, but now I must admit that I 
am seduced by the idea and by the huge time savings it allows. Naturally, I was wondering if the 
same could be achieved with R, and was quite happy to find out that it also possible to write unit
tests in R using a package called &lt;code&gt;testthat&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Unit tests (Not to be confused with unit root tests for time series) are small functions that test
your code and help you make sure everything is alright. I&amp;#39;m going to show how the &lt;code&gt;testthat&lt;/code&gt; 
packages works with a very trivial example, that might not do justice to the idea of
unit testing. But you&amp;#39;ll hopefully see why writing unit tests is not a waste of your time,
especially if your project gets very complex (if you&amp;#39;re writing a package for example).&lt;/p&gt;

&lt;p&gt;First, you&amp;#39;ll need to download and install &lt;code&gt;testthat&lt;/code&gt;. Some dependencies will also be installed.&lt;/p&gt;

&lt;p&gt;Now, you&amp;#39;ll need a function to test. Let&amp;#39;s suppose you&amp;#39;ve written a function that returns the
nth Fibonacci number:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;Fibonacci &amp;lt;- function(n){
    a &amp;lt;- 0
    b &amp;lt;- 1
    for (i in 1:n){
        temp &amp;lt;- b
        b &amp;lt;- a
        a &amp;lt;- a + temp
    }
    return(a)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You then save this function in a file, let&amp;#39;s call it &lt;code&gt;fibo.R&lt;/code&gt;. What you&amp;#39;ll probably do once you&amp;#39;ve
written this function, is to try it out:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;Fibonacci(5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;#39;ll see that the function returns the right result and continue programming. The idea behind
unit testing is write a bunch of functions that you can run after you make changes to your code,
just to check that everything is still running as it should.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s create a script called &lt;code&gt;test_fibo.R&lt;/code&gt; and write the following code in it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;test_that(&amp;quot;Test Fibo(15)&amp;quot;,{
  phi &amp;lt;- (1 + sqrt(5))/2
  psi &amp;lt;- (1 - sqrt(5))/2
  expect_equal(Fibonacci(15), (phi**15 - psi**15)/sqrt(5))
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code above uses Binet&amp;#39;s formula, a closed form formula that gives the nth Fibonacci number and compares it 
our implementation of the algorithm. If you didn&amp;#39;t know about Binet&amp;#39;s formula, you could simply compute some numbers
by hand and compare them to what your function returns, for example. The function &lt;code&gt;expect_equal&lt;/code&gt; is a function from the 
package &lt;code&gt;testthat&lt;/code&gt; and does exactly what it tells. We expect the result of our implementation to be equal to the result of
Binet&amp;#39;s Formula. The file &lt;code&gt;test_fibo.R&lt;/code&gt; can contain as many tests as you need. 
Also, the file that contains the tests must start with the string &lt;code&gt;test&lt;/code&gt;, so that &lt;code&gt;testthat&lt;/code&gt; knows with files it has to run.&lt;/p&gt;

&lt;p&gt;Now, we&amp;#39;re almost done, create yet another script, let&amp;#39;s call it &lt;code&gt;run_tests.R&lt;/code&gt; and write the following code in it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;library(testthat) 

source(&amp;quot;path/to/fibo.R&amp;quot;)

test_results &amp;lt;- test_dir(&amp;quot;path/to/tests&amp;quot;, reporter=&amp;quot;summary&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running these lines, and if everything goes well, you should see a message like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; library(testthat)
&amp;gt; source(&amp;quot;path/to/fibo.R&amp;quot;)
&amp;gt; test_results &amp;lt;- test_dir(&amp;quot;path/to/tests&amp;quot;, reporter=&amp;quot;summary&amp;quot;)

.
Your tests are dandy! 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the small &lt;code&gt;.&lt;/code&gt; over the message? This means that one test was run successfully. You&amp;#39;ll get one dot per successful
test. If you take a look at &lt;code&gt;test_results&lt;/code&gt; you&amp;#39;ll see this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; test_results
         file context          test nb failed skipped error  user system  real
1 test_fibo.R         Test Fibo(15)  1      0   FALSE FALSE 0.004      0 0.006
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;#39;ll see each file and each function inside the files that were tested, and also whether the test was skipped, failed
etc. This may seem overkill for such a simple function, but imagine that you write dozens of functions that get more
and more complex over time. You might have to change a lot of lines because as time goes by you add new functionality,
but don&amp;#39;t want to break what was working. Running your unit tests each time you make changes can help you pinpoint 
regressions in your code. Unit tests can also help you start with your code. It can happen that sometimes you don&amp;#39;t
know exactly how to start; well you could start by writing a unit test that returns the result you want to have and 
then try to write the code to make that unit test pass. This is called test-driven development.&lt;/p&gt;

&lt;p&gt;I hope that this post motivated you to write unit tests and make you a better R programmer!&lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bootstrapping standard errors for difference-in-differences estimation with R</title>
      <link>https://www.brodrigues.co/blog/2015-11-11-bootstrapping-did-with-r/</link>
      <pubDate>Wed, 11 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2015-11-11-bootstrapping-did-with-r/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;body&gt;
&lt;p&gt;I’m currently working on a paper (with my colleague Vincent Vergnat who is also a Phd candidate at BETA) where I want to estimate the causal impact of the birth of a child on hourly and daily wages as well as yearly worked hours. For this we are using non-parametric difference-in-differences (henceforth DiD) and thus have to bootstrap the standard errors. In this post, I show how this is possible using the function &lt;code&gt;boot&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For this we are going to replicate the example from Wooldridge’s &lt;em&gt;Econometric Analysis of Cross Section and Panel Data&lt;/em&gt; and more specifically the example on page 415. You can download the data for R &lt;a href=&#34;https://www.brodrigues.co/assets/files/kielmc.RData&#34;&gt;here&lt;/a&gt;. The question we are going to try to answer is &lt;em&gt;how much does the price of housing decrease due to the presence of an incinerator in the neighborhood?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First put the data in a folder and set the correct working directory and load the &lt;code&gt;boot&lt;/code&gt; library.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(boot)
setwd(&amp;quot;/home/path/to/data/kiel data/&amp;quot;)
load(&amp;quot;kielmc.RData&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you need to write a function that takes the data as an argument, as well as an indices argument. This argument is used by the &lt;code&gt;boot&lt;/code&gt; function to select samples. This function should return the statistic you’re interested in, in our case, the DiD estimate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;run_DiD &amp;lt;- function(my_data, indices){
    d &amp;lt;- my_data[indices,]
    return(
        mean(d$rprice[d$year==1981 &amp;amp; d$nearinc==1]) -
        mean(d$rprice[d$year==1981 &amp;amp; d$nearinc==0]) -
        (mean(d$rprice[d$year==1978 &amp;amp; d$nearinc==1]) -
        mean(d$rprice[d$year==1978 &amp;amp; d$nearinc==0]))
    )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’re almost done! To bootstrap your DiD estimate you just need to use the boot function. If you have cpu with multiple cores (which you should, single core machines are quite outdated by now) you can even parallelize the bootstrapping.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_est &amp;lt;- boot(data, run_DiD, R=1000, parallel=&amp;quot;multicore&amp;quot;, ncpus = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now you should just take a look at your estimates:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_est&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
ORDINARY NONPARAMETRIC BOOTSTRAP&lt;/p&gt;

&lt;p&gt;Call:
boot(data = data, statistic = run_DiD, R = 1000, parallel = &amp;quot;multicore&amp;quot;,
 ncpus = 2)&lt;/p&gt;

&lt;p&gt;Bootstrap Statistics :
 original    bias    std. error
t1* -11863.9 -553.3393    8580.435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These results are very similar to the ones in the book, only the standard error is higher.&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;You can get confidence intervals like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(boot_est$t, c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       2.5%      97.5% 
## -30186.397   3456.133&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or a t-statistic:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_est$t0/sd(boot_est$t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -1.382669&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or the density of the replications:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(density(boot_est$t))&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;https://www.brodrigues.co/img/density_did.png&#34; width=&#34;670&#34; height=&#34;450&#34; /&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Just as in the book, we find that the DiD estimate is not significant to the 5% level.&lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Update to Introduction to programming econometrics with R</title>
      <link>https://www.brodrigues.co/blog/2015-05-03-update-introduction-r-programming/</link>
      <pubDate>Sun, 03 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2015-05-03-update-introduction-r-programming/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;This semester I taught a course on applied econometrics with the R programming language. For this, I created a document that I gave to my students and shared online. This is the kind of document I would have liked to read when I first started using R. I already had some programming experience in C and Pascal but this is not necessarily the case for everyone that is confronted to R when they start learning about econometrics.&lt;/p&gt;

&lt;p&gt;This is why the beginning of the document focuses more on general programming knowledge and techniques, and then only on econometrics. People online seemed to like the document, as I&amp;rsquo;ve received some positive comments by David Smith from Revolution R (read his blog post about the document &lt;a href=&#34;http://blog.revolutionanalytics.com/2015/01/introduction-to-applied-econometrics-with-r.html&#34;&gt;here&lt;/a&gt;) and Dave Giles which links to David&amp;rsquo;s blog post &lt;a href=&#34;http://davegiles.blogspot.fr/2015/04/introduction-to-applied-econometrics.html?spref=tw&#34;&gt;here&lt;/a&gt;. People on twitter have also retweeted David&amp;rsquo;s and Dave&amp;rsquo;s tweets to their blog posts and I&amp;rsquo;ve received some requests by people to send them the PDF by email (because they live in places where Dropbox is not accessible unfortunately).&lt;/p&gt;

&lt;p&gt;The document is still a work in progress (and will probably remain so for a long time), but I&amp;rsquo;ve added some new sections about reproducible research and thought that this update could warrant a new blog post.&lt;/p&gt;

&lt;p&gt;For now, only linear models are reviewed, but I think I&amp;rsquo;ll start adding some chapters about non-linear models soonish. The goal for these notes, however, is not to re-invent the wheel: there are lots of good books about econometrics with R out there and packages that estimate a very wide range of models. What I want for these notes, is to focus more on the programming knowledge an econometrician needs, in a very broad and general sense. I want my students to understand that R is a true programming language, and that they need to use every feature offered by such a language, and not think of R as a black box into which you only type pre-programmed commands, but also be able to program their own routines.&lt;/p&gt;

&lt;p&gt;Also, I&amp;rsquo;ve made it possible to create the PDF using a Makefile. This may be useful for people that do not have access to Dropbox, but are familiar with git.&lt;/p&gt;

&lt;p&gt;You can compile the book in two ways: first download the whole repository:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git clone git@bitbucket.org:b-rodrigues/programmingeconometrics.git&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and then, with Rstudio, open the file &lt;em&gt;appliedEconometrics.Rnw&lt;/em&gt; and knit it. Another solution is to use the Makefile. Just type:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;make&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;inside a terminal (should work on GNU+Linux and OSX systems) and it should compile the document. You may get some message about &amp;ldquo;additional information&amp;rdquo; for some R packages. When these come up, just press Q on your keyboard to continue the compilation process.&lt;/p&gt;

&lt;p&gt;Get the notes &lt;a href=&#34;https://cloud.openmailbox.org/index.php/s/ghZwBxMb24tWGSL&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As always, if you have questions or suggestions, do not hesitate to send me an  &lt;a href=&#34;mailto:contact@brodrigues.co&#34;&gt;email&lt;/a&gt; and I sure hope you&amp;rsquo;ll find these notes useful!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Export R output to a file</title>
      <link>https://www.brodrigues.co/blog/2015-02-22-export-r-output-to-file/</link>
      <pubDate>Sun, 22 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2015-02-22-export-r-output-to-file/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;body&gt;&lt;/p&gt;

&lt;p&gt;Sometimes it is useful to export the output of a long-running R command. For example, you might want to run a time consuming regression just before leaving work on Friday night, but would like to get the output saved inside your Dropbox folder to take a look at the results before going back to work on Monday.&lt;/p&gt;
&lt;p&gt;This can be achieved very easily using &lt;code&gt;capture.output()&lt;/code&gt; and &lt;code&gt;cat()&lt;/code&gt; like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;out &amp;lt;- capture.output(summary(my_very_time_consuming_regression))

cat(&amp;quot;My title&amp;quot;, out, file=&amp;quot;summary_of_my_very_time_consuming_regression.txt&amp;quot;, sep=&amp;quot;\n&amp;quot;, append=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;my_very_time_consuming_regression&lt;/code&gt; is an object of class &lt;code&gt;lm&lt;/code&gt; for example. I save the output of &lt;code&gt;summary(my_very_time_consuming_regression)&lt;/code&gt; as text using &lt;code&gt;capture.output&lt;/code&gt; and save it in a variable called &lt;code&gt;out&lt;/code&gt;. Finally, I save &lt;code&gt;out&lt;/code&gt; to a file called &lt;code&gt;summary_of_my_very_time_consuming_regression.txt&lt;/code&gt; with the first sentence being &lt;code&gt;My title&lt;/code&gt; (you can put anything there). The file &lt;code&gt;summary_of_my_very_time_consuming_regression.txt&lt;/code&gt; doesn’t have to already exist in your working directory. The option &lt;code&gt;sep=&amp;quot;\n&amp;quot;&lt;/code&gt; is important or else the whole output will be written in a single line. Finally, &lt;code&gt;append=TRUE&lt;/code&gt; makes sure your file won’t be overwritten; additional output will be appended to the file, which can be nice if you want to compare different versions of your model.&lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to programming econometrics with R</title>
      <link>https://www.brodrigues.co/blog/2015-01-12-introduction-to-programming-econometrics-with-r/</link>
      <pubDate>Mon, 12 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2015-01-12-introduction-to-programming-econometrics-with-r/</guid>
      <description>

&lt;p&gt;This semester, I&amp;rsquo;ll be teaching an introduction to applied econometrics with R, so I&amp;rsquo;ve decided to write a very small book called &amp;ldquo;Introduction to programming Econometrics with R&amp;rdquo;. This is primarily intended for bachelor students and the focus is not much on econometric theory, but more on how to implement econometric theory into computer code, using the R programming language. It&amp;rsquo;s very basic and doesn&amp;rsquo;t cover any advanced topics in econometrics and is intended for people with 0 previous programming knowledge. It is still very rough around the edges, and it&amp;rsquo;s missing the last chapter about reproducible research, and the references, but I think it&amp;rsquo;s time to put it out there; someone else than my students may find it useful. The book&amp;rsquo;s probably full of typos and mistakes, so don&amp;rsquo;t hesitate to drop me an e-mail if you find something fishy:
contact@brodrigues.co&lt;/p&gt;

&lt;p&gt;Also there might be some sections at the beginning that only concern my students. Just ignore that.&lt;/p&gt;

&lt;p&gt;Get it here: &lt;a href=&#34;https://cloud.openmailbox.org/index.php/s/ghZwBxMb24tWGSL&#34;&gt;download&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;update-2017-01-22&#34;&gt;Update (2017-01-22)&lt;/h3&gt;

&lt;p&gt;You might find the book useful as it is now, but I never had a chance to finish it. I might get back to
it once I&amp;rsquo;ll have more time, and port it to bookdown.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R, R with Atlas, R with OpenBLAS and Revolution R Open: which is fastest?</title>
      <link>https://www.brodrigues.co/blog/2014-11-11-benchmarks-r-blas-atlas-rro/</link>
      <pubDate>Tue, 11 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2014-11-11-benchmarks-r-blas-atlas-rro/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;body&gt;&lt;/p&gt;

&lt;p&gt;In this short post, I benchmark different &amp;ldquo;versions&amp;rdquo; of R. I compare the execution speeds of R, R linked against OpenBLAS, R linked against ATLAS and Revolution R Open. Revolution R Open is a new open source version of R made by Revolution Analytics. It is linked against MKL and should offer huge speed improvements over vanilla R. Also, it uses every cores of your computer by default, without any change whatsoever to your code.&lt;/p&gt;

&lt;p&gt;TL;DR: Revolution R Open is the fastest of all the benchmarked versions (with R linked against OpenBLAS and ATLAS just behind), and easier to setup. &lt;/p&gt;

&lt;h2&gt;Setup&lt;/h2&gt;

&lt;p&gt;I benchmarked these different versions of R using &lt;code&gt;R-benchmark-25.R&lt;/code&gt; that you can download &lt;a href=&#34;http://r.research.att.com/benchmarks/R-benchmark-25.R&#34;&gt;here&lt;/a&gt;. This benchmark file was created by Simon Urbanek.&lt;/p&gt;

&lt;p&gt;I ran the benchmarks on my OpenSUSE 13.2 computer with a Pentium Dual-Core CPU E6500@2.93GHz with 4GB of Ram. It&amp;#39;s outdated, but it&amp;#39;s still quite fast for most of my numerical computation needs. I installed &amp;ldquo;vanilla&amp;rdquo; R from the official OpenSUSE repositories which is currently at version 3.1.2.&lt;/p&gt;

&lt;p&gt;Then, I downloaded OpenBLAS and ATLAS also from the official OpenSUSE repositories and made R use these libraries instead of its own implementation of BLAS. The way I did that is a bit hacky, but works: first, go to &lt;code&gt;/usr/lib64/R/lib&lt;/code&gt; and backup &lt;code&gt;libRblas.so&lt;/code&gt; (rename it to &lt;code&gt;libRblas.soBackup&lt;/code&gt; for instance). Then link &lt;code&gt;/usr/lib64/libopenblas.so.0&lt;/code&gt; to &lt;code&gt;/usr/lib64/R/lib/libRblas&lt;/code&gt;, and that&amp;#39;s it, R will use OpenBLAS. For ATLAS, you can do it in the same fashion, but you&amp;#39;ll find the library in &lt;code&gt;/usr/lib64/atlas/&lt;/code&gt;. These paths should be the same for any GNU/Linux distribution. For other operating systems, I&amp;#39;m sure you can find where these libraries are with Google.&lt;/p&gt;

&lt;p&gt;The last version I benchmarked was Revolution R Open. This is a new version of R released by Revolution Analytics. Revolution Analytics had their own version of R, called Revolution R, for quite some time now. They decided to release a completely free as in freedom and free as in free beer version of this product which they now renamed Revolution R Open. You can download Revolution R Open &lt;a href=&#34;http://mran.revolutionanalytics.com/download/#review&#34;&gt;here&lt;/a&gt;. You can have both &amp;ldquo;vanilla&amp;rdquo; R and Revolution R Open installed on your system. &lt;/p&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;I ran the &lt;code&gt;R-benchmark-25.R&lt;/code&gt; 6 times for every version but will only discuss the 4 best runs.&lt;/p&gt;

&lt;p&gt;&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 11px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 11px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-0ord{text-align:right}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
&lt;tr&gt;
&lt;th class=&#34;tg-031e&#34;&gt;R version&lt;/th&gt;
&lt;th class=&#34;tg-0ord&#34;&gt;Fastest run&lt;/th&gt;
&lt;th class=&#34;tg-0ord&#34;&gt;Slowest run&lt;/th&gt;
&lt;th class=&#34;tg-0ord&#34;&gt;Mean Run&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tg-031e&#34;&gt;Vanilla R&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;63.65&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;66.21&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;64.61&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tg-031e&#34;&gt;OpenBLAS R&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;15.63&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;18.96&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;16.94&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tg-031e&#34;&gt;ATLAS R&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;16.92&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;21.57&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;18.24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tg-031e&#34;&gt;RRO&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;14.96&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;16.08&lt;/td&gt;
&lt;td class=&#34;tg-0ord&#34;&gt;15.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;As you can read from the table above, Revolution R Open was the fastest of the four versions, but not significantly faster than BLAS or ATLAS R. However, RRO uses all the available cores by default, so if your code relies on a lot matrix algebra, RRO might be actually a lot more faster than OpenBLAS and ATLAS R. Another advantage of RRO is that it is very easy to install, and also works with Rstudio and is compatible with every R package to existence. &#34;Vanilla&#34; R is much slower than the other three versions, more than 3 times as slow! &lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;With other benchmarks, you could get other results, but I don&#39;t think that &#34;vanilla&#34; R could beat any of the other three versions. Whatever your choice, I recommend not using plain, &amp;ldquo;vanilla&amp;rdquo; R. The other options are much faster than standard R, and don&amp;#39;t require much work to set up. I&amp;#39;d personally recommend Revolution R Open, as it is free software and compatible with CRAN packages and Rstudio. &lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Object Oriented Programming with R: An example with a Cournot duopoly</title>
      <link>https://www.brodrigues.co/blog/2014-04-23-r-s4-rootfinding/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2014-04-23-r-s4-rootfinding/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;body&gt;
&lt;p&gt;I started reading &lt;em&gt;Applied Computational Economics &amp;amp; Finance&lt;/em&gt; by Mario J. Miranda and Paul L. Fackler. It is a very interesting book that I recommend to every one of my colleagues. The only issue I have with this book, is that the programming language they use is Matlab, which is proprietary. While there is a free as in freedom implementation of the Matlab language, namely Octave, I still prefer using R. In this post, I will illustrate one example the authors present in the book with R, using the package &lt;code&gt;rootSolve&lt;/code&gt;. &lt;code&gt;rootSolve&lt;/code&gt; implements Newtonian algorithms to find roots of functions; to specify the functions for which I want the roots, I use R&amp;#39;s Object-Oriented Programming (OOP) capabilities to build a model that returns two functions. This is optional, but I found that it was a good example to illustrate OOP, even though simpler solutions exist, one of which was proposed by reddit user TheDrownedKraken (whom I thank) and will be presented at the end of the article.&lt;/p&gt;&lt;/p&gt;

&lt;h3&gt;Theoretical background&lt;/h3&gt;

&lt;p&gt;The example is taken from Miranda&amp;#39;s and Fackler&amp;#39;s book, on page 35. The authors present a Cournot duopoly model. In a Cournot duopoly model, two firms compete against each other by quantities. Both produce a certain quantity of an homogenous good, and take the quantity produce by their rival as given. &lt;/p&gt;

&lt;p&gt;The inverse demand of the good is :&lt;/p&gt;

&lt;p&gt;$$P(q) = q^{-\dfrac{1}{\eta}}$$&lt;/p&gt;

&lt;p&gt;the cost function for firm i is:&lt;/p&gt;

&lt;p&gt;$$C_i(q_i) = P(q_1+q_2)*q_i - C_i(q_i)$$&lt;/p&gt;

&lt;p&gt;and the profit for firm i:&lt;/p&gt;

&lt;p&gt;$$\pi_i(q1,q2) = P(q_1+q_2)q_i - C_i(q_i)$$&lt;/p&gt;

&lt;p&gt;The optimality condition for firm i is thus:&lt;/p&gt;

&lt;p&gt;$$\dfrac{\partial \pi_i}{\partial q_i} = (q1+q2)^{-\dfrac{1}{\eta}} - \dfrac{1}{\eta} (q_1+q_2)^{\dfrac{-1}{\eta-1}}q_i - c_iq_i=0.$$&lt;/p&gt;

&lt;h3&gt;Implementation in R&lt;/h3&gt;

&lt;p&gt;If we want to find the optimal quantities \(q_1\) and \(q_2\) we need to program the optimality condition and we could also use the jacobian of the optimality condition. The jacobian is generally useful to speed up the root finding routines. This is were OOP is useful. First let&amp;#39;s create a new class, called &lt;em&gt;Model&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;setClass(Class = &amp;quot;Model&amp;quot;, slots = list(OptimCond = &amp;quot;function&amp;quot;, JacobiOptimCond = &amp;quot;function&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This new class has two &lt;em&gt;slots&lt;/em&gt;, which here are functions (in general &lt;em&gt;slots&lt;/em&gt; are properties of your class); we need the model to return the optimality condition and the jacobian of the optimality condition.&lt;/p&gt;

&lt;p&gt;Now we can create a function which will return these two functions for certain values of the parameters, &lt;em&gt;c&lt;/em&gt; and  &lt;img src=&#34;http://latex.codecogs.com/png.latex?\inline \eta&#34; alt=&#34;\inline \eta&#34; /&gt; of the model:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_mod &amp;lt;- function(eta, c) {
    e = -1/eta

    OptimCond &amp;lt;- function(q) {
        return(sum(q)^e + e * sum(q)^(e - 1) * q - diag(c) %*% q)
    }

    JacobiOptimCond &amp;lt;- function(q) {
        return((e * sum(q)^e) * array(1, c(2, 2)) + (e * sum(q)^(e - 1)) * diag(1, 
            2) + (e - 1) * e * sum(q)^(e - 2) * q * c(1, 1) - diag(c))
    }

    return(new(&amp;quot;Model&amp;quot;, OptimCond = OptimCond, JacobiOptimCond = JacobiOptimCond))

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function &lt;code&gt;my_mod&lt;/code&gt; takes two parameters, &lt;code&gt;eta&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; and returns two functions, the optimality condition and the jacobian of the optimality condition. Both are now accessible via &lt;code&gt;my_mod(eta=1.6,c = c(0.6,0.8))@OptimCond&lt;/code&gt; and &lt;code&gt;my_mod(eta=1.6,c = c(0.6,0.8))@JacobiOptimCond&lt;/code&gt; respectively (and by specifying values for &lt;code&gt;eta&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Now, we can use the &lt;code&gt;rootSolve&lt;/code&gt; package to get the optimal values \(q_1\) and \(q_2\) &lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;library(&amp;quot;rootSolve&amp;quot;)

multiroot(f = my_mod(eta = 1.6, c = c(0.6, 0.8))@OptimCond, start = c(1, 1), 
    maxiter = 100, jacfunc = my_mod(eta = 1.6, c = c(0.6, 0.8))@JacobiOptimCond)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $root
## [1] 0.8396 0.6888
## 
## $f.root
##            [,1]
## [1,] -2.220e-09
## [2,]  9.928e-09
## 
## $iter
## [1] 4
## 
## $estim.precis
## [1] 6.074e-09
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After 4 iterations, we get that  &lt;img src=&#34;http://latex.codecogs.com/png.latex?\inline q_1&#34; alt=&#34;\inline q_1&#34; /&gt;  and  &lt;img src=&#34;http://latex.codecogs.com/png.latex?\inline q_2&#34; alt=&#34;\inline q_2&#34; /&gt; are equal to 0.84 and 0.69 respectively, which are the same values as in the book!&lt;/p&gt;

&lt;h3&gt;Suggestion by Reddit user, TheDrownedKraken&lt;/h3&gt;

&lt;p&gt;I posted this blog post on the rstats subbreddit on &lt;a href=&#34;http://www.reddit.com&#34;&gt;www.reddit.com&lt;/a&gt;. I got a very useful comment by reddit member TheDrownedKraken which suggested the following approach, which doesn&amp;#39;t need a new class to be build. I thank him for this. Here is his suggestion:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;generator &amp;lt;- function(eta, a) {
    e = -1/eta

    OptimCond &amp;lt;- function(q) {
        return(sum(q)^e + e * sum(q)^(e - 1) * q - diag(a) %*% q)
    }

    JacobiOptimCond &amp;lt;- function(q) {
        return((e * sum(q)^e) * array(1, c(2, 2)) + (e * sum(q)^(e - 1)) * diag(1, 
            2) + (e - 1) * e * sum(q)^(e - 2) * q * c(1, 1) - diag(a))
    }

    return(list(OptimCond = OptimCond, JacobiOptimCond = JacobiOptimCond))

}

f.s &amp;lt;- generator(eta = 1.6, a = c(0.6, 0.8))

multiroot(f = f.s$OptimCond, start = c(1, 1), maxiter = 100, jacfunc = f.s$JacobiOptimCond)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $root
## [1] 0.8396 0.6888
## 
## $f.root
##            [,1]
## [1,] -2.220e-09
## [2,]  9.928e-09
## 
## $iter
## [1] 4
## 
## $estim.precis
## [1] 6.074e-09
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using R as a Computer Algebra System with Ryacas</title>
      <link>https://www.brodrigues.co/blog/2013-12-31-r-cas/</link>
      <pubDate>Tue, 31 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2013-12-31-r-cas/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;/head&gt;&lt;/p&gt;

&lt;p&gt;&lt;body&gt;
&lt;p&gt;R is used to perform statistical analysis and doesn&amp;#39;t focus on symbolic maths. But it is sometimes useful to let the computer derive a function for you (and have the analytic expression of said derivative), but maybe you don&amp;#39;t want to leave your comfy R shell. It is possible to turn R into a full-fledged computer algebra system. CASs are tools that perform symbolic operations, such as getting the expression of the derivative of a user-defined (and thus completely arbitrary) function. Popular CASs include the proprietary Mathematica and Maple. There exists a lot of CASs under a Free Software license, Maxima (based on the very old Macsyma), Yacas, Xcas&amp;hellip; In this post I will focus on Yacas and the &lt;code&gt;Ryacas&lt;/code&gt; libarary. There is also the possibility to use the &lt;code&gt;rSympy&lt;/code&gt; library that uses the &lt;code&gt;Sympy&lt;/code&gt; Python library, which has a lot more features than Yacas. However, depending on your operating system installation can be tricky as it also requires &lt;code&gt;rJava&lt;/code&gt; as a dependency. &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Even though &lt;code&gt;Ryacas&lt;/code&gt; is quite nice to have, there are some issues though. For example, let&amp;#39;s say you want the first derivative of a certain function f. If you use &lt;code&gt;Ryacas&lt;/code&gt; to get it, the returned object won&amp;#39;t be a function. There is a way to &amp;ldquo;extract&amp;rdquo; the text from the returned object and make a function out of it. But there are still other issues; I&amp;#39;ll discuss them later.&lt;/p&gt;

&lt;h2&gt;Installation&lt;/h2&gt;

&lt;p&gt;Installation should be rather painless. On Linux you need to install Yacas first, which should be available in the major distros&amp;#39; repositories. Then you can install &lt;code&gt;Ryacas&lt;/code&gt; from within the R shell. On Windows, you need to run these three commands (don&amp;#39;t bother installing Yacas first):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;#39;Ryacas&amp;#39;)
library(Ryacas)
yacasInstall()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find more information on the &lt;a href=&#34;https://code.google.com/p/ryacas/#INSTALLATION&#34;&gt;project&amp;#39;s page&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Example session&lt;/h2&gt;

&lt;p&gt;First, you must load &lt;code&gt;Ryacas&lt;/code&gt; and define symbols that you will use in your functions.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;require(&amp;quot;Ryacas&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: Ryacas Loading required package: XML
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;x &amp;lt;- Sym(&amp;quot;x&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then define your fonctions:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_func &amp;lt;- function(x) {
    return(x/(x^2 + 3))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can get the derivative for instance:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_deriv &amp;lt;- yacas(deriv(my_func(x), x))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Starting Yacas!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you check the class of &lt;code&gt;my_deriv&lt;/code&gt;, you&amp;#39;ll see that it is of class &lt;code&gt;yacas&lt;/code&gt;, which is not very useful. Let&amp;#39;s «convert» it to a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_deriv2 &amp;lt;- function(x) {
    eval(parse(text = my_deriv$YacasForm))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then evaluate it. A lot of different operations are possible. But there are some problems.&lt;/p&gt;

&lt;h2&gt;Issues with Ryacas&lt;/h2&gt;

&lt;p&gt;You can&amp;#39;t use elements of a vector as parameters of your function, i.e.:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;theta &amp;lt;- Sym(&amp;quot;theta&amp;quot;)
func &amp;lt;- function(x) {
    return(theta[1] * x + theta[2])
}
# Let&amp;#39;s integrate this
Func &amp;lt;- yacas(Integrate(func(x), x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;returns &lt;code&gt;(x^2*theta)/2+NA*x;&lt;/code&gt; which is not quite what we want&amp;hellip;there is a workaround however. Define your functions like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;a &amp;lt;- Sym(&amp;quot;a&amp;quot;)
b &amp;lt;- Sym(&amp;quot;b&amp;quot;)
func2 &amp;lt;- function(x) {
    return(a * x + b)
}
# Let&amp;#39;s integrate this
Func2 &amp;lt;- yacas(Integrate(func2(x), x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;we get the expected result: &lt;code&gt;(x^2*a)/2+b*x;&lt;/code&gt;. Now replace &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; by the thetas:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;Func2 &amp;lt;- gsub(&amp;quot;a&amp;quot;, &amp;quot;theta[1]&amp;quot;, Func2$YacasForm)
Func2 &amp;lt;- gsub(&amp;quot;b&amp;quot;, &amp;quot;theta[2]&amp;quot;, Func2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have what we want: &lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;Func2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;(x^2*theta[1])/2+theta[2]*x;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then copy-paste this result into a function.&lt;/p&gt;

&lt;p&gt;Another problem is if you use built-in functions that are different between R and Yacas. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_log &amp;lt;- function(x) {
    return(sin(log(2 + x)))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now try to differentiate it:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;dmy_log &amp;lt;- yacas(deriv(my_log(x), x))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you get: &lt;code&gt;Cos(Ln(x+2))/(x+2);&lt;/code&gt;. The problem with this, is that R doesn&amp;#39;t recognize &lt;code&gt;Cos&lt;/code&gt; as the cosine (which is &lt;code&gt;cos&lt;/code&gt; in R) and the same goes for &lt;code&gt;Ln&lt;/code&gt;. These are valid Yacas functions, but that is not the case in R. So you&amp;#39;ll have to use &lt;code&gt;gsub&lt;/code&gt; to replace these functions and then copy paste the end result into a function.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;While it has some flaws, &lt;code&gt;Ryacas&lt;/code&gt; can be quite useful if you need to derive or integrate complicated expressions that you then want to use in R. Using some of the tricks I showed here, you should be able to overcome some of its shortcomings. If installation of &lt;code&gt;rJava&lt;/code&gt; and thus &lt;code&gt;rSympy&lt;/code&gt; becomes easier, I&amp;#39;ll probably also do a short blog-post about it, as it has more features than &lt;code&gt;Ryacas&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Method of Simulated Moments with R</title>
      <link>https://www.brodrigues.co/blog/2013-01-29-method-of-simulated-moments-with-r/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2013-01-29-method-of-simulated-moments-with-r/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;/head&gt;&lt;/p&gt;

&lt;p&gt;&lt;body&gt;&lt;/p&gt;

&lt;p&gt;This document details section &lt;em&gt;12.5.6. Unobserved Heterogeneity Example&lt;/em&gt;. The original source code giving the results from table 12.3 are available from the authors&amp;#39; site &lt;a href=&#34;http://cameron.econ.ucdavis.edu/mmabook/mmaprograms.html&#34;&gt;here&lt;/a&gt; and written for Stata. This is an attempt to translate the code to R.&lt;/p&gt;

&lt;p&gt;Consult the original source code if you want to read the authors&amp;#39; comments. If you want the R source code without all the commentaries, grab it here. This is not guaranteed to work, nor to be correct. It could set your pet on fire and/or eat your first born. Use at your own risk. I may, or may not, expand this example. Corrections, constructive criticism are welcome.&lt;/p&gt;

&lt;p&gt;The model is the same as the one described here, so I won&amp;#39;t go into details. The moment condition used is \( E[(y_i-\theta-u_i)]=0 \), so we can replace the expectation operator by the empirical mean:&lt;/p&gt;

&lt;p&gt;\[ \dfrac{1}{N} \sum_{i=1}^N(y_i - \theta - E[u_i])=0 \]&lt;/p&gt;

&lt;p&gt;Supposing that \( E[\overline{u}] \) is unknown, we can instead use the method of simulated moments for \( \theta \) defined by:&lt;/p&gt;

&lt;p&gt;\[ \dfrac{1}{N} \sum_{i=1}^N(y_i - \theta - \dfrac{1}{S} \sum_{s=1}^S u_i^s)=0 \]&lt;/p&gt;

&lt;h3&gt;Import the data&lt;/h3&gt;

&lt;p&gt;You can consult the original source code to see how the authors simulated the data. To get the same results, and verify that I didn&amp;#39;t make mistakes I prefer importing their data directly from their website.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;data &amp;lt;- read.table(&amp;quot;http://cameron.econ.ucdavis.edu/mmabook/mma12p2mslmsm.asc&amp;quot;)
u &amp;lt;- data[, 1]
e &amp;lt;- data[, 2]
y &amp;lt;- data[, 3]
numobs &amp;lt;- length(u)
simreps &amp;lt;- 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Simulation&lt;/h3&gt;

&lt;p&gt;In the code below, we simulate the equation defined above:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;usim &amp;lt;- -log(-log(runif(simreps)))
esim &amp;lt;- rnorm(simreps, 0, 1)

isim &amp;lt;- 0
while (isim &amp;lt; simreps) {

    usim = usim - log(-log(runif(simreps)))
    esim = esim + rnorm(simreps, 0, 1)

    isim = isim + 1

}

usimbar = usim/simreps
esimbar = esim/simreps

theta = y - usimbar - esimbar

theta_msm &amp;lt;- mean(theta)
approx_sterror &amp;lt;- sd(theta)/sqrt(simreps)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These steps yield the following results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Theta MSM= 1.188 Approximate Standard Error= 0.01676
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simulated Maximum Likelihood with R</title>
      <link>https://www.brodrigues.co/blog/2013-01-16-simulated-maximum-likelihood-with-r/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2013-01-16-simulated-maximum-likelihood-with-r/</guid>
      <description>&lt;p&gt;&lt;head&gt;
&lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt;
&lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;/head&gt;&lt;/p&gt;

&lt;p&gt;&lt;body&gt;&lt;/p&gt;

&lt;p&gt;This document details section &lt;em&gt;12.4.5. Unobserved Heterogeneity 
Example&lt;/em&gt; from Cameron and Trivedi&#39;s book - MICROECONOMETRICS: Methods and 
Applications. The original source code giving the results from table 12.2 are 
available from the authors&amp;#39; site &lt;a 
href=&#34;http://cameron.econ.ucdavis.edu/mmabook/mmaprograms.html&#34;&gt;here&lt;/a&gt; and 
written for Stata. This is an attempt to translate the code to R. I&#39;d like to 
thank Reddit user &lt;a 
href=&#34;http://www.reddit.com/user/anonemouse2010&#34;&gt;anonemouse2010&lt;/a&gt; for his 
advice which helped me write the function.&lt;/p&gt;

&lt;p&gt;Consult the original source code if you want to read the authors&amp;#39; comments. If you want the R source code without all the commentaries, grab it &lt;a href=&#39;https://www.brodrigues.co/assets/code/simulated_max_lik.R&#39;&gt;here&lt;/a&gt;. This is not guaranteed to work, nor to be correct. It could set your pet on fire and/or eat your first born. Use at your own risk. I may, or may not, expand this example. Corrections, constructive criticism are welcome.&lt;/p&gt;

&lt;p&gt;The model is \( y=\theta+u+\varepsilon \) where \( \theta \) is a scalar parameter equal to 1. \( u \) is extreme value type 1 (Gumbel distribution), \( \varepsilon \leadsto \mathbb{N}(0,1) \). For more details, consult the book.&lt;/p&gt;

&lt;h3&gt;Import the data&lt;/h3&gt;

&lt;p&gt;You can consult the original source code to see how the authors simulated the data. To get the same results, and verify that I didn&amp;#39;t make mistakes I prefer importing their data directly from their website.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;data &amp;lt;- read.table(&amp;quot;http://cameron.econ.ucdavis.edu/mmabook/mma12p2mslmsm.asc&amp;quot;)
u &amp;lt;- data[, 1]
e &amp;lt;- data[, 2]
y &amp;lt;- data[, 3]
numobs &amp;lt;- length(u)
simreps &amp;lt;- 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Simulation&lt;/h3&gt;

&lt;p&gt;In the code below, the following likelihood function:

$$\log{\hat{L}_N(\theta)} = \dfrac{1}{N} \sum_{i=1}^N\log{\big( \dfrac{1}{S}\sum_{s=1}^S \dfrac{1}{\sqrt{2\pi}} \exp \{ -(-y_i-\theta-u_i^s)^2/2 \}\big)}$$

which can be found on page 397 is programmed using the function &lt;code&gt;sapply&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;denssim &amp;lt;- function(theta) {
    loglik &amp;lt;- mean(sapply(y, function(y) log(mean((1/sqrt(2 * pi)) * exp(-(y - theta + log(-log(runif(simreps))))^2/2)))))
    return(-loglik)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This likelihood is then maximized:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;system.time(res &amp;lt;- optim(0.1, denssim, method = &amp;quot;BFGS&amp;quot;, control = list(maxit = simreps)))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed 
##   21.98    0.08   22.09
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Convergence is achieved pretty rapidly, to &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## [1] 1.101
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which is close to the true value of the parameter 1 (which was used to generate the data). &lt;/p&gt;

&lt;p&gt;Let&amp;#39;s try again with another parameter value, for example \( \theta=2.5 \). We have to generate y again:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;y2 &amp;lt;- 2.5 + u + e
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and slightly modify the likelihood:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;denssim2 &amp;lt;- function(theta) {
    loglik &amp;lt;- mean(sapply(y2, function(y2) log(mean((1/sqrt(2 * pi)) * exp(-(y2 - 
        theta + log(-log(runif(simreps))))^2/2)))))
    return(-loglik)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which can then be maximized:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;system.time(res2 &amp;lt;- optim(0.1, denssim2, method = &amp;quot;BFGS&amp;quot;, control = list(maxit = simreps)))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed 
##   12.56    0.00   12.57
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The value that maximizes the likelihood is: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## [1] 2.713
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which is close to the true value of the parameter 2.5 (which was used to generate the data). &lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear Gmm with R - Example with a logistic regression</title>
      <link>https://www.brodrigues.co/blog/2013-11-07-gmm-with-rmd/</link>
      <pubDate>Thu, 07 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/blog/2013-11-07-gmm-with-rmd/</guid>
      <description>&lt;!-- MathJax scripts --&gt;

&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;/head&gt;&lt;/p&gt;

&lt;p&gt;&lt;body&gt;
&lt;p&gt;In this post, I will explain how you can use the R &lt;code&gt;gmm&lt;/code&gt; package to estimate a non-linear model, and more specifically a logit model. For my research, I have to estimate Euler equations using the Generalized Method of Moments. I contacted Pierre Chaussé, the creator of the &lt;code&gt;gmm&lt;/code&gt; library for help, since I was having some difficulties. I am very grateful for his help (without him, I&amp;#39;d still probably be trying to estimate my model!).&lt;/p&gt;&lt;/p&gt;

&lt;h3&gt;Theoretical background, motivation and data set&lt;/h3&gt;

&lt;p&gt;I will not dwell in the theory too much, because you can find everything you need &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalized_method_of_moments&#34;&gt;here&lt;/a&gt;. I think it&#39;s more interesting to try to understand why someone would use the Generalized Method of Moments instead of maximization of the log-likelihood. Well, in some cases, getting the log-likelihood can be quite complicated, as can be the case for arbitrary, non-linear models (for example if you want to estimate the parameters of a very non-linear utility function). Also, moment conditions can sometimes be readily available, so using GMM instead of MLE is trivial. And finally, GMM is... well, a very general method: every popular estimator can be obtained as a special case of the GMM estimator, which makes it quite useful.&lt;/p&gt;

&lt;p&gt;Another question that I think is important to answer is: why this post? Well, because that&#39;s exactly the kind of post I would have loved to have found 2 months ago, when I was beginning to work with the GMM. Most posts I found presented the &lt;code&gt;gmm&lt;/code&gt; package with very simple and trivial examples, which weren&#39;t very helpful. The example presented below is not very complicated per se, but much more closer to a real-world problem than most stuff that is out there. At least, I hope you will find it useful!&lt;/p&gt;

&lt;p&gt;For illustration purposes, I&amp;#39;ll use data from Marno Verbeek&amp;#39;s &lt;em&gt;A guide to modern Econometrics&lt;/em&gt;, used in the illustration on page 197. You can download the data from the book&amp;#39;s companion page &lt;a href=&#34;http://www.econ.kuleuven.ac.be/gme/&#34;&gt;here&lt;/a&gt; under the section &lt;em&gt;Data sets&lt;/em&gt; or from the &lt;code&gt;Ecdat&lt;/code&gt; package in R. I use the data set from Gretl though, as the dummy variables are numeric (instead of class &lt;code&gt;factor&lt;/code&gt;) which makes life easier when writing your own functions. You can get the data set &lt;a href=&#34;https://www.brodrigues.co/assets/files/benefits.R&#34;&gt;here&lt;/a&gt;. &lt;/p&gt;

&lt;h3&gt;Implementation in R&lt;/h3&gt;

&lt;p&gt;I don&amp;#39;t estimate the exact same model, but only use a subset of the variables available in the data set. Keep in mind that this post is just for illustration purposes.&lt;/p&gt;

&lt;p&gt;First load the &lt;code&gt;gmm&lt;/code&gt; package and load the data set:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;require(&amp;quot;gmm&amp;quot;)
data &amp;lt;- read.table(&amp;quot;path/to/data/benefits.R&amp;quot;, header = T)

attach(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then estimate a logit model with the &lt;code&gt;glm()&lt;/code&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;native &amp;lt;- glm(y ~ age + age2 + dkids + dykids + head + male + married + rr +  rr2, family = binomial(link = &amp;quot;logit&amp;quot;), na.action = na.pass)

summary(native)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = y ~ age + age2 + dkids + dykids + head + male + 
##     married + rr + rr2, family = binomial(link = &amp;quot;logit&amp;quot;), na.action = na.pass)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.889  -1.379   0.788   0.896   1.237  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&amp;gt;|z|)   
## (Intercept) -1.00534    0.56330   -1.78   0.0743 . 
## age          0.04909    0.02300    2.13   0.0328 * 
## age2        -0.00308    0.00293   -1.05   0.2924   
## dkids       -0.10922    0.08374   -1.30   0.1921   
## dykids       0.20355    0.09490    2.14   0.0320 * 
## head        -0.21534    0.07941   -2.71   0.0067 **
## male        -0.05988    0.08456   -0.71   0.4788   
## married      0.23354    0.07656    3.05   0.0023 **
## rr           3.48590    1.81789    1.92   0.0552 . 
## rr2         -5.00129    2.27591   -2.20   0.0280 * 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 6086.1  on 4876  degrees of freedom
## Residual deviance: 5983.9  on 4867  degrees of freedom
## AIC: 6004
## 
## Number of Fisher Scoring iterations: 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now comes the interesting part: how can you estimate such a non-linear model with the &lt;code&gt;gmm()&lt;/code&gt; function from the &lt;code&gt;gmm&lt;/code&gt; package? &lt;/p&gt;

&lt;p&gt;For every estimation with the Generalized Method of Moments, you will need valid moment conditions. It turns out that in the case of the logit model, this moment condition is quite simple:&lt;/p&gt;

&lt;p&gt;$$
E[X&amp;rsquo; * (Y-\Lambda(X&amp;rsquo;\theta))] = 0
$$&lt;/p&gt;

&lt;p&gt;where \( \Lambda() \) is the logistic function. Let&amp;#39;s translate this condition into code. First, we need the logistic function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;logistic &amp;lt;- function(theta, data) {
    return(1/(1 + exp(-data %*% theta)))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and let&amp;#39;s also define a new data frame, to make our life easier with the moment conditions (don&#39;t forget to add a column of ones to the matrix, hence the &lt;code&gt;1&lt;/code&gt; after &lt;code&gt;y&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;dat &amp;lt;- data.matrix(cbind(y, 1, age, age2, dkids, dykids, head, male, married, 
    rr, rr2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and now the moment condition itself:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;moments &amp;lt;- function(theta, data) {
    y &amp;lt;- as.numeric(data[, 1])
    x &amp;lt;- data.matrix(data[, 2:11])
    m &amp;lt;- x * as.vector((y - logistic(theta, x)))
    return(cbind(m))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The moment condition(s) are given by a function which returns a matrix with as many columns as moment conditions (same number of columns as parameters for just-identified models).&lt;/p&gt;

&lt;p&gt;To use the &lt;code&gt;gmm()&lt;/code&gt; function to estimate our model, we need to specify some initial values to get the maximization routine going. One neat trick is simply to use the coefficients of a linear regression; I found it to work well in a lot of situations:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;init &amp;lt;- (lm(y ~ age + age2 + dkids + dykids + head + male + married + rr + rr2))$coefficients
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And finally, we have everything to use &lt;code&gt;gmm()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;r&#34;&gt;my_gmm &amp;lt;- gmm(moments, x = dat, t0 = init, type = &amp;quot;iterative&amp;quot;, crit = 1e-25, wmatrix = &amp;quot;optimal&amp;quot;, method = &amp;quot;Nelder-Mead&amp;quot;, control = list(reltol = 1e-25, maxit = 20000))

summary(my_gmm)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 
## Call:
## gmm(g = moments, x = dat, t0 = init, type = &amp;quot;iterative&amp;quot;, wmatrix = &amp;quot;optimal&amp;quot;, 
##     crit = 1e-25, method = &amp;quot;Nelder-Mead&amp;quot;, control = list(reltol = 1e-25, 
##         maxit = 20000))
## 
## 
## Method:  iterative 
## 
## Kernel:  Quadratic Spectral
## 
## Coefficients:
##              Estimate    Std. Error  t value     Pr(&amp;gt;|t|)  
## (Intercept)  -0.9090571   0.5751429  -1.5805761   0.1139750
## age           0.0394254   0.0231964   1.6996369   0.0891992
## age2         -0.0018805   0.0029500  -0.6374640   0.5238227
## dkids        -0.0994031   0.0842057  -1.1804799   0.2378094
## dykids        0.1923245   0.0950495   2.0234150   0.0430304
## head         -0.2067669   0.0801624  -2.5793498   0.0098987
## male         -0.0617586   0.0846334  -0.7297189   0.4655620
## married       0.2358055   0.0764071   3.0861736   0.0020275
## rr            3.7895781   1.8332559   2.0671300   0.0387219
## rr2          -5.2849002   2.2976075  -2.3001753   0.0214383
## 
## J-Test: degrees of freedom is 0 
##                 J-test               P-value            
## Test E(g)=0:    0.00099718345776501  *******            
## 
## #############
## Information related to the numerical optimization
## Convergence code =  10 
## Function eval. =  17767 
## Gradian eval. =  NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Please, notice the options &lt;code&gt;crit=1e-25,method=&amp;quot;Nelder-Mead&amp;quot;,control=list(reltol=1e-25,maxit=20000)&lt;/code&gt;: these options mean that the Nelder-Mead algorithm is used, and to specify further options to the Nelder-Mead algorithm, the &lt;code&gt;control&lt;/code&gt; option is used. This is very important, as Pierre Chaussé explained to me: non-linear optimization is an art, and most of the time the default options won&amp;#39;t cut it and will give you false results. To add insult to injury, the Generalized Method of Moments itself is very capricious and you will also have to play around with different initial values to get good results. As you can see, the Convergence code equals 10, which is a code specific to the Nelder-Mead method which indicates «degeneracy of the Nelder–Mead simplex.» . I&#39;m not sure if this is a bad thing though, but other methods can give you better results. I&#39;d suggest you try always different maximization routines with different starting values to see if your estimations are robust. Here, the results are very similar to what we obtained with the built-in function &lt;code&gt;glm()&lt;/code&gt; so we can stop here.&lt;/p&gt;

&lt;p&gt;Should you notice any error whatsoever, do not hesitate to tell me.&lt;/p&gt;

&lt;p&gt;&lt;/body&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Books</title>
      <link>https://www.brodrigues.co/about/books/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/about/books/</guid>
      <description>

&lt;h2 id=&#34;building-reproducible-analytical-pipelines-with-r&#34;&gt;Building reproducible analytical pipelines with R&lt;/h2&gt;

&lt;p&gt;&lt;a href = &#34;https://leanpub.com/raps-with-r/&#34;&gt;&lt;img
src=&#34;https://d2sofvawe08yqg.cloudfront.net/raps-with-r/s_hero2x?1676902653&#34;
align=&#34;left&#34; style=&#34;display: inline; margin: 10px 50px 10px 10px; border-width:
0px;&#34; width=&#34;180&#34; /&gt;&lt;/a&gt;&lt;p&gt;Build reproducible analytical pipelines that will
output consistent, high-quality analyses using the R programming language, Git,
Github and Docker. Learn about functional and literate programming to keep your
code concise, easier to test, easier to share and easily understandable by
others.&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;
&lt;ul&gt;
  &lt;li&gt;Read it for free: &lt;a href=&#34;https://raps-with-r.dev/&#34;&gt;https://raps-with-r.dev/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Buy the DRM free Epub or PDF: &lt;a href=&#34;https://leanpub.com/raps-with-r/&#34;&gt;https://leanpub.com/raps-with-r/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Buy a physical copy on Amazon: &lt;a href=&#34;https://www.amazon.com/Building-reproducible-analytical-pipelines-R/dp/B0C87H6MGF&#34;&gt;https://www.amazon.com/Building-reproducible-analytical-pipelines-R/dp/B0C87H6MGF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;h2 style=&#34;margin-top:3cm;&#34;&gt;Modern R with the tidyverse&lt;/h2&gt;

&lt;p&gt;&lt;a href = &#34;https://leanpub.com/modern_tidyverse&#34;&gt;&lt;img
src=&#34;https://d2sofvawe08yqg.cloudfront.net/modern_tidyverse/s_hero2x?1620608950&#34;
align=&#34;left&#34; style=&#34;display: inline; margin: 10px 50px 10px 10px; border-width:
0px;&#34; width=&#34;180&#34; /&gt;&lt;/a&gt;&lt;p&gt;This book focuses on teaching you how to use R in a
modern way. Why modern? Because you will learn about the tidyverse collection of
packages, which enable you to write efficient, legible code. You will also learn
about functional programming, some statistical methods, writing your own
packages&amp;hellip; By the end of the book, you will have all the knowledge and tools on
hand to use R for your day-to-day data science tasks!&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;
&lt;ul&gt;
  &lt;li&gt;Read it for free: &lt;a href=&#34;https://modern-rstats.eu/&#34;&gt;https://modern-rstats.eu/&lt;/a&gt;&lt;/li&gt;
&lt;/li&gt;
  &lt;li&gt;Buy the DRM free Epub or PDF (very out of date, update coming Q4-2023): &lt;a href=&#34;https://leanpub.com/modern_tidyverse/&#34;&gt;https://leanpub.com/modern_tidyverse/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Buy a physical copy (coming 2023)&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talks and interviews</title>
      <link>https://www.brodrigues.co/about/talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/about/talks/</guid>
      <description>

&lt;h2 id=&#34;talks-presentation-workshops&#34;&gt;Talks, presentation, workshops&amp;hellip;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;BUILDING REPRODUCIBLE ANALYTICAL PIPELINES WITH R, DOCKER AND NIX&lt;/em&gt;: online talk for RLadies Rome, on the 29th of June 2024. &lt;a href=&#34;https://github.com/b-rodrigues/rladies_rome_repro_2024/tree/main&#34;&gt;Repository&lt;/a&gt;, &lt;a href=&#34;https://raw.githack.com/b-rodrigues/rladies_rome_repro_2024/targets-runs/rendered_slides/pres.html#/title-slide&#34;&gt;Slides&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=0bPMKYi7XRE&#34;&gt;video&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Rix: reproducible environments with Nix&lt;/em&gt;: talk I gave for the online part of the 2024 edition of useR! in Salzburg. &lt;a href=&#34;https://www.youtube.com/watch?v=tM4JrCWZpwA&#34;&gt;Video&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;RIX: ENVIRONNEMENTS DE DÉVELOPPEMENT REPRODUCTIBLES POUR DÉVELOPPEURS R&lt;/em&gt;, in French, talk and tutorial I gave for the 2024 edition of the &lt;em&gt;Rencontres R&lt;/em&gt; in Vannes, Brittany, France. &lt;a href=&#34;https://raw.githack.com/b-rodrigues/rr_2024/targets-runs/rendered_slides/presentation/pres_rr_2024.html#/title-slide&#34;&gt;Slides&lt;/a&gt; and &lt;a href=&#34;https://github.com/b-rodrigues/rr_2024/tree/main/tuto&#34;&gt;tutorial&lt;/a&gt;. No video available.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Rix: ENVIRONNEMENTS DE DÉVELOPPEMENT REPRODUCTIBLES POUR DÉVELOPPEURS R&lt;/em&gt;, in French, talk I gave on the 7th of June, 2024 for the INED (&lt;em&gt;Institute Nationale d&amp;rsquo;Études Démographiques&lt;/em&gt;, National institute for demographic studies). &lt;a href=&#34;https://github.com/b-rodrigues/russ_workshop&#34;&gt;Repository&lt;/a&gt;, &lt;a href=&#34;https://raw.githack.com/b-rodrigues/russ_workshop/targets-runs/rendered_slides/russ_pres.html#/title-slide&#34;&gt;Slides&lt;/a&gt; and &lt;a href=&#34;https://www.canal-u.tv/chaines/ined/rix-environnements-de-developpement-reproductibles-pour-developpeurs-r#videos&#34;&gt;Video&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Reproducible research with Nix and rix&lt;/em&gt;, a talk I gave at the DIPF, Leibniz Institute for Research and Information in Education, in LOS! (Leibniz Open Science!), the event series of the Leibniz Strategy Forum on Open Science. The workshop was held online, on May 16, 2024. &lt;a href=&#34;https://github.com/b-rodrigues/dipf_workshop&#34;&gt;Repository&lt;/a&gt;, &lt;a href=&#34;https://github.com/b-rodrigues/dipf_workshop&#34;&gt;Slides&lt;/a&gt; and &lt;a href=&#34;https://zpid.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=864361e7-d573-457b-95fc-b1a30073651e&#34;&gt;video of the talk&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;rix: An R package for reproducible dev environments with Nix (FOSDEM 2024)&amp;rdquo;&lt;/em&gt;, a talk I gave at FOSDEM 2024 on the 4th of February 2024 in the Nix and NixOS dev room. Video &lt;a href=&#34;https://www.youtube.com/watch?v=eWt1oXatxw8&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;Building reproducible analytical pipelines&amp;rdquo;&lt;/em&gt;, Workshop I gave for the &lt;a href=&#34;https://www.meetup.com/tunis-r-user-group/&#34;&gt;&amp;ldquo;R User Group Tunis&amp;rdquo;&lt;/a&gt; on December 9th, 2023. Video &lt;a href=&#34;https://www.youtube.com/watch?v=1jVJSPsC4Yo&#34;&gt;here&lt;/a&gt;. Slides and code &lt;a href=&#34;https://github.com/b-rodrigues/raps_rug_tunis/tree/master/raps_rug_tunis&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;Porquê usar monads (programação funcional)? Uma ilustração com o pacote {chronicler}&amp;rdquo;&lt;/em&gt; (&lt;em&gt;Why use monads (functional programming)? An illustration with the {chronicler} package&lt;/em&gt;), Talk I gave (online) at the INE (Instituto Nacional de Estatística), on the 7th of June 2023. &lt;a href=&#34;https://jocular-panda-1e5d6e.netlify.app/#/title-slide&#34;&gt;Slides in Portuguese&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;La reproductibilité avec R, ou pourquoi celle-ci est située sur un continuum&amp;rdquo;&lt;/em&gt; (&lt;em&gt;Reproducibility with R, or why it lies on a continuum&lt;/em&gt;). Talk I gave at the &lt;em&gt;Rencontres R&lt;/em&gt; 2023 in Avignon, France, on the 26th of June 2023. &lt;a href=&#34;https://649017259ea33242fbd1a328--courageous-cajeta-2542d9.netlify.app/#/title-slide&#34;&gt;Slides in French&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/kan7-thkqYk&#34;&gt;Video with English subtitles.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;Building reproducible analytical pipelines&amp;rdquo;&lt;/em&gt;, Workshop I gave for &lt;a href=&#34;https://sites.google.com/view/dariia-mykhailyshyna/main/r-workshops-for-ukraine#h.i3fjt5lw8dyo&#34;&gt;&amp;ldquo;Workshops for Ukraine&amp;rdquo;&lt;/a&gt; on June 29th, 2023. You can pull the Docker image with the slides and code &lt;a href=&#34;https://hub.docker.com/repository/docker/brodriguesco/raps_ukraine/general&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;&amp;ldquo;Building reproducible analytical pipelines&amp;rdquo;&lt;/em&gt;, Talk I gave for &lt;em&gt;ReproducibiliTea UCL&lt;/em&gt; on the 19th of July, 2023. &lt;a href=&#34;https://64a7f00fce57ea61a8302dd5--stellar-bublanina-8574b2.netlify.app/#/title-slide&#34;&gt;Slides&lt;/a&gt; and &lt;a href=&#34;https://youtu.be/zs6LtT0PavM&#34;&gt;Video&lt;/a&gt;. You can pull the Docker image with the slides and code &lt;a href=&#34;https://hub.docker.com/repository/docker/brodriguesco/raps_reprotea/general&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;interviews-podcasts&#34;&gt;Interviews, podcasts&amp;hellip;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;French &lt;a href=&#34;https://youtu.be/vI6KbMJAMQk&#34;&gt;Data Workers Podcast #1 Large Scale Testing : Contenir la covid-19 avec des dépistages ciblés&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;French &lt;a href=&#34;https://archive.is/uNxNw&#34;&gt;Bruno Rodrigues défend une approche basée sur la reproductibilité de la data science au Luxembourg&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;English &lt;a href=&#34;https://www.youtube.com/watch?v=aXfjhf2cDo0&#34;&gt;Leanpub Frontmatter Podcast #263&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Who am I?</title>
      <link>https://www.brodrigues.co/about/me/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.brodrigues.co/about/me/</guid>
      <description>&lt;p&gt;My name is Bruno Rodrigues and hold a PhD in Economics from the
&lt;a href=&#34;http://www.unistra.fr&#34;&gt;University of Strasbourg&lt;/a&gt;.&lt;/p&gt;

&lt;div style=&#34;text-align:center;&#34;&gt;
    &lt;img src=&#34;https://www.brodrigues.co/img/profile.jpg&#34;/&gt;
&lt;/div&gt;

&lt;p&gt;I&amp;rsquo;m currently employed as a statistician for the Ministry of Higher Education and Research in
Luxembourg. Before that I was senior data scientist and then manager in the data science team
at PwC Luxembourg, and before that I was a research assistant at &lt;a href=&#34;http://www.statistiques.public.lu/en/actors/statec/organisation/red/&#34;&gt;STATEC Research&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My hobbies are boxing, lifting weights, cycling, cooking and reading or listening to audiobooks,
which is more compatible with the life of a young father.
I started this blog to share my enthusiasm for statistics. My blog posts are reshared on
&lt;a href=&#34;https://www.r-bloggers.com/&#34;&gt;R-bloggers&lt;/a&gt; and &lt;a href=&#34;https://rweekly.org/&#34;&gt;RWeekly&lt;/a&gt;.
I also enjoy learning about the R programming language and sharing my knowledge.
That&amp;rsquo;s why I made this blog and write &lt;a href=&#34;../books&#34;&gt;ebooks&lt;/a&gt;.
I also have a &lt;a href=&#34;https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ&#34;&gt;youtube channel&lt;/a&gt;,
where I show some tips and tricks with R, or rant about stuff.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>